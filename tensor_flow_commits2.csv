Commit Message,Name,Email,Updated at,Files Changed,Contributor,All Checks Passed
"[XLA:GPU] Clang-tidy cleanup for xla/service/algebraic_simplifier.cc

PiperOrigin-RevId: 639390879",Kuy Mainwaring,kuym@google.com,2024-06-01 21:15:17,third_party/xla/xla/service/algebraic_simplifier.cc,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/command_buffer_scheduling.cc

PiperOrigin-RevId: 639390244",Kuy Mainwaring,kuym@google.com,2024-06-01 21:10:10,third_party/xla/xla/service/gpu/command_buffer_scheduling.cc,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/fusions/transpose.cc

PiperOrigin-RevId: 639390119",Kuy Mainwaring,kuym@google.com,2024-06-01 21:09:01,third_party/xla/xla/service/gpu/fusions/transpose.cc,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/fusions/mlir/mlir_fusion_emitter.h

PiperOrigin-RevId: 639352731",Kuy Mainwaring,kuym@google.com,2024-06-01 16:31:29,third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.h,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h

PiperOrigin-RevId: 639352712",Kuy Mainwaring,kuym@google.com,2024-06-01 16:31:24,third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/runtime/nccl_all_gather_thunk.cc

PiperOrigin-RevId: 639351617",Kuy Mainwaring,kuym@google.com,2024-06-01 16:24:41,third_party/xla/xla/service/gpu/runtime/nccl_all_gather_thunk.cc,kuym,False
"Automated Code Change

PiperOrigin-RevId: 639314567",A. Unique TensorFlower,gardener@tensorflow.org,2024-06-01 11:30:45,"tensorflow/lite/core/async/testing/BUILD, tensorflow/lite/core/async/testing/test_backend.cc, tensorflow/lite/core/async/testing/test_backend.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 639293926",A. Unique TensorFlower,gardener@tensorflow.org,2024-06-01 09:13:17,"tensorflow/lite/delegates/gpu/common/testing/BUILD, tensorflow/lite/delegates/gpu/common/testing/interpreter_utils.cc",tensorflower-gardener,False
"Update GraphDef version to 1880.

PiperOrigin-RevId: 639292068",A. Unique TensorFlower,gardener@tensorflow.org,2024-06-01 09:02:17,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-06-01

PiperOrigin-RevId: 639292023",A. Unique TensorFlower,gardener@tensorflow.org,2024-06-01 09:02:08,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Adds a validation check to BasicStringArray to ensure that the underlying buffers an array, when they get ready, are consistent with the sharding specified at the time of its (array's) construction.

PiperOrigin-RevId: 639219351",A. Unique TensorFlower,gardener@tensorflow.org,2024-06-01 02:03:10,"third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.cc, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.h, third_party/xla/xla/python/pjrt_ifrt/basic_string_array_test.cc",tensorflower-gardener,False
"[xla:cpu] Add TraceMe annotations to XLA:CPU thunks

PiperOrigin-RevId: 639213971",Eugene Zhulenev,ezhulenev@google.com,2024-06-01 01:30:50,"third_party/xla/xla/service/cpu/runtime/BUILD, third_party/xla/xla/service/cpu/runtime/call_thunk.cc, third_party/xla/xla/service/cpu/runtime/call_thunk.h, third_party/xla/xla/service/cpu/runtime/copy_thunk.cc, third_party/xla/xla/service/cpu/runtime/copy_thunk.h, third_party/xla/xla/service/cpu/runtime/copy_thunk_test.cc, third_party/xla/xla/service/cpu/runtime/kernel_thunk.cc, third_party/xla/xla/service/cpu/runtime/kernel_thunk.h, third_party/xla/xla/service/cpu/runtime/kernel_thunk_test.cc, third_party/xla/xla/service/cpu/runtime/thunk.cc, third_party/xla/xla/service/cpu/runtime/thunk.h, third_party/xla/xla/service/cpu/runtime/while_thunk.cc, third_party/xla/xla/service/cpu/runtime/while_thunk.h, third_party/xla/xla/service/cpu/thunk_emitter.cc",ezhulenev,False
"[xla:cpu] Add support for multi-output elemental loops

+ enabled exhaustive tests for thunks runtime

PiperOrigin-RevId: 639194922",Eugene Zhulenev,ezhulenev@google.com,2024-05-31 23:59:02,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/runtime/copy_thunk.cc, third_party/xla/xla/service/cpu/runtime/kernel_thunk.cc, third_party/xla/xla/service/cpu/thunk_emitter.cc, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/exhaustive/BUILD",ezhulenev,False
"Uses Stacker api to compute table stacking logic for SC

PiperOrigin-RevId: 639186593",Ziyin Huang,ziyinh@google.com,2024-05-31 23:25:01,"tensorflow/core/tpu/kernels/sparse_core_layout.cc, tensorflow/core/tpu/kernels/sparse_core_layout.h, tensorflow/python/tpu/BUILD, tensorflow/python/tpu/_pywrap_sparse_core_layout.pyi, tensorflow/python/tpu/pywrap_sparse_core_layout.cc, tensorflow/python/tpu/tpu_embedding_v3.py, tensorflow/python/tpu/tpu_embedding_v3_additional_test.py, tensorflow/tools/api/golden/v1/tensorflow.tpu.experimental.embedding.-sparse-core-embedding-config.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.tpu.experimental.embedding.-t-p-u-embedding-v2.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.tpu.experimental.embedding.-sparse-core-embedding-config.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.tpu.experimental.embedding.-t-p-u-embedding-v2.pbtxt",pineapplejuice233,False
"PR #13244: [ROCm]  Get rid of .bazelrc file in run_xla script

Imported from GitHub PR https://github.com/openxla/xla/pull/13244

Copybara import of the project:

--
e05087b657e6014431826c62ffc417137e7a66b0 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm]  Get rid of .bazelrc file in run_xla script

Merging this change closes #13244

PiperOrigin-RevId: 639177139",Harsha H S,hsharsha@users.noreply.github.com,2024-05-31 22:51:14,third_party/xla/build_tools/rocm/run_xla.sh,hsharsha,False
"Switch libtensorflow (Windows) to use Docker + Clang.

PiperOrigin-RevId: 639158619",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 21:45:08,"tensorflow/tools/ci_build/rel/windows/cpu_libtensorflow.bat, tensorflow/tools/ci_build/windows/cpu/bazel/run_libtensorflow.bat, tensorflow/tools/ci_build/windows/libtensorflow_cpu.sh",tensorflower-gardener,False
"Add more logging to remote tensor handle serialization

PiperOrigin-RevId: 639147348",Anshuman Goswami,anshumang@google.com,2024-05-31 21:07:39,"tensorflow/core/common_runtime/eager/tensor_handle.cc, tensorflow/core/distributed_runtime/eager/remote_mgr.cc",anshumang,False
"[XLA:TPU] Fix a bug in GetGatherScatterBatchParallelDims.

The bug is that the function does not handle the case where the indices are a copy of a concatenate. Thus this we add code to search up a tree of copies to see if the first non-copy op is a concatenate, in which case we can use that to test if it is a concatenate of an iota, to then find parallel dims.

PiperOrigin-RevId: 639139490",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 20:42:22,third_party/xla/xla/hlo/utils/hlo_sharding_util.cc,tensorflower-gardener,False
"Fix a bug that tries to access RUNTIME_FUNCTION_REFS after deletion

PiperOrigin-RevId: 639138453",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 20:38:30,tensorflow/python/eager/polymorphic_function/atomic_function.py,tensorflower-gardener,False
"Support cast in Ifrt restore operation

PiperOrigin-RevId: 639134024",Deqiang Chen,deqiangc@google.com,2024-05-31 20:24:03,"tensorflow/compiler/mlir/tensorflow/ir/host_runtime/tfrt_ops.td, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_mlrt_ops.td, tensorflow/compiler/mlir/tfrt/tests/ifrt/lower_to_ifrt_restore_variable.mlir, tensorflow/compiler/mlir/tfrt/tests/mlrt/tf_to_mlrt.mlir, tensorflow/compiler/mlir/tfrt/transforms/ifrt/lower_to_ifrt_restore_variable.cc, tensorflow/compiler/mlir/tfrt/transforms/mlrt/tf_to_mlrt.cc, tensorflow/core/tfrt/mlrt/kernel/BUILD, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc",deqiangc,False
"Allow optional KV store overwrites.
Cleanups: use std::string_view, migrate away from TF_ASSERT/EXPECT.

PiperOrigin-RevId: 639131697",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 20:15:15,"tensorflow/core/distributed_runtime/coordination/coordination_service_barrier_proxy_test.cc, third_party/xla/third_party/tsl/tsl/protobuf/coordination_service.proto, third_party/xla/xla/pjrt/distributed/BUILD, third_party/xla/xla/pjrt/distributed/client.cc, third_party/xla/xla/pjrt/distributed/client.h, third_party/xla/xla/pjrt/distributed/client_server_test.cc, third_party/xla/xla/python/xla.cc, third_party/xla/xla/python/xla_extension/__init__.pyi, third_party/xla/xla/tsl/distributed_runtime/coordination/BUILD, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.h, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.h, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_rpc_handler.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_test.cc",tensorflower-gardener,False
"[xla:cpu] Fix ir_emitter2 test crash

PiperOrigin-RevId: 639123120",Eugene Zhulenev,ezhulenev@google.com,2024-05-31 19:49:04,third_party/xla/xla/service/cpu/ir_emitter2.cc,ezhulenev,False
"#tf-data-sevice Downgrade null model warning to vlog.

PiperOrigin-RevId: 639092597",Matt Callanan,mpcallanan@google.com,2024-05-31 18:13:08,tensorflow/core/kernels/data/experimental/data_service_dataset_op.cc,mpcallanan,False
"[TOCO Removal] Copy converter's Python API wrapper to a more appropriate dir.

Previously, the converter's Python API was intertwined with TOCO. This CL
copies it to a new location and does some light renaming in preparating of
further disentangling of TOCO artifacts from the TFL converter. Method
signatures are left untouched.

We copy rather than move to decouple migrating away from TOCO and deletion of
TOCO artifacts. TOCO APIs will be removed/deleted in subsequent CLs.

PiperOrigin-RevId: 639090132",Arian Arfaian,aarfaian@google.com,2024-05-31 18:06:15,"tensorflow/compiler/mlir/lite/metrics/BUILD, tensorflow/compiler/mlir/lite/python/BUILD, tensorflow/compiler/mlir/lite/python/_pywrap_converter_api.pyi, tensorflow/compiler/mlir/lite/python/converter_python_api.cc, tensorflow/compiler/mlir/lite/python/converter_python_api.h, tensorflow/compiler/mlir/lite/python/converter_python_api_wrapper.cc, tensorflow/compiler/mlir/lite/python/wrap_converter.py, tensorflow/compiler/mlir/lite/sparsity/BUILD, tensorflow/lite/python/BUILD, tensorflow/lite/python/analyzer.py, tensorflow/lite/python/convert.py, tensorflow/lite/python/convert_test.py, tensorflow/lite/python/metrics/BUILD, tensorflow/lite/python/metrics/wrapper/metrics_wrapper.py, tensorflow/lite/toco/BUILD, tensorflow/lite/toco/logging/BUILD, tensorflow/lite/toco/tensorflow_graph_matching/BUILD, tensorflow/lite/toco/tflite/BUILD, tensorflow/python/BUILD, tensorflow/tools/def_file_filter/symbols_pybind.txt, third_party/xla/third_party/tsl/tools/def_file_filter/symbols_pybind.txt",arfaian,False
"[xla:cpu] NFC: Remove deprecated linalg-based dot instruction codegen

PiperOrigin-RevId: 639075801",Eugene Zhulenev,ezhulenev@google.com,2024-05-31 17:22:24,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/dot_op_emitter.cc, third_party/xla/xla/service/cpu/dot_op_emitter.h, third_party/xla/xla/service/cpu/mlir_emitter.cc, third_party/xla/xla/service/cpu/mlir_emitter.h",ezhulenev,False
"Remove unnecessary dependency accidentally included in a refactoring.

PiperOrigin-RevId: 639072371",Kyle Lucke,klucke@google.com,2024-05-31 17:10:40,third_party/xla/xla/pjrt/gpu/BUILD,klucke,False
"Add max_enqueued_batches option for model servers.

PiperOrigin-RevId: 639069686",Deqiang Chen,deqiangc@google.com,2024-05-31 17:02:53,"tensorflow/compiler/mlir/tfrt/tests/reconfig_batch_op.mlir, tensorflow/compiler/mlir/tfrt/transforms/passes.cc, tensorflow/compiler/mlir/tfrt/transforms/passes.h, tensorflow/compiler/mlir/tfrt/transforms/reconfig_batch_op.cc, tensorflow/compiler/mlir/tfrt/transforms/tfrt_pipeline_options.h, tensorflow/compiler/mlir/tfrt/translate/import_model.cc, tensorflow/compiler/mlir/tfrt/translate/tfrt_compile_options.cc, tensorflow/compiler/mlir/tfrt/translate/tfrt_compile_options.h",deqiangc,False
"[XLA:GPU] Use xla_gpu.apply_indexing in ir_emitter_triton.

`xla_gpu.apply_indexing` is the new preferred way to emit IndexingMaps.

PiperOrigin-RevId: 639066133",Oleg Shyshkov,shyshkov@google.com,2024-05-31 16:51:11,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_mem_utils_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",olegshyshkov,False
"BUILD file cleanup of old packaging rules.

PiperOrigin-RevId: 639053590",Kyle Lucke,klucke@google.com,2024-05-31 16:06:52,"tensorflow/BUILD, third_party/xla/xla/stream_executor/BUILD",klucke,False
"CSE after inlining.

Without this, we can end up with functions that
aren't inlined even though they're only called
once (after CSE).

PiperOrigin-RevId: 639052830",Johannes Reifferscheid,jreiffers@google.com,2024-05-31 16:03:57,third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc,jreiffers,False
"[XLA:GPU] Add ToString() methods to Tiled HLO instructions and computations.

PiperOrigin-RevId: 639051471",Oleg Shyshkov,shyshkov@google.com,2024-05-31 15:59:39,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tiled_hlo_instruction.cc, third_party/xla/xla/service/gpu/model/symbolic_tiled_hlo_instruction.h, third_party/xla/xla/service/gpu/model/tiled_hlo_computation.cc, third_party/xla/xla/service/gpu/model/tiled_hlo_computation.h, third_party/xla/xla/service/gpu/model/tiled_hlo_instruction.cc",olegshyshkov,False
"Remove compatibility constraint.

PiperOrigin-RevId: 639049798",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 15:54:12,third_party/xla/xla/service/BUILD,tensorflower-gardener,False
"[XLA:GPU] Use HloFusionAdaptor::GetParameters() instead of FindFusionArguments.

We now have two functions that produce the same results. GetParameters() is more convenient.

PiperOrigin-RevId: 639045016",Oleg Shyshkov,shyshkov@google.com,2024-05-31 15:36:11,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/hlo_traversal.h, third_party/xla/xla/service/gpu/hlo_traversal_test.cc",olegshyshkov,False
"Use DOxygen comments in lite/core/c/operator.h.

PiperOrigin-RevId: 639041799",Fergus Henderson,fergus@google.com,2024-05-31 15:24:05,tensorflow/lite/core/c/operator.h,fergushenderson,False
"Avoid rewrite ReadVaraibleOps that are assigned in the same module

PiperOrigin-RevId: 639030592",Deqiang Chen,deqiangc@google.com,2024-05-31 14:37:13,"tensorflow/compiler/mlir/tfrt/tests/ifrt/sink_variable_as_named_array.mlir, tensorflow/compiler/mlir/tfrt/transforms/ifrt/sink_variable_as_named_array.cc",deqiangc,False
"Roll forward without ConvertGenerator

To avoid BUILD problem in some OSS configurations.

Reverts 9ca5a013eca72dfc8f117a7d27a9d53102978a83

PiperOrigin-RevId: 639025529",Tamás Danyluk,tdanyluk@google.com,2024-05-31 14:15:43,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/triton_support.cc, third_party/xla/xla/service/gpu/triton_support.h, third_party/xla/xla/service/gpu/triton_support_test.cc, third_party/xla/xla/service/gpu/triton_tiling_propagation.cc",tdanyluk,False
"[XLA:GPU][NFC] Add filecheck test for all-reduce-splitter pass.

PiperOrigin-RevId: 639020890",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-31 13:54:42,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/all_reduce_splitter_test.cc",golechwierowicz,False
"[MHLO] Add support for batching dims when legalizing `mhlo.gather` to linalg

PiperOrigin-RevId: 639017063",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 13:35:30,"third_party/xla/xla/mlir_hlo/mhlo/transforms/legalize_to_linalg/legalize_to_linalg.cc, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-linalg.mlir",tensorflower-gardener,False
"[XLA:GPU][NFC] Split logical RS if it is AR + DS to AR + DS + AR.

PiperOrigin-RevId: 638999678",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-31 12:12:34,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/all_reduce_splitter.cc, third_party/xla/xla/service/all_reduce_splitter.h, third_party/xla/xla/service/all_reduce_splitter_test.cc",golechwierowicz,False
"Remove unused header

PiperOrigin-RevId: 638985816",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 11:04:35,tensorflow/lite/kernels/embedding_lookup_test.cc,tensorflower-gardener,False
"Fix crash in unoptimized builds.

PiperOrigin-RevId: 638983687",Johannes Reifferscheid,jreiffers@google.com,2024-05-31 10:56:04,third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc,jreiffers,False
"Add runtime test for radix sort correctness

PiperOrigin-RevId: 638982005",Sergey Kozub,sergeykozub@google.com,2024-05-31 10:46:13,"third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gpu_cub_sort_test.cc",sergeykozub,False
"Reverts adc512abf8c35c7c6874821c5fd6f6b26e371e1e

PiperOrigin-RevId: 638979119",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 10:32:49,"tensorflow/compiler/mlir/lite/ir/tfl_ops.td, tensorflow/compiler/mlir/lite/tests/ops.mlir, tensorflow/lite/kernels/embedding_lookup.cc, tensorflow/lite/kernels/embedding_lookup_test.cc",tensorflower-gardener,False
"Update GraphDef version to 1879.

PiperOrigin-RevId: 638958096",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 09:03:55,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-31

PiperOrigin-RevId: 638957695",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 09:02:30,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Enable batched radix sort using CUB library

CUB library provides `DeviceSegmentedRadixSort::SortKeys` and `DeviceSegmentedRadixSort::SortPairs` functions that allow sorting multiple segments at the same time.

`GpuSortRewriter` pass now supports any sorts where the sort dimension is minor.
If the `batch_size` passed to the custom kernel is greater than one, scratch size is increased to hold the segment offsets at the end of the buffer.

PiperOrigin-RevId: 638948437",Sergey Kozub,sergeykozub@google.com,2024-05-31 08:25:37,"third_party/xla/xla/service/gpu/cub_sort_kernel.cu.cc, third_party/xla/xla/service/gpu/cub_sort_kernel.h, third_party/xla/xla/service/gpu/gpu_sort_rewriter.cc, third_party/xla/xla/service/gpu/gpu_sort_rewriter_test.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/cub_sort_thunk.cc, third_party/xla/xla/service/gpu/runtime/cub_sort_thunk.h",sergeykozub,False
"Automated Code Change

PiperOrigin-RevId: 638917814",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 06:22:21,tensorflow/lite/kernels/internal/BUILD,tensorflower-gardener,False
"Remove obsolete TODO item.

PiperOrigin-RevId: 638904633",Dan Suh,dansuh@google.com,2024-05-31 05:21:42,tensorflow/compiler/mlir/quantization/tensorflow/debugging/mlir_dump.cc,dansuh17,False
"Remove obsolete TODO item.

PiperOrigin-RevId: 638902688",Dan Suh,dansuh@google.com,2024-05-31 05:12:30,tensorflow/compiler/mlir/quantization/tensorflow/python/py_function_lib.py,dansuh17,False
"Automated Code Change

PiperOrigin-RevId: 638898736",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 04:54:23,"tensorflow/core/grappler/BUILD, tensorflow/core/grappler/devices.cc",tensorflower-gardener,False
"Support DenseBoolArrayAttr in MLRT

PiperOrigin-RevId: 638892428",Deqiang Chen,deqiangc@google.com,2024-05-31 04:25:16,"tensorflow/compiler/mlir/tfrt/translate/mlrt/mlir_to_bytecode.cc, tensorflow/compiler/mlir/tfrt/translate/mlrt/mlir_to_bytecode_test.cc, tensorflow/compiler/mlir/tfrt/translate/mlrt/testdata/basic_attributes.mlir",deqiangc,False
"Add DynamicApproxTopKOp to StableHLO

This CL adds a DynamicApproxTopKOp to StableHLO. This op is a dynamic version of the ApproxTopKOp. The op is represented via a custom call to `stablehlo.dynamic_approx_top_k`. The custom call has the regular operand of ApproxTopKOp plus an additional `k` operand that determines the shape of the output.

The semantics of DynamicApproxTopKOp are inherited from semantics of ApproxTopKOp.

PiperOrigin-RevId: 638876781",George Necula,necula@google.com,2024-05-31 03:10:59,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/python/xla_client.py",gnecula,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638874762",Kyle Lucke,klucke@google.com,2024-05-31 03:03:43,"third_party/xla/xla/BUILD, third_party/xla/xla/array.h, third_party/xla/xla/layout_util.cc, third_party/xla/xla/layout_util.h, third_party/xla/xla/literal.cc, third_party/xla/xla/literal.h, third_party/xla/xla/literal_comparison.cc, third_party/xla/xla/literal_comparison.h, third_party/xla/xla/literal_test.cc, third_party/xla/xla/protobuf_util.cc, third_party/xla/xla/protobuf_util.h, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/service/layout_normalization.cc, third_party/xla/xla/service_interface.h, third_party/xla/xla/shape_layout.cc, third_party/xla/xla/shape_layout.h, third_party/xla/xla/shape_tree.h, third_party/xla/xla/shape_util.cc, third_party/xla/xla/shape_util.h, third_party/xla/xla/shape_util_test.cc, third_party/xla/xla/sharding_op_util.cc, third_party/xla/xla/sharding_op_util.h, third_party/xla/xla/status_macros.cc, third_party/xla/xla/status_macros.h, third_party/xla/xla/status_macros_test.cc, third_party/xla/xla/statusor.h, third_party/xla/xla/test_helpers.h",klucke,False
"[xla:cpu] Add support for a copy with layout change (traspose) to CopyThunk

PiperOrigin-RevId: 638858788",Eugene Zhulenev,ezhulenev@google.com,2024-05-31 01:47:29,"third_party/xla/xla/service/cpu/runtime/BUILD, third_party/xla/xla/service/cpu/runtime/copy_thunk.cc, third_party/xla/xla/service/cpu/runtime/copy_thunk.h, third_party/xla/xla/service/cpu/runtime/copy_thunk_test.cc, third_party/xla/xla/service/cpu/runtime/kernel_thunk.cc, third_party/xla/xla/service/cpu/thunk_emitter.cc",ezhulenev,False
"#tf-data-service Add a worker client test for alternative data transfer mechanisms.

PiperOrigin-RevId: 638846795",Matt Callanan,mpcallanan@google.com,2024-05-31 00:57:24,"tensorflow/core/data/service/BUILD, tensorflow/core/data/service/test_cluster.cc, tensorflow/core/data/service/test_cluster.h, tensorflow/core/data/service/worker_client_test.cc",mpcallanan,False
"[xla:cpu] Add support for emitting reduction kernels

PiperOrigin-RevId: 638844214",Eugene Zhulenev,ezhulenev@google.com,2024-05-31 00:45:52,"third_party/xla/xla/service/cpu/ir_emitter.h, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/ir_emitter2.h, third_party/xla/xla/service/cpu/thunk_emitter.cc, third_party/xla/xla/service/cpu/thunk_emitter.h",ezhulenev,False
"Right now, the shape inference code only looks at `_Arg`s to match user-given `arg_shapes`, as `_Arg`s are what placeholder ops are represented during runtime. To run shape inference ahead-of-time (with static graph and input shapes), we need the shape inference code to examine `Placeholder` ops as well; thus this cl

PiperOrigin-RevId: 638837715",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-31 00:18:25,"tensorflow/compiler/jit/BUILD, tensorflow/compiler/jit/shape_inference.cc, tensorflow/compiler/jit/shape_inference.h, tensorflow/compiler/jit/shape_inference_test.cc",tensorflower-gardener,False
"[xla:gpu] Reuse CanTritonHandleGEMM in GpuAlgebraicSimplifier

We should not duplicate the code to determine if triton can handle a gemm

PiperOrigin-RevId: 638834952",Anlun Xu,anlunx@google.com,2024-05-31 00:07:44,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier.cc, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier_test.cc, third_party/xla/xla/service/gpu/triton_support.cc, third_party/xla/xla/service/gpu/triton_support.h",anlunx,False
"Automated g4 rollback of changelist 638510790.

Reverts 8e437155b9927d505afe1c708616f0763aef3d9b

PiperOrigin-RevId: 638826803",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 23:39:32,tensorflow/core/tfrt/graph_executor/graph_execution_options.cc,tensorflower-gardener,False
"Update docstring to satisfy bulidifier

PiperOrigin-RevId: 638820536",David Dunleavy,ddunleavy@google.com,2024-05-30 23:17:59,third_party/xla/xla/service/gpu/build_defs.bzl,ddunl,False
"[xla:pjrt:cpu] Correctly create PjRt memory for constant allocations

PiperOrigin-RevId: 638818872",Eugene Zhulenev,ezhulenev@google.com,2024-05-30 23:12:22,"third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/cpu_executable.h",ezhulenev,False
"Pattern-match FP8 calls with input converts without scales.

This change pattern matches the following into an FP8 cublasLT custom call

  dot(x.astype(jnp.float16), y.astype(jnp.float16))

We previously matched a version of this that also included scaling into a custom call.

  dot(x.astype(jnp.float16) * x_scale, y.astype(jnp.float16) * y_scale)

Now the scales are optional even when the inputs are cast to FP16. There is no particular reason to cast inputs to FP16 if there are no input scales, but at least one internal model does this.

PiperOrigin-RevId: 638814065",Reed Wanderman-Milne,reedwm@google.com,2024-05-30 22:58:04,"third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc",reedwm,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638796198",Kyle Lucke,klucke@google.com,2024-05-30 22:03:34,"third_party/xla/xla/client/lib/BUILD, third_party/xla/xla/client/lib/matrix.cc, third_party/xla/xla/client/lib/matrix_test.cc, third_party/xla/xla/client/lib/tridiagonal.cc, third_party/xla/xla/client/lib/tridiagonal_test.cc, third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_test.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.h, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers_test.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.h, third_party/xla/xla/pjrt/distributed/BUILD, third_party/xla/xla/pjrt/distributed/topology_util.cc, third_party/xla/xla/pjrt/distributed/topology_util.h, third_party/xla/xla/pjrt/distributed/util.h, third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/kernels/custom_kernel_fusion.cc, third_party/xla/xla/service/gpu/kernels/custom_kernel_fusion.h, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_fusion.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/gpu_hlo_cost_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tiled_hlo_instruction.cc",klucke,False
"Add profiling_info_pb2 to lite.py

PiperOrigin-RevId: 638786147",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 21:33:50,tensorflow/lite/python/lite.py,tensorflower-gardener,False
"First cl to implement a pass to unstack loop operands.

This pass implements unstacking for loop operands. Generally speaking, unstacking is the act of breaking a rank n tensor into n smaller n-1 rank tensors without changing the semantics of the program. There are different patterns that can benefit from unstacking. This pass aims to implement such patterns. The patterns implemented are not exhaustive by any means. There are more patterns to be added.
The pass is not added to the compiler yet.

PiperOrigin-RevId: 638785310",Farzin Houshmand,farzinh@google.com,2024-05-30 21:31:45,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_unstacker.cc, third_party/xla/xla/service/hlo_unstacker.h, third_party/xla/xla/service/hlo_unstacker_test.cc, third_party/xla/xla/service/while_loop_unroller.cc",farzinhoushmand,False
"Allow sharing the same IFRT client across multiple IFRT Proxy sessions

PiperOrigin-RevId: 638779549",Junwhan Ahn,junwhan@google.com,2024-05-30 21:14:21,"third_party/xla/xla/python/ifrt_proxy/server/grpc_server.cc, third_party/xla/xla/python/ifrt_proxy/server/grpc_server.h, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.h",junwhanahn,False
"Add note on TensorFlow NumPy 2.0 upgrade in the next release

PiperOrigin-RevId: 638776511",Kanglan Tang,kanglan@google.com,2024-05-30 21:05:47,RELEASE.md,kanglant,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638772258",Kyle Lucke,klucke@google.com,2024-05-30 20:54:29,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/fusions/fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/fusion_emitter.h, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/input_slices.cc, third_party/xla/xla/service/gpu/fusions/input_slices.h, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.h, third_party/xla/xla/service/gpu/fusions/loop.cc, third_party/xla/xla/service/gpu/fusions/loop.h, third_party/xla/xla/service/gpu/fusions/loop_mlir.h, third_party/xla/xla/service/gpu/fusions/reduction.cc, third_party/xla/xla/service/gpu/fusions/scatter.cc, third_party/xla/xla/service/gpu/fusions/scatter.h, third_party/xla/xla/service/gpu/fusions/scatter_mlir.h, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.h",klucke,False
"Inline one-off use small functions as lambdas

PiperOrigin-RevId: 638770068",Anshuman Goswami,anshumang@google.com,2024-05-30 20:47:19,tensorflow/core/common_runtime/eager/execute.cc,anshumang,False
"Reverts 73e2bb2a020aec9124c7f1c99a1eaaac6ab96a22

PiperOrigin-RevId: 638769822",Eugene Zhulenev,ezhulenev@google.com,2024-05-30 20:46:31,"third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream_executor_interface.h",ezhulenev,False
"Include stream_executor.h in a few files that were missing its inclusion.

PiperOrigin-RevId: 638758402",Kyle Lucke,klucke@google.com,2024-05-30 20:11:31,"tensorflow/compiler/tf2xla/xla_helpers.cc, tensorflow/core/tpu/kernels/tpu_configuration_ops.cc, third_party/xla/xla/service/gpu/make_batch_pointers.cc, third_party/xla/xla/stream_executor/gpu/gpu_blas_lt.cc, third_party/xla/xla/stream_executor/lazy_op_runner.h",klucke,False
"Reverts 8f8ce5cbf917285f77e1c08e75ffa011324565ef

PiperOrigin-RevId: 638740644",Tamás Danyluk,tdanyluk@google.com,2024-05-30 19:14:35,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/triton_support.cc, third_party/xla/xla/service/gpu/triton_support.h, third_party/xla/xla/service/gpu/triton_support_test.cc, third_party/xla/xla/service/gpu/triton_tiling_propagation.cc",tdanyluk,False
"Tighten the error tolerances after fixing an internal bug related to flush-subnormal-to-zero semantics for Sqrt, Rsqrt, and Cbrt on TPU. After this fix, the behavior matches that on GPUs.

PiperOrigin-RevId: 638730152",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 18:45:22,"third_party/xla/xla/tests/exhaustive/exhaustive_op_test_utils.h, third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_f32_or_smaller.cc",tensorflower-gardener,False
"Remove bench_microkernels build variant (we can just use test_microkernels), and remove -UNDEBUG from the bazel BUILD.

PiperOrigin-RevId: 638727422",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 18:38:03,tensorflow/lite/delegates/xnnpack/BUILD,tensorflower-gardener,False
"Support per-axis embedding lookup reference kernel

PiperOrigin-RevId: 638725225",Pauline Sho,psho@google.com,2024-05-30 18:32:37,"tensorflow/compiler/mlir/lite/ir/tfl_ops.td, tensorflow/compiler/mlir/lite/tests/ops.mlir, tensorflow/lite/kernels/embedding_lookup.cc, tensorflow/lite/kernels/embedding_lookup_test.cc",paulinesho,False
"Fix time_span filter in visibility filtering

PiperOrigin-RevId: 638724310",Yin Zhang,yinzz@google.com,2024-05-30 18:30:53,"tensorflow/core/profiler/convert/trace_viewer/trace_events.cc, tensorflow/core/profiler/convert/trace_viewer/trace_events.h, tensorflow/core/profiler/convert/trace_viewer/trace_viewer_visibility.h",zzzaries,False
"Integrate LLVM at llvm/llvm-project@765206e05045

Updates LLVM usage to match
[765206e05045](https://github.com/llvm/llvm-project/commit/765206e05045)

PiperOrigin-RevId: 638718977",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 18:17:12,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Fix test build.

PiperOrigin-RevId: 638714289",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 18:05:19,tensorflow/c/experimental/ops/gen/common/BUILD,tensorflower-gardener,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638700851",Kyle Lucke,klucke@google.com,2024-05-30 17:30:57,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/autotuner_util.cc, third_party/xla/xla/service/gpu/buffer_allocations.cc, third_party/xla/xla/service/gpu/buffer_allocations.h, third_party/xla/xla/service/gpu/collective_permute_cycle_decomposer.cc, third_party/xla/xla/service/gpu/command_buffer_scheduling.cc, third_party/xla/xla/service/gpu/command_buffer_scheduling.h, third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc, third_party/xla/xla/service/gpu/cublas_cudnn.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_norm_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_pad_for_convolutions.cc, third_party/xla/xla/service/gpu/cudnn_vectorize_convolutions.cc, third_party/xla/xla/service/gpu/cusolver_context.cc, third_party/xla/xla/service/gpu/dot_dimension_sorter.cc, third_party/xla/xla/service/gpu/dot_sparsity_rewriter.cc, third_party/xla/xla/service/gpu/double_buffer_loop_unrolling.cc, third_party/xla/xla/service/gpu/fusion_wrapper.cc, third_party/xla/xla/service/gpu/gemm_fusion.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_compiler.h, third_party/xla/xla/service/gpu/gpu_conv_runner.h, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/gpu_fused_mha_runner.h, third_party/xla/xla/service/gpu/gpu_hlo_schedule.cc, third_party/xla/xla/service/gpu/gpu_layout_assignment.cc, third_party/xla/xla/service/gpu/gpu_layout_assignment.h, third_party/xla/xla/service/gpu/gpu_memory_space_assignment.h, third_party/xla/xla/service/gpu/gpu_norm_runner.h, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.cc, third_party/xla/xla/service/gpu/hlo_fusion_stats.cc, third_party/xla/xla/service/gpu/ir_emission_utils.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.h, third_party/xla/xla/service/gpu/kernel_arguments.cc, third_party/xla/xla/service/gpu/make_batch_pointers.cc, third_party/xla/xla/service/gpu/make_batch_pointers.h, third_party/xla/xla/service/gpu/matmul_utils.cc, third_party/xla/xla/service/gpu/move_copy_to_users.cc, third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/service/gpu/pipelined_p2p_rewriter.cc, third_party/xla/xla/service/gpu/runtime_intrinsics.cc, third_party/xla/xla/service/gpu/softmax_rewriter_triton.cc, third_party/xla/xla/service/gpu/softmax_rewriter_triton.h, third_party/xla/xla/service/gpu/split_k_gemm_rewriter.cc, third_party/xla/xla/service/gpu/split_k_gemm_rewriter.h, third_party/xla/xla/service/gpu/target_util.cc, third_party/xla/xla/service/gpu/topk_specializer.cc, third_party/xla/xla/service/gpu/topk_splitter.cc, third_party/xla/xla/service/gpu/topk_test.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis.h",klucke,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638697803",Kyle Lucke,klucke@google.com,2024-05-30 17:22:52,"third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.cc, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.h, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/cpu/cpu_client_test.cc, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/cpu_compiler.h, third_party/xla/xla/service/cpu/cpu_xfeed.h, third_party/xla/xla/service/cpu/mlir_emitter.h, third_party/xla/xla/service/cpu/parallel_task_assignment.cc, third_party/xla/xla/service/spmd/BUILD, third_party/xla/xla/service/spmd/custom_call_handler.cc, third_party/xla/xla/service/spmd/dot_handler.cc, third_party/xla/xla/service/spmd/gather_scatter_handler.cc, third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc, third_party/xla/xla/service/spmd/spmd_partitioner_util.h",klucke,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638696669",Kyle Lucke,klucke@google.com,2024-05-30 17:19:37,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/algebraic_simplifier.cc, third_party/xla/xla/service/all_gather_combiner.cc, third_party/xla/xla/service/all_gather_decomposer.cc, third_party/xla/xla/service/all_gather_decomposer.h, third_party/xla/xla/service/batchnorm_expander.cc, third_party/xla/xla/service/call_inliner.cc, third_party/xla/xla/service/collective_pipeliner.cc, third_party/xla/xla/service/collective_pipeliner_test.cc, third_party/xla/xla/service/computation_placer.cc, third_party/xla/xla/service/computation_placer.h, third_party/xla/xla/service/conditional_code_motion.cc, third_party/xla/xla/service/cpu_gpu_shape_verifier.cc, third_party/xla/xla/service/dot_decomposer.cc, third_party/xla/xla/service/dot_dimension_merger.cc, third_party/xla/xla/service/dump.cc, third_party/xla/xla/service/dump.h, third_party/xla/xla/service/dynamic_dimension_inference.cc, third_party/xla/xla/service/dynamic_dimension_inference.h, third_party/xla/xla/service/dynamic_padder.cc, third_party/xla/xla/service/dynamic_padder_test.cc, third_party/xla/xla/service/dynamic_window_utils.h, third_party/xla/xla/service/executable.cc, third_party/xla/xla/service/generic_transfer_manager.cc, third_party/xla/xla/service/generic_transfer_manager.h, third_party/xla/xla/service/gpu_compilation_environment.cc, third_party/xla/xla/service/hlo_alias_analysis.h, third_party/xla/xla/service/hlo_cost_analysis.cc, third_party/xla/xla/service/hlo_dataflow_analysis.cc, third_party/xla/xla/service/hlo_dataflow_analysis.h, third_party/xla/xla/service/hlo_dataflow_analysis_test.cc, third_party/xla/xla/service/hlo_dce.cc, third_party/xla/xla/service/hlo_dce.h, third_party/xla/xla/service/hlo_graph_dumper.cc, third_party/xla/xla/service/hlo_liveness_analysis.cc, third_party/xla/xla/service/hlo_liveness_analysis.h, third_party/xla/xla/service/hlo_module_dce.cc, third_party/xla/xla/service/hlo_module_group_metadata.h, third_party/xla/xla/service/hlo_module_group_util.h, third_party/xla/xla/service/hlo_module_util.cc, third_party/xla/xla/service/hlo_module_util.h, third_party/xla/xla/service/hlo_parser.cc, third_party/xla/xla/service/hlo_parser_test.cc, third_party/xla/xla/service/hlo_proto_util.h, third_party/xla/xla/service/hlo_rematerialization.cc, third_party/xla/xla/service/hlo_runner_pjrt.cc, third_party/xla/xla/service/hlo_value_semantics_analysis.cc, third_party/xla/xla/service/hlo_value_semantics_analysis.h, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/hlo_verifier_test.cc, third_party/xla/xla/service/host_memory_transfer_asyncifier.cc, third_party/xla/xla/service/host_offload_legalize.cc, third_party/xla/xla/service/host_offloader.cc, third_party/xla/xla/service/latency_hiding_scheduler.cc, third_party/xla/xla/service/layout_assignment.cc, third_party/xla/xla/service/layout_assignment.h, third_party/xla/xla/service/layout_assignment_test.cc, third_party/xla/xla/service/mapped_ptr_container_sorter.h, third_party/xla/xla/service/optimize_input_output_buffer_alias_test.cc, third_party/xla/xla/service/p2p_schedule_preparation.cc, third_party/xla/xla/service/reduce_decomposer.cc, third_party/xla/xla/service/reduce_window_rewriter.cc, third_party/xla/xla/service/reduce_window_rewriter.h, third_party/xla/xla/service/reshape_decomposer.cc, third_party/xla/xla/service/shape_inference.cc, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/source_map_util.h, third_party/xla/xla/service/stochastic_convert_decomposer.cc, third_party/xla/xla/service/stochastic_convert_decomposer_test.cc, third_party/xla/xla/service/transfer_manager.cc, third_party/xla/xla/service/transfer_manager.h, third_party/xla/xla/service/while_loop_all_reduce_code_motion.cc, third_party/xla/xla/service/while_loop_concat_code_motion.cc, third_party/xla/xla/service/xla_compile_main.cc",klucke,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638685700",Kyle Lucke,klucke@google.com,2024-05-30 16:48:35,"third_party/xla/xla/stream_executor/tpu/BUILD, third_party/xla/xla/stream_executor/tpu/tpu_executable.h, third_party/xla/xla/stream_executor/tpu/tpu_executable_interface.cc, third_party/xla/xla/stream_executor/tpu/tpu_executable_interface.h, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_op_executable.cc, third_party/xla/xla/stream_executor/tpu/tpu_op_executable.h, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager_interface.h, third_party/xla/xla/tools/BUILD, third_party/xla/xla/tools/extract_collective_operations.cc, third_party/xla/xla/tools/hlo_control_flow_flattening.cc, third_party/xla/xla/tools/hlo_control_flow_flattening.h, third_party/xla/xla/tools/hlo_decomposer.cc, third_party/xla/xla/tools/hlo_extractor.cc, third_party/xla/xla/tools/run_hlo_module.cc, third_party/xla/xla/tools/run_hlo_module.h, third_party/xla/xla/tools/xla_compile_lib.cc, third_party/xla/xla/translate/hlo_to_mhlo/BUILD, third_party/xla/xla/translate/hlo_to_mhlo/custom_call_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_function_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_function_importer.h, third_party/xla/xla/translate/hlo_to_mhlo/hlo_module_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_module_importer.h, third_party/xla/xla/translate/hlo_to_mhlo/hlo_to_mlir_hlo.h, third_party/xla/xla/translate/hlo_to_mhlo/translate.cc",klucke,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638685569",Kyle Lucke,klucke@google.com,2024-05-30 16:48:06,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h, third_party/xla/xla/service/gpu/runtime/annotation.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_test.cc, third_party/xla/xla/service/gpu/runtime/conditional_thunk.cc, third_party/xla/xla/service/gpu/runtime/conditional_thunk.h, third_party/xla/xla/service/gpu/runtime/copy_thunk.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.h, third_party/xla/xla/service/gpu/runtime/gemm_thunk.h, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.cc, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.h, third_party/xla/xla/service/gpu/runtime/kernel_thunk.cc, third_party/xla/xla/service/gpu/runtime/kernel_thunk.h, third_party/xla/xla/service/gpu/runtime/memset_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.h, third_party/xla/xla/service/gpu/runtime/send_recv_thunk.cc, third_party/xla/xla/service/gpu/runtime/send_recv_thunk.h",klucke,False
"[xla:cpu] Add support for emitting fusions with thread local computations

PiperOrigin-RevId: 638682359",Eugene Zhulenev,ezhulenev@google.com,2024-05-30 16:36:51,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/ir_emitter.cc, third_party/xla/xla/service/cpu/ir_emitter.h, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/ir_emitter2.h, third_party/xla/xla/service/cpu/ir_emitter2_test.cc",ezhulenev,False
"[XLA:GPU] Fix logic for symbol lookup

Currently, we return/log bad Status when symbol is not found, but the logic for
resolving the constants does not expect it to be always found. This leads to
two issues:

1. Log spam from ""Failed to found symbol"" error messages.
2. Hiding actual errors, if the symbol failed to resolve in some other ways.

Returning StatusOr<optional<>> achieves both goals.

PiperOrigin-RevId: 638677474",George Karpenkov,cheshire@google.com,2024-05-30 16:20:53,"third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream_executor_interface.h",cheshire,False
"Make Stream a pure virtual base class to start eliminating circular dependencies between and StreamExecutor.

PiperOrigin-RevId: 638677132",Kyle Lucke,klucke@google.com,2024-05-30 16:19:41,"tensorflow/c/experimental/stream_executor/stream_executor_internal.h, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_stream.h, third_party/xla/xla/stream_executor/host/host_stream.cc, third_party/xla/xla/stream_executor/host/host_stream.h, third_party/xla/xla/stream_executor/stream.h, third_party/xla/xla/stream_executor/stream_common.cc, third_party/xla/xla/stream_executor/stream_common.h, third_party/xla/xla/stream_executor/tpu/tpu_stream_interface.h",klucke,False
"[XLA] Support running multiple modules in run_hlo_module

PiperOrigin-RevId: 638663872",George Karpenkov,cheshire@google.com,2024-05-30 15:34:42,"third_party/xla/docs/tools.md, third_party/xla/xla/tools/BUILD, third_party/xla/xla/tools/run_hlo_module.h, third_party/xla/xla/tools/run_hlo_module_main.cc",cheshire,False
"Add flag to disable autotune for hlo compile tests.

PiperOrigin-RevId: 638662736",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 15:30:48,third_party/xla/xla/service/gpu/build_defs.bzl,tensorflower-gardener,False
"[xla:cpu] Add support for kWhile thunk

PiperOrigin-RevId: 638660503",Eugene Zhulenev,ezhulenev@google.com,2024-05-30 15:23:22,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/runtime/BUILD, third_party/xla/xla/service/cpu/runtime/thunk.cc, third_party/xla/xla/service/cpu/runtime/thunk.h, third_party/xla/xla/service/cpu/runtime/while_thunk.cc, third_party/xla/xla/service/cpu/runtime/while_thunk.h, third_party/xla/xla/service/cpu/thunk_emitter.cc, third_party/xla/xla/service/cpu/thunk_emitter.h",ezhulenev,False
"[XLA:GPU][Triton] Lower FP8 conversion instructions to Triton's FP_TO_FP instead of arith to be correctly handled.

PiperOrigin-RevId: 638659789",Mohammed Anany,manany@google.com,2024-05-30 15:20:51,third_party/xla/xla/service/gpu/ir_emitter_triton.cc,Moerafaat,False
"[XLA] Simplify multihost_hlo_runner interface

Remove redundant --hlo_file flag, and allow multiple modules.

Also SPMD and num hosts/replicas is now inferred from the module.

PiperOrigin-RevId: 638649677",George Karpenkov,cheshire@google.com,2024-05-30 14:45:04,"third_party/xla/docs/tools.md, third_party/xla/xla/service/gpu/build_defs.bzl, third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/README.md, third_party/xla/xla/tools/multihost_hlo_runner/hlo_runner_main.cc",cheshire,False
"Update OpenXLA's Triton dependency to include the AMD backend.

- https://github.com/openxla/triton/pull/7
- https://github.com/openxla/triton/commit/25e4e02dcaf57f01ba49608345a9bbbbc20152bf
- https://github.com/triton-lang/triton/pull/4031

PiperOrigin-RevId: 638615931",Christian Sigg,csigg@google.com,2024-05-30 12:18:21,"third_party/triton/temporary/fp8_splat_partial_revert.patch, third_party/triton/temporary/local_alloc_lowering_fix.patch, third_party/triton/temporary/series.bzl, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/temporary/fp8_splat_partial_revert.patch, third_party/xla/third_party/triton/temporary/local_alloc_lowering_fix.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/workspace.bzl",chsigg,False
"Automated Code Change

PiperOrigin-RevId: 638604921",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 11:22:16,third_party/xla/xla/mlir_hlo/mhlo/transforms/prepare_for_export/prepare_for_export.cc,tensorflower-gardener,False
"[XLA] Propagate error properly via Status from MLIR pipeline

PiperOrigin-RevId: 638586753",George Karpenkov,cheshire@google.com,2024-05-30 09:58:02,"third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc",cheshire,False
"[XLA] Update shmem memory usage requirements for new column reduction vector size

PiperOrigin-RevId: 638579013",George Karpenkov,cheshire@google.com,2024-05-30 09:21:34,"third_party/xla/xla/service/gpu/gpu_fusible.cc, third_party/xla/xla/service/gpu/multi_output_fusion_test.cc",cheshire,False
"[XLA:GPU] Add TritonSupportTest for dynamic-slice
Also support indices of type S8, S16. (S32 was already supported.)

PiperOrigin-RevId: 638577418",Tamás Danyluk,tdanyluk@google.com,2024-05-30 09:14:49,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/triton_support.cc, third_party/xla/xla/service/gpu/triton_support.h, third_party/xla/xla/service/gpu/triton_support_test.cc, third_party/xla/xla/service/gpu/triton_tiling_propagation.cc",tdanyluk,False
"Slightly refactor IsSupportedF8Pattern in gemm_rewriter.cc.

This makes no functional changes.

The overall logic is a bit more clear now. A type InstrPath is added, aliasing the type 'std::vector<std::pair<HloInstruction *, int>>' which was previously passed around. This type is now always ordered from operand to user instead of being reversed within IsSupportedF8Pattern. The comments for several functions were expanded. FindF8SubgraphRecursive now only returns an InstrPath instead of both returning one and taking one in.

PiperOrigin-RevId: 638576830",Reed Wanderman-Milne,reedwm@google.com,2024-05-30 09:12:29,third_party/xla/xla/service/gpu/gemm_rewriter.cc,reedwm,False
"PR #11832: [XLA:CPU][oneDNN] Enable oneDNN MatMul + BiasAdd + Sigmoid fusion.

Imported from GitHub PR https://github.com/openxla/xla/pull/11832

This PR enables oneDNN MatMul+BiasAdd+Sigmoid fusion for FP32, BF16 and F16.
Copybara import of the project:

--
0a3429d4ae71db667878e7a04c9f3bd021a5aad5 by nhatle <nhat.le@intel.com>:

Enable OneDNN MatMul + BiasAdd + Sigmoid fusion

--
21cf1253d5a284849a1dc0adc0e4d3d2253305d7 by nhatle <nhat.le@intel.com>:

Small fix

--
e6fff8b7bead347f3c725deb99922ebcbdb7d090 by nhatle <nhat.le@intel.com>:

Update HandleDivide to use new version of ElementwiseSafeIntermediates function

Merging this change closes #11832

PiperOrigin-RevId: 638576403",nhatle,nhat.le@intel.com,2024-05-30 09:10:28,"third_party/xla/xla/service/cpu/backend_config.proto, third_party/xla/xla/service/cpu/onednn_matmul.cc, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/tests/onednn_matmul_test.cc",nhatleSummer22,False
"[NFC] More informative error message on error from MLIR emitters

1. Dump MLIR module to dumping folder for inspection
2. Don't attempt to attach MLIR module contents to error: it's too large to
fit, inconsistent with other errors, and will lose the stack trace.

PiperOrigin-RevId: 638574923",George Karpenkov,cheshire@google.com,2024-05-30 09:04:48,third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc,cheshire,False
"Update GraphDef version to 1878.

PiperOrigin-RevId: 638574726",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 09:04:00,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-30

PiperOrigin-RevId: 638574706",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 09:03:56,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Integrate StableHLO at openxla/stablehlo@c44d9af8

PiperOrigin-RevId: 638559828",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-30 08:03:34,"tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf.cc, third_party/stablehlo/temporary.patch, third_party/stablehlo/workspace.bzl, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/workspace.bzl, third_party/xla/xla/mlir_hlo/bindings/c/Attributes.cc, third_party/xla/xla/mlir_hlo/bindings/c/Attributes.h, third_party/xla/xla/mlir_hlo/bindings/python/MlirHloModule.cc, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.cc, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.td, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops_attrs.td, third_party/xla/xla/mlir_hlo/mhlo/IR/mhlo_bytecode.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/expand_ops_simplifier/expand_ops_simplifier.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_stablehlo/hlo_legalize_to_stablehlo.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/legalize_to_linalg/legalize_to_linalg.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/legalize_torch_index_select_to_gather/legalize_torch_index_select_to_gather.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/mhlo_canonicalize_gather/mhlo_canonicalize_gather.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/mhlo_canonicalize_scatter/mhlo_canonicalize_scatter.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/stablehlo_legalize_to_hlo/stablehlo_legalize_to_hlo.cc, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-stablehlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/ops.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/stablehlo-legalize-to-hlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/verifier_scatter_op.mlir, third_party/xla/xla/mlir_hlo/tests/python/attributes.py, third_party/xla/xla/translate/hlo_to_mhlo/attribute_importer.cc, third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",mlevesquedion,False
"[XLA:GPU] Add a ""draft"" version of a generic Triton Fusion Emitter.

This change introduces a new Triton emitter that should eventually replace the existing `MatMul` and `SoftMax` emitters.

Highlights:
- The new emitter is a replacement of the existing `TiledSoftMax` emitter and covers all of those cases.
- For now the new emitter can also generate some non-SoftMax fusions, e.g. I've added a simple reduction fusion test.

TODO in future changes:
- Add more tests.
- The new emitter replaces `TiledSoftMax` but is otherwise unused, because no HLO-passes set it as a backend yet. We should hook it up.
- Extend the new emitter to support 2D and 3D launch grids. At the moment it only supports a 1D grid.
- Compute the `output_tile_sizes` in a generic way or pipe them in from the Tiling Analysis.
- Extend the launch-dimensions computation to support generic fusions. Not quite sure how to do this yet.

PiperOrigin-RevId: 638555878",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-30 07:49:16,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/triton.cc, third_party/xla/xla/service/gpu/gpu_fusible.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/ir_emission_utils.h, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/triton_fusion_numerics_verifier.cc, third_party/xla/xla/service/gpu/triton_support_test.cc",dimitar-asenov,False
"Automated Code Change

PiperOrigin-RevId: 638551258",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 07:27:48,tensorflow/core/grappler/inputs/file_input_yielder.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 638550941",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 07:25:50,"tensorflow/core/transforms/const_dedupe_hoist/BUILD, tensorflow/core/transforms/const_dedupe_hoist/pass.cc",tensorflower-gardener,False
"Reverts a03918a8b580ea180e16cd902f2c8f077b50e790

PiperOrigin-RevId: 638525320",Adrian Kuegel,akuegel@google.com,2024-05-30 05:29:28,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/gather_simplifier.cc, third_party/xla/xla/service/gather_simplifier_test.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/layout_normalization.cc, third_party/xla/xla/service/layout_normalization_test.cc",akuegel,False
"[XLA:GPU] Add a GUnit matcher for TiledHloInstruction

PiperOrigin-RevId: 638524836",Oleg Shyshkov,shyshkov@google.com,2024-05-30 05:26:14,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc, third_party/xla/xla/service/gpu/model/tiled_hlo_instruction.h",olegshyshkov,False
"Disable MLIR-based TF graph optimizer

PiperOrigin-RevId: 638510790",Kuangyuan Chen,chky@google.com,2024-05-30 04:13:30,tensorflow/core/tfrt/graph_executor/graph_execution_options.cc,cky9301,False
"[XLA:LHS] Add a rule for async ops that release nonextendable resources so that their overlap is closed right after their estimated time has passed. Also improve logging levels.

PiperOrigin-RevId: 638504189",Seher Ellis,sacer@google.com,2024-05-30 03:40:39,"third_party/xla/xla/service/latency_hiding_scheduler.cc, third_party/xla/xla/service/latency_hiding_scheduler.h",seherellis,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638502077",Kyle Lucke,klucke@google.com,2024-05-30 03:29:24,"third_party/xla/xla/backends/interpreter/BUILD, third_party/xla/xla/backends/interpreter/compiler.cc, third_party/xla/xla/backends/interpreter/compiler.h, third_party/xla/xla/backends/profiler/cpu/BUILD, third_party/xla/xla/backends/profiler/cpu/metadata_collector.cc, third_party/xla/xla/hlo/evaluator/BUILD, third_party/xla/xla/hlo/evaluator/hlo_evaluator.cc, third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/service/cpu/tests/BUILD, third_party/xla/xla/service/cpu/tests/cpu_noalias_test.cc, third_party/xla/xla/service/gpu/llvm_gpu_backend/BUILD, third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc, third_party/xla/xla/service/heap_simulator/BUILD, third_party/xla/xla/service/heap_simulator/heap_simulator.cc, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_blas_lt.h, third_party/xla/xla/tools/hlo_bisect/BUILD, third_party/xla/xla/tools/hlo_bisect/hlo_bisect_state.h, third_party/xla/xla/tools/hlo_opt/BUILD, third_party/xla/xla/tools/hlo_opt/opt_main.cc, third_party/xla/xla/translate/mhlo_to_hlo/BUILD, third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",klucke,False
"[TF] Remove unused TF->HLO conversion pattern

The C++ pattern is dead code as the op is already replaced by a TableGen pattern in legalize_tf_patterns.td

PiperOrigin-RevId: 638500450",David Majnemer,majnemer@google.com,2024-05-30 03:20:36,"tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config_test.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf.cc",majnemer,False
"Added a minor utility function to compute an elementwise product of two vectors.

PiperOrigin-RevId: 638486930",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 02:19:00,"third_party/xla/xla/BUILD, third_party/xla/xla/hlo/ir/BUILD, third_party/xla/xla/hlo/ir/hlo_instruction_utils.cc, third_party/xla/xla/hlo/ir/hlo_instruction_utils.h, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/algebraic_simplifier.cc, third_party/xla/xla/util.cc, third_party/xla/xla/util.h",tensorflower-gardener,False
"[stream_executor:host] Implement Launch method

This is a part of the ongoing effort https://github.com/openxla/xla/issues/7234

PiperOrigin-RevId: 638481503",Vladyslav Tsilytskyi,tsilytskyi@google.com,2024-05-30 01:50:20,"third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/host/host_kernel.cc, third_party/xla/xla/stream_executor/host/host_kernel.h, third_party/xla/xla/stream_executor/host/host_kernel_test.cc, third_party/xla/xla/stream_executor/stream_executor_test.cc",tvladyslav,False
"Implement `AssembleArrayFromSingleDeviceArrays` for BasicStringArray.

PiperOrigin-RevId: 638477621",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 01:28:10,"third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/basic_string_array_test.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc",tensorflower-gardener,False
"Support paging in TfrtSavedModelServable.

PiperOrigin-RevId: 638471838",Siqiao Wu,siqiaowu@google.com,2024-05-30 01:01:39,tensorflow/cc/saved_model/testdata/half_plus_two_v2/00000123/assets.extra/validation_result_do_not_edit,SiqiaoWu1993,False
"Allow model builder to build a model based on a file descriptor.

PiperOrigin-RevId: 638468928",Shiqing Yan,shiqing@google.com,2024-05-30 00:48:08,"tensorflow/lite/core/BUILD, tensorflow/lite/core/model_builder.cc, tensorflow/lite/core/model_builder.h",shiqing117,False
"[IFRT] Add several commonly used APIs to `xla::ifrt::Sharding`

This CL adds commonly used APIs for sharding.
* Equality test (`==`, `!=`): Checks if two shardings have the same logical partitioning (see below) and same device assignment.
* `GetShardShape`: Returns a shard shape if this sharding always returns a single shard shape. A faste version of taking the first shard's shape from `Disassemble()` result.
* `HasSamePartitioning`: Tests if two shardings have the same logical partitioning, which is when two shardings have the same type and their own partitioning scheme is equivalent.
* `WithDeviceAssignment`: Returns a new `Sharding` of the same type, with devices and/or memory_kind replaced.

PiperOrigin-RevId: 638463143",Hyeontaek Lim,hyeontaek@google.com,2024-05-30 00:21:46,"third_party/xla/xla/python/ifrt/sharding.cc, third_party/xla/xla/python/ifrt/sharding.h, third_party/xla/xla/python/ifrt/sharding_test.cc, third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/xla_sharding.cc, third_party/xla/xla/python/pjrt_ifrt/xla_sharding.h, third_party/xla/xla/python/pjrt_ifrt/xla_sharding_test.cc",hyeontaek,False
"Change MatchShapeCoveringDynamicIndexInstruction to return the dynamic index if matched.

PiperOrigin-RevId: 638463074",Farzin Houshmand,farzinh@google.com,2024-05-30 00:21:26,"third_party/xla/xla/service/scan_loop_accumulator_input_unification.cc, third_party/xla/xla/service/while_loop_unroller.cc, third_party/xla/xla/service/while_loop_unroller.h, third_party/xla/xla/service/while_loop_unroller_test.cc",farzinhoushmand,False
"Adds IDs of modules on which the compilation stage was run to the CompilationLogEntry and the `MetricsHookInterface::RecordCompilationMetrics()` API.

PiperOrigin-RevId: 638461027",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-30 00:12:09,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/metrics.proto, third_party/xla/xla/service/metrics_hook_interface.h",tensorflower-gardener,False
"Fix diff command for bazelrc in XLA build script

PiperOrigin-RevId: 638455152",David Dunleavy,ddunleavy@google.com,2024-05-29 23:50:05,third_party/xla/.kokoro/linux/build.sh,ddunl,False
"PR #13065: [NVIDIA] Disable the bias reuse for fp8 dot

Imported from GitHub PR https://github.com/openxla/xla/pull/13065

For some operations, we might want to do the `output to operand aliasing` to reuse the memory space. For example, in the dot operation, we can alias the output to the bias operand, when they have the same shape.

However, this aliasing is not always safe especially when the dot outputs fp8 outputs. In this case the bias is 2x larger than expected output and the HLO verifier will complain.

This PR fixes this issue by disabling the `output to operand aliasing`  for fp8 dot.

cc. @philipphack @hx89 @nluehr
Copybara import of the project:

--
711e3097a80d9ff6e48b80924a1e81ff940ac240 by kaixih <kaixih@nvidia.com>:

Disable bias reuse for fp8 dot

--
7d86b99396385f85e6e04a28dc8d824fd53e91f3 by kaixih <kaixih@nvidia.com>:

Update to a general solution

--
15f774667013045c7d8d9e38ac80a45645313b1e by kaixih <kaixih@nvidia.com>:

Address comments

Merging this change closes #13065

PiperOrigin-RevId: 638454718",Kaixi Hou,kaixih@nvidia.com,2024-05-29 23:48:10,"third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc",kaixih,False
"PR #13107: [ROCm] Fix reduce_row_vectorized.hlo.test

Imported from GitHub PR https://github.com/openxla/xla/pull/13107

Copybara import of the project:

--
6555b6d216bb18b1f98eb36c5dac3f58f4d09c05 by mmakevic <Milica.Makevic@amd.com>:

Fix reduce_row_vectorized.hlo.test

Merging this change closes #13107

PiperOrigin-RevId: 638453162",mmakevic-amd,Milica.Makevic@amd.com,2024-05-29 23:41:59,third_party/xla/xla/service/gpu/tests/reduce_row_vectorized.hlo,mmakevic-amd,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/4662f7552dc2e420ee20361c077b7aeb334a1087.

PiperOrigin-RevId: 638450863",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 23:33:40,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638442690",Kyle Lucke,klucke@google.com,2024-05-29 23:05:12,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/array.h, third_party/xla/xla/python/ifrt/client.h, third_party/xla/xla/python/ifrt/executable.h, third_party/xla/xla/python/ifrt/mock.h, third_party/xla/xla/python/ifrt/value.h",klucke,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638441439",Kyle Lucke,klucke@google.com,2024-05-29 23:01:42,"third_party/xla/xla/service/memory_space_assignment/BUILD, third_party/xla/xla/service/memory_space_assignment/algorithm.cc, third_party/xla/xla/service/memory_space_assignment/algorithm.h, third_party/xla/xla/service/memory_space_assignment/allocation.cc, third_party/xla/xla/service/memory_space_assignment/allocation.h, third_party/xla/xla/service/memory_space_assignment/cost_analysis_test.cc, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer.cc, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer.h, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer_test.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.h, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc, third_party/xla/xla/service/memory_space_assignment/prefetch_interval_picker.cc",klucke,False
"Reverts c82138f5a838ca67b55697d12a137b4662c08525

PiperOrigin-RevId: 638435735",Victor Stone,victorstone@google.com,2024-05-29 22:40:12,third_party/xla/xla/service/host_offload_legalize.cc,SandSnip3r,False
"[XLA] Stop duplicating broadcasts before host memory offloading.

HostOffloader will do this as needed.

PiperOrigin-RevId: 638422085",Victor Stone,victorstone@google.com,2024-05-29 21:56:13,third_party/xla/xla/service/host_offload_legalize.cc,SandSnip3r,False
"[xla:cpu] Add support for kCall thunks

PiperOrigin-RevId: 638414662",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 21:32:35,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/runtime/BUILD, third_party/xla/xla/service/cpu/runtime/call_thunk.cc, third_party/xla/xla/service/cpu/runtime/call_thunk.h, third_party/xla/xla/service/cpu/runtime/thunk.cc, third_party/xla/xla/service/cpu/runtime/thunk.h, third_party/xla/xla/service/cpu/thunk_emitter.cc, third_party/xla/xla/service/cpu/thunk_emitter.h",ezhulenev,False
"[xla:cpu] Add support for kAbs and kReverse elemental host kernels

PiperOrigin-RevId: 638409741",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 21:16:47,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/thunk_emitter.cc",ezhulenev,False
"[xla:cpu] Pack constants of sub-byte element type into dense storage compatible with XLA format

+ added a few more tests that now pass with thunks runtime

PiperOrigin-RevId: 638405998",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 21:05:30,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc",ezhulenev,False
"[xla:gpu] Add support for u32 and u64 offset constants

PiperOrigin-RevId: 638404105",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 21:00:58,"third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h",ezhulenev,False
"PR #13165:  [ROCm] Update ROCm version to 6.0.2

Imported from GitHub PR https://github.com/openxla/xla/pull/13165

Copybara import of the project:

--
0a2b2ea90005d8c00e2afd77dac3a34be8673661 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Update ROCm version to 6.0.2

Merging this change closes #13165

PiperOrigin-RevId: 638399484",Harsha H S,hsharsha@users.noreply.github.com,2024-05-29 20:46:56,third_party/xla/build_tools/rocm/run_xla.sh,hsharsha,False
"Load variable concurrently

PiperOrigin-RevId: 638397250",Deqiang Chen,deqiangc@google.com,2024-05-29 20:39:12,"tensorflow/core/tfrt/mlrt/kernel/BUILD, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc, tensorflow/core/tfrt/mlrt/kernel/shard_restore_util.cc, tensorflow/core/tfrt/mlrt/kernel/shard_restore_util.h, tensorflow/core/tfrt/mlrt/kernel/shard_restore_util_test.cc, tensorflow/core/tfrt/mlrt/kernel/testdata/gen_checkpoint.py",deqiangc,False
"Delete duplicate schema.fbs (new location is //third_party/tensorflow/compiler/mlir/lite/schema/schema.fbs)

PiperOrigin-RevId: 638391440",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 20:22:33,tensorflow/lite/schema/schema.fbs,tensorflower-gardener,False
"Update mlir tests to reflect new namespace change

PiperOrigin-RevId: 638391003",Samuel Agyakwa,sagyakwa@google.com,2024-05-29 20:21:06,tensorflow/compiler/mlir/tfrt/tests/tfrt_fallback/tf_delegate.mlir,sagyakwa,False
"[Triton] Fixing an issue where LocalAllocOp doesn't support DotOperandEncoding when it calls emitIndices during lowering.

The change basically inserts a layout conversion from DotOperandEncoding to the original parent encoding when creating a LocalAllocOp and modifies RemoveLayoutConversions pass to not canonicalize it away.

PiperOrigin-RevId: 638387502",Mohammed Anany,manany@google.com,2024-05-29 20:09:43,"third_party/triton/temporary/local_alloc_lowering_fix.patch, third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/local_alloc_lowering_fix.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/tests/sparse_ttg_accelerate_matmul.mlir",Moerafaat,False
"move loop-invariant code outside the loop

PiperOrigin-RevId: 638386434",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 20:06:34,third_party/xla/xla/python/pjrt_ifrt/xla_executable_impl_test_lib.cc,tensorflower-gardener,False
"[xla:cpu] Add support for emitting host kernels for fusions

PiperOrigin-RevId: 638379451",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 19:45:34,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/ir_emitter2.h, third_party/xla/xla/service/cpu/thunk_emitter.cc, third_party/xla/xla/service/cpu/thunk_emitter.h",ezhulenev,False
"[XLA:GPU] Do not CHECK in nvptx_compiler, we return Status already

PiperOrigin-RevId: 638376738",George Karpenkov,cheshire@google.com,2024-05-29 19:36:16,third_party/xla/xla/service/gpu/nvptx_compiler.cc,cheshire,False
"PR #13018: [ROCm] Distinguish between AMD and NVIDIA GPUs with relevant tags

Imported from GitHub PR https://github.com/openxla/xla/pull/13018

Add `requires-gpu-amd` for AMD gpus and unit tests that require AMD backend. Use `requires-gpu-nvidia` for any nvidia gpu backend.
Copybara import of the project:

--
8c3c52760c37b6c9fc17910174df6bfa396b5b5e by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Distinguish between AMD and NVIDIA GPUs with relevant tags

--
0bf9ab80d06284883df19f17f421eb6a691c0dd8 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

Change ALL_GPU_BACKENDS to GPU_BACKENDS

Merging this change closes #13018

PiperOrigin-RevId: 638364879",Harsha H S,hsharsha@users.noreply.github.com,2024-05-29 18:58:35,"third_party/xla/.kokoro/linux/build.sh, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/tests/build_defs.bzl",hsharsha,False
"Remove Stream::platform_specific_stream method, and keep it on GpuStream where it makes sense.

PiperOrigin-RevId: 638356187",Kyle Lucke,klucke@google.com,2024-05-29 18:32:28,"third_party/xla/xla/stream_executor/gpu/gpu_stream.cc, third_party/xla/xla/stream_executor/gpu/gpu_stream.h, third_party/xla/xla/stream_executor/stream.cc, third_party/xla/xla/stream_executor/stream.h",klucke,False
"Use numpy as the source of truth for expm1 test.

PiperOrigin-RevId: 638355993",David Majnemer,majnemer@google.com,2024-05-29 18:31:53,tensorflow/compiler/tests/unary_ops_test.py,majnemer,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638355193",Kyle Lucke,klucke@google.com,2024-05-29 18:29:50,"third_party/xla/xla/backends/profiler/plugin/BUILD, third_party/xla/xla/backends/profiler/plugin/plugin_tracer.cc, third_party/xla/xla/backends/profiler/plugin/plugin_tracer.h, third_party/xla/xla/client/BUILD, third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder.h, third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_api.h, third_party/xla/xla/hlo/utils/BUILD, third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util.h, third_party/xla/xla/service/llvm_ir/BUILD, third_party/xla/xla/service/llvm_ir/kernel_support_library.h, third_party/xla/xla/service/llvm_ir/llvm_util.cc, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/multithreaded_compilation_test.cc, third_party/xla/xla/tests/test_utils.cc, third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc, third_party/xla/xla/tools/multihost_hlo_runner/hlo_runner_main.cc",klucke,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638354595",Kyle Lucke,klucke@google.com,2024-05-29 18:28:19,"third_party/xla/xla/hlo/ir/BUILD, third_party/xla/xla/hlo/ir/dfs_hlo_visitor.h, third_party/xla/xla/hlo/ir/dynamic_parameter_binding.cc, third_party/xla/xla/hlo/ir/dynamic_parameter_binding.h, third_party/xla/xla/hlo/ir/hlo_input_output_alias_config.cc, third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h, third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/hlo/ir/hlo_instructions.h, third_party/xla/xla/hlo/ir/hlo_schedule.h, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/custom_call_sharding.cc, third_party/xla/xla/python/mlir.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/types.h, third_party/xla/xla/python/util.cc, third_party/xla/xla/python/util.h, third_party/xla/xla/python/xplane_to_profile_instructions.cc, third_party/xla/xla/python/xplane_to_profile_instructions.h",klucke,False
"[IFRT] Add function for converting from xla::ifrt::Sharding to OpSharding.

PiperOrigin-RevId: 638354440",Ionel Gog,icgog@google.com,2024-05-29 18:27:57,"third_party/xla/xla/python/ifrt/support/BUILD, third_party/xla/xla/python/ifrt/support/sharding_conversions.cc, third_party/xla/xla/python/ifrt/support/sharding_conversions.h, third_party/xla/xla/python/ifrt/support/sharding_conversions_test.cc",ICGog,False
"PR #13194: [ROCm] Fix build break in xla/service/gpu/ir_emitter_triton_rocm.cc

Imported from GitHub PR https://github.com/openxla/xla/pull/13194

Issue is present after following commit:
https://github.com/openxla/triton/commit/6d54ba2fba40073a21c22f5fac2bdc5fb385a655
Copybara import of the project:

--
c870abf922ae32592a693938f2ea829712e57347 by Zoran Jovanovic <zjovanov@amd.com>:

[ROCm] Fix build break in xla/service/gpu/ir_emitter_triton_rocm.cc

Merging this change closes #13194

PiperOrigin-RevId: 638350201",zoranjovanovic-ns,126815388+zoranjovanovic-ns@users.noreply.github.com,2024-05-29 18:16:15,third_party/xla/xla/service/gpu/ir_emitter_triton_rocm.cc,zoranjovanovic-ns,False
"Add support for NCHW layout in stablehlo.composites for jax.image.resize and torch.nn.interpolate in nearest mode.

PiperOrigin-RevId: 638344504",Vamsi Manchala,vamsimanchala@google.com,2024-05-29 18:01:43,"tensorflow/compiler/mlir/lite/stablehlo/tests/composite-lowering.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_patterns.td, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_utils.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_utils.h",vamsimanchala,False
"[xla:gpu] Exclude collectives from command buffers if CUDA < 12.3

Tracing NCCL collectives relies on CUDA feature that was added in 12.3

PiperOrigin-RevId: 638338001",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 17:44:09,third_party/xla/xla/service/gpu/command_buffer_scheduling.cc,ezhulenev,False
"Add simple loop peeling for imperfect tiling.

This is very ad-hoc and ugly, but it works for now.

PiperOrigin-RevId: 638337640",Johannes Reifferscheid,jreiffers@google.com,2024-05-29 17:43:08,"third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",jreiffers,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638327367",Kyle Lucke,klucke@google.com,2024-05-29 17:13:19,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_dot_handler.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_runner.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc",klucke,False
"[xprof] Add infrastructure to render host offload transfers in trace viewer.

This adds a new line to the trace viewer to support host offload ops.

PiperOrigin-RevId: 638322073",Jackson Stokes,jacksonstokes@google.com,2024-05-29 16:59:29,"tensorflow/core/profiler/utils/BUILD, tensorflow/core/profiler/utils/derived_timeline.cc, tensorflow/core/profiler/utils/host_offload_utils.cc, tensorflow/core/profiler/utils/host_offload_utils.h, tensorflow/core/profiler/utils/trace_utils.h, tensorflow/core/profiler/utils/xplane_schema.h, third_party/xla/third_party/tsl/tsl/profiler/utils/trace_utils.h, third_party/xla/third_party/tsl/tsl/profiler/utils/xplane_schema.cc, third_party/xla/third_party/tsl/tsl/profiler/utils/xplane_schema.h",jvstokes,False
"[xla] Add `test_xla_cpu_thunks` tag to test XLA:CPU with thunks runtime

PiperOrigin-RevId: 638321698",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 16:58:27,third_party/xla/xla/tests/BUILD,ezhulenev,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638320089",Kyle Lucke,klucke@google.com,2024-05-29 16:53:41,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/exceptions.h, third_party/xla/xla/pjrt/host_callback_test.cc, third_party/xla/xla/pjrt/layout_mode.cc, third_party/xla/xla/pjrt/local_device_state.h, third_party/xla/xla/pjrt/mlir_to_hlo.cc, third_party/xla/xla/pjrt/mlir_to_hlo.h, third_party/xla/xla/pjrt/pjrt_api.cc, third_party/xla/xla/pjrt/pjrt_api.h, third_party/xla/xla/pjrt/pjrt_c_api_client.cc, third_party/xla/xla/pjrt/pjrt_c_api_client.h, third_party/xla/xla/pjrt/pjrt_client.h, third_party/xla/xla/pjrt/pjrt_executable.cc, third_party/xla/xla/pjrt/pjrt_executable.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h, third_party/xla/xla/pjrt/status_casters.h, third_party/xla/xla/pjrt/tracked_device_buffer.h, third_party/xla/xla/pjrt/transpose.cc, third_party/xla/xla/pjrt/utils.cc, third_party/xla/xla/pjrt/utils.h",klucke,False
"[xla:ffi] Renamed BufferBase to AnyBuffer

BufferBase is too opaque to guess that it should be used for arguments which
accept any combination of dtype/rank.

PiperOrigin-RevId: 638319805",Sergei Lebedev,slebedev@google.com,2024-05-29 16:52:53,"third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_test.cc, third_party/xla/xla/pjrt/cpu/cpu_client_test.cc, third_party/xla/xla/python/custom_calls_testlib.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc, third_party/xla/xla/service/gpu/custom_call_test.cc, third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc, third_party/xla/xla/service/llvm_ir/alias_analysis_test.cc, third_party/xla/xla/tests/custom_call_test.cc",superbobry,False
"Change IsCollectiveWithChannelId to return the instruction with channel_id or nullptr.

PiperOrigin-RevId: 638307912",Farzin Houshmand,farzinh@google.com,2024-05-29 16:14:12,"third_party/xla/xla/service/collective_ops_utils.cc, third_party/xla/xla/service/collective_ops_utils.h, third_party/xla/xla/service/collective_ops_utils_test.cc, third_party/xla/xla/service/while_loop_unroller.cc",farzinhoushmand,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638294947",Kyle Lucke,klucke@google.com,2024-05-29 15:31:26,"third_party/xla/xla/python/ifrt_proxy/integration_tests/BUILD, third_party/xla/xla/python/ifrt_proxy/integration_tests/mock_array_test.cc",klucke,False
"Create a simple loop unswitching pass.

In some cases, LLVM's loop unswitcher doesn't detect our
conditions as trivial and doesn't optimize.

PiperOrigin-RevId: 638266302",Johannes Reifferscheid,jreiffers@google.com,2024-05-29 13:41:58,"third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/passes.h, third_party/xla/xla/service/gpu/fusions/mlir/passes.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/unswitch_loops.mlir, third_party/xla/xla/service/gpu/fusions/mlir/unswitch_loops.cc",jreiffers,False
"Sort summands by distance of symbols to insertion point.

By emitting more distant summands first, we maximize opportunities for LICM.

PiperOrigin-RevId: 638262010",Johannes Reifferscheid,jreiffers@google.com,2024-05-29 13:22:21,"third_party/xla/xla/service/gpu/fusions/mlir/simplify_affine.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/simplify_affine.mlir",jreiffers,False
"Combine sparsity patches

PiperOrigin-RevId: 638252468",Tori Baker,vwbaker@google.com,2024-05-29 12:40:11,"third_party/triton/xla_extensions/series.bzl, third_party/triton/xla_extensions/sparse_dot.patch, third_party/triton/xla_extensions/sparse_dot_fixes_y24w17.patch, third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch, third_party/triton/xla_extensions/sparse_dot_nvgpu.patch, third_party/triton/xla_extensions/sparse_dot_passes.patch, third_party/xla/third_party/triton/xla_extensions/series.bzl, third_party/xla/third_party/triton/xla_extensions/sparse_dot.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w17.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_nvgpu.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_passes.patch",vwbaker,False
"Reduce logs in XNNPack delegate for prod builds.

PiperOrigin-RevId: 638251994",Quentin Khan,qkhan@google.com,2024-05-29 12:37:25,tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc,qukhan,False
"Define ""bad indices handling"" utilities.

PiperOrigin-RevId: 638244760",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 12:05:36,"tensorflow/core/util/BUILD, tensorflow/core/util/bad_indices_policy.cc, tensorflow/core/util/bad_indices_policy.h, tensorflow/core/util/bad_indices_policy_test.cc",tensorflower-gardener,False
"Revert usage of always_inline attribute.

This is not necessary, we already inline functions with just one caller. The
problem that we didn't inline in some cases was just that there were dead
functions which called them. After removing dead functions, inlining works.
Rename PreInlinerPass to EraseDeadFunctions pass.

PiperOrigin-RevId: 638241030",Adrian Kuegel,akuegel@google.com,2024-05-29 11:50:06,"third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/erase_dead_functions.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/passes.h, third_party/xla/xla/service/gpu/fusions/mlir/passes.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/inlining.mlir",akuegel,False
"Automated Code Change

PiperOrigin-RevId: 638239528",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 11:42:11,"tensorflow/core/kernels/batching_util/adaptive_shared_batch_scheduler.h, tensorflow/core/kernels/batching_util/shared_batch_scheduler.h",tensorflower-gardener,False
"Always inline functions that are called only once.

PiperOrigin-RevId: 638217258",Johannes Reifferscheid,jreiffers@google.com,2024-05-29 10:06:48,"third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/lower_xla_gpu_to_scf.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/passes.h, third_party/xla/xla/service/gpu/fusions/mlir/passes.td, third_party/xla/xla/service/gpu/fusions/mlir/pre_inliner.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/inlining.mlir, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_xla_gpu_to_scf.mlir",jreiffers,False
"More unsigned reduction fixes.

This is terrible. I would like to order one progressive
lowering please.

PiperOrigin-RevId: 638217181",Johannes Reifferscheid,jreiffers@google.com,2024-05-29 10:06:24,"third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.h, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",jreiffers,False
"Automated Code Change

PiperOrigin-RevId: 638216250",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 10:02:56,"tensorflow/core/framework/model.cc, tensorflow/core/framework/node_def_builder_test.cc, tensorflow/core/framework/op_kernel.cc, tensorflow/core/framework/op_kernel.h, tensorflow/core/framework/op_kernel_test.cc, tensorflow/core/framework/queue_interface.h, tensorflow/core/framework/reader_interface.h, tensorflow/core/framework/resource_handle.h, tensorflow/core/framework/resource_mgr.cc, tensorflow/core/framework/resource_mgr.h",tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-29

PiperOrigin-RevId: 638201606",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 09:03:38,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1877.

PiperOrigin-RevId: 638201594",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 09:03:35,tensorflow/core/public/version.h,tensorflower-gardener,False
"Go: Update generated wrapper functions for TensorFlow ops.

PiperOrigin-RevId: 638197172",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 08:49:07,tensorflow/go/op/wrappers.go,tensorflower-gardener,False
"[JAX] Automatically share PGO data for GPU latency-hiding scheduler.

Overall the idea is to collect profile data for each module given amount of times (which can be configured) then recompile the module with the aggregated profile data.

1. We need to track how many times each module were profiled and collect profiling results. For this i added a ProfileSessionRunner class at profile.py. The class can track how many times an instance of it was called to profile a session and also can aggregate profile results.

2. We need associate profiling session to the module at the interpreter. To do this i added a dictionary to pjit.py which associates Jaxpr with profile session runner.

3. The profile session runner should be passed to pxla.py and then called.

4. We need to correctly deal with fast path at the interpreter level, so JAX won't use HLO directly if PGLE need to be collected, but also JAX will not recompiled the module only for PGLE. See changes in pjit.py and in lru_cache.h

5. Once FDO is collected we need to share it between hosts to keep deterministic compilation.

PiperOrigin-RevId: 638197166",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 08:49:06,"third_party/xla/xla/pjrt/lru_cache.h, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/aggregate_profile.cc, third_party/xla/xla/python/aggregate_profile.h, third_party/xla/xla/python/aggregate_profile_test.cc, third_party/xla/xla/python/pjit.cc, third_party/xla/xla/python/profiler.cc, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_extension/profiler.pyi",tensorflower-gardener,False
"[XLA:GPU] Pre-factoring: Add GetDnnVersionInfo helper that returns StatusOr.

Replace repetitive code with calls to the helper.

PiperOrigin-RevId: 638194978",Thomas Joerg,tjoerg@google.com,2024-05-29 08:42:01,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_layout_assignment_test.cc, third_party/xla/xla/service/gpu/stream_executor_util.cc, third_party/xla/xla/service/gpu/stream_executor_util.h, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc",thomasjoerg,False
"[XLA:GPU] Fix infinite loop in `ApproximateMatch` indexing test util.

Previously, if one string was strictly a prefix of the other one (ignoring
spaces), we would run into an infinite loop when reaching the end of the
shorter string.

PiperOrigin-RevId: 638194222",Benjamin Chetioui,bchetioui@google.com,2024-05-29 08:39:19,third_party/xla/xla/service/gpu/model/indexing_test_utils.cc,bchetioui,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 638189714",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 08:21:41,"tensorflow/core/ops/compat/ops_history_v2/GatherNd.pbtxt, tensorflow/core/ops/ops.pbtxt",tensorflower-gardener,False
"[XLA:GPU] Fix compute time calculation in the performance model.

The compute time should be calculated based on the number of active cores, which is the minimum of the number of blocks and the number of cores on the device.

Originally suggested in https://github.com/openxla/xla/pull/12208.

Co-authored-by: lingzhi98 <lingzhi.zhou@intel.com>
PiperOrigin-RevId: 638183155",Oleg Shyshkov,shyshkov@google.com,2024-05-29 07:58:38,"third_party/xla/xla/service/gpu/model/gpu_collective_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.h, third_party/xla/xla/service/gpu/model/gpu_performance_model_test.cc",olegshyshkov,False
"Automated Code Change

PiperOrigin-RevId: 638179522",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 07:42:49,"tensorflow/core/distributed_runtime/coordination/BUILD, tensorflow/core/distributed_runtime/coordination/coordination_service_barrier_proxy.cc",tensorflower-gardener,False
"[xla:cpu] Make HostKernel::Launch process all work in the main thread if thread_pool_ is nullptr.

PiperOrigin-RevId: 638179007",Penporn Koanantakool,penporn@google.com,2024-05-29 07:40:49,third_party/xla/xla/stream_executor/host/host_kernel.cc,penpornk,False
"bad_indices_policy for GatherNd

PiperOrigin-RevId: 638173737",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 07:18:24,"tensorflow/compiler/mlir/lite/stablehlo/tests/legalize_hlo.mlir, tensorflow/compiler/mlir/lite/tests/prepare-tf.mlir, tensorflow/compiler/mlir/lite/transforms/legalize_patterns.td, tensorflow/compiler/mlir/tensorflow/ir/tf_generated_ops.td, tensorflow/core/ops/array_ops.cc, tensorflow/tools/api/golden/v1/tensorflow.raw_ops.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.raw_ops.pbtxt",tensorflower-gardener,False
"PR #13047: [XLA:GPU] Lowering cublasLt thunk to command buffer

Imported from GitHub PR https://github.com/openxla/xla/pull/13047

Copybara import of the project:

--
ee872b54d6301f2dfb1168b57dcd5b6e8a0c4561 by Shawn Wang <shawnw@nvidia.com>:

Lowering cublasLt thunk to command buffer

Merging this change closes #13047

PiperOrigin-RevId: 638167448",Shawn Wang,shawnw@nvidia.com,2024-05-29 06:54:05,"third_party/xla/xla/service/buffer_assignment.cc, third_party/xla/xla/service/gpu/command_buffer_scheduling.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_emitter.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.h, third_party/xla/xla/xla.proto",shawnwang18,False
"Stop using xla/status.h in favor of absl/status/status.h.

PiperOrigin-RevId: 638161446",Kyle Lucke,klucke@google.com,2024-05-29 06:27:19,"third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_array.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.h",klucke,False
"Automated Code Change

PiperOrigin-RevId: 638146225",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 05:16:13,"tensorflow/examples/custom_ops_doc/multiplex_1/multiplex_1_kernel.cc, tensorflow/examples/custom_ops_doc/multiplex_1/multiplex_1_op.cc",tensorflower-gardener,False
"[xla:cpu] IrEmitter2: Get fast_min_max flag from hlo module config

PiperOrigin-RevId: 638103879",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 02:05:47,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/ir_emitter2.h, third_party/xla/xla/service/cpu/ir_emitter2_test.cc",ezhulenev,False
"[xla:cpu] Add support for host kernels with multiple operands

PiperOrigin-RevId: 638100809",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 01:51:42,"third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/thunk_emitter.cc",ezhulenev,False
"[xla:gpu] NFC: Simplify AddressComputationThunk by replacing llvm::zip with struct

Remove accidental copies of various temporaries by packing all arguments into struct and iterating over a single vector.

Also fix a bug with accessing offsets buffers stored on host, original [arg_idx + offset] offset computation is simply incorrect.

PiperOrigin-RevId: 638098333",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 01:37:57,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h",ezhulenev,False
"[xla:cpu] NFC: Give human readable names to LLVM IR instructions in host kernel prototype

Example:

```
  %tdim_x_gep = getelementptr inbounds %SE_HOST_KernelThreadDim, ptr %2, i32 0
  %tdim_y_gep = getelementptr inbounds %SE_HOST_KernelThreadDim, ptr %2, i32 1
  %tdim_z_gep = getelementptr inbounds %SE_HOST_KernelThreadDim, ptr %2, i32 2
  %tdim_x = load i64, ptr %tdim_x_gep, align 4
  %tdim_y = load i64, ptr %tdim_y_gep, align 4
  %tdim_z = load i64, ptr %tdim_z_gep, align 4
  %3 = getelementptr inbounds %SE_HOST_KernelCallFrame, ptr %0, i32 0, i32 1
  %tid_x_gep = getelementptr inbounds %SE_HOST_KernelThread, ptr %3, i32 0, i32 0
  %tid_y_gep = getelementptr inbounds %SE_HOST_KernelThread, ptr %3, i32 0, i32 1
  %tid_z_gep = getelementptr inbounds %SE_HOST_KernelThread, ptr %3, i32 0, i32 2
  %tid_x = load i64, ptr %tid_x_gep, align 4
  %tid_y = load i64, ptr %tid_y_gep, align 4
  %tid_z = load i64, ptr %tid_z_gep, align 4
  %args_gep = getelementptr inbounds %SE_HOST_KernelCallFrame, ptr %0
  %args = load ptr, ptr %args_gep, align 8
  %arg0_gep = getelementptr %SE_HOST_KernelArg, ptr %args, i32 0, i32 0
  %arg0 = load ptr, ptr %arg0_gep, align 8
  %args_gep1 = getelementptr inbounds %SE_HOST_KernelCallFrame, ptr %0
  %args2 = load ptr, ptr %args_gep1, align 8
  %arg1_gep = getelementptr %SE_HOST_KernelArg, ptr %args2, i32 1, i32 0
  %arg1 = load ptr, ptr %arg1_gep, align 8
```

PiperOrigin-RevId: 638096582",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 01:29:37,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/ir_emitter2_test.cc",ezhulenev,False
"[xla:cpu] Add support for KernelThunk and jit-compiling elemental host kernels

PiperOrigin-RevId: 638094579",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 01:18:52,"third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/cpu_executable.cc, third_party/xla/xla/service/cpu/cpu_executable.h, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/ir_emitter2.h, third_party/xla/xla/service/cpu/ir_emitter2_test.cc, third_party/xla/xla/service/cpu/runtime/BUILD, third_party/xla/xla/service/cpu/runtime/copy_thunk_test.cc, third_party/xla/xla/service/cpu/runtime/kernel_thunk.cc, third_party/xla/xla/service/cpu/runtime/kernel_thunk.h, third_party/xla/xla/service/cpu/runtime/kernel_thunk_test.cc, third_party/xla/xla/service/cpu/runtime/thunk.cc, third_party/xla/xla/service/cpu/runtime/thunk.h, third_party/xla/xla/service/cpu/thunk_emitter.cc, third_party/xla/xla/service/cpu/thunk_emitter.h",ezhulenev,False
"[xla:gpu] Fix static thread local leak in WhileThunk

PiperOrigin-RevId: 638092195",Eugene Zhulenev,ezhulenev@google.com,2024-05-29 01:07:18,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/while_thunk.cc",ezhulenev,False
"Add support for fusion-start and fusion-done operations in HLO.

PiperOrigin-RevId: 638074101",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-29 00:01:21,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc, third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.h, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/ir_emitter_context.h, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.h, third_party/xla/xla/service/gpu/runtime/thunk.h, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/async_kernel_launch_test.cc",tensorflower-gardener,False
"Remove fallback call to MLIR bridge.

PiperOrigin-RevId: 638072221",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-28 23:55:26,"tensorflow/compiler/mlir/tf2xla/api/v2/legalize_tf.cc, tensorflow/compiler/mlir/tf2xla/api/v2/legalize_tf_test.cc",tensorflower-gardener,False
"[xla:gpu] Detect dynamic slice offsets derived from loop iteration number and skip D2H transfer for them

PiperOrigin-RevId: 638061115",Eugene Zhulenev,ezhulenev@google.com,2024-05-28 23:21:49,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc",ezhulenev,False
"Collapse Stream & StreamInterface classes into a single base class.

PiperOrigin-RevId: 638057108",Kyle Lucke,klucke@google.com,2024-05-28 23:09:37,"tensorflow/c/experimental/stream_executor/BUILD, tensorflow/c/experimental/stream_executor/stream_executor_internal.h, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_stream.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/BUILD, third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc, third_party/xla/xla/stream_executor/stream.cc, third_party/xla/xla/stream_executor/stream.h, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_interface.h, third_party/xla/xla/stream_executor/tpu/BUILD, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.h, third_party/xla/xla/stream_executor/tpu/tpu_platform.h",klucke,False
"Merge pull request #65936 from tensorflow:Surya-GatherV2_axis_fix

PiperOrigin-RevId: 638055474",TensorFlower Gardener,gardener@tensorflow.org,2024-05-29 00:01:30,tensorflow/core/kernels/gather_op.cc,tensorflower-gardener,False
"Use opaque layout PJRT_Layouts_MemoryLayout in PjRtCApiBuffer::layout() to keep all the layout information.

PjRtCApiBuffer::layout() was using PJRT_Buffer_GetMemoryLayout, which will be deprecated. PJRT_Buffer_GetMemoryLayout uses explicit PJRT_Buffer_MemoryLayout which does not contain all the layout information.
PiperOrigin-RevId: 638048293",Jieying Luo,jieying@google.com,2024-05-28 22:43:45,"third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/CHANGELOG.md, third_party/xla/xla/pjrt/c/pjrt_c_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_cpu_internal.cc, third_party/xla/xla/pjrt/pjrt_c_api_client.cc",jyingl3,False
"[pt composite lowerings]

Add lowering from composite for average pool when ceil_mode=true and count_pad=true

Additionally, the following refactors:
* Simplify padding string determination
* Use intermediate struct to parse attrs into c types
* Rename some functions to be more cleared where they are used
* Constrain enum usage to within one function, so remove enum

PiperOrigin-RevId: 638046183",Luke Boyer,lukeboyer@google.com,2024-05-28 22:36:52,"tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/tests/composite-lowering.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_avg_pool.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_avg_pool.h, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_avg_pool_patterns.td, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_pass.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_utils.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_utils.h",LukeBoyer,False
"Check for int quant types before folding qconst into tpose conv.

PiperOrigin-RevId: 638044288",Luke Boyer,lukeboyer@google.com,2024-05-28 22:32:05,"tensorflow/compiler/mlir/lite/tests/quantize.mlir, tensorflow/compiler/mlir/lite/transforms/quantize_patterns.td",LukeBoyer,False
"Remove StreamInterface::implementation method, and just cast based on the stream pointer.

PiperOrigin-RevId: 638035755",Kyle Lucke,klucke@google.com,2024-05-28 22:03:16,"tensorflow/c/experimental/stream_executor/stream_executor.cc, tensorflow/c/experimental/stream_executor/stream_executor_internal.h, tensorflow/c/kernels.cc, tensorflow/compiler/jit/xla_tpu_device.cc, third_party/xla/xla/backends/interpreter/executor.cc, third_party/xla/xla/service/cpu/cpu_executable.cc, third_party/xla/xla/stream_executor/gpu/gpu_stream.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_stream.cc, third_party/xla/xla/stream_executor/stream.cc, third_party/xla/xla/stream_executor/stream.h, third_party/xla/xla/stream_executor/tpu/tpu_executable.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_op_executable.cc, third_party/xla/xla/stream_executor/tpu/tpu_stream.h, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager.cc",klucke,False
"Do not assign `ExecutionStreamAssignments` to `HloComputations` that are only reachable through embedded calls.

`ExecutionStreamAssignment` relies on the the input `HloModule` being flat. In other words, each computation must be called by a single instruction. This is generally achieved by processing the `HloModule` with `FlattenCallGraph`. However, this pass only flattens sequential calls.

The good news is that we don't need to assign `ExecutionStreamIds` to instructions invoked via embedded calls because they end up in the same kernel as the parent instruction. So this change ignores all instructions reachable through embedded calls (e.g. fusions, sorts, etc.).

PiperOrigin-RevId: 638029921",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-28 21:45:53,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/execution_stream_assignment.cc, third_party/xla/xla/service/gpu/execution_stream_assignment.h, third_party/xla/xla/service/gpu/execution_stream_assignment_test.cc",tensorflower-gardener,False
"Re-enable eager test with TFRT:TPU

PiperOrigin-RevId: 638025499",Sizhi Tan,sizhi@google.com,2024-05-28 21:31:34,tensorflow/compiler/tests/BUILD,sizhit2,False
"Update robin_map dependency to v1.3.0.

This will be needed for a future nanobind v2.0 update.

PiperOrigin-RevId: 638025070",Peter Hawkins,phawkins@google.com,2024-05-28 21:30:15,"third_party/robin_map/workspace.bzl, third_party/xla/third_party/robin_map/workspace.bzl",hawkinsp,False
"Integrate LLVM at llvm/llvm-project@9b79acedd689

Updates LLVM usage to match
[9b79acedd689](https://github.com/llvm/llvm-project/commit/9b79acedd689)

PiperOrigin-RevId: 638022318",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-28 21:21:13,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"[XLA:GPU] Remove the `emit_param_load_fn` callback in `EmitTiledScope`.

PiperOrigin-RevId: 638015368",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-28 21:00:45,third_party/xla/xla/service/gpu/ir_emitter_triton.cc,dimitar-asenov,False
"Break LegalizeTfWithTf2xla out of passes.h to make using it easier.

PiperOrigin-RevId: 638013818",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-28 20:55:45,"tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/transforms/tf_stablehlo_pass.cc, tensorflow/compiler/mlir/lite/transforms/prepare_tf.cc, tensorflow/compiler/mlir/tf2xla/transforms/BUILD, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf_with_tf2xla.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf_with_tf2xla_passes.h, tensorflow/compiler/mlir/tf2xla/transforms/passes.h, tensorflow/compiler/mlir/tf2xla/transforms/xla_legalize_tf.cc",tensorflower-gardener,False
"Correct instrumentation of MLIR bridge ph1

PiperOrigin-RevId: 638011127",Catherine Payne,paynecl@google.com,2024-05-28 20:47:02,"tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/lower_cluster_to_runtime_ops_test.cc, tensorflow/compiler/mlir/tf2xla/api/v1/cluster_tf_test.cc, tensorflow/compiler/mlir/tf2xla/api/v2/cluster_tf_test.cc, tensorflow/core/framework/metrics.cc, tensorflow/core/framework/metrics.h",paynecl,False
"[xla:cpu] NFC: Merge HostKernelEmitter into IrEmitter2

IrEmitter2 (will be renamed to IrEmitter) will be the main owner of all the state relevant for emitting host kernels IR.

PiperOrigin-RevId: 638010688",Eugene Zhulenev,ezhulenev@google.com,2024-05-28 20:45:33,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/host_kernel_emitter.cc, third_party/xla/xla/service/cpu/host_kernel_emitter.h, third_party/xla/xla/service/cpu/host_kernel_emitter_test.cc, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/ir_emitter2.h, third_party/xla/xla/service/cpu/ir_emitter2_test.cc",ezhulenev,False
"creat jax config api to allow custom pjrt client create option settings. this allows a device platform's pjrt client be aware of the calling (customer) ml framework

PiperOrigin-RevId: 638009713",Yazhou Zu,yzu@google.com,2024-05-28 20:42:18,third_party/xla/xla/python/xla_client.py,zuasia,False
"[XLA:GPU] Remove structured matchers for `SymbolicTile` tests and use string matcher instead.

Also filter out the printing of the string ""rt_vars"" when the symbolic tile
does not contain any runtime variable.

This is in preparation for adding support for constraints, which would have
required yet another matcher without this change.

PiperOrigin-RevId: 638006815",Benjamin Chetioui,bchetioui@google.com,2024-05-28 20:33:32,"third_party/xla/xla/service/gpu/model/symbolic_tile.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_test.cc",bchetioui,False
"[XLA:GPU] Extract launch dimensions for SoftMax Triton fusions.

PiperOrigin-RevId: 638002536",Oleg Shyshkov,shyshkov@google.com,2024-05-28 20:21:06,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base_test.cc",olegshyshkov,False
"[XLA:GPU] Extract tiled block creation in the Triton emitter into a standalone function and add tests.

This change both extracts the logic and generalizes it so that it works with more than one dimension.

PiperOrigin-RevId: 638002384",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-28 20:20:39,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/ir_emitter_triton_mem_utils_test.cc",dimitar-asenov,False
"[xla:cpu] Add rudimentary elemental ir emitter support for host kernels

+ extract elemental math emitter into a shared library

PiperOrigin-RevId: 637998478",Eugene Zhulenev,ezhulenev@google.com,2024-05-28 20:07:54,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/elemental_ir_emitter.h, third_party/xla/xla/service/cpu/elemental_math_emitter.cc, third_party/xla/xla/service/cpu/elemental_math_emitter.h, third_party/xla/xla/service/cpu/ir_emitter.cc, third_party/xla/xla/service/cpu/ir_emitter.h, third_party/xla/xla/service/cpu/ir_emitter2.cc, third_party/xla/xla/service/cpu/ir_emitter2.h, third_party/xla/xla/service/cpu/ir_emitter2_test.cc, third_party/xla/xla/service/elemental_ir_emitter.h",ezhulenev,False
"[XLA:GPU] Handle 0-D `MakeBlockPtr` in `EmitParameterLoad` instead of `EmitTiledSoftmax`.

This enables cleaner code in followup changes.

PiperOrigin-RevId: 637983067",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-28 19:16:22,third_party/xla/xla/service/gpu/ir_emitter_triton.cc,dimitar-asenov,False
"[xla:cpu] Add initial version of HostKernelEmitter to build host kernel LLVM IR

PiperOrigin-RevId: 637982980",Eugene Zhulenev,ezhulenev@google.com,2024-05-28 19:16:09,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/host_kernel_emitter.cc, third_party/xla/xla/service/cpu/host_kernel_emitter.h, third_party/xla/xla/service/cpu/host_kernel_emitter_test.cc, third_party/xla/xla/service/cpu/thunk_emitter.cc",ezhulenev,False
"[XLA:GPU] Remove unnecessary arg for the IndexingMap::Simplify.

PiperOrigin-RevId: 637979547",Alexander Belyaev,pifon@google.com,2024-05-28 19:04:12,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/input_slices_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/loop.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/ir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/simplify_affine.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/scatter.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.h, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc, third_party/xla/xla/service/gpu/model/symbolic_tile.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc",pifon2a,False
"[xla] Annotate called computations with instruction type after flattening call graph

Each HloComputation has a field that tells to what kind of HloInstruction it is attached to. It is lost when we clone computations to flatten the graph. Also it can be lost in earlier rewrites.

After call graph flattening it is guaranteed that HloComputation <-> HloInstruction has a 1 to 1 mapping and each computation has exactly one callee instruction.

This information is required for later rewrites.

PiperOrigin-RevId: 637975560",Eugene Zhulenev,ezhulenev@google.com,2024-05-28 18:53:21,"third_party/xla/xla/hlo/ir/hlo_computation.h, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/flatten_call_graph.cc",ezhulenev,False
"Add post-partition optimization pass to TFRTSession.

PiperOrigin-RevId: 637972800",Chris Minge,chrisminge@google.com,2024-05-28 18:44:33,tensorflow/core/tfrt/tfrt_session/tfrt_session.cc,CMinge,False
"[Multi-host GPU]Integrate GPU topology into PjRtClient for multi-host GPU support

--Integrate GpuTopology into PjRtTopologyDescription to represent multi-host GPU topologies
--Utilize GlobalTopology to build GpuTopology during PjRt client creation
--Update relevant tests

PiperOrigin-RevId: 637971846",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-28 18:41:26,"tensorflow/core/common_runtime/eager/BUILD, tensorflow/core/common_runtime/eager/context_distributed_manager.cc, tensorflow/core/tfrt/saved_model/saved_model_aot_compile.cc, third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_internal.cc, third_party/xla/xla/pjrt/distributed/topology_util.cc, third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/gpu_topology.cc, third_party/xla/xla/pjrt/gpu/gpu_topology.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler_test.cc",tensorflower-gardener,False
Adjust tolerance for XLA Conv test,Akhil Goel,akhil.goel@intel.com,2024-05-28 19:07:35,tensorflow/compiler/tests/tensor_float_32_test.py,akhilgoe,True
"Minor refactor:  rename the 'lower bound batch threads' transform to a more generic 'reconfig batch op'.  It makes no logical changes.

PiperOrigin-RevId: 637963842",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-28 18:18:53,"tensorflow/compiler/mlir/tfrt/BUILD, tensorflow/compiler/mlir/tfrt/tests/reconfig_batch_op.mlir, tensorflow/compiler/mlir/tfrt/transforms/passes.cc, tensorflow/compiler/mlir/tfrt/transforms/passes.h, tensorflow/compiler/mlir/tfrt/transforms/reconfig_batch_op.cc",tensorflower-gardener,False
"[XLA:SPMD:CollectiveMatmul]
Sort the modified dimension fields for the new dot operation.

PiperOrigin-RevId: 637963589",Seher Ellis,sacer@google.com,2024-05-28 18:18:13,"third_party/xla/xla/service/spmd/BUILD, third_party/xla/xla/service/spmd/dot_handler.cc, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc",seherellis,False
"[xla:cpu] Add support for emitting constant allocations with thunk-based runtime

To use thunk runtime in tests:

bazel test //xla/tests:copy_test_cpu --test_env=XLA_FLAGS=""--xla_dump_to=/tmp/xla-cpu --xla_cpu_use_thunk_runtime=true"" --test_env=TF_CPP_VMODULE=copy_thunk=3 --test_output=all

PiperOrigin-RevId: 637962850",Eugene Zhulenev,ezhulenev@google.com,2024-05-28 18:15:51,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/cpu_executable.cc, third_party/xla/xla/service/cpu/cpu_executable.h, third_party/xla/xla/service/cpu/runtime/buffer_allocations.cc, third_party/xla/xla/service/cpu/thunk_emitter.cc, third_party/xla/xla/service/cpu/thunk_emitter.h",ezhulenev,False
"NFC: BUILD file changes

Reverts 2ddbc6e6e3a02a0fdb9d533dcc080fbd3051e386

PiperOrigin-RevId: 637962175",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-28 18:13:52,third_party/xla/xla/stream_executor/cuda/BUILD,tensorflower-gardener,False
"[xla:gpu] Do not copy constant dynamic-slice offsets from device memory

When dynamic-slice/dynamic-update-slice offset is defined by a constant value there is no need to issue D2H transfer to move it to host, and instead we can use the value known at compile time.

This saves 2 out of 3 memory copies for dot operation inside jax.lax.scan loop.

PiperOrigin-RevId: 637935353",Eugene Zhulenev,ezhulenev@google.com,2024-05-28 17:00:06,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc",ezhulenev,False
"[Triton][NFC] Clean-up duplicate bug reference

PiperOrigin-RevId: 637922896",Mohammed Anany,manany@google.com,2024-05-28 16:18:16,"third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc",Moerafaat,False
"Integrate Triton up to [399b20e8](https://github.com/openai/triton/commits/399b20e8135ea48d0592f94d5d84486571375e3d)

PiperOrigin-RevId: 637921279",Tori Baker,vwbaker@google.com,2024-05-28 16:13:12,"third_party/triton/temporary/enable_mma_v3.patch, third_party/triton/temporary/exclude_failing_h100_tests.patch, third_party/triton/temporary/fp8_splat_partial_revert.patch, third_party/triton/temporary/reduction_mma_v3_fix.patch, third_party/triton/temporary/series.bzl, third_party/triton/workspace.bzl, third_party/triton/xla_extensions/sparse_dot_fixes_y24w17.patch, third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch, third_party/triton/xla_extensions/sparse_dot_passes.patch, third_party/xla/third_party/triton/temporary/enable_mma_v3.patch, third_party/xla/third_party/triton/temporary/exclude_failing_h100_tests.patch, third_party/xla/third_party/triton/temporary/fp8_splat_partial_revert.patch, third_party/xla/third_party/triton/temporary/reduction_mma_v3_fix.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w17.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_passes.patch, third_party/xla/xla/service/gpu/ir_emitter_triton_cuda.cc",vwbaker,False
"[TSL] Do not cut the stack trace from Status when creating fatal error message

PiperOrigin-RevId: 637917998",George Karpenkov,cheshire@google.com,2024-05-28 16:03:03,third_party/xla/third_party/tsl/tsl/platform/status.cc,cheshire,False
"[XLA:GPU] Add a util to reset programs count and deflake `gpu_compiler_test`.

Previously, running `gpu_compiler_test` in different orders would yield
different results for `GpuCompilerTest.CompiledProgramsCount`.

PiperOrigin-RevId: 637916181",Benjamin Chetioui,bchetioui@google.com,2024-05-28 15:58:08,"third_party/xla/xla/service/gpu/gpu_compiler_test.cc, third_party/xla/xla/service/gpu/metrics.cc, third_party/xla/xla/service/gpu/metrics.h",bchetioui,False
"Add cuDNN 9 Docker images with CUDA 12.1 and 12.2

PiperOrigin-RevId: 637914649",Henning Becker,hebecker@google.com,2024-05-28 15:51:49,"tensorflow/tools/ci_build/Dockerfile.rbe.cuda12.1-cudnn9.1-ubuntu20.04-manylinux2014-multipython, tensorflow/tools/ci_build/Dockerfile.rbe.cuda12.2-cudnn9.1-ubuntu20.04-manylinux2014-multipython, tensorflow/tools/toolchains/remote_config/containers.bzl, third_party/xla/third_party/tsl/tools/toolchains/remote_config/containers.bzl, third_party/xla/tools/toolchains/remote_config/containers.bzl",beckerhe,False
"Add missing newline in the output of run_hlo_module
This is very annoying if one uses the tool frequently

PiperOrigin-RevId: 637911853",Sergey Kozub,sergeykozub@google.com,2024-05-28 15:41:06,third_party/xla/xla/tools/run_hlo_module.cc,sergeykozub,False
"Fix shuffle_reduce with unsigned arguments.

arith.bitcast can't convert from ui64 to i64.

PiperOrigin-RevId: 637911146",Johannes Reifferscheid,jreiffers@google.com,2024-05-28 15:38:17,"third_party/xla/xla/service/gpu/fusions/mlir/lower_xla_gpu_to_scf.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_xla_gpu_to_scf.mlir",jreiffers,False
"Remove `use_gpu` flag from xla_cc_test

We have logic for running a test on GPU in both `xla_test` and `xla_cc_test`
which is duplicate and unnecessary.

The logic in `xla_test` is much more sophisticated and allows more fine
grained control on where to run a test. So I'm removing
all GPU functionaliy from `xla_cc_test` and migrating users to
`xla_test`.

PiperOrigin-RevId: 637901435",Henning Becker,hebecker@google.com,2024-05-28 15:03:26,"third_party/xla/xla/backends/profiler/gpu/BUILD, third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/cudnn_norm_rewriter_test.cc, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/stream_executor/cuda/BUILD, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/tests/BUILD, third_party/xla/xla/xla.bzl",beckerhe,False
"Merged commit includes the following changes:
637889039  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Remove experimental_adaptive_avx_optimization flag from XNNPACK delegate options

    It's always on now.

--
637886275  by A. Unique TensorFlower<gardener@tensorflow.org>:

    [XLA:GPU][IndexAnalysis] Use a flag for IsKnownEmpty instead of recomputing every time.

    Right now, we would try to simplify or compose with indexing maps that have a known empty domain. That's incorrect, but checking if the domain is empty every time is expensive and can be cached.

--
637876088  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal config change

--
637864812  by A. Unique TensorFlower<gardener@tensorflow.org>:

    PR #13088: [ROCm] Fix reduce_atomic_min.hlo.test

    Imported from GitHub PR https://github.com/openxla/xla/pull/13088

    Copybara import of the project:

    --
    b241e076198c03fffd8c7e3a6568070ef0223653 by mmakevic <Milica.Makevic@amd.com>:

    Fix reduce_atomic_min.hlo.test

    --
    f894f1954513019f0ca6890a27e09e0fee9d462e by mmakevic <Milica.Makevic@amd.com>:

    Remove extra space

    Merging this change closes #13088

--
637860531  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Remove xla_gpu_normalize_layouts flag.

    By now, this is really not experimental anymore.

--
637857834  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Add heuristic for when to treat Gather ops as coalesced.

--
637820064  by A. Unique TensorFlower<gardener@tensorflow.org>:

    compat: Update forward compatibility horizon to 2024-05-28

--
637820063  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Update GraphDef version to 1876.

--
637756070  by A. Unique TensorFlower<gardener@tensorflow.org>:
    Automated rollback of changelist 636206934.

637674999  by A. Unique TensorFlower<gardener@tensorflow.org>:

    [xla:cpu] Add initial support for Thunk-based execution to CpuCompiler and CpuExecutable

    Add support for compiling XLA:CPU HloModule to a ThunkSequence instead of a LLVM module and a jit-compiled function.

--
637666734  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Don't fuse inside computations that are already fused.

--
637657345  by A. Unique TensorFlower<gardener@tensorflow.org>:
    Automated rollback of changelist 636208997.

637651034  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Integrate LLVM at llvm/llvm-project@fddf350f9640

    Updates LLVM usage to match
    [fddf350f9640](https://github.com/llvm/llvm-project/commit/fddf350f9640)

--
637639233  by A. Unique TensorFlower<gardener@tensorflow.org>:

    PR #12940: [ROCm] Fix dot_bf16.hlo.test on ROCm

    Imported from GitHub PR https://github.com/openxla/xla/pull/12940

    Added additional params for `hlo_lit_tests` as a workaround, so `mi200.txtpb` would be used in `dot_bf16.hlo.test` for rocm.
    Copybara import of the project:

    --
    c3bb3a7349266a51ff22a2e18dab0afb6e81bad4 by mmakevic <Milica.Makevic@amd.com>:

    Have dot_bf16.hlo.test use mi200.txtpb for rocm

    Merging this change closes #12940

--
637632492  by A. Unique TensorFlower<gardener@tensorflow.org>:

    PR #13089: Fix reduce_large_row_to_scalar.hlo.test

    Imported from GitHub PR https://github.com/openxla/xla/pull/13089

    Copybara import of the project:

    --
    ae97058c01ca57107a2566a6f190d51f5ad4ca0e by mmakevic <Milica.Makevic@amd.com>:

    Fix reduce_large_row_to_scalar.hlo.test

    Merging this change closes #13089

--
637623329  by A. Unique TensorFlower<gardener@tensorflow.org>:
    Automated rollback of changelist 637594837.

637607386  by A. Unique TensorFlower<gardener@tensorflow.org>:
    Automated rollback of changelist 636926669.

637594837  by A. Unique TensorFlower<gardener@tensorflow.org>:

    [XLA:GPU] Pass CUDA_VERSION explicitly into CudnnFusedConvRewriter.

    Passing the CuDNN version will be the next step.

--
637580666  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Remove usage of --xla_gpu_enable_triton_hopper in autotuner

--
637578573  by A. Unique TensorFlower<gardener@tensorflow.org>:

    [XLA:GPU] Add documentation about RTVars.

--
637570959  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Update GraphDef version to 1875.

--
637570942  by A. Unique TensorFlower<gardener@tensorflow.org>:

    compat: Update forward compatibility horizon to 2024-05-27

--
637561798  by A. Unique TensorFlower<gardener@tensorflow.org>:

    PR #12979: [NVIDIA] Fix PGLE for latency estimation of p2p instructions

    Imported from GitHub PR https://github.com/openxla/xla/pull/12979

    PGLE doesn't recognize p2p instruction such as send or recv as async operations.
    This adds the utility to check if instruction is a p2p communication instruction.
    Copybara import of the project:

    --
    469b2d31ff6b0270dda28f8754462681514d0e04 by TJ Xu <tjx@nvidia.com>:

    fix pgle not recognizing p2p instructions

    Merging this change closes #12979

--
637560035  by A. Unique TensorFlower<gardener@tensorflow.org>:

    [xla:gpu] Track loop iteration counter of a WhileThunk in thread local variable

--
637552495  by A. Unique TensorFlower<gardener@tensorflow.org>:

    PR #13056: Use `operator->` with XLA FFI Result Buffers in custom call docs

    Imported from GitHub PR https://github.com/openxla/xla/pull/13056

    Copybara import of the project:

    --
    7940a1a02a0f93736a88406958edf62488bdbe19 by Andrey Portnoy <aportnoy@nvidia.com>:

    Use `operator->` with XLA FFI Result Buffers in custom call docs

    Merging this change closes #13056

--
637547404  by A. Unique TensorFlower<gardener@tensorflow.org>:

    PR #13068: Introduce the Blackwell compute capability.

    Imported from GitHub PR https://github.com/openxla/xla/pull/13068

    Introduce the Blackwell compute capability. Future Blackwell-specific changes can be guarded by this capability.
    Copybara import of the project:

    --
    cc1adebc95166b2d3979cc01de954a1895515ad4 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

    Introduce the Blackwell compute capability. Future Blackwell-specific changes can be guarded by this capability.

    Merging this change closes #13068

--
637541058  by A. Unique TensorFlower<gardener@tensorflow.org>:

    PR #13061: Add Tirton support for XLA clamp

    Imported from GitHub PR https://github.com/openxla/xla/pull/13061

    Add Triton support for XLA clamp instruction. Clamp is a common instruction found in FP8 fusions, and will be used in cuDNN fusions:

    This is a fix for perviously rolled-back PR due to internal ir_emitter_triton test failure: https://github.com/openxla/xla/commit/d114eceb0afa4289e1ba4468a0474d2c1ffe4123

    cc @sergeykozub @sergachev
    Copybara import of the project:

    --
    3496ba2fa86571ab290e0881dd06400c415d80b6 by Elfie Guo <elfieg@nvidia.com>:

    Add Tirton support for XLA clamp.

    Merging this change closes #13061

--
637366630  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Update GraphDef version to 1874.

--
637366295  by A. Unique TensorFlower<gardener@tensorflow.org>:

    compat: Update forward compatibility horizon to 2024-05-26

--
637185396  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Automated Code Change

--
637168744  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Update GraphDef version to 1873.

--
637168421  by A. Unique TensorFlower<gardener@tensorflow.org>:

    compat: Update forward compatibility horizon to 2024-05-25

--
637166714  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Attempt loading libOpenCL.so before libOpenCL-pixel.so

--
637137789  by A. Unique TensorFlower<gardener@tensorflow.org>:

    feat: Implement hermetic Python version matching system Python version

--
637102058  by A. Unique TensorFlower<gardener@tensorflow.org>:

    [IFRT] Add xla::ifrt::Sharding::IsFullyReplicated()

    IFRT Sharding type gains `IsFullyReplicated()`, which quickly tells if the
    sharding represents a fully-replicated sharding.

    The main motivation is to make full replication information queriable at IFRT
    shardings and prepare for enabling IFRT implementations to handle full
    replication directly.

    There are a preset of rules:

    * `SingleDeviceSharding` is trivially fully replicated by its definition.
    * `ConcreteSharding` and `OpaqueSharding` is not fully replicated. They have special cases where it may be fully replicated, but the user is advised to use a more specific sharding type to represent such cases.
    * `ConcreteEvenSharding` may/may not fully replicated. This is controlled at creation time.
    * `ShardingParamSharding` and (IFRT) `HloSharding` depend on whether their lower-level sharding represents full replication.

    `ConcreteEvenSharding` is a noteworthy case where the full replication information
    does not come from the existing source of the information. This is because the
    creators of this sharding (e.g., JAX) typically has the information, but the
    replication information is lost when coercing it into `ConcreteEvenSharding`.
    This problem will be gradually less problematic once JAX uses a higher-level
    IFRT sharding type (mainly (IFRT) `HloSharding`) at more places.

    This change extends the `Sharding` type, but the new method is not used by any
    existing code.

--
637097325  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Ensure delegates properly delegate models

--
637080761  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Add barrier logs.

--
637070664  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Clean up include and build file

--
637069670  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Use the `LoadedClientGraph`'s copy of `FunctionLibraryDefinition` instead of getting it from the `FallbackState` in the parent `GraphExecutor`

--
637069442  by A. Unique TensorFlower<gardener@tensorflow.org>:

    update doc ref

--
637061122  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Refactor exhaustive testing of unary float32 functions into a library.

--
637046941  by A. Unique TensorFlower<gardener@tensorflow.org>:

    fix profile_util's compatible_with tag typo

--
637028365  by A. Unique TensorFlower<gardener@tensorflow.org>:

    [XLA] Refactor HostOffloader.

    Change HostOffloader's algorithm for identifying host memory offloading. This approach supports every conceivable host memory offloading pattern (as of today).

--
637023690  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Simplify volumes for docker container in XLA build script

--
637018892  by A. Unique TensorFlower<gardener@tensorflow.org>:

    move flatbuffer_compatibility_test target to tflite compiler

--
637008187  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Add copyright notice to profiler_utils.cc

--
636990162  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Adds a proto profile summary formatter to the TFLite benchmark.
    Adds a Python script to convert benchmark profile protos to a JSON consumable by the model-explorer.

--
636976463  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Add profiler_util to enable flexibly tpu profiler registration for different purposes

--

PiperOrigin-RevId: 637889039",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-28 14:13:20,"tensorflow/compiler/mlir/lite/schema/BUILD, tensorflow/compiler/mlir/lite/schema/flatbuffer_compatibility_test.cc, tensorflow/compiler/mlir/lite/schema/schema_v3b.fbs, tensorflow/core/kernels/BUILD, tensorflow/core/kernels/gather_nd_op.cc, tensorflow/core/kernels/gather_nd_op.h, tensorflow/core/kernels/scatter_nd_op.cc, tensorflow/core/kernels/scatter_nd_op.h, tensorflow/core/kernels/scatter_nd_op_cpu_impl.h, tensorflow/core/kernels/scatter_nd_op_gpu.cu.cc, tensorflow/core/ops/uniform_quant_ops.cc, tensorflow/core/public/version.h, tensorflow/core/tfrt/common/BUILD, tensorflow/core/tfrt/common/async_value_tensor.cc, tensorflow/core/tfrt/common/async_value_tensor.h, tensorflow/core/tfrt/common/create_pjrt_client_util.cc, tensorflow/core/tfrt/common/create_pjrt_client_util.h, tensorflow/core/tfrt/common/create_pjrt_client_util_test.cc, tensorflow/core/tfrt/common/global_state.cc, tensorflow/core/tfrt/common/pjrt_client_factory_options.h, tensorflow/core/tfrt/common/pjrt_client_factory_registry.cc, tensorflow/core/tfrt/common/pjrt_client_factory_registry.h, tensorflow/core/tfrt/common/pjrt_cpu_client_registration.cc, tensorflow/core/tfrt/common/pjrt_cpu_client_registration_test.cc, tensorflow/core/tfrt/common/pjrt_gpu_client_registration.cc, tensorflow/core/tfrt/common/pjrt_gpu_client_registration_test.cc, tensorflow/core/tfrt/common/pjrt_state.cc, tensorflow/core/tfrt/common/pjrt_state.h, tensorflow/core/tfrt/common/pjrt_state_test.cc, tensorflow/core/tfrt/common/pjrt_util.cc, tensorflow/core/tfrt/common/pjrt_util.h, tensorflow/core/tfrt/common/pjrt_util_test.cc, tensorflow/core/tfrt/graph_executor/graph_executor.cc, tensorflow/lite/CMakeLists.txt, tensorflow/lite/delegates/gpu/cl/opencl_wrapper.cc, tensorflow/lite/delegates/utils/experimental/stable_delegate/BUILD, tensorflow/lite/delegates/utils/experimental/stable_delegate/kernel_test_main.cc, tensorflow/lite/delegates/xnnpack/conv_2d_test.cc, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.h, tensorflow/lite/kernels/test_util.cc, tensorflow/lite/kernels/test_util.h, tensorflow/lite/profiling/BUILD, tensorflow/lite/profiling/profile_summarizer.cc, tensorflow/lite/profiling/profile_summarizer.h, tensorflow/lite/profiling/profile_summary_formatter.cc, tensorflow/lite/profiling/profile_summary_formatter.h, tensorflow/lite/profiling/profile_summary_formatter_test.cc, tensorflow/lite/profiling/proto/BUILD, tensorflow/lite/profiling/proto/CMakeLists.txt, tensorflow/lite/profiling/proto/profiling_info.proto, tensorflow/lite/python/BUILD, tensorflow/lite/schema/BUILD, tensorflow/lite/tools/BUILD, tensorflow/lite/tools/benchmark/CMakeLists.txt, tensorflow/lite/tools/benchmark/README.md, tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc, tensorflow/lite/tools/benchmark/profiling_listener.cc, tensorflow/lite/tools/benchmark/profiling_listener.h, tensorflow/lite/tools/cmake/modules/FindProtobuf.cmake, tensorflow/lite/tools/cmake/modules/protobuf.cmake, tensorflow/python/compat/compat.py, third_party/llvm/generated.patch, third_party/llvm/workspace.bzl, third_party/py/python_init_repositories.bzl, third_party/py/python_repo.bzl, third_party/xla/.kokoro/linux/build.sh, third_party/xla/docs/custom_call.md, third_party/xla/docs/indexing.md, third_party/xla/third_party/py/python_init_repositories.bzl, third_party/xla/third_party/py/python_repo.bzl, third_party/xla/third_party/tsl/third_party/py/python_init_repositories.bzl, third_party/xla/third_party/tsl/third_party/py/python_repo.bzl, third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/ifrt/sharding.cc, third_party/xla/xla/python/ifrt/sharding.h, third_party/xla/xla/python/ifrt/sharding_serdes.cc, third_party/xla/xla/python/ifrt/sharding_serdes.proto, third_party/xla/xla/python/ifrt/sharding_serdes_test.cc, third_party/xla/xla/python/ifrt/sharding_test.cc, third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/xla_sharding.cc, third_party/xla/xla/python/pjrt_ifrt/xla_sharding.h, third_party/xla/xla/python/pjrt_ifrt/xla_sharding_test.cc, third_party/xla/xla/python/profiler.cc, third_party/xla/xla/python/profiler_utils.cc, third_party/xla/xla/python/profiler_utils.h, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/cpu_executable.cc, third_party/xla/xla/service/cpu/cpu_executable.h, third_party/xla/xla/service/cpu/runtime/BUILD, third_party/xla/xla/service/cpu/runtime/copy_thunk.cc, third_party/xla/xla/service/cpu/runtime/thunk.cc, third_party/xla/xla/service/cpu/runtime/thunk.h, third_party/xla/xla/service/cpu/thunk_emitter.cc, third_party/xla/xla/service/cpu/thunk_emitter.h, third_party/xla/xla/service/gpu/conv_layout_normalization_test.cc, third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/instruction_fusion.cc, third_party/xla/xla/service/gpu/instruction_fusion.h, third_party/xla/xla/service/gpu/instruction_fusion_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/coalescing_analysis.h, third_party/xla/xla/service/gpu/model/coalescing_analysis_test.cc, third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc, third_party/xla/xla/service/gpu/model/indexing_test_utils.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/while_thunk.cc, third_party/xla/xla/service/gpu/runtime/while_thunk.h, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/dot_bf16.hlo, third_party/xla/xla/service/gpu/tests/reduce_atomic_min.hlo, third_party/xla/xla/service/gpu/tests/reduce_large_row_to_scalar.hlo, third_party/xla/xla/service/gpu/triton_support.cc, third_party/xla/xla/service/host_offloader.cc, third_party/xla/xla/service/host_offloader.h, third_party/xla/xla/service/host_offloader_test.cc, third_party/xla/xla/service/latency_hiding_scheduler.cc, third_party/xla/xla/service/latency_hiding_scheduler.h, third_party/xla/xla/service/profile_guided_latency_estimator.cc, third_party/xla/xla/service/profile_guided_latency_estimator_test.cc, third_party/xla/xla/stream_executor/device_description.h, third_party/xla/xla/tests/exhaustive/BUILD, third_party/xla/xla/tests/exhaustive/exhaustive_test_main.cc, third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_f32_or_smaller.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/xla/xla.proto, third_party/xla/xla/xla_data.proto",tensorflower-gardener,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/cudnn_workspace_rewriter.h

PiperOrigin-RevId: 636966632",Kuy Mainwaring,kuym@google.com,2024-05-24 17:42:30,third_party/xla/xla/service/gpu/cudnn_workspace_rewriter.h,kuym,False
"[xla:python] Add support for registering custom call targets for all XLA execution stages and for XLA FFI traits

PiperOrigin-RevId: 636963591",Eugene Zhulenev,ezhulenev@google.com,2024-05-24 17:32:41,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_client.pyi, third_party/xla/xla/python/xla_client_test.py, third_party/xla/xla/python/xla_compiler.cc",ezhulenev,False
"[xla:ffi] Add XLA_FFI_ExecutionStage enum to call frame and add to to error logs

Add execution stage to error logs to be able to distinguish errors coming from different execution stages.

PiperOrigin-RevId: 636956894",Eugene Zhulenev,ezhulenev@google.com,2024-05-24 17:10:10,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/call_frame.h, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_api.h, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.h",ezhulenev,False
"Update cuDNN to version 9.1.1 in JAX

PiperOrigin-RevId: 636956696",Henning Becker,hebecker@google.com,2024-05-24 17:09:34,"ci/official/containers/linux_arm64/cuda.packages.txt, third_party/xla/.kokoro/jax/build.sh",beckerhe,False
"Use graph_executor fallback_state for ProcessFunctionLibraryRuntime func_lib_def, and ConvertTfMlirToBef.

PiperOrigin-RevId: 636949843",Chris Minge,chrisminge@google.com,2024-05-24 16:49:30,tensorflow/core/tfrt/graph_executor/graph_executor.cc,CMinge,False
"[xla:cpu] Add initial Thunk-based runtime implementation to XLA:CPU backend

Using XLA:GPU Thunks as an example start XLA:CPU interpreter runtime from a basic definition of Thunk and BufferAllocations.

Long term CPU and GPU Thunks will be unified under a shared XLA runtime.

PiperOrigin-RevId: 636945087",Eugene Zhulenev,ezhulenev@google.com,2024-05-24 16:30:30,"third_party/xla/xla/service/cpu/runtime/BUILD, third_party/xla/xla/service/cpu/runtime/buffer_allocations.cc, third_party/xla/xla/service/cpu/runtime/buffer_allocations.h, third_party/xla/xla/service/cpu/runtime/copy_thunk.cc, third_party/xla/xla/service/cpu/runtime/copy_thunk.h, third_party/xla/xla/service/cpu/runtime/copy_thunk_test.cc, third_party/xla/xla/service/cpu/runtime/thunk.cc, third_party/xla/xla/service/cpu/runtime/thunk.h",ezhulenev,False
"[XLA:GPU] Bump up default vector size for column reduction to 4

Experiments across different GPUs/shapes/vector sizes show that whenever
possible, larger vector size is always beneficial.

PiperOrigin-RevId: 636931880",George Karpenkov,cheshire@google.com,2024-05-24 15:43:37,"third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",cheshire,False
"Reverts b08e2063af508844dc5c610c9774d06fcc312578

PiperOrigin-RevId: 636926669",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-24 15:22:58,"third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc, third_party/xla/xla/service/gpu/triton_support.cc",tensorflower-gardener,False
"Generally allow intermediate ops with multiple users in epilogues.

Before, we only allowed it for reduce epilogues, but after a recent fix this
should also work correctly for other fusions with epilogues.

Reverts changelist 602615649

PiperOrigin-RevId: 636905382",Adrian Kuegel,akuegel@google.com,2024-05-24 14:03:45,"third_party/xla/xla/service/gpu/ir_emission_utils.cc, third_party/xla/xla/service/gpu/ir_emission_utils.h, third_party/xla/xla/service/gpu/ir_emission_utils_test.cc, third_party/xla/xla/service/gpu/multi_output_fusion_test.cc",akuegel,False
"[XLA:GPU] Remove ignore_control_dependencies from HloCSE pass.

PiperOrigin-RevId: 636903955",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-24 13:59:47,third_party/xla/xla/service/gpu/gpu_compiler.cc,golechwierowicz,False
"PR #12948: [ROCm] Provide run_xla script to facilitate running XLA unit tests

Imported from GitHub PR https://github.com/openxla/xla/pull/12948

This is first step in enabling CI runs on AMD hardware. Planning to use this repository to house ROCm related scripts.
Copybara import of the project:

--
5465e8b4b83302dabf6ceb64552fd841fb29f2b0 by Harsha HS <harsha.havanurshamsundara@amd.com>:

[ROCm] Provide run_xla script to facilitate running XLA unit tests

--
d5a1217b452539607571ca4c8d76907722fd05bc by Harsha H S <hsharsha@users.noreply.github.com>:

Update run_xla.sh

Merging this change closes #12948

PiperOrigin-RevId: 636901595",Harsha H S,hsharsha@users.noreply.github.com,2024-05-24 13:47:53,third_party/xla/build_tools/rocm/run_xla.sh,hsharsha,False
"Remove GOOGLE_CUDA and TENSORFLOW_USE_ROCM defines from topk_specializer.cc

PiperOrigin-RevId: 636891351",Thomas Joerg,tjoerg@google.com,2024-05-24 13:03:39,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/topk_specializer.cc",thomasjoerg,False
"PR #13020: Support lowering XLA clamp instruction to cuDNN.

Imported from GitHub PR https://github.com/openxla/xla/pull/13020

Support lowering XLA clamp instruction to cuDNN.
cc @sergachev
Copybara import of the project:

--
47dc71f2a0d5887461a0b7d985328442e0e8da2f by Elfie Guo <elfieg@nvidia.com>:

Support lowering clamp instruction to cuDNN.

Merging this change closes #13020

PiperOrigin-RevId: 636875273",Elfie Guo,elfieg@nvidia.com,2024-05-24 11:59:00,"third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc, third_party/xla/xla/service/gpu/triton_support.cc",elfiegg,False
"[XLA:GPU] Let TritonFusion depend on CUDA or ROCm headers (transitively).

So far, we guard the dep with `#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM` and return an unimplemented error otherwise. However, having `""triton""` in the build graph makes no sense if neither CUDA nor ROCm toolkits are available at build time. This PR moves the `if_gpu_is_configured` branching upwards in the build graph to `""ir_emitter_unnested`"".

PiperOrigin-RevId: 636875057",Thomas Joerg,tjoerg@google.com,2024-05-24 11:57:45,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/triton.cc",thomasjoerg,False
"PR #12297: Fix side output index computation for transpose fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/12297

There exist bug in ComputeThreadIdToOutputIndexing func. Currently, this func can not calculate indexing map correctly for sided output. Fix it and add corresponding test.
Copybara import of the project:

--
807c3cc82b1cb58ded59e8900135c29ee949c605 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix sided ouput index computation for transpose fusion

--
0ca08e78c1da3c43dee32460e1244a8d7e6e2aea by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

restore

--
2f187c842eeddaf941416b321b9fe7c032721a59 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

format

--
fdb4d065da077e70a9b3544b4df78ce0b555012a by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

remove change to input indexing due to equivalence

--
5484f950e16b6c97b65ca9d56bf6fa3dd65b909f by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

use transpose hero index

--
5f08e19051e235419c8ac7f7dbdfb8c2ba5934f2 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

typo

--
4804d1cfa6f22a09a29760753cbda3030485a0fa by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix build error

--
468cc85886ae15b60dcc8e5edc17530e3d62efa8 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix condition when side ouput inputs shape is not equal to output shape

--
5f33d319c0be6cb8d840d35c8a54210a9a4aeec0 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix transpose test

--
d362fb2dffca7a6172d2386db3d105ac91a96ee0 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix error caused by func signature change

--
c5fb450cf36a4e07b2e2de0e71e4c01cb1d1e866 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix test

--
cf78f46a2961a58ee31636022055e9f04b594fd0 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

add comment to illustrate what input indexing mean for side ouput

--
54789eb05ecc751881ea34c02346d19a1660bf9d by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

add test to check if root0 and root1 has same input indexing when share input

--
f7db8e3e3f928311f210b3dd4111937a129b839c by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix hlo verifier error

--
8567c4e9dd516120e0fe14a1bcc1ee573eb7da4c by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

missing conflict

--
f0c1a66df84b2af1f8673b9ab7b2a4fb7c2144f3 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

format

--
7763742ff0138f6e297487414858be42ac671697 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix bugs caused by vectorization support of transpose mlir emitter

--
bc1d3854e90f66b2874d54bbcdd48a45d8dccf1c by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

set correuse ranpose hero index

Merging this change closes #12297

PiperOrigin-RevId: 636868860",lingzhi98,103185827+lingzhi98@users.noreply.github.com,2024-05-24 11:23:09,"third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/transpose_test.cc",lingzhi98,False
"Consistently use {} for Interval construction.

Apparently some compiler has a problem with ().

PiperOrigin-RevId: 636866646",Johannes Reifferscheid,jreiffers@google.com,2024-05-24 11:12:05,third_party/xla/xla/service/gpu/model/indexing_map_test.cc,jreiffers,False
"PR #12864: [ROCm] fix DeviceAllocate code

Imported from GitHub PR https://github.com/openxla/xla/pull/12864

Copybara import of the project:

--
2e6dfa841a495c1f0babf0ff6f877bc1866bf319 by Ruturaj4 <ruturaj.vaidya@amd.com>:

[ROCm] fix DeviceAllocate code

Merging this change closes #12864

PiperOrigin-RevId: 636848518",Ruturaj Vaidya,ruturaj.vaidya@amd.com,2024-05-24 09:49:43,third_party/xla/xla/stream_executor/rocm/rocm_driver.cc,Ruturaj4,False
"compat: Update forward compatibility horizon to 2024-05-24

PiperOrigin-RevId: 636838738",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-24 09:02:43,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1872.

PiperOrigin-RevId: 636838698",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-24 09:02:33,tensorflow/core/public/version.h,tensorflower-gardener,False
"PR #13021: Fix build issue of gpu_sparse_dot_test

Imported from GitHub PR https://github.com/openxla/xla/pull/13021

replaces EXPECT_OK with TF_EXPECT_OK and added relevant header file and dependency.

Error:
#10 1431.9 xla/service/gpu/tests/gpu_sparse_dot_test.cc:134:3: error: use of undeclared identifier 'EXPECT_OK'
[1792](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1792)#10 1431.9   134 |   EXPECT_OK(dense_module);
[1793](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1793)#10 1431.9       |   ^
[1794](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1794)#10 1431.9 xla/service/gpu/tests/gpu_sparse_dot_test.cc:137:3: error: use of undeclared identifier 'EXPECT_OK'
[1795](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1795)#10 1431.9   137 |   EXPECT_OK(dense_result);
[1796](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1796)#10 1431.9       |   ^
[1797](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1797)#10 1431.9 xla/service/gpu/tests/gpu_sparse_dot_test.cc:158:3: error: use of undeclared identifier 'EXPECT_OK'
[1798](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1798)#10 1431.9   158 |   EXPECT_OK(sparse_module);
[1799](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1799)#10 1431.9       |   ^
[1800](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1800)#10 1431.9 xla/service/gpu/tests/gpu_sparse_dot_test.cc:161:3: error: use of undeclared identifier 'EXPECT_OK'
[1801](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1801)#10 1431.9   161 |   EXPECT_OK(sparse_result);
[1802](https://gitlab-master.nvidia.com/dl/openxla/ci/-/jobs/94442414#L1802)#10 1431.9       |   ^
Copybara import of the project:

--
a7d07b02230794d9c13175b39473666d5d067c54 by hmonishN <hmonish@nvidia.com>:

fixing build issue for this test

--
e45b3b975c40b318ac4918859b364d8e8c3b304a by hmonishN <hmonish@nvidia.com>:

fix build error

--
077b7a5b8277cb2e55b57aca64102871326afd0d by Harshit Monish <143435143+hmonishN@users.noreply.github.com>:

Incorporated review comment.

Merging this change closes #13021

PiperOrigin-RevId: 636832662",Harshit Monish,143435143+hmonishN@users.noreply.github.com,2024-05-24 08:32:40,"third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gpu_sparse_dot_test.cc",hmonishN,False
"PR #13039: [XLA:GPU] Add debug code to VLOG allocation info if GpuExecutable has any memory addressed changed.

Imported from GitHub PR https://github.com/openxla/xla/pull/13039

Help to identify command buffer perf issues.

Copybara import of the project:

--
05c24d4707017755ee75a1d6058928fccfac1f83 by Shawn Wang <shawnw@nvidia.com>:

Add debug code to dump if GpuExecutable has any memory addressed changed

--
5fabaab97573a8059f0fe993514c03332c7e6ae8 by Shawn Wang <shawnw@nvidia.com>:

add comments

Merging this change closes #13039

PiperOrigin-RevId: 636827911",Shawn Wang,shawnw@nvidia.com,2024-05-24 08:12:17,"third_party/xla/xla/service/buffer_assignment.cc, third_party/xla/xla/service/buffer_assignment.h, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/gpu_executable.h",shawnwang18,False
"Fix multi-output in-place DUS.

This fixes jax/tests:pmap_test_gpu_2gpu.

PiperOrigin-RevId: 636822010",Johannes Reifferscheid,jreiffers@google.com,2024-05-24 07:45:54,"third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc",jreiffers,False
"Integrate LLVM at llvm/llvm-project@10dc3a8e916d

Updates LLVM usage to match
[10dc3a8e916d](https://github.com/llvm/llvm-project/commit/10dc3a8e916d)

PiperOrigin-RevId: 636778164",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-24 04:21:55,"tensorflow/dtensor/mlir/BUILD, tensorflow/dtensor/mlir/dtensor_allreduce_combine_optimization.cc, third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Allow specifying compilation environment for ifrt compilation

PiperOrigin-RevId: 636770238",Deqiang Chen,deqiangc@google.com,2024-05-24 03:41:52,"tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler_test.cc, tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_executable_registry_test.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test_util.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc, tensorflow/core/tfrt/saved_model/tests/saved_model_ifrt_test.cc",deqiangc,False
"NFC: BUILD file changes

Reverts 6e7d46a6730224d5c3e1fd66e0273ad4f42b56fc

PiperOrigin-RevId: 636758334",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-24 02:53:50,third_party/xla/xla/stream_executor/cuda/BUILD,tensorflower-gardener,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/fusions/cudnn_test.cc

PiperOrigin-RevId: 636727962",Kuy Mainwaring,kuym@google.com,2024-05-24 00:23:40,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc",kuym,False
"PR #13034: Fix typo

Imported from GitHub PR https://github.com/openxla/xla/pull/13034

Copybara import of the project:

--
6f47dc87ed665bc6723e6fb62f93fbcc20c858b5 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Fix typo

Merging this change closes #13034

PiperOrigin-RevId: 636722167",Dimitris Vardoulakis,dvardoulakis@nvidia.com,2024-05-24 00:00:27,third_party/xla/xla/service/gpu/stream_executor_util.cc,dimvar,False
"allow a tpu pjrt client to be created with extra options

PiperOrigin-RevId: 636716482",Yazhou Zu,yzu@google.com,2024-05-23 23:38:27,"third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_client.pyi",zuasia,False
"Remove unused hlo_proto import in local_client

PiperOrigin-RevId: 636713752",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-23 23:29:32,third_party/xla/xla/client/local_client.h,mlevesquedion,False
"Extend MakeFakeLiteralWithSameValue() to support tuple shape

PiperOrigin-RevId: 636699991",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 22:40:55,"third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc",tensorflower-gardener,False
"NFC: BUILD file changes

PiperOrigin-RevId: 636696802",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 22:30:24,third_party/xla/xla/stream_executor/cuda/BUILD,tensorflower-gardener,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/ir_emitter_triton.h

PiperOrigin-RevId: 636693962",Kuy Mainwaring,kuym@google.com,2024-05-23 22:21:44,third_party/xla/xla/service/gpu/ir_emitter_triton.h,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/hlo_traversal.h

PiperOrigin-RevId: 636693913",Kuy Mainwaring,kuym@google.com,2024-05-23 22:21:33,third_party/xla/xla/service/gpu/hlo_traversal.h,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/gpu_windowed_einsum_handler.{cc,h}

PiperOrigin-RevId: 636693767",Kuy Mainwaring,kuym@google.com,2024-05-23 22:21:02,"third_party/xla/xla/service/gpu/gpu_windowed_einsum_handler.cc, third_party/xla/xla/service/gpu/gpu_windowed_einsum_handler.h",kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/gpu_fusible_test.cc

PiperOrigin-RevId: 636693448",Kuy Mainwaring,kuym@google.com,2024-05-23 22:19:46,third_party/xla/xla/service/gpu/gpu_fusible_test.cc,kuym,False
"Add support for local wheel files in hermetic python

This allows users to specify a list of workspaces that contain pre-built local wheels without need to manually add them in requirements.txt files.

The wheels will be automatically processed by bazel rules and injected into the requirements_lock_<py_version>.txt on the fly (assuming `HERMETIC_PYTHON_VERSION=py_version`).

This feature is mainly inspired by pytorch/xla demand, since building pytorch/xla implies first building pytorch repo locally and then pointing to its artifacts (both raw .so files and entire .whl) in pytorch/xla build.

This also helps JAX to facilitate build_jaxlib=false case, as it would eliminate need to manually update requirements_locak.txt files in JAX CI as well.

PiperOrigin-RevId: 636691616",Vadym Matsishevskyi,vam@google.com,2024-05-23 22:13:59,"third_party/py/python_init_pip.bzl, third_party/py/python_init_repositories.bzl, third_party/py/python_repo.bzl, third_party/xla/third_party/py/python_init_pip.bzl, third_party/xla/third_party/py/python_init_repositories.bzl, third_party/xla/third_party/py/python_repo.bzl, third_party/xla/third_party/tsl/third_party/py/python_init_pip.bzl, third_party/xla/third_party/tsl/third_party/py/python_init_repositories.bzl, third_party/xla/third_party/tsl/third_party/py/python_repo.bzl",vam-google,False
"Remove artifact registry auth configuration since we've made the image public.

PiperOrigin-RevId: 636679999",Quoc Truong,quoct@google.com,2024-05-23 21:35:40,third_party/xla/.kokoro/linux/build.sh,quoctruong,False
"Added int/uint2 dtypes to the various bits of the XLA runtime

See google/jax#21369.

PiperOrigin-RevId: 636667084",Sergei Lebedev,slebedev@google.com,2024-05-23 20:57:41,"third_party/xla/xla/pjrt/c/pjrt_c_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.cc, third_party/xla/xla/python/ifrt/dtype.h, third_party/xla/xla/python/ifrt/dtype.proto, third_party/xla/xla/python/pjrt_ifrt/pjrt_array.cc, third_party/xla/xla/python/py_values.cc, third_party/xla/xla/python/types.cc, third_party/xla/xla/python/types.h, third_party/xla/xla/python/xla_extension/__init__.pyi, third_party/xla/xla/service/llvm_ir/llvm_util.cc",superbobry,False
"Reverts 4ce1a064f2e4b0c141aa64f590716db1cc9d74df

PiperOrigin-RevId: 636666940",Luke Boyer,lukeboyer@google.com,2024-05-23 20:57:12,"tensorflow/compiler/mlir/lite/tests/quantize-dynamic-range.mlir, tensorflow/compiler/mlir/lite/tests/quantize.mlir, tensorflow/compiler/mlir/lite/transforms/quantize_patterns.td",LukeBoyer,False
"Add option recreate_buffers_between_repeats to control whether recreate PjRt buffer between repeated runs

PiperOrigin-RevId: 636635793",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 19:19:00,"third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.h",tensorflower-gardener,False
"Add TensorFlow version to `TPU_ML_PLATFORM_VERSION` environment variables.

This will allow us to track the version of TensorFlow that is being used to run on Cloud TPU.

PiperOrigin-RevId: 636635626",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 19:18:23,"tensorflow/python/tpu/BUILD, tensorflow/python/tpu/__init__.py",tensorflower-gardener,False
"Migrate away from llvm::StringRef::equals

Note that llvm::StringRef::equals has been deprecated upstream.

PiperOrigin-RevId: 636616762",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 18:24:44,third_party/xla/xla/python/refine_polymorphic_shapes.cc,tensorflower-gardener,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/runtime/{in,out}feed_thunk.cc

PiperOrigin-RevId: 636613353",Kuy Mainwaring,kuym@google.com,2024-05-23 18:14:33,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/infeed_thunk.cc, third_party/xla/xla/service/gpu/runtime/outfeed_thunk.cc",kuym,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 636596301",Kyle Lucke,klucke@google.com,2024-05-23 17:28:47,"third_party/xla/xla/backends/profiler/gpu/cupti_buffer_events.cc, third_party/xla/xla/backends/profiler/gpu/cupti_tracer.cc, third_party/xla/xla/backends/profiler/gpu/device_tracer_cuda.cc, third_party/xla/xla/backends/profiler/gpu/device_tracer_rocm.cc, third_party/xla/xla/client/BUILD, third_party/xla/xla/client/client.cc, third_party/xla/xla/client/lib/BUILD, third_party/xla/xla/client/lib/math.cc, third_party/xla/xla/client/lib/matrix.cc, third_party/xla/xla/client/lib/tridiagonal.cc, third_party/xla/xla/client/lib/tridiagonal_test.cc, third_party/xla/xla/client/local_client.cc, third_party/xla/xla/client/padding.cc, third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/outfeed_receiver_test.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/xplane_to_profile_instructions.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/annotation.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/llvm_ir/BUILD, third_party/xla/xla/service/llvm_ir/dynamic_update_slice_util.cc, third_party/xla/xla/service/llvm_ir/kernel_support_library.cc, third_party/xla/xla/service/llvm_ir/kernel_support_library.h, third_party/xla/xla/service/llvm_ir/llvm_util.cc, third_party/xla/xla/service/llvm_ir/loop_emitter.cc, third_party/xla/xla/service/llvm_ir/sort_util.cc",klucke,False
"[xla] Move the shape check in HloReshapeInstruction constructor back to
CreateReshape.

PiperOrigin-RevId: 636593668",Bixia Zheng,bixia@google.com,2024-05-23 17:21:25,"third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instructions.cc",bixia1,False
"Make Stream inherit from StreamInterface, and all the concrete StreamInterfaces inherit from Stream.

This is the first step in eliminating StreamInterface as a separate class, and making Stream an abstract base class.

PiperOrigin-RevId: 636592651",Kyle Lucke,klucke@google.com,2024-05-23 17:18:46,"tensorflow/c/experimental/stream_executor/stream_executor.cc, tensorflow/c/experimental/stream_executor/stream_executor_internal.h, third_party/xla/xla/backends/interpreter/executor.h, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_stream.cc, third_party/xla/xla/stream_executor/gpu/gpu_stream.h, third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_stream.cc, third_party/xla/xla/stream_executor/host/host_stream.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream.cc, third_party/xla/xla/stream_executor/stream.h, third_party/xla/xla/stream_executor/stream_interface.h, third_party/xla/xla/stream_executor/tpu/BUILD, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_stream.h, third_party/xla/xla/stream_executor/tpu/tpu_stream_interface.h",klucke,False
"[GPU] Remove spam logs.

PiperOrigin-RevId: 636577910",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 16:33:55,third_party/xla/xla/stream_executor/integrations/tf_allocator_adapter.h,tensorflower-gardener,False
"Increase the tensor merge size limit for the dot merger pass from 16 -> 32 MB

PiperOrigin-RevId: 636576708",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 16:29:36,third_party/xla/xla/service/gpu/gpu_compiler.cc,tensorflower-gardener,False
"Update cuDNN to version 9.1.1 in XLA

PiperOrigin-RevId: 636572106",Henning Becker,hebecker@google.com,2024-05-23 16:13:36,"tensorflow/tools/ci_build/Dockerfile.rbe.cuda12.3-cudnn9.1-ubuntu20.04-manylinux2014-multipython, tensorflow/tools/ci_build/install/install_deb_packages.sh, tensorflow/tools/toolchains/remote_config/configs.bzl, tensorflow/tools/toolchains/remote_config/containers.bzl, third_party/tensorrt/tensorrt_configure.bzl, third_party/xla/.kokoro/linux/build.sh, third_party/xla/third_party/tsl/third_party/tensorrt/tensorrt_configure.bzl, third_party/xla/third_party/tsl/tools/toolchains/remote_config/configs.bzl, third_party/xla/third_party/tsl/tools/toolchains/remote_config/containers.bzl, third_party/xla/tools/toolchains/remote_config/configs.bzl, third_party/xla/tools/toolchains/remote_config/containers.bzl",beckerhe,False
"[xla:ffi] NFC: Remove dependency on ServiceExecutableRunOptions from XLA FFI

It's very hard to reconstruct ServiceExecutableRunOptions at various points where we want to call FFI handler. Also xla::Service at this point considered to be a legacy API. Instead pass the minimal set of data that might be needed by FFI handler explicitly via CallOptions.

PiperOrigin-RevId: 636557222",Eugene Zhulenev,ezhulenev@google.com,2024-05-23 15:16:59,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/api/BUILD, third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_api.h, third_party/xla/xla/ffi/ffi_test.cc, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.h",ezhulenev,False
"[cleanup] Remove unused classes

PiperOrigin-RevId: 636550927",Sergey Kozub,sergeykozub@google.com,2024-05-23 14:55:14,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_degenerate_dim_remover.cc, third_party/xla/xla/service/gpu/gemm_degenerate_dim_remover.h, third_party/xla/xla/service/gpu/gemm_degenerate_dim_remover_test.cc, third_party/xla/xla/service/gpu/gemv_rewriter.cc, third_party/xla/xla/service/gpu/gemv_rewriter.h, third_party/xla/xla/service/gpu/gemv_rewriter_test.cc",sergeykozub,False
"Update XNNPack version.

PiperOrigin-RevId: 636550437",Quentin Khan,qkhan@google.com,2024-05-23 14:53:07,"tensorflow/lite/tools/cmake/modules/xnnpack.cmake, tensorflow/workspace2.bzl",qukhan,False
"Remove the use of xla::OkStatus now that it's just an alias to absl::OkStatus.

PiperOrigin-RevId: 636549690",Kyle Lucke,klucke@google.com,2024-05-23 14:50:22,third_party/xla/xla/python/pjrt_ifrt/pjrt_array.cc,klucke,False
"Enable wgmma instructions in triton for hopper

PiperOrigin-RevId: 636543103",Tori Baker,vwbaker@google.com,2024-05-23 14:23:30,"third_party/triton/temporary/enable_mma_v3.patch, third_party/triton/temporary/series.bzl, third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch, third_party/xla/third_party/triton/temporary/enable_mma_v3.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/tests/sparse_ttg_accelerate_matmul.mlir, third_party/xla/xla/service/gpu/tests/sparse_ttg_fence_insertion.mlir",vwbaker,False
"Do not restrict Hopper block sizes in the autotuner

PiperOrigin-RevId: 636541686",Sergey Kozub,sergeykozub@google.com,2024-05-23 14:18:03,third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc,sergeykozub,False
"Fix unsigned vectorized reductions.

This fixes xla/tests:reduce_test_gpu.

PiperOrigin-RevId: 636540427",Johannes Reifferscheid,jreiffers@google.com,2024-05-23 14:12:34,"third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.h, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc",jreiffers,False
"[XLA:FFI] Add helper macro to register enum attributes decoding.

PiperOrigin-RevId: 636539980",Adam Banaś,adambanas@google.com,2024-05-23 14:10:44,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/api/BUILD, third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/ffi_test.cc, third_party/xla/xla/tests/custom_call_test.cc",Adam-Banas,False
"Delete GetMemRefSizeInBytes method

It is unused now.

PiperOrigin-RevId: 636533268",Adrian Kuegel,akuegel@google.com,2024-05-23 13:40:34,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emission_utils.cc",akuegel,False
"Get rid of half.hpp dependency in sparse dot test

PiperOrigin-RevId: 636532888",Sergey Kozub,sergeykozub@google.com,2024-05-23 13:39:00,"third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gpu_sparse_dot_test.cc",sergeykozub,False
"Enable MMA_V3 for Triton Hopper tests

They are expecting the set of generated instructions to include wgmma-related code, and fail otherwise.

PiperOrigin-RevId: 636532273",Goran Flegar,gflegar@google.com,2024-05-23 13:36:09,"third_party/triton/temporary/exclude_failing_h100_tests.patch, third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/exclude_failing_h100_tests.patch, third_party/xla/third_party/triton/temporary/series.bzl",gflegar,False
"Fix a crash in unoptimized builds.

getIntOrFloatBitWidth asserts that the type is an integer, but
we only check the type after calling it.

PiperOrigin-RevId: 636531275",Johannes Reifferscheid,jreiffers@google.com,2024-05-23 13:31:29,third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc,jreiffers,False
"Don't fold constants in affine_apply.fold.

This sometimes (rarely) fails with ""folder reused existing op
for one result but constant materialization failed for another
result"". Not sure why, but it's just a not very important
runtime optimization
anyway.

PiperOrigin-RevId: 636530184",Johannes Reifferscheid,jreiffers@google.com,2024-05-23 13:26:34,third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc,jreiffers,False
"Correctly process sparse dots (do not drop sparsity info when calling CreateDot)

PiperOrigin-RevId: 636517867",Sergey Kozub,sergeykozub@google.com,2024-05-23 12:33:34,"third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/matmul_utils.cc",sergeykozub,False
"PR #12991: [GPU] Refactor GEMM fusion autotuner.

Imported from GitHub PR https://github.com/openxla/xla/pull/12991

Copybara import of the project:

--
f6e85691b51bdd17fc6167ad8f8cb00d7411fec9 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Replace a hash map by a vector of pairs in GEMM fusion autotuner.

This will be needed for multi-host autotuning to split tasks between hosts reliably.

--
44682f67eb6e9c521f381a7c3dd93fee95f59366 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU][NFC] Refactor for loop iterators.

Merging this change closes #12991

PiperOrigin-RevId: 636506422",Ilia Sergachev,isergachev@nvidia.com,2024-05-23 11:45:08,"third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.h",sergachev,False
"Automated Code Change

PiperOrigin-RevId: 636502625",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 11:30:21,"tensorflow/core/runtime_fallback/kernel/BUILD, tensorflow/core/runtime_fallback/kernel/conversion/conversion.cc",tensorflower-gardener,False
"Use apply_indexing for GEP index calculations.

PiperOrigin-RevId: 636500369",Johannes Reifferscheid,jreiffers@google.com,2024-05-23 11:20:00,"third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc, third_party/xla/xla/service/gpu/fusions/mlir/passes.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_tensors.mlir",jreiffers,False
"Integrate LLVM at llvm/llvm-project@446f66d685c2

Updates LLVM usage to match
[446f66d685c2](https://github.com/llvm/llvm-project/commit/446f66d685c2)

PiperOrigin-RevId: 636497297",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 11:07:04,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Simplify arith.minsi and maxsi.

PiperOrigin-RevId: 636495600",Johannes Reifferscheid,jreiffers@google.com,2024-05-23 11:01:11,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/passes.td, third_party/xla/xla/service/gpu/fusions/mlir/simplify_affine.cc, third_party/xla/xla/service/gpu/fusions/mlir/simplify_arith.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/simplify_arith.mlir",jreiffers,False
"Automated Code Change

PiperOrigin-RevId: 636490381",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 10:38:45,"tensorflow/core/data/service/task_runner.cc, tensorflow/core/data/service/task_runner.h, tensorflow/core/data/service/task_runner_test.cc, tensorflow/core/data/service/test_cluster.h, tensorflow/core/data/service/validate_utils.cc, tensorflow/core/data/service/worker_client.cc, tensorflow/core/data/service/worker_client.h, tensorflow/core/data/service/worker_client_test.cc, tensorflow/core/data/service/worker_impl.cc, tensorflow/core/data/service/worker_impl.h",tensorflower-gardener,False
"Support more operators on Intervals.

- comparison of intervals with intervals (not just intervals
  with points)
- addition and multiplication - implement saturating semantics
  for these. Also fix our current multiplication bound.
- min and max

And add a bunch of tests. This is in preparation for more arith
simplification.

PiperOrigin-RevId: 636481027",Johannes Reifferscheid,jreiffers@google.com,2024-05-23 10:01:47,"third_party/xla/xla/service/gpu/fusions/mlir/simplify_arith.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",jreiffers,False
"Fix incorrect call to `getInt` when type is unsigned

Produces a runtime error. Use `getUInt` instead.
Fixes #12915

PiperOrigin-RevId: 636479572",Paweł Paruzel,paruzelp@google.com,2024-05-23 09:56:22,third_party/xla/xla/ffi/attribute_map.cc,pparuzel,False
"Reverts 1165601296e2baba5535c8f9ba7510e1373b9d6c

PiperOrigin-RevId: 636479468",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 09:55:56,"tensorflow/compiler/mlir/lite/ir/tfl_ops.td, tensorflow/compiler/mlir/lite/tests/ops.mlir, tensorflow/lite/kernels/embedding_lookup.cc, tensorflow/lite/kernels/embedding_lookup_test.cc",tensorflower-gardener,False
"Fold sequences of apply_indexing ops.

But only if this leads to simplification.

PiperOrigin-RevId: 636475718",Johannes Reifferscheid,jreiffers@google.com,2024-05-23 09:38:39,"third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/canonicalize.mlir",jreiffers,False
"[XLA:GPU][NFC] Add and refactor GPU reduce-scatter-creator tests.

PiperOrigin-RevId: 636472439",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-23 09:23:56,"third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gpu_reduce_scatter_creator_test.cc",golechwierowicz,False
"[XLA:GPU] Enable 'xla_gpu_all_reduce_contiguous' by default.

PiperOrigin-RevId: 636472416",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-23 09:23:48,third_party/xla/xla/debug_options_flags.cc,golechwierowicz,False
"Update GraphDef version to 1871.

PiperOrigin-RevId: 636468013",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 09:05:03,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-23

PiperOrigin-RevId: 636467621",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 09:03:24,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"[XLA:GPU] Remove num_threads from EstimateRunTimeData.

PiperOrigin-RevId: 636465362",Oleg Shyshkov,shyshkov@google.com,2024-05-23 08:55:01,"third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.h",olegshyshkov,False
"Automated Code Change

PiperOrigin-RevId: 636464306",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 08:49:33,"tensorflow/compiler/mlir/tensorflow/transforms/initialize_variables_in_session_init.cc, tensorflow/compiler/mlir/tensorflow/transforms/lift_variables.cc, tensorflow/compiler/mlir/tensorflow/transforms/xla_call_module_deserialization.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 636462473",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 08:41:09,"tensorflow/core/kernels/batching_util/batch_resource_base.cc, tensorflow/core/kernels/batching_util/batch_scheduler.h",tensorflower-gardener,False
"Fix warp order calculations for MMA_V3 layouts. Hopper forces a [0,1] order for mma_v3 layouts (https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#matrix-fragments-for-wgmma-mma-async-m64nnk8) while keeping a [1,0] order for thread layouts so these two things have to be kept separate.

PiperOrigin-RevId: 636444009",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 07:20:02,"third_party/triton/temporary/reduction_mma_v3_fix.patch, third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/reduction_mma_v3_fix.patch, third_party/xla/third_party/triton/temporary/series.bzl",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 636438481",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 06:58:22,"tensorflow/core/debug/bfc_dump_reader.cc, tensorflow/core/debug/debug_graph_utils.cc",tensorflower-gardener,False
"PR #12951: Update PJRT C API readme to link to header

Imported from GitHub PR https://github.com/openxla/xla/pull/12951

Copybara import of the project:

--
edab0ad80b2c2cdc5d7debcb5dc1511de76a3908 by Skye Wanderman-Milne <skyewm@google.com>:

Update PJRT C API readme to link to header

Merging this change closes #12951

PiperOrigin-RevId: 636431068",Skye Wanderman-Milne,skyewm@google.com,2024-05-23 06:25:59,third_party/xla/xla/pjrt/c/README.md,skye,False
"Expose `ExecuteOptions:untuple_result` via `RunningOptions:untuple_result`

PiperOrigin-RevId: 636430391",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 06:22:36,"third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.h",tensorflower-gardener,False
"Disable NCCL comm splitting by default as it leads to deadlocks

Reverts f47b0b66880ba3d947d55ca88a75e5d4c2bcd3ba

PiperOrigin-RevId: 636397404",Eugene Zhulenev,ezhulenev@google.com,2024-05-23 03:56:52,third_party/xla/xla/debug_options_flags.cc,ezhulenev,False
"[xla:ffi] Add prepare and initialize stages to XLA FFI handler registration

PiperOrigin-RevId: 636380515",Eugene Zhulenev,ezhulenev@google.com,2024-05-23 02:48:55,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_test.cc, third_party/xla/xla/python/xla_compiler.cc, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.cc, third_party/xla/xla/service/gpu/custom_call_test.cc, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.h",ezhulenev,False
"Fix audit wheel issue

PiperOrigin-RevId: 636362500",Sandeep Dasgupta,sdasgup@google.com,2024-05-23 01:24:17,tensorflow/tools/pip_package/build_pip_package.py,sdasgup3,False
"Add a check that if any single dimension of an xla shape is 0 the data size is 0.

PiperOrigin-RevId: 636352383",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-23 00:41:06,third_party/xla/xla/shape_util_test.cc,tensorflower-gardener,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/runtime/...

PiperOrigin-RevId: 636346969",Kuy Mainwaring,kuym@google.com,2024-05-23 00:20:05,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/copy_thunk.h, third_party/xla/xla/service/gpu/runtime/cudnn_thunk.cc, third_party/xla/xla/service/gpu/runtime/fused_mha_thunk.cc, third_party/xla/xla/service/gpu/runtime/gemm_thunk.cc, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.cc, third_party/xla/xla/service/gpu/runtime/kernel_thunk.cc, third_party/xla/xla/service/gpu/runtime/triangular_solve_thunk.cc",kuym,False
"Fix Artifact registry permission errors.

PiperOrigin-RevId: 636334484",Quoc Truong,quoct@google.com,2024-05-22 23:35:45,third_party/xla/.kokoro/linux/build.sh,quoctruong,False
"Unify the GetInput methods

Modify GetInput by id to return a pointer of Tensor. This is consistent with the GetInput by name variant.

This way the GetInput won't make a copy of the Tensor in DirectPluginOpKernel, and won't change the buffer refcount.

PiperOrigin-RevId: 636331149",Haibo Huang,hhb@google.com,2024-05-22 23:25:12,"tensorflow/core/common_runtime/next_pluggable_device/BUILD, tensorflow/core/common_runtime/next_pluggable_device/c_plugin_op_kernel.cc, tensorflow/core/common_runtime/next_pluggable_device/c_plugin_op_kernel.h, tensorflow/core/common_runtime/next_pluggable_device/direct_plugin_op_kernel.cc, tensorflow/core/common_runtime/next_pluggable_device/direct_plugin_op_kernel.h, tensorflow/core/common_runtime/next_pluggable_device/plugin_op_kernel.h, tensorflow/core/common_runtime/next_pluggable_device/plugin_op_kernel_helper.h",hhb,False
"Support per-axis embedding lookup reference kernel

PiperOrigin-RevId: 636329728",Pauline Sho,psho@google.com,2024-05-22 23:20:34,"tensorflow/compiler/mlir/lite/ir/tfl_ops.td, tensorflow/compiler/mlir/lite/tests/ops.mlir, tensorflow/lite/kernels/embedding_lookup.cc, tensorflow/lite/kernels/embedding_lookup_test.cc",paulinesho,False
"#tf-data-service Fix worker client test for reading over gRPC.

Without this change, we were silently upgrading to the local worker.

PiperOrigin-RevId: 636329280",Matt Callanan,mpcallanan@google.com,2024-05-22 23:19:04,tensorflow/core/data/service/worker_client_test.cc,mpcallanan,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/cudnn_norm_rewriter.cc

PiperOrigin-RevId: 636320462",Kuy Mainwaring,kuym@google.com,2024-05-22 22:50:44,third_party/xla/xla/service/gpu/cudnn_norm_rewriter.cc,kuym,False
"Some refactoring to while_loop_unroller.cc

PiperOrigin-RevId: 636310715",Farzin Houshmand,farzinh@google.com,2024-05-22 22:18:07,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/while_loop_unroller.cc",farzinhoushmand,False
"Move StreamExecutorMemoryAllocator to its own header & implementation file.

This helps eliminate some circular dependencies.

PiperOrigin-RevId: 636308369",Kyle Lucke,klucke@google.com,2024-05-22 22:10:32,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/backend.cc, third_party/xla/xla/service/backend.h, third_party/xla/xla/service/generic_transfer_manager_test.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/autotuner_util.h, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk_test.cc, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc, third_party/xla/xla/service/gpu/tests/gpu_too_many_blocks_test.cc, third_party/xla/xla/service/hlo_runner.cc, third_party/xla/xla/service/shaped_buffer_test.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/device_memory_allocator.h, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/redzone_allocator_test.cc, third_party/xla/xla/stream_executor/stream_executor_memory_allocator.cc, third_party/xla/xla/stream_executor/stream_executor_memory_allocator.h, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/buffer_donation_test.cc, third_party/xla/xla/tests/cpu_gpu_fusion_test.cc, third_party/xla/xla/tests/dot_operation_test.cc, third_party/xla/xla/tests/dynamic_ops_test.cc, third_party/xla/xla/tests/hlo_test_base.cc, third_party/xla/xla/tests/local_client_execute_test.cc, third_party/xla/xla/tests/local_client_test_base.cc, third_party/xla/xla/tests/local_client_test_base.h, third_party/xla/xla/tests/while_test.cc, third_party/xla/xla/tools/BUILD, third_party/xla/xla/tools/xla_compile_lib.cc",klucke,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 636301896",Kyle Lucke,klucke@google.com,2024-05-22 21:51:05,"third_party/xla/xla/python/pjrt_ifrt/pjrt_array.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_tuple.cc",klucke,False
"Remove LowerToMlProgramAndHlo() function.

PiperOrigin-RevId: 636294031",Matthias Kramm,kramm@google.com,2024-05-22 21:26:08,"tensorflow/compiler/mlir/tensorflow/utils/mlprogram_util.cc, tensorflow/compiler/mlir/tensorflow/utils/mlprogram_util.h",matthiaskramm,False
"[cusparse] Add better stubs for cusparseGetErrorString and cusparseGetErrorName.

Fixes segfault in JAX if an invalid cuda version is installed (https://github.com/google/jax/issues/21349).

PiperOrigin-RevId: 636289430",Peter Hawkins,phawkins@google.com,2024-05-22 21:11:32,"third_party/xla/xla/tsl/cuda/BUILD.bazel, third_party/xla/xla/tsl/cuda/cusparse_stub.cc",hawkinsp,False
"Remove unused attributes from IfrtLoadVariableOp

PiperOrigin-RevId: 636287765",Deqiang Chen,deqiangc@google.com,2024-05-22 21:06:11,"tensorflow/compiler/mlir/tensorflow/ir/host_runtime/tfrt_ops.td, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_mlrt_ops.td, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_ops.td, tensorflow/compiler/mlir/tfrt/tests/ifrt/sink_variable_as_named_array.mlir, tensorflow/compiler/mlir/tfrt/tests/mlrt/rewrite_ifrt_load_variable.mlir, tensorflow/compiler/mlir/tfrt/tests/mlrt/tf_to_mlrt.mlir, tensorflow/compiler/mlir/tfrt/transforms/ifrt/sink_variable_as_named_array.cc, tensorflow/compiler/mlir/tfrt/transforms/mlrt/tf_to_mlrt.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc, tensorflow/core/tfrt/ops/ifrt_program_ops.cc",deqiangc,False
"Add checks to ensure that the device indices in the sharding are valid.

The size of input_mapping depends on metadata.num_cores_per_replica(). And metadata is a protobuffer assigned by the poc.mlir. Missing validation for the index of input_mappings will lead to an out-of-bound vulnerability.

PiperOrigin-RevId: 636286863",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 21:03:40,"tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/utils/xla_sharding_util.cc",tensorflower-gardener,False
"[xla:gpu] Fix a bug in pipelined-p2p-rewriter.

Previously, we call module schedule update each time when we transform a
while-body as well as at the end of the pass. It turns out that updating the
schedule for each while-body is not necessary and can also bring in changes
that aren't track and cause problem in keeping track of the instructions in
instruction_sequence. This CL removes the updating for each while-body.

Add a test.

PiperOrigin-RevId: 636269493",Bixia Zheng,bixia@google.com,2024-05-22 20:12:03,"third_party/xla/xla/service/gpu/pipelined_p2p_rewriter.cc, third_party/xla/xla/service/gpu/pipelined_p2p_rewriter_test.cc",bixia1,False
"[pjrt] Add an API to add user data to FFI context via PJRT_ExecuteContext

PiperOrigin-RevId: 636260703",Eugene Zhulenev,ezhulenev@google.com,2024-05-22 19:45:00,"third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/CHANGELOG.md, third_party/xla/xla/pjrt/c/pjrt_c_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_ffi_extension.h, third_party/xla/xla/pjrt/c/pjrt_c_api_ffi_internal.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_ffi_internal.h, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_internal.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_test.cc",ezhulenev,False
"Remove versions restrictions in hermetic python implementation.

PiperOrigin-RevId: 636255731",Vadym Matsishevskyi,vam@google.com,2024-05-22 19:28:10,"third_party/py/python_repo.bzl, third_party/xla/third_party/py/python_repo.bzl, third_party/xla/third_party/tsl/third_party/py/python_repo.bzl",vam-google,False
"MLIR emitters: Vectorize column reductions.

Special thanks to github user lingzhi98 who experimented with this in
https://github.com/openxla/xla/pull/11018.

I tried to make the logic as similar for vectorized and non-vectorized
reductions as I could. The vectorized logic looks like this:

- produce N reduced elements per thread, store the intermediate results in
  a vector V
- loop over the N elements of V, writing each one to shmem
- loop over N elements, reading them from shmem and writing the result to
  global memory

PiperOrigin-RevId: 636243118",Johannes Reifferscheid,jreiffers@google.com,2024-05-22 18:48:02,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.h, third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc, third_party/xla/xla/service/gpu/fusions/mlir/lower_to_llvm.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.h, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_tensors.mlir, third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",jreiffers,False
"Simplify more reshapes.

PiperOrigin-RevId: 636241926",Johannes Reifferscheid,jreiffers@google.com,2024-05-22 18:44:08,"third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",jreiffers,False
"Keep outside compilation attribute of DecomposeResourceGather op in TableGen decompose_resource_ops rewrites

PiperOrigin-RevId: 636241036",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 18:41:16,"tensorflow/compiler/mlir/tensorflow/tests/decompose_resource_ops.mlir, tensorflow/compiler/mlir/tensorflow/transforms/decompose_resource_ops.td, tensorflow/compiler/mlir/tensorflow/transforms/rewrite_util.cc, tensorflow/compiler/mlir/tensorflow/transforms/rewrite_util.h, tensorflow/compiler/mlir/tensorflow/utils/attribute_utils.h",tensorflower-gardener,False
"[pjrt] Add initial APIs to create and destroy PJRT_ExecuteContext

Registering user-defined types with FFI and passing user data to FFI handlers via execute context coming in followup PRs.

PiperOrigin-RevId: 636239268",Eugene Zhulenev,ezhulenev@google.com,2024-05-22 18:36:01,"third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/CHANGELOG.md, third_party/xla/xla/pjrt/c/pjrt_c_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_cpu_internal.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_internal.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_test.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.h",ezhulenev,False
"[XLA:GPU] Make ""collectives-schedule-linearizer"" a last optimisation pass.

PiperOrigin-RevId: 636238545",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-22 18:33:50,"third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_compiler.h",golechwierowicz,False
"Make Event::PollForStatus a virtual method, and override it where necessary.

This enables Event to be a completely virtual base class, and removes it from circular dependencies.

PiperOrigin-RevId: 636235458",Kyle Lucke,klucke@google.com,2024-05-22 18:26:36,"tensorflow/c/experimental/stream_executor/stream_executor.cc, tensorflow/c/experimental/stream_executor/stream_executor_internal.h, third_party/xla/xla/backends/interpreter/executor.h, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/cuda/cuda_event.cc, third_party/xla/xla/stream_executor/cuda/cuda_event.h, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/event.h, third_party/xla/xla/stream_executor/gpu/gpu_event.cc, third_party/xla/xla/stream_executor/gpu/gpu_event.h, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/BUILD, third_party/xla/xla/stream_executor/rocm/rocm_event.cc, third_party/xla/xla/stream_executor/rocm/rocm_event.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/tpu/tpu_event.h, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.h, third_party/xla/xla/stream_executor/tpu/tpu_executor_c_api.h, third_party/xla/xla/stream_executor/tpu/tpu_executor_init_fns.inc",klucke,False
"Update dependency on old schema location.

PiperOrigin-RevId: 636229438",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 18:09:50,tensorflow/lite/python/BUILD,tensorflower-gardener,False
"PR #12633: Fix handling of unknown flags in the multihost HLO runner.

Imported from GitHub PR https://github.com/openxla/xla/pull/12633

Fixes https://github.com/openxla/xla/issues/7923
Copybara import of the project:

--
71083c7d6dfdcaec1a5458b3f1cd04b11e13f8bd by Ilia Sergachev <isergachev@nvidia.com>:

Fix handling of unknown flags in the multihost HLO runner.

Merging this change closes #12633

PiperOrigin-RevId: 636229361",Ilia Sergachev,isergachev@nvidia.com,2024-05-22 18:09:37,third_party/xla/xla/tools/multihost_hlo_runner/hlo_runner_main.cc,sergachev,False
"Adding MLIR debugging instrumentation to experimental MLIR Quantizer

PiperOrigin-RevId: 636226941",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 18:03:19,"tensorflow/compiler/mlir/lite/quantization/lite/BUILD, tensorflow/compiler/mlir/lite/quantization/lite/quantize_model.cc, tensorflow/compiler/mlir/lite/quantization/lite/quantize_model.h, tensorflow/lite/python/convert.py, tensorflow/lite/python/lite.py, tensorflow/lite/python/wrap_toco.py, tensorflow/lite/toco/python/BUILD, tensorflow/lite/toco/python/toco_python_api.cc, tensorflow/lite/toco/python/toco_python_api.h, tensorflow/python/_pywrap_toco_api.pyi, tensorflow/python/lite/toco_python_api_wrapper.cc",tensorflower-gardener,False
"[XLA:GPU] Simplify launch dimensions estimate for non-kernel fusions.

That estimate should not be used in production code, because fusions that don't implement KernelFusionInterface don't generate CUDA kernels and there is nothing to fuse. We keep this estimate as a fallback mechanism. We don't have any additional information about the kernel, so we can simplify the heuristic and assume we launch one thread per output element and 128 threads per block.

PiperOrigin-RevId: 636223298",Oleg Shyshkov,shyshkov@google.com,2024-05-22 17:54:20,"third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.h",olegshyshkov,False
"[XLA:CPU] Use thread pool to run host kernel functions in parallel.

PiperOrigin-RevId: 636222671",Vladyslav Tsilytskyi,tsilytskyi@google.com,2024-05-22 17:52:31,"third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_kernel.cc, third_party/xla/xla/stream_executor/host/host_kernel.h, third_party/xla/xla/stream_executor/host/host_kernel_test.cc",tvladyslav,False
"Merge pull request #67751 from Intel-tensorflow:gaurides/update_bf16_lists

PiperOrigin-RevId: 636219125",TensorFlower Gardener,gardener@tensorflow.org,2024-05-22 18:24:28,tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h,tensorflower-gardener,False
"Fix the flakiness in xplane processsing.

PiperOrigin-RevId: 636215943",Feng Wang,wffw@google.com,2024-05-22 17:32:54,"tensorflow/core/profiler/convert/xplane_to_op_stats.cc, tensorflow/core/profiler/convert/xplane_to_op_stats_test.cc",lionelfeng,False
"PR #12942: [GPU] Fix cuDNN GEMM test tolerances.

Imported from GitHub PR https://github.com/openxla/xla/pull/12942

Use the maximum absolute difference observed on 20 runs of these tests with different seed values.
Copybara import of the project:

--
c438b08ea7240c23ae98bc8dcf4ef45fa6d2e89c by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix cuDNN GEMM test tolerances.

Use the maximum absolute difference observed on 20 runs of these tests with different seed values.

Merging this change closes #12942

PiperOrigin-RevId: 636213649",Ilia Sergachev,isergachev@nvidia.com,2024-05-22 17:26:33,third_party/xla/xla/service/gpu/fusions/cudnn_test.cc,sergachev,False
"Added an option for scatter ops to drop bad indices instead of returning error. This change is to help the developers implement custom scatter ops that emulates the behavior on GPU.

PiperOrigin-RevId: 636208997",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 17:13:44,"tensorflow/core/kernels/BUILD, tensorflow/core/kernels/scatter_nd_op.cc, tensorflow/core/kernels/scatter_nd_op.h, tensorflow/core/kernels/scatter_nd_op_cpu_impl.h, tensorflow/core/kernels/scatter_nd_op_gpu.cu.cc",tensorflower-gardener,False
"Remove StreamExecutorInterface::WaitForEventOnExternalStream and replace with a proper virtual method on Event.

PiperOrigin-RevId: 636207445",Kyle Lucke,klucke@google.com,2024-05-22 17:09:15,"third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/event.cc, third_party/xla/xla/stream_executor/event.h, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_event.cc, third_party/xla/xla/stream_executor/gpu/gpu_event.h, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream_executor_interface.h",klucke,False
"Added option to drop bad gather index. This is to help developer add GPU-compatible version of GatherNd afterwards.

PiperOrigin-RevId: 636206934",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 17:08:03,"tensorflow/core/kernels/gather_nd_op.cc, tensorflow/core/kernels/gather_nd_op.h",tensorflower-gardener,False
"Merge pull request #66023 from Intel-tensorflow:gaurides/add_back_bf16_sum_mean

PiperOrigin-RevId: 636204412",TensorFlower Gardener,gardener@tensorflow.org,2024-05-22 17:29:51,tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h,tensorflower-gardener,False
"Fixes source list after schema utility functions relocation.

PiperOrigin-RevId: 636200612",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 16:50:25,tensorflow/lite/schema/BUILD,tensorflower-gardener,False
"Integrate Triton up to [14800bfa](https://github.com/openai/triton/commits/14800bfa0cfa0930fcaed22fc1e91a8e13430580)

PiperOrigin-RevId: 636200022",Aliia Khasanova,aliia@google.com,2024-05-22 16:48:20,"third_party/triton/temporary/linear_layout_compose_asan.patch, third_party/triton/temporary/series.bzl, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/temporary/linear_layout_compose_asan.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/xla/service/gpu/ir_emitter_triton_cuda.cc",,False
"[XLA:GPU] Use EstimateRunTimeData::ToString instead of VLogResult.

The same logic to print roughly the same parameters in duplicated between to places.

PiperOrigin-RevId: 636197839",Oleg Shyshkov,shyshkov@google.com,2024-05-22 16:41:09,"third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.h",olegshyshkov,False
"Add a test for GatherNdOp to verify that it returns an error when the indices are out of range.

PiperOrigin-RevId: 636191256",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 16:19:27,"tensorflow/core/kernels/BUILD, tensorflow/core/kernels/gather_nd_op_test.cc",tensorflower-gardener,False
"Clean up xla_gpu_ops.

- Move & and * next to the type, where they belong, as
  everyone knows.
- fix `reserve` calls in FoldApplyIndexingOperands

PiperOrigin-RevId: 636181040",Johannes Reifferscheid,jreiffers@google.com,2024-05-22 15:46:14,third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc,jreiffers,False
"#tf-data Turn up `map_fusion` experiment to 1% task-level.

PiperOrigin-RevId: 636169144",Matt Callanan,mpcallanan@google.com,2024-05-22 15:04:11,tensorflow/core/data/dataset_utils.cc,mpcallanan,False
"Copybara import of the project:

--
f5617d7323d6059022ec3e495e5d4d0fa3ccb1b1 by Sergei Lebedev <slebedev@google.com>:

Removed noop # type: ignore comments

mypy should now flag these by default.

PiperOrigin-RevId: 636146344",Sergei Lebedev,slebedev@google.com,2024-05-22 13:34:27,"third_party/xla/xla/python/xla_client.pyi, third_party/xla/xla/python/xla_extension/__init__.pyi",superbobry,False
"Normalize layouts for Gather.

Unfortunately this requires to temporarily use unsorted offset_dims attribute.
GatherSimplifier can turn this into valid HLO again.

PiperOrigin-RevId: 636143803",Adrian Kuegel,akuegel@google.com,2024-05-22 13:22:27,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/gather_simplifier.cc, third_party/xla/xla/service/gather_simplifier_test.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/layout_normalization.cc, third_party/xla/xla/service/layout_normalization_test.cc",akuegel,False
"[XLA:GPU] Remove StatusOr from GetFusionEmitter.

GetFusionEmitter never returns an error.

PiperOrigin-RevId: 636142987",Oleg Shyshkov,shyshkov@google.com,2024-05-22 13:18:41,"third_party/xla/xla/service/gpu/fusions/concatenate_test.cc, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/fusions.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_test.cc, third_party/xla/xla/service/gpu/fusions/input_slices_test.cc, third_party/xla/xla/service/gpu/fusions/loop_test.cc, third_party/xla/xla/service/gpu/fusions/scatter_test.cc, third_party/xla/xla/service/gpu/fusions/transpose_test.cc, third_party/xla/xla/service/gpu/fusions/triton_test.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/model/coalescing_analysis_test.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.cc",olegshyshkov,False
"Fix TFLite XNNPack delegate `weight_cache_test.cc` when running on android.

The temporary folder is located at `/data/local/tmp/` for Android.

PiperOrigin-RevId: 636134383",Quentin Khan,qkhan@google.com,2024-05-22 12:44:56,"tensorflow/lite/delegates/xnnpack/BUILD, tensorflow/lite/delegates/xnnpack/weight_cache_test.cc",qukhan,False
"[XLA:GPU] Move buffer assignment logic to MemcpyFusion::Emit.

GetFusionEmitter should be responsible only for matching the correct emitter. If buffer assignment fails, there is no way to fix that and we propagate status to the caller anyway, so it's better to do it in MemcpyFusion::Emit.

PiperOrigin-RevId: 636121302",Oleg Shyshkov,shyshkov@google.com,2024-05-22 11:46:38,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/copy.cc, third_party/xla/xla/service/gpu/fusions/copy.h, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/fusions.h",olegshyshkov,False
"Automated Code Change

PiperOrigin-RevId: 636109295",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 10:52:52,"tensorflow/lite/BUILD, tensorflow/lite/graph_info_test.cc, tensorflow/lite/interpreter_test.cc",tensorflower-gardener,False
"Support negative transpose permutation in TFLite XNNPack delegate.

PiperOrigin-RevId: 636108629",Quentin Khan,qkhan@google.com,2024-05-22 10:49:20,tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc,qukhan,False
"PR #12438: [XLA:GPU] add force inline option to get better llvm splits

Imported from GitHub PR https://github.com/openxla/xla/pull/12438

Add option to XLA to enforce inlining before llvm splitModule or set preserveLocals=False to get more balanced splits in parallel compilation case.

Some data of GPT3 5B model with different setting:
```
Compilation: TSL:XlaCompile:#module=pjit__wrapped_step_fn,program_id=24#: 3.754429084s (parallel + inline) runtime: 1.0s
Compilation: TSL:XlaCompile:#module=pjit__wrapped_step_fn,program_id=24#: 4.676450341s (parallel + no inline) runtime: 1.0s
Compilation: TSL:XlaCompile:#module=pjit__wrapped_step_fn,program_id=24#: 3.051018704s (parallel + perserve_local=False) runtime: 1.4s
Compilation: TSL:XlaCompile:#module=pjit__wrapped_step_fn,program_id=24#: 4.862938161s (serial) runtime: 1.0s
```

However, the runtime per step of perserve_locals=False vs other three setup is 1.4s vs 1.0s.
Copybara import of the project:

--
5f61718691d265c8609a89dc2349b1362045f7c5 by Cjkkkk <ske@nvidia.com>:

add force inline and no preserve local option to get better llvm splits

--
f32419eb792206de332be481bc59650c9d37a564 by Cjkkkk <ske@nvidia.com>:

remove preserveLocals option

Merging this change closes #12438

PiperOrigin-RevId: 636104761",Shanbin Ke,ske@nvidia.com,2024-05-22 10:32:37,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/xla.proto",Cjkkkk,False
"Check that strided slice begin, end and stride tensors are supported in XNNPack delegate.

PiperOrigin-RevId: 636099078",Quentin Khan,qkhan@google.com,2024-05-22 10:07:46,tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc,qukhan,False
"Automated Code Change

PiperOrigin-RevId: 636098802",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 10:06:46,"tensorflow/core/tpu/graph_rewrite/BUILD, tensorflow/core/tpu/graph_rewrite/combine_tpu_embedding_load_retrieve_pass.cc, tensorflow/core/tpu/graph_rewrite/combine_tpu_embedding_load_retrieve_pass.h, tensorflow/core/tpu/graph_rewrite/cond_builder.cc, tensorflow/core/tpu/graph_rewrite/configure_tpu_embedding_rewrite_pass.cc, tensorflow/core/tpu/graph_rewrite/configure_tpu_embedding_rewrite_pass.h, tensorflow/core/tpu/graph_rewrite/distributed_tpu_configuration_rewrite_pass.cc, tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_helpers.cc, tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_helpers.h, tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_pass.cc, tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc, tensorflow/core/tpu/graph_rewrite/host_training_loop_optimization_util.cc, tensorflow/core/tpu/graph_rewrite/incomplete_nodedef_builder.h, tensorflow/core/tpu/graph_rewrite/tpu_embedding_rewrite_pass_utils.cc, tensorflow/core/tpu/graph_rewrite/tpu_embedding_software_deduplication_rewrite_pass.cc, tensorflow/core/tpu/graph_rewrite/tpu_embedding_software_deduplication_rewrite_pass.h, tensorflow/core/tpu/graph_rewrite/update_tpu_embedding_ops_passes.cc, tensorflow/core/tpu/graph_rewrite/update_tpu_embedding_ops_passes.h, tensorflow/core/tpu/graph_rewrite/variable_merger_pass.cc, tensorflow/core/tpu/graph_rewrite/variable_merger_pass.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 636098770",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 10:06:41,"tensorflow/lite/BUILD, tensorflow/lite/simple_planner_test.cc, tensorflow/lite/stderr_reporter.cc, tensorflow/lite/string_util_test.cc, tensorflow/lite/test_util_test.cc",tensorflower-gardener,False
"Fix bug in FusionCanShareBufferHint() for transpose multi-output fusions.

We did not correctly check whether a fusion root is accessed in two different
iteration orders. If there is another root that has a transpose hero, the
iteration orders will be different.

PiperOrigin-RevId: 636096047",Adrian Kuegel,akuegel@google.com,2024-05-22 09:56:06,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/buffer_sharing.cc, third_party/xla/xla/service/gpu/gpu_copy_insertion_test.cc",akuegel,False
"Check shape of inputs in XNNPack delegate.

- Add.
- Dequantize
- Div.
- Mul.
- Quantize
- Square.
- Squared difference.
- Sub.

PiperOrigin-RevId: 636095200",Quentin Khan,qkhan@google.com,2024-05-22 09:51:59,tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc,qukhan,False
"[XLA:GPU] Fixing indexing maps examples documentation

PiperOrigin-RevId: 636092626",Mohammed Anany,manany@google.com,2024-05-22 09:40:46,third_party/xla/docs/indexing.md,Moerafaat,False
"Update GraphDef version to 1870.

PiperOrigin-RevId: 636083620",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 09:02:15,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-22

PiperOrigin-RevId: 636083590",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 09:02:08,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 636077905",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 08:38:07,"tensorflow/compiler/tf2xla/kernels/BUILD, tensorflow/compiler/tf2xla/kernels/identity_op.cc, tensorflow/compiler/tf2xla/kernels/if_op.cc, tensorflow/compiler/tf2xla/kernels/if_op.h, tensorflow/compiler/tf2xla/kernels/if_while_utils.cc, tensorflow/compiler/tf2xla/kernels/if_while_utils.h, tensorflow/compiler/tf2xla/kernels/image_ops.cc, tensorflow/compiler/tf2xla/kernels/image_resize_ops.cc, tensorflow/compiler/tf2xla/kernels/image_resize_ops.h, tensorflow/compiler/tf2xla/kernels/in_topk_op.cc, tensorflow/compiler/tf2xla/kernels/index_ops.cc, tensorflow/compiler/tf2xla/kernels/l2loss_op.cc, tensorflow/compiler/tf2xla/kernels/light_outside_compilation.cc, tensorflow/compiler/tf2xla/kernels/light_outside_compilation.h, tensorflow/compiler/tf2xla/kernels/listdiff_op.cc, tensorflow/compiler/tf2xla/kernels/lower_upper_bound_ops.cc, tensorflow/compiler/tf2xla/kernels/lrn_ops.cc, tensorflow/compiler/tf2xla/kernels/matmul_op.cc, tensorflow/compiler/tf2xla/kernels/matrix_band_part_op.cc, tensorflow/compiler/tf2xla/kernels/matrix_diag_ops.cc, tensorflow/compiler/tf2xla/kernels/matrix_inverse_op.cc, tensorflow/compiler/tf2xla/kernels/matrix_solve_op.cc, tensorflow/compiler/tf2xla/kernels/matrix_triangular_solve_op.cc, tensorflow/compiler/tf2xla/kernels/mirror_pad_op.cc, tensorflow/compiler/tf2xla/kernels/next_after_op.cc, tensorflow/compiler/tf2xla/kernels/no_op.cc, tensorflow/compiler/tf2xla/kernels/one_hot_op.cc, tensorflow/compiler/tf2xla/kernels/pack_op.cc, tensorflow/compiler/tf2xla/kernels/pad_op.cc, tensorflow/compiler/tf2xla/kernels/pooling_ops.cc, tensorflow/compiler/tf2xla/kernels/qr_op.cc, tensorflow/compiler/tf2xla/kernels/quantize_and_dequantize_op.cc, tensorflow/compiler/tf2xla/kernels/random_ops.cc, tensorflow/compiler/tf2xla/kernels/random_ops_util.cc, tensorflow/compiler/tf2xla/kernels/random_ops_util.h, tensorflow/compiler/tf2xla/kernels/reduce_window_op.cc, tensorflow/compiler/tf2xla/kernels/reduction_ops.cc, tensorflow/compiler/tf2xla/kernels/reduction_ops.h, tensorflow/compiler/tf2xla/kernels/reduction_ops_common.cc, tensorflow/compiler/tf2xla/kernels/relu_op.cc, tensorflow/compiler/tf2xla/kernels/replica_id_op.cc, tensorflow/compiler/tf2xla/kernels/resampler_addon_ops.cc, tensorflow/compiler/tf2xla/kernels/resampler_ops.cc, tensorflow/compiler/tf2xla/kernels/resampler_ops.h, tensorflow/compiler/tf2xla/kernels/reshape_op.cc, tensorflow/compiler/tf2xla/kernels/retval_op.cc, tensorflow/compiler/tf2xla/kernels/reverse_op.cc, tensorflow/compiler/tf2xla/kernels/reverse_sequence_op.cc, tensorflow/compiler/tf2xla/kernels/rng_converter_utils.cc, tensorflow/compiler/tf2xla/kernels/rng_converter_utils.h, tensorflow/compiler/tf2xla/kernels/rng_converter_utils_test.cc",tensorflower-gardener,False
"Add build macro to generate hlo compilations test build rules.

PiperOrigin-RevId: 636073156",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 08:19:16,"third_party/xla/xla/service/gpu/build_defs.bzl, third_party/xla/xla/tools/multihost_hlo_runner/BUILD",tensorflower-gardener,False
"Also allow epilogues for kCopy ops.

Normally we replace kCopy with transpose in LayoutNormalization. But if some
other pass reintroduces copies, we should still handle them in the same way as
logical transposes.

PiperOrigin-RevId: 636072731",Adrian Kuegel,akuegel@google.com,2024-05-22 08:17:34,"third_party/xla/xla/service/gpu/gpu_fusible_test.cc, third_party/xla/xla/service/gpu/ir_emission_utils.cc, third_party/xla/xla/service/gpu/ir_emission_utils_test.cc",akuegel,False
"Allow fMHA test to run on A100+

Reverts 02195873785c2a582bc4a41363433b9361d701da

PiperOrigin-RevId: 636066982",Henning Becker,hebecker@google.com,2024-05-22 07:53:43,third_party/xla/xla/service/gpu/tests/BUILD,beckerhe,False
"PR #12907: Fix link error in for_all_thunks_test

Imported from GitHub PR https://github.com/openxla/xla/pull/12907

Use xla_cc_test instead of cc_test to ensure that all shared objects are available for linking.
Copybara import of the project:

--
dc432e9d10e40f2bd0759fa30764d4eefcc5360c by Andrew Goodbody <andrew.goodbody@linaro.org>:

Fix link error in for_all_thunks_test

Use xla_cc_test instead of cc_test to ensure that all shared objects
are available for linking.

Merging this change closes #12907

PiperOrigin-RevId: 636062102",Andrew Goodbody,andrew.goodbody@linaro.org,2024-05-22 07:30:40,third_party/xla/xla/service/gpu/runtime/BUILD,elfringham,False
"Make all the concrete Event types inherit from Event rather than EventInterface, which has no virtual methods.

PiperOrigin-RevId: 636047452",Kyle Lucke,klucke@google.com,2024-05-22 06:25:22,"tensorflow/c/experimental/stream_executor/BUILD, tensorflow/c/experimental/stream_executor/stream_executor.cc, tensorflow/c/experimental/stream_executor/stream_executor_internal.h, third_party/xla/xla/backends/interpreter/BUILD, third_party/xla/xla/backends/interpreter/executor.h, third_party/xla/xla/service/gpu/runtime/copy_thunk.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/event.cc, third_party/xla/xla/stream_executor/event.h, third_party/xla/xla/stream_executor/event_interface.h, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_event.cc, third_party/xla/xla/stream_executor/gpu/gpu_event.h, third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/tpu/BUILD, third_party/xla/xla/stream_executor/tpu/tpu_event.h, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_platform.cc, third_party/xla/xla/stream_executor/tpu/tpu_platform.h, third_party/xla/xla/stream_executor/tpu/tpu_platform_interface.h",klucke,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 636045709",Kyle Lucke,klucke@google.com,2024-05-22 06:16:41,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/algebraic_simplifier.cc, third_party/xla/xla/service/all_gather_combiner.cc, third_party/xla/xla/service/all_gather_decomposer.cc, third_party/xla/xla/service/all_reduce_combiner.cc, third_party/xla/xla/service/all_reduce_contiguous.cc, third_party/xla/xla/service/allocation_tracker.cc, third_party/xla/xla/service/ar_crs_combiner.cc, third_party/xla/xla/service/batchnorm_expander.cc, third_party/xla/xla/service/bfloat16_conversion_folding.cc, third_party/xla/xla/service/bfloat16_propagation.cc, third_party/xla/xla/service/buffer_assignment.cc, third_party/xla/xla/service/buffer_assignment.h, third_party/xla/xla/service/buffer_assignment_test.cc, third_party/xla/xla/service/call_graph.cc, third_party/xla/xla/service/call_graph_test.cc, third_party/xla/xla/service/call_inliner.cc, third_party/xla/xla/service/collective_permute_decomposer.cc, third_party/xla/xla/service/collective_pipeliner.cc, third_party/xla/xla/service/collective_pipeliner_test.cc, third_party/xla/xla/service/compilation_environments.cc, third_party/xla/xla/service/computation_layout.cc, third_party/xla/xla/service/computation_placer.cc, third_party/xla/xla/service/conditional_canonicalizer.cc, third_party/xla/xla/service/conditional_code_motion.cc, third_party/xla/xla/service/conditional_to_select.cc, third_party/xla/xla/service/convert_async_collectives_to_sync.cc, third_party/xla/xla/service/convert_async_collectives_to_sync_test.cc, third_party/xla/xla/service/convolution_group_converter.cc, third_party/xla/xla/service/copy_insertion.cc, third_party/xla/xla/service/cpu_gpu_shape_verifier.cc, third_party/xla/xla/service/defuser.cc, third_party/xla/xla/service/dfs_hlo_visitor_with_default_test.cc, third_party/xla/xla/service/dot_dimension_merger.cc, third_party/xla/xla/service/dynamic_dimension_inference.cc, third_party/xla/xla/service/dynamic_dimension_inference_test.cc, third_party/xla/xla/service/dynamic_padder.cc, third_party/xla/xla/service/dynamic_padder_test.cc, third_party/xla/xla/service/eigh_expander.cc, third_party/xla/xla/service/executable.cc, third_party/xla/xla/service/execution_tracker.cc, third_party/xla/xla/service/flatten_call_graph.cc, third_party/xla/xla/service/float_normalization.cc, third_party/xla/xla/service/generic_transfer_manager.cc, third_party/xla/xla/service/gpu_compilation_environment.cc, third_party/xla/xla/service/hlo_alias_analysis.cc, third_party/xla/xla/service/hlo_computation_test.cc, third_party/xla/xla/service/hlo_cost_analysis.cc, third_party/xla/xla/service/hlo_dataflow_analysis.cc, third_party/xla/xla/service/hlo_dce.cc, third_party/xla/xla/service/hlo_domain_map.cc, third_party/xla/xla/service/hlo_domain_remover.cc, third_party/xla/xla/service/hlo_domain_test.cc, third_party/xla/xla/service/hlo_domain_verifier.cc, third_party/xla/xla/service/hlo_graph_dumper.cc, third_party/xla/xla/service/hlo_instruction_test.cc, third_party/xla/xla/service/hlo_memory_scheduler.cc, third_party/xla/xla/service/hlo_module_group_metadata.cc, third_party/xla/xla/service/hlo_module_group_util.cc, third_party/xla/xla/service/hlo_module_util.cc, third_party/xla/xla/service/hlo_parser.cc, third_party/xla/xla/service/hlo_pass_fix.h, third_party/xla/xla/service/hlo_pass_interface.h, third_party/xla/xla/service/hlo_pass_pipeline.cc, third_party/xla/xla/service/hlo_rematerialization.cc, third_party/xla/xla/service/hlo_replication_analysis.cc, third_party/xla/xla/service/hlo_runner_pjrt.cc, third_party/xla/xla/service/hlo_value_semantics_analysis.cc, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/hlo_verifier.h, third_party/xla/xla/service/host_memory_transfer_asyncifier.cc, third_party/xla/xla/service/host_offload_legalize.cc, third_party/xla/xla/service/host_offloader.cc, third_party/xla/xla/service/indexed_array_analysis.cc, third_party/xla/xla/service/latency_hiding_scheduler.cc, third_party/xla/xla/service/layout_assignment.cc, third_party/xla/xla/service/layout_assignment.h, third_party/xla/xla/service/layout_normalization.cc, third_party/xla/xla/service/logical_buffer_analysis.cc, third_party/xla/xla/service/map_inliner.cc, third_party/xla/xla/service/mapped_ptr_container_sorter.h, third_party/xla/xla/service/p2p_schedule_preparation.cc, third_party/xla/xla/service/qr_expander.cc, third_party/xla/xla/service/reduce_decomposer.cc, third_party/xla/xla/service/reduce_scatter_combiner.cc, third_party/xla/xla/service/reduce_window_rewriter.cc, third_party/xla/xla/service/reshape_decomposer.cc, third_party/xla/xla/service/reshape_mover_test.cc, third_party/xla/xla/service/service.cc, third_party/xla/xla/service/shape_inference.cc, third_party/xla/xla/service/shaped_buffer_test.cc, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/slice_sinker.cc, third_party/xla/xla/service/space_to_batch_converter.cc, third_party/xla/xla/service/stochastic_convert_decomposer.cc, third_party/xla/xla/service/sub_byte_normalization.cc, third_party/xla/xla/service/topk_rewriter.cc, third_party/xla/xla/service/transfer_manager.cc, third_party/xla/xla/service/transpose_folding.cc, third_party/xla/xla/service/tree_reduction_rewriter.cc, third_party/xla/xla/service/tuple_points_to_analysis.cc, third_party/xla/xla/service/while_loop_all_reduce_code_motion.cc, third_party/xla/xla/service/while_loop_concat_code_motion.cc, third_party/xla/xla/service/while_loop_constant_sinking.cc",klucke,False
"Remove GOOGLE_CUDA preprocssor guards from scoped_annotation.h

They are not needed anymore and only break the platform abstraction, so let's remove them.

PiperOrigin-RevId: 636038244",Henning Becker,hebecker@google.com,2024-05-22 05:41:24,"third_party/xla/third_party/tsl/tsl/profiler/lib/BUILD, third_party/xla/third_party/tsl/tsl/profiler/lib/scoped_annotation.h",beckerhe,False
"Automated Code Change

PiperOrigin-RevId: 636035484",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 05:26:37,"third_party/xla/xla/service/llvm_ir/buffer_assignment_util.cc, third_party/xla/xla/service/llvm_ir/buffer_assignment_util.h",tensorflower-gardener,False
"Eliminate a race condition in host_tracer_test in ThreadPool::Schedule and collecting the trace data.

PiperOrigin-RevId: 636012434",Kyle Lucke,klucke@google.com,2024-05-22 03:22:44,third_party/xla/xla/backends/profiler/cpu/host_tracer_test.cc,klucke,False
"Update ir_emmiter to only add necessary information.

Other details about the event can be added in post processing.

PiperOrigin-RevId: 636012366",Clive Verghese,cliveverghese@google.com,2024-05-22 03:22:10,"third_party/xla/xla/service/cpu/cpu_runtime.cc, third_party/xla/xla/service/cpu/cpu_runtime.h, third_party/xla/xla/service/cpu/ir_emitter.cc",cliveverghese,False
"Fix configure.py issue with --clang_path.

If --clang_path is passed a symlink, an error would occur when building C++ files that had includes from the standard library. E.g., a possible error was:

ERROR: /root/.cache/bazel/_bazel_root/e4ab50d61a21943a819d1e092972a817/external/zlib/BUILD.bazel:5:11: Compiling zutil.c [for tool] failed: undeclared inclusion(s) in rule '@zlib//:zlib':
this rule is missing dependency declarations for the following files included by 'zutil.c':
  '/usr/lib/clang/17/include/stddef.h'
  '/usr/lib/clang/17/include/__stddef_max_align_t.h'
  '/usr/lib/clang/17/include/limits.h'
  '/usr/lib/clang/17/include/stdarg.h'

The clang on the PATH, such as /usr/bin/clang-17, is usually symlinked to a file such as /usr/lib/llvm-17/bin/clang, so this would typically cause issues when building with --clang_path.

The issue is that bazel gives such errors when compiled with a symlinked clang. Without --clang_path, we resolved symlinks, but not with --clang_path. This change also resolves symlinks with --clang_path.

PiperOrigin-RevId: 636004628",Reed Wanderman-Milne,reedwm@google.com,2024-05-22 02:49:14,"third_party/xla/build_tools/configure/configure.py, third_party/xla/build_tools/configure/configure_test.py",reedwm,False
"[XLA] Minor cleanups

No functional change is intended.

PiperOrigin-RevId: 636002485",David Majnemer,majnemer@google.com,2024-05-22 02:34:15,third_party/xla/xla/hlo/ir/hlo_module.cc,majnemer,False
"Move host-compute-offloading wrapping after SPMD sharding to shard calls executed on host

PiperOrigin-RevId: 635998816",Eugene Zhulenev,ezhulenev@google.com,2024-05-22 02:12:18,third_party/xla/xla/service/spmd/spmd_partitioner.cc,ezhulenev,False
"[XLA] Generalize iota tile assignment transpose handling.

PiperOrigin-RevId: 635995520",Ce Zheng,zce@google.com,2024-05-22 01:54:12,"third_party/xla/xla/hlo/ir/tile_assignment.cc, third_party/xla/xla/tests/tile_assignment_test.cc",cezheng,False
"Replace some no_aarch64 tags with not_run:arm

PiperOrigin-RevId: 635995152",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-22 01:51:42,"third_party/xla/.kokoro/linux/build.sh, third_party/xla/xla/python/ifrt_proxy/server/BUILD, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/tests/BUILD",tensorflower-gardener,False
"PR #12915: Handle unsigned MLIR integers during FFI attribute conversion

Imported from GitHub PR https://github.com/openxla/xla/pull/12915

Copybara import of the project:

--
7a26d6fa5ca122ad3ad56ba9e3668eab8c9b0235 by Andrey Portnoy <aportnoy@nvidia.com>:

Handle unsigned MLIR integers during FFI attribute conversion

Merging this change closes #12915

PiperOrigin-RevId: 635988605",Andrey Portnoy,aportnoy@nvidia.com,2024-05-22 01:13:57,third_party/xla/xla/ffi/attribute_map.cc,andportnoy,False
"[host_offloading] Add call-to-custom-call conversion for host offloading to HostOffloadingPrepare pass

PiperOrigin-RevId: 635986731",Eugene Zhulenev,ezhulenev@google.com,2024-05-22 01:05:45,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/host_offloading_prepare.cc, third_party/xla/xla/service/host_offloading_prepare.h, third_party/xla/xla/service/host_offloading_prepare_test.cc",ezhulenev,False
"Update onednn from v3.4.1 to v3.4.2.

PiperOrigin-RevId: 635968674",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 23:44:47,tensorflow/workspace2.bzl,tensorflower-gardener,False
"Fix auto_sharding_runner dependencies.

PiperOrigin-RevId: 635968367",Kyle Lucke,klucke@google.com,2024-05-21 23:43:44,third_party/xla/xla/hlo/experimental/auto_sharding/BUILD,klucke,False
"PR #12912: Overload operator<< for XLA_FFI_DataType

Imported from GitHub PR https://github.com/openxla/xla/pull/12912

Copybara import of the project:

--
32908d2d90a89269c655dff6d999bfc974f405a9 by Andrey Portnoy <aportnoy@nvidia.com>:

Overload operator<< for XLA_FFI_DataType

Merging this change closes #12912

PiperOrigin-RevId: 635960244",Andrey Portnoy,aportnoy@nvidia.com,2024-05-21 23:11:49,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/ffi.h",andportnoy,False
"Port SavedModel to StableHLO Converter to tensorfow/compiler/mlir/

PiperOrigin-RevId: 635947472",Sandeep Dasgupta,sdasgup@google.com,2024-05-21 22:27:32,"tensorflow/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow_to_stablehlo/BUILD, tensorflow/compiler/mlir/tensorflow_to_stablehlo/README.md, tensorflow/compiler/mlir/tensorflow_to_stablehlo/python/BUILD, tensorflow/compiler/mlir/tensorflow_to_stablehlo/python/integration_test/tensorflow_to_stablehlo_test.py, tensorflow/compiler/mlir/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo.cc, tensorflow/compiler/mlir/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo.pyi, tensorflow/compiler/mlir/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo_lib.cc, tensorflow/compiler/mlir/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo_lib.h, tensorflow/compiler/mlir/tensorflow_to_stablehlo/tests/test_tf_to_stablehlo.mlir, tensorflow/compiler/mlir/tensorflow_to_stablehlo/tf_to_stablehlo.cc, tensorflow/compiler/mlir/tensorflow_to_stablehlo/tf_to_stablehlo.h, tensorflow/compiler/mlir/tensorflow_to_stablehlo/tf_to_stablehlo_translate.cc, tensorflow/python/BUILD, tensorflow/tools/def_file_filter/symbols_pybind.txt, third_party/xla/third_party/tsl/tools/def_file_filter/symbols_pybind.txt",sdasgup3,False
"add case that allows broadcasting for add in gpu_compatiblilty.cc

PiperOrigin-RevId: 635943193",Steven Toribio,toribiosteven@google.com,2024-05-21 22:14:44,"tensorflow/lite/tools/versioning/gpu_compatibility.cc, tensorflow/lite/tools/versioning/gpu_compatibility_test.cc",turbotoribio,False
"Fix the issues with the quantized tests in `batch_matmul_test.cc`.

PiperOrigin-RevId: 635942430",Quentin Khan,qkhan@google.com,2024-05-21 22:12:09,"tensorflow/lite/kernels/BUILD, tensorflow/lite/kernels/batch_matmul_test.cc",qukhan,False
"Fix for rocm CI after 9500b98

PiperOrigin-RevId: 635928377",David Dunleavy,ddunleavy@google.com,2024-05-21 21:25:46,third_party/xla/xla/tests/BUILD,ddunl,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 635927531",Kyle Lucke,klucke@google.com,2024-05-21 21:23:01,"third_party/xla/xla/service/gpu/collective_permute_cycle_decomposer.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/dot_sparsity_rewriter.cc, third_party/xla/xla/service/gpu/gemm_fusion.cc, third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/gpu_memory_space_assignment.h, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.cc, third_party/xla/xla/service/gpu/gpu_windowed_einsum_handler.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis.h, third_party/xla/xla/service/spmd/canonicalize_all_gather_for_cse_test.cc, third_party/xla/xla/service/spmd/custom_call_handler.cc, third_party/xla/xla/service/spmd/dot_handler.cc, third_party/xla/xla/service/spmd/fft_handler.cc, third_party/xla/xla/service/spmd/gather_scatter_handler.cc, third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc, third_party/xla/xla/service/spmd/stateful_rng_spmd_partitioner.cc, third_party/xla/xla/service/spmd/whole_graph_manual_pass_test.cc",klucke,False
"Added public announcement for the future TensorRT support deprecation.

PiperOrigin-RevId: 635919343",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 20:58:17,RELEASE.md,tensorflower-gardener,False
"Remove the need for StreamExecutorInterface::DeallocateEvent.

PiperOrigin-RevId: 635910366",Kyle Lucke,klucke@google.com,2024-05-21 20:29:51,"tensorflow/c/experimental/stream_executor/stream_executor.cc, third_party/xla/xla/backends/interpreter/executor.h, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/event.cc, third_party/xla/xla/stream_executor/gpu/gpu_event.cc, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/tpu/BUILD, third_party/xla/xla/stream_executor/tpu/tpu_event.h, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.h, third_party/xla/xla/stream_executor/tpu/tpu_platform.h, third_party/xla/xla/stream_executor/tpu/tpu_platform_interface.h",klucke,False
"PR #12901: [ROCM] fixing gemm_rewriter subtest BF16GemmCodeGen

Imported from GitHub PR https://github.com/openxla/xla/pull/12901

This is a subtest fix for ROCM platform

@xla-rotation: would you please take a look?
Copybara import of the project:

--
fe6147564252a291003f9dae1de504052a9296f1 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

fixing gemm_rewriter subtest

Merging this change closes #12901

PiperOrigin-RevId: 635908017",pemeliya,141146080+pemeliya@users.noreply.github.com,2024-05-21 20:22:25,third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc,pemeliya,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 635907580",Kyle Lucke,klucke@google.com,2024-05-21 20:21:04,"third_party/xla/xla/hlo/ir/dfs_hlo_visitor.cc, third_party/xla/xla/hlo/ir/dfs_hlo_visitor_with_default.h, third_party/xla/xla/hlo/ir/dynamic_parameter_binding.cc, third_party/xla/xla/hlo/ir/hlo_computation.cc, third_party/xla/xla/hlo/ir/hlo_computation.h, third_party/xla/xla/hlo/ir/hlo_input_output_alias_config.cc, third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h, third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/hlo/ir/hlo_module.cc, third_party/xla/xla/hlo/ir/hlo_module.h, third_party/xla/xla/hlo/ir/hlo_module_metadata.cc, third_party/xla/xla/hlo/ir/hlo_schedule.cc, third_party/xla/xla/hlo/ir/hlo_sharding.cc, third_party/xla/xla/hlo/ir/hlo_sharding_metadata.cc",klucke,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 635902683",Kyle Lucke,klucke@google.com,2024-05-21 20:05:32,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_dot_handler.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_runner.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc",klucke,False
"Add accessor for TraceEventsByLevel().

PiperOrigin-RevId: 635899882",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 19:56:40,tensorflow/core/profiler/convert/trace_viewer/trace_events.h,tensorflower-gardener,False
"Use TF2 for mwms_pjrt_gpu_test

PiperOrigin-RevId: 635898879",Edward Schwartz,schwartzedward@google.com,2024-05-21 19:53:08,"tensorflow/python/distribute/BUILD, tensorflow/python/distribute/mwms_pjrt_gpu_test.py",SeeForTwo,False
"Fix TFLite XNNPack delegate weight cache test when run in android emulator.

PiperOrigin-RevId: 635898411",Quentin Khan,qkhan@google.com,2024-05-21 19:51:28,tensorflow/lite/delegates/xnnpack/weight_cache_test.cc,qukhan,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 635887485",Kyle Lucke,klucke@google.com,2024-05-21 19:12:12,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/host_callback_test.cc, third_party/xla/xla/pjrt/mlir_to_hlo.cc, third_party/xla/xla/pjrt/pjrt_executable.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h, third_party/xla/xla/pjrt/tracked_device_buffer_test.cc, third_party/xla/xla/pjrt/transpose.cc, third_party/xla/xla/pjrt/utils.cc, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/client_library_test_base.cc, third_party/xla/xla/tests/llvm_compiler_test.cc, third_party/xla/xla/tests/llvm_irgen_test_base.cc, third_party/xla/xla/tests/params_test.cc, third_party/xla/xla/tests/test_utils.cc, third_party/xla/xla/tests/verified_hlo_module.cc, third_party/xla/xla/tests/xla_hlo_profile_test.cc, third_party/xla/xla/tools/BUILD, third_party/xla/xla/tools/dumped_computation_to_operation_list.cc, third_party/xla/xla/tools/hlo_control_flow_flattening.cc, third_party/xla/xla/tools/hlo_extractor.cc, third_party/xla/xla/tools/hlo_module_loader.cc, third_party/xla/xla/tools/run_hlo_module.cc, third_party/xla/xla/tools/xla_compile_lib.cc",klucke,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/nvptx_compiler_test.cc

PiperOrigin-RevId: 635881535",Kuy Mainwaring,kuym@google.com,2024-05-21 18:54:14,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/nvptx_compiler_test.cc",kuym,False
"Replace numpy string aliases for numpy 2.0 compatibility

NumPy 2.0 removes the aliases np.string_ (for np.bytes_) and np.unicode_ (for np.str_) to enforce a single way to access string data types.

All instances where np.string_ and np.unicode_ are used in TF have been updated.

Note that, internally, tf.string is now mapped to np.bytes_ to align with NumPy 2.0's changes. However, the public-facing TensorFlow types tf.string remains unchanged as it does not have duplicate naming issues, so it is probably not worth updating its name.

See https://numpy.org/devdocs/numpy_2_0_migration_guide.html#changes-to-namespaces and https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.string_.

PiperOrigin-RevId: 635869119",Kanglan Tang,kanglan@google.com,2024-05-21 18:16:47,"tensorflow/lite/python/interpreter_test.py, tensorflow/lite/python/lite_test.py, tensorflow/lite/python/lite_v2_test.py, tensorflow/lite/testing/zip_test_utils.py, tensorflow/python/debug/cli/tensor_format.py, tensorflow/python/framework/flexible_dtypes.py, tensorflow/python/kernel_tests/array_ops/constant_op_eager_test.py, tensorflow/python/kernel_tests/array_ops/constant_op_test.py, tensorflow/python/kernel_tests/sparse_ops/sparse_to_dense_op_py_test.py, tensorflow/python/kernel_tests/strings_ops/unsorted_segment_join_op_test.py, tensorflow/python/ops/numpy_ops/np_dtypes.py, tensorflow/python/ops/numpy_ops/np_utils.py, tensorflow/tools/ci_build/osx/arm64/tensorflow_metal_plugin_test.py",kanglant,False
"Enable profiler tracing support for threadpools

PiperOrigin-RevId: 635864691",Clive Verghese,cliveverghese@google.com,2024-05-21 18:04:22,"third_party/xla/third_party/tsl/tsl/platform/default/BUILD, third_party/xla/third_party/tsl/tsl/platform/default/tracing_impl.h, third_party/xla/xla/backends/profiler/cpu/host_tracer_test.cc",cliveverghese,False
"Make ThreadpoolEventCollector instance static to prevent access after deletions.

PiperOrigin-RevId: 635863595",Clive Verghese,cliveverghese@google.com,2024-05-21 18:01:58,"third_party/xla/third_party/tsl/tsl/profiler/backends/cpu/threadpool_listener.cc, third_party/xla/third_party/tsl/tsl/profiler/backends/cpu/threadpool_listener.h",cliveverghese,False
"Support chunked protocol buffer filename in `tf.saved_model.contains_saved_model()`.

PiperOrigin-RevId: 635858259",Seunghoon Park,seunghoonpark@google.com,2024-05-21 17:47:05,tensorflow/python/saved_model/loader_impl.py,pclove1,False
"Relocating common schema utility functions.

PiperOrigin-RevId: 635854027",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 17:34:31,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/flatbuffer_import.cc, tensorflow/compiler/mlir/lite/flatbuffer_operator.cc, tensorflow/compiler/mlir/lite/kernels/internal/BUILD, tensorflow/compiler/mlir/lite/kernels/internal/README, tensorflow/compiler/mlir/lite/kernels/internal/compatibility_macros.h, tensorflow/compiler/mlir/lite/quantization/lite/BUILD, tensorflow/compiler/mlir/lite/quantization/lite/quantize_model_test.cc, tensorflow/compiler/mlir/lite/quantization/lite/quantize_weights_test.cc, tensorflow/compiler/mlir/lite/schema/BUILD, tensorflow/compiler/mlir/lite/schema/schema_conversion_utils.cc, tensorflow/compiler/mlir/lite/schema/schema_conversion_utils.h, tensorflow/compiler/mlir/lite/schema/schema_generated.h, tensorflow/compiler/mlir/lite/schema/schema_utils.cc, tensorflow/compiler/mlir/lite/schema/schema_utils.h, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/BUILD, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/importer_test_min_max.cc, tensorflow/lite/CMakeLists.txt, tensorflow/lite/experimental/acceleration/mini_benchmark/BUILD, tensorflow/lite/experimental/acceleration/mini_benchmark/runner_test.cc, tensorflow/lite/experimental/acceleration/mini_benchmark/validator_test.cc, tensorflow/lite/kernels/CMakeLists.txt, tensorflow/lite/python/optimize/BUILD, tensorflow/lite/python/optimize/calibration_wrapper.cc, tensorflow/lite/schema/BUILD, tensorflow/lite/schema/schema_conversion_utils.h, tensorflow/lite/schema/schema_utils.h, tensorflow/lite/tools/serialization/BUILD, tensorflow/lite/tools/serialization/enum_mapping.h, tensorflow/lite/tools/serialization/writer_lib.cc, tensorflow/lite/tools/serialization/writer_lib.h, tensorflow/lite/tools/versioning/BUILD, tensorflow/lite/tools/versioning/op_version.cc, tensorflow/lite/tools/versioning/op_version.h, tensorflow/lite/tools/versioning/runtime_version.cc, tensorflow/lite/tools/versioning/runtime_version.h, tensorflow/opensource_only.files",tensorflower-gardener,False
"Move MatchShapeCoveringDynamicIndex function to while_loop_unroller.h and update other usages to use the same method.

Add support for matching ds and dus that are inside (nested)fusions within loop bodies.

PiperOrigin-RevId: 635852343",Farzin Houshmand,farzinh@google.com,2024-05-21 17:29:51,"third_party/xla/xla/service/scan_loop_accumulator_input_unification.cc, third_party/xla/xla/service/while_loop_unroller.cc, third_party/xla/xla/service/while_loop_unroller.h, third_party/xla/xla/service/while_loop_unroller_test.cc",farzinhoushmand,False
"Adapt to NumPy 2.0 namespace changes: np.inf and np.nan

NumPy 2.0 introduces namespace changes that deprecate certain ways of accessing special values like np.inf and np.nan.

All instances where np.Inf and np.infty (aliases for np.inf), np.NINF (equivalent to -np.inf), or np.NaN (equivalent to np.nan) are used have been updated to their canonical forms, ensuring compatibility with NumPy 2.0.

See https://numpy.org/devdocs/numpy_2_0_migration_guide.html#changes-to-namespaces.

PiperOrigin-RevId: 635848655",Kanglan Tang,kanglan@google.com,2024-05-21 17:18:37,"tensorflow/compiler/tests/random_ops_test.py, tensorflow/compiler/tests/segment_reduction_ops_test.py, tensorflow/compiler/tests/unary_ops_test.py, tensorflow/lite/testing/op_tests/is_finite.py, tensorflow/python/keras/callbacks.py, tensorflow/python/kernel_tests/math_ops/topk_op_test.py, tensorflow/python/kernel_tests/random/parameterized_truncated_normal_op_test.py, tensorflow/python/ops/math_grad_test.py, tensorflow/python/ops/math_ops_test.py, tensorflow/python/ops/weak_tensor_math_ops_test.py, tensorflow/python/ops/weak_tensor_ops_test.py",kanglant,False
"PR #12896: [GPU][NFC] Remove deprecated runtime proto message.

Imported from GitHub PR https://github.com/openxla/xla/pull/12896

Copybara import of the project:

--
32ded36419a4a1b2177a6374846497a8bb458ac9 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU][NFC] Remove deprecated runtime proto message.

Merging this change closes #12896

PiperOrigin-RevId: 635846667",Ilia Sergachev,isergachev@nvidia.com,2024-05-21 17:13:18,third_party/xla/xla/service/gpu/executable.proto,sergachev,False
"Remove unreferenced and deprecated CompileGraphToXlaHlo.

PiperOrigin-RevId: 635843821",Arturo Schmidt,arturoschmidt@google.com,2024-05-21 17:05:27,"tensorflow/compiler/mlir/tf2xla/api/v1/compile_mlir_util.cc, tensorflow/compiler/mlir/tf2xla/api/v1/compile_mlir_util.h",rocketas,False
"[XLA:FFI] Fix annotating buffer `dimensions` memory

The last dimension of FFI buffers `dimensions` member variable was not annotated as initialized memory, because of an off-by-one code error.
It went unnoticed because of usage absl::c_accumulate algorithm in tests. Modified one test to directly access dimensions in a for loop, cause that triggers sanitizer check.

PiperOrigin-RevId: 635840115",Adam Banaś,adambanas@google.com,2024-05-21 16:55:04,"third_party/xla/xla/service/cpu/runtime_handle_ffi_call.cc, third_party/xla/xla/tests/custom_call_test.cc",Adam-Banas,False
"Fix PJRT doc redirection

PiperOrigin-RevId: 635839196",Elliot English,elliotenglish@google.com,2024-05-21 16:52:01,third_party/xla/xla/pjrt/c/docs/pjrt_integration_guide.md,,False
"Integrate LLVM at llvm/llvm-project@9f449c342781

Updates LLVM usage to match
[9f449c342781](https://github.com/llvm/llvm-project/commit/9f449c342781)

PiperOrigin-RevId: 635833653",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 16:33:35,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Align DRQ TransposeConv XNNPack test with reference TFLite implementation

PiperOrigin-RevId: 635826787",Artsiom Ablavatski,artsiom@google.com,2024-05-21 16:09:37,"tensorflow/lite/delegates/xnnpack/dynamically_quantized_transpose_conv_test.cc, tensorflow/lite/delegates/xnnpack/dynamically_quantized_transpose_conv_tester.cc, tensorflow/lite/delegates/xnnpack/dynamically_quantized_transpose_conv_tester.h",ablavatski,False
"Migrate away from llvm::StringRef::equals

Note that llvm::StringRef::equals has been deprecated upstream.

PiperOrigin-RevId: 635822562",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 15:55:32,tensorflow/core/runtime_fallback/kernel/kernel_fallback_execute_compat.cc,tensorflower-gardener,False
"Move schema_fbs_with_reflection to mlir/lite/schema.

PiperOrigin-RevId: 635816622",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 15:32:58,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/flatbuffer_to_string.cc, tensorflow/compiler/mlir/lite/schema/BUILD, tensorflow/lite/schema/BUILD",tensorflower-gardener,False
"Split sum-modification from sum-visitation.

Currently, we're both computing values and modifying sums in one step, which is
not very nice. This splits the modification parts from the traversal parts
where feasible. There's some almost-duplication in the mod/div simplifiers
which could probably be cleaned up, but so far I failed to find a good name for
it.

PiperOrigin-RevId: 635815457",Johannes Reifferscheid,jreiffers@google.com,2024-05-21 15:28:19,third_party/xla/xla/service/gpu/model/indexing_map.cc,jreiffers,False
"Tighten reduction loop bounds for MLIR emitter.

See the added comment for an example of a problematic bound
that is currently created.

PiperOrigin-RevId: 635796929",Johannes Reifferscheid,jreiffers@google.com,2024-05-21 14:14:34,"third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc",jreiffers,False
"[Triton] Fix a use-after-free bug in LinearLayout::compose.

`output.apply(bases)` returns a temporary object and `llvm::make_second_range` doesn't copy or take ownership. As a result, `newBases` points to deallocated memory.

Also rename `newBases` to `outerBases`, because there is `newBases` variable in the outer scope.

PiperOrigin-RevId: 635795849",Oleg Shyshkov,shyshkov@google.com,2024-05-21 14:09:47,"third_party/triton/temporary/linear_layout_compose_asan.patch, third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/linear_layout_compose_asan.patch, third_party/xla/third_party/triton/temporary/series.bzl",olegshyshkov,False
"Rename `RewriteSumIf` to `RemoveSummands`.

It was pointed out to me that this code is terrible. Let this
be the first part of my formal apology.

PiperOrigin-RevId: 635792761",Johannes Reifferscheid,jreiffers@google.com,2024-05-21 13:58:01,third_party/xla/xla/service/gpu/model/indexing_map.cc,jreiffers,False
"PR #12897: [GPU] Fix cuDNN GEMM scalar constants test condition.

Imported from GitHub PR https://github.com/openxla/xla/pull/12897

Copybara import of the project:

--
71b57fd71d603bc8c346283796f6859761eef014 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix cuDNN GEMM scalar constants test condition.

Merging this change closes #12897

PiperOrigin-RevId: 635792570",Ilia Sergachev,isergachev@nvidia.com,2024-05-21 13:57:26,third_party/xla/xla/service/gpu/fusions/cudnn_test.cc,sergachev,False
"Reverts 42ac0dde8f7855c87dfea2217b03b8ee7e829ae9

PiperOrigin-RevId: 635790293",Quentin Khan,qkhan@google.com,2024-05-21 13:47:26,tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc,qukhan,False
"Remove the use of xla::OkStatus now that it's just an alias to absl::OkStatus.

PiperOrigin-RevId: 635783707",Kyle Lucke,klucke@google.com,2024-05-21 13:14:19,"third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc, third_party/xla/xla/pjrt/distributed/BUILD, third_party/xla/xla/pjrt/distributed/client_server_test.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/inspect_sharding.cc, third_party/xla/xla/translate/mhlo_to_hlo/BUILD, third_party/xla/xla/translate/mhlo_to_hlo/layout_util.cc",klucke,False
"Replace all remaining uses of affine.apply with apply_indexing.

Also split indexing maps into one map per result, to not block
LICM.

PiperOrigin-RevId: 635767137",Johannes Reifferscheid,jreiffers@google.com,2024-05-21 12:01:17,"third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/concatenate_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.h, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.h, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/model/indexing_map.h",jreiffers,False
"Automated Code Change

Fix header includes

PiperOrigin-RevId: 635748303",Adrian Kuegel,akuegel@google.com,2024-05-21 10:37:22,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/mlir_emitter_test_base.h, third_party/xla/xla/service/gpu/fusions/reduction.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.h, third_party/xla/xla/service/gpu/fusions/scatter.cc, third_party/xla/xla/service/gpu/fusions/scatter.h, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/scatter_test.cc, third_party/xla/xla/service/gpu/fusions/tiling_util.cc, third_party/xla/xla/service/gpu/fusions/tiling_util.h, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.h, third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/transpose_test.cc, third_party/xla/xla/service/gpu/fusions/triton.cc, third_party/xla/xla/service/gpu/fusions/triton.h, third_party/xla/xla/service/gpu/fusions/triton_test.cc",akuegel,False
"[xla:gpu] Fail gracefully (i.e. don't segfault) if Triton MLIR isn't parsable.

PiperOrigin-RevId: 635742591",Chris Jones,cjfj@google.com,2024-05-21 10:13:13,third_party/xla/xla/service/gpu/ir_emitter_unnested.cc,chr1sj0nes,False
"[Triton] Re-enable createRemoveLayoutConversionPass.

PiperOrigin-RevId: 635739578",Mohammed Anany,manany@google.com,2024-05-21 10:00:18,"third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_cuda.cc",Moerafaat,False
"Re-land: [XLA:GPU] Store fusion_roots and fusion_heroes as HloInstructionAdaptor in HloFusionAnalysis.

Reverts 23ac61b9f8a787925a089772a70e288fe42a336c

PiperOrigin-RevId: 635737157",Oleg Shyshkov,shyshkov@google.com,2024-05-21 09:50:22,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/concatenate.cc, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/reduction.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.h, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/fusion_analysis_cache_test.cc",olegshyshkov,False
"Automated Code Change

PiperOrigin-RevId: 635733471",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 09:35:06,"tensorflow/c/experimental/ops/gen/common/case_format.cc, tensorflow/c/experimental/ops/gen/common/case_format_test.cc, tensorflow/c/experimental/ops/gen/common/controller.cc, tensorflow/c/experimental/ops/gen/common/path_config.cc, tensorflow/c/experimental/ops/gen/common/source_code.cc, tensorflow/c/experimental/ops/gen/common/view_util.cc",tensorflower-gardener,False
"Add unbounded dynamism test for FftOp.

PiperOrigin-RevId: 635731691",Gunhyun Park,gunhyun@google.com,2024-05-21 09:26:22,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"compat: Update forward compatibility horizon to 2024-05-21

PiperOrigin-RevId: 635725518",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 09:02:27,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1869.

PiperOrigin-RevId: 635725513",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 09:02:26,tensorflow/core/public/version.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 635716090",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 08:21:04,tensorflow/core/common_runtime/executor.cc,tensorflower-gardener,False
"MLIR emitters: Vectorize transposes with small element types.

Special thanks to github user lingzhi98, who proposed and benchmarked
this optimization and implemented it in https://github.com/openxla/xla/pull/12552.
It turned out that the Tiling abstraction made this harder than it needs to be.
This is an independent reimplementation that removes the Tiling abstraction, but
reuses lingzhi98's tests and most of their heuristic for enabling vectorization.

The differences in the heuristic are:
- respect the shared memory budget
- enable vectorization if the dimensions are divisible by 2, not just when
  they are divisible by 64.

PiperOrigin-RevId: 635715722",Johannes Reifferscheid,jreiffers@google.com,2024-05-21 08:19:06,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.h, third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/tiling_util.h, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.h, third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.h",jreiffers,False
"Automated Code Change

PiperOrigin-RevId: 635712904",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-21 08:06:27,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/dot_operand_converter_test.cc, third_party/xla/xla/service/gpu/dot_sparsity_rewriter_test.cc, third_party/xla/xla/service/gpu/fusion_merger_test.cc",tensorflower-gardener,False
"Rename Buffer to GetBuffer.

InterpreterValue::Buffer having the same name as Buffer is considered
invalid by GCC.

sed ""s/\.Buffer/.GetBuffer/g"" -i `find . -name '*.cc'`

PiperOrigin-RevId: 635710161",Johannes Reifferscheid,jreiffers@google.com,2024-05-21 07:55:38,"third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/arith.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/bufferization.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/builtin.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/memref.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/mhlo.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/vector.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter_value.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter_value.h, third_party/xla/xla/mlir/tools/mlir_replay/public/execution_trace_utils.cc",jreiffers,False
"Internal change only.

PiperOrigin-RevId: 635704825",Johannes Reifferscheid,jreiffers@google.com,2024-05-21 07:28:15,third_party/xla/xla/service/gpu/ir_emitter_unnested.cc,jreiffers,False
"PR #12845: [XLA:GPU] add workspace rewrite for FP8 gemm

Imported from GitHub PR https://github.com/openxla/xla/pull/12845

Add  workspace rewrite for FP8 with amax fusion.
Copybara import of the project:

--
a2b7f41caff2924798021d130566379e65984750 by Shawn Wang <shawnw@nvidia.com>:

add workspace rewrite for FP8 gemm

Merging this change closes #12845

PiperOrigin-RevId: 635646533",Shawn Wang,shawnw@nvidia.com,2024-05-21 02:42:32,"third_party/xla/xla/service/gpu/backend_configs.proto, third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc",shawnwang18,False
"Introduce MakeConstantWithShape in hlo_creation_util file.

PiperOrigin-RevId: 635641775",Farzin Houshmand,farzinh@google.com,2024-05-21 02:22:14,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_creation_utils.cc, third_party/xla/xla/service/hlo_creation_utils.h, third_party/xla/xla/service/while_loop_unroller.cc",farzinhoushmand,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/cudnn_workspace_rewriter.cc

PiperOrigin-RevId: 635617583",Kuy Mainwaring,kuym@google.com,2024-05-21 00:27:23,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/cudnn_workspace_rewriter.cc",kuym,False
"PR #12848: [XLA:GPU] Add force_update function for conditional commands

Imported from GitHub PR https://github.com/openxla/xla/pull/12848

Copybara import of the project:

--
9f8daced1e91da4abca328406b8c42cfcc250d20 by Shawn Wang <shawnw@nvidia.com>:

update force_update for conditional commands

--
1ffd8e0f59158bb40ad35f0ed205c48c1287cc18 by Shawn Wang <shawnw@nvidia.com>:

fix

Merging this change closes #12848

PiperOrigin-RevId: 635614435",Shawn Wang,shawnw@nvidia.com,2024-05-21 00:12:09,"third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h",shawnwang18,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/gpu_conv_rewriter_test.cc

PiperOrigin-RevId: 635612157",Kuy Mainwaring,kuym@google.com,2024-05-21 00:03:36,third_party/xla/xla/service/gpu/gpu_conv_rewriter_test.cc,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/amdgpu_compiler.cc

PiperOrigin-RevId: 635607046",Kuy Mainwaring,kuym@google.com,2024-05-20 23:43:02,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/amdgpu_compiler.cc",kuym,False
"Add restore_uid to TPUEmbeddingShardedVariable.

PiperOrigin-RevId: 635600618",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 23:17:06,tensorflow/python/tpu/tpu_embedding_v3.py,tensorflower-gardener,False
"Add support for building and pushing to Artifact Registry for Linux ARM64 images.

PiperOrigin-RevId: 635582651",Quoc Truong,quoct@google.com,2024-05-20 22:08:23,ci/official/containers/linux_arm64/build.sh,quoctruong,False
"Automated Code Change

PiperOrigin-RevId: 635581142",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 22:03:27,tensorflow/core/common_runtime/graph_execution_state.cc,tensorflower-gardener,False
"Add SavedModel to StableHLO Converter to TensorFlow pip package

PiperOrigin-RevId: 635568823",Sandeep Dasgupta,sdasgup@google.com,2024-05-20 21:19:45,"RELEASE.md, tensorflow/BUILD, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/BUILD, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/README.md, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/python/BUILD, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo.cc, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo_lib.cc, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo_lib.h, tensorflow/python/BUILD, tensorflow/tools/def_file_filter/symbols_pybind.txt, third_party/xla/third_party/tsl/tools/def_file_filter/symbols_pybind.txt",sdasgup3,False
"Automated Code Change

PiperOrigin-RevId: 635568697",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 21:19:23,"tensorflow/core/common_runtime/next_pluggable_device/BUILD, tensorflow/core/common_runtime/next_pluggable_device/plugin_coordination_service_agent_helper.h",tensorflower-gardener,False
"When pruning function bodies, enable pruning side-effect-free ""stateful"" ops.

Previously, function pruning would leave in place ops marked as ""stateful"" that are also side-effect free, even when they have no downstream dependencies. In the case of ""ResourceGather"" this op can trigger a relatively large amount of CPU work and memory bandwidth consumption, so it is valuable to be able to prune it.

PiperOrigin-RevId: 635559636",Derek Murray,mrry@google.com,2024-05-20 20:52:10,"tensorflow/core/common_runtime/function_def_utils.cc, tensorflow/core/common_runtime/lower_function_call_op_test.cc",mrry,False
"Remove never called TpuExecutor_DeallocateEvent.

PiperOrigin-RevId: 635558747",Kyle Lucke,klucke@google.com,2024-05-20 20:49:14,"third_party/xla/xla/stream_executor/tpu/tpu_executor_c_api.h, third_party/xla/xla/stream_executor/tpu/tpu_executor_init_fns.inc",klucke,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 635549245",Kyle Lucke,klucke@google.com,2024-05-20 20:17:19,"third_party/xla/xla/backends/interpreter/executable_base.cc, third_party/xla/xla/backends/profiler/cpu/metadata_collector.cc, third_party/xla/xla/backends/profiler/plugin/plugin_tracer.cc, third_party/xla/xla/backends/profiler/tpu/tpu_tracer.cc, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/hlo/evaluator/hlo_evaluator.cc, third_party/xla/xla/hlo/evaluator/hlo_evaluator_typed_visitor.h, third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.cc, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/distributed/client_server_test.cc, third_party/xla/xla/pjrt/distributed/util.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc, third_party/xla/xla/service/cpu/tests/cpu_noalias_test.cc, third_party/xla/xla/service/heap_simulator/heap_simulator.cc, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/tools/hlo_bisect/hlo_bisect_state.cc, third_party/xla/xla/tools/hlo_bisect/hlo_bisect_utils.cc, third_party/xla/xla/tools/hlo_opt/opt_main.cc, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_function_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_module_importer.cc, third_party/xla/xla/translate/mhlo_to_hlo/translate.cc, third_party/xla/xla/tsl/util/byte_swap_array.h",klucke,False
"Use == instead of equals method (deprecated)

PiperOrigin-RevId: 635545562",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-20 20:03:35,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch",mlevesquedion,False
"Cleanup dependency on tracing.h

PiperOrigin-RevId: 635539097",Clive Verghese,cliveverghese@google.com,2024-05-20 19:39:41,"tensorflow/compiler/jit/xla_device.cc, tensorflow/core/debug/debug_grpc_io_utils_test.cc, tensorflow/core/debug/debug_grpc_testlib.cc, tensorflow/core/distributed_runtime/master_session.cc, tensorflow/core/distributed_runtime/rpc/BUILD, tensorflow/core/distributed_runtime/rpc/grpc_master_service.cc, tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc, tensorflow/core/distributed_runtime/rpc/grpc_remote_worker.cc, tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc, tensorflow/core/distributed_runtime/worker.cc, tensorflow/core/framework/dataset.h, tensorflow/core/framework/run_handler.cc, tensorflow/core/kernels/collective_nccl.cc, tensorflow/core/kernels/collective_nccl_all_to_all.cc, tensorflow/core/kernels/collective_nccl_broadcaster.cc, tensorflow/core/kernels/collective_nccl_gatherer.cc, tensorflow/core/kernels/collective_nccl_reducer.cc, tensorflow/core/kernels/data/experimental/map_and_batch_dataset_op.cc, tensorflow/core/kernels/function_ops.cc, tensorflow/core/nccl/collective_communicator.cc, tensorflow/core/tfrt/run_handler_thread_pool/BUILD, tensorflow/core/tfrt/run_handler_thread_pool/run_handler.cc",cliveverghese,False
"Automated Code Change

PiperOrigin-RevId: 635533415",Kyle Lucke,klucke@google.com,2024-05-20 19:17:07,"tensorflow/compiler/mlir/lite/transforms/legalize_tf.cc, tensorflow/core/tpu/kernels/tpu_execute_op.cc, tensorflow/core/tpu/tpu_execute.cc",klucke,False
"Remove `PjRtStreamExecutorMemorySpace` specialization from `PjRtStreamExecutorClient`

This allows us to use existing host memory spaces for GPUs without having to reimplement them for stream executor clients.

PiperOrigin-RevId: 635531851",Junwhan Ahn,junwhan@google.com,2024-05-20 19:11:22,"tensorflow/core/common_runtime/eager/context_distributed_manager.cc, tensorflow/core/common_runtime/gpu/gpu_device.cc, third_party/xla/xla/examples/axpy/stablehlo_compile_test.cc, third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/interpreter_device.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client_test.cc",junwhanahn,False
"Move Event creation into each StreamExecutorInterface derived class.

PiperOrigin-RevId: 635531604",Kyle Lucke,klucke@google.com,2024-05-20 19:10:17,"tensorflow/c/experimental/stream_executor/stream_executor.cc, tensorflow/c/experimental/stream_executor/stream_executor_test.cc, third_party/xla/xla/backends/interpreter/executor.h, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/event.cc, third_party/xla/xla/stream_executor/event.h, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h, third_party/xla/xla/stream_executor/tpu/BUILD, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.h",klucke,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 635530537",Kyle Lucke,klucke@google.com,2024-05-20 19:06:36,"third_party/xla/xla/array.h, third_party/xla/xla/layout_util.cc, third_party/xla/xla/literal.cc, third_party/xla/xla/literal.h, third_party/xla/xla/literal_comparison.cc, third_party/xla/xla/shape_layout.cc, third_party/xla/xla/shape_tree.h, third_party/xla/xla/shape_util.cc, third_party/xla/xla/shape_util.h, third_party/xla/xla/sharding_op_util.cc, third_party/xla/xla/status_macros_test.cc, third_party/xla/xla/util.h",klucke,False
"Replace the use of xla::OkStatus with absl::OkStatus now that they're the same.

PiperOrigin-RevId: 635524889",Kyle Lucke,klucke@google.com,2024-05-20 18:49:30,"third_party/xla/xla/service/cpu/cpu_executable.cc, third_party/xla/xla/service/cpu/cpu_layout_assignment.cc, third_party/xla/xla/service/cpu/cpu_xfeed.cc, third_party/xla/xla/service/cpu/dot_op_emitter.cc, third_party/xla/xla/service/cpu/ir_emitter.cc, third_party/xla/xla/service/cpu/ir_function.cc, third_party/xla/xla/service/cpu/mlir_emitter.cc, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/service/cpu/onednn_ops_rewriter.cc, third_party/xla/xla/service/memory_space_assignment/algorithm.cc, third_party/xla/xla/service/memory_space_assignment/allocation.cc, third_party/xla/xla/service/memory_space_assignment/allocation.h, third_party/xla/xla/service/memory_space_assignment/cost_analysis_test.cc, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer.cc, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer_test.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",klucke,False
"Add missing parentheses in XLA custom calls doc.

When reading through custom_call.md, I noticed these two missing parentheses.

PiperOrigin-RevId: 635522222",Dan Foreman-Mackey,danfm@google.com,2024-05-20 18:39:46,third_party/xla/docs/custom_call.md,dfm,False
"[XLA] Support transposing iota tile assignment with tile dimensions combining multiple reshape dimensions.

PiperOrigin-RevId: 635514612",Ce Zheng,zce@google.com,2024-05-20 18:15:48,"third_party/xla/xla/hlo/ir/tile_assignment.cc, third_party/xla/xla/tests/tile_assignment_test.cc",cezheng,False
"Temporarily disable xnnpack cache test on Android.

PiperOrigin-RevId: 635513547",Weiyi Wang,weiyiw@google.com,2024-05-20 18:12:10,tensorflow/lite/delegates/xnnpack/BUILD,sirakiin,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 635513502",Kyle Lucke,klucke@google.com,2024-05-20 18:12:00,"third_party/xla/xla/client/client.cc, third_party/xla/xla/client/client.h, third_party/xla/xla/client/global_data.cc, third_party/xla/xla/client/local_client.cc, third_party/xla/xla/client/local_client.h, third_party/xla/xla/client/padding.cc, third_party/xla/xla/client/padding.h, third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder.h, third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/python/jax_jit.cc, third_party/xla/xla/python/outfeed_receiver_test.cc, third_party/xla/xla/python/pmap_lib.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/py_values.h, third_party/xla/xla/python/util.cc, third_party/xla/xla/python/util.h, third_party/xla/xla/python/xplane_to_profile_instructions.cc, third_party/xla/xla/python/xplane_to_profile_instructions.h",klucke,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 635510656",Kyle Lucke,klucke@google.com,2024-05-20 18:04:16,"third_party/xla/xla/service/spmd/canonicalize_all_gather_for_cse_test.cc, third_party/xla/xla/service/spmd/convolution_handler.cc, third_party/xla/xla/service/spmd/custom_call_handler.cc, third_party/xla/xla/service/spmd/dot_handler.cc, third_party/xla/xla/service/spmd/fft_handler.cc, third_party/xla/xla/service/spmd/gather_scatter_handler.cc, third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/spmd/spmd_partitioner.h, third_party/xla/xla/service/spmd/stateful_rng_spmd_partitioner.cc, third_party/xla/xla/service/spmd/stateful_rng_spmd_partitioner.h, third_party/xla/xla/service/spmd/whole_graph_manual_pass_test.cc, third_party/xla/xla/stream_executor/tpu/tpu_executable.h, third_party/xla/xla/stream_executor/tpu/tpu_executable_interface.cc, third_party/xla/xla/stream_executor/tpu/tpu_executable_interface.h, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.h, third_party/xla/xla/stream_executor/tpu/tpu_executor_interface.h, third_party/xla/xla/stream_executor/tpu/tpu_node_context.cc, third_party/xla/xla/stream_executor/tpu/tpu_node_context.h, third_party/xla/xla/stream_executor/tpu/tpu_platform.cc, third_party/xla/xla/stream_executor/tpu/tpu_platform.h, third_party/xla/xla/stream_executor/tpu/tpu_profiler_c_api.h, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager.cc, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager.h, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager_interface.h",klucke,False
"Remove the use of xla::OkStatus now that it's just an alias to absl::OkStatus.

PiperOrigin-RevId: 635509418",Kyle Lucke,klucke@google.com,2024-05-20 18:01:22,third_party/xla/xla/python/ifrt/shape.cc,klucke,False
"Use AllocateDestinationBuffer instead of CreateUninitializedBuffer for
AsyncHostToDeviceTransferManager::Create. This is to synchronize the h2d stream with the compute stream.

With this change, PjRtStreamExecutorBuffer::Delete doesn't need to schedule deallocation on compute stream if there are no other use cases that don't wait for the compute steam before writing to the HBM.

PiperOrigin-RevId: 635508746",Yifan Jiang,yifanjiang@google.com,2024-05-20 18:00:01,"third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",yifjiang,False
"Remove unnecessary uses of `gpu_any` backend

If a test is intended for the v100 backend, that will run in OSS, so no need for the extra `gpu_any` backend.

The usage in hlo_opt should've been removed already in a previous change.

PiperOrigin-RevId: 635505667",David Dunleavy,ddunleavy@google.com,2024-05-20 17:51:34,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/tools/hlo_opt/BUILD",ddunl,False
"Simplify JAX lowering rules for cumulative sum

Upstream fix has landed => removing CPU workaround.

PiperOrigin-RevId: 635505632",George Karpenkov,cheshire@google.com,2024-05-20 17:51:27,third_party/xla/xla/python/xla_client.py,cheshire,False
"Reenable/tag previously broken tests on ARM builds of XLA

Some tests work now because of hermetic python in XLA, while cross-compilation still breaks other tests.

PiperOrigin-RevId: 635504270",David Dunleavy,ddunleavy@google.com,2024-05-20 17:47:16,"third_party/xla/.kokoro/linux/build.sh, third_party/xla/xla/service/BUILD, third_party/xla/xla/tests/BUILD",ddunl,False
"Update np.float_ and np.complex_ to match Numpy 2.0.

Numpy 2.0 removed the aliases np.float_ and np.complex_. Direct usages of np.float_ and np.complex_ are replaced with np.float64 and np.complex128, respectively.
See https://github.com/numpy/numpy/issues/24743 and https://numpy.org/devdocs/numpy_2_0_migration_guide.html#changes-to-namespaces.

Consistent with JAX, TF retains dtype wrappers for float_ and complex_. This is considered useful for determining the default float/complex type, providing compatibility with older code that might still rely on these aliases.

PiperOrigin-RevId: 635502855",Kanglan Tang,kanglan@google.com,2024-05-20 17:43:00,"tensorflow/python/ops/numpy_ops/np_dtypes.py, tensorflow/python/ops/numpy_ops/tests/np_test.py, tensorflow/python/ops/numpy_ops/tests/test_util.py",kanglant,False
"Migrate away from llvm::StringRef::equals

Note that llvm::StringRef::equals has been deprecated upstream.

PiperOrigin-RevId: 635499769",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 17:33:39,tensorflow/dtensor/mlir/expansions/reduce_spmd_expander.cc,tensorflower-gardener,False
"Clean up include and build file

PiperOrigin-RevId: 635495307",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 17:20:48,"tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_executable_registry.h, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.cc, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.h, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils.h, tensorflow/core/tfrt/ifrt/ifrt_model_context.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h, tensorflow/core/tfrt/ifrt/sharding_utils.cc, tensorflow/core/tfrt/ifrt/sharding_utils.h, tensorflow/core/tfrt/ifrt/sharding_utils_test.cc",tensorflower-gardener,False
"Compute stats should clone the feature configs before updating them.

PiperOrigin-RevId: 635480121",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 16:32:15,"tensorflow/python/tpu/tpu_embedding_v3.py, tensorflow/python/tpu/tpu_embedding_v3_test.py",tensorflower-gardener,False
"Add float/double template specializations for `TensorEq` matcher.

Adds template specializations that improve floating-point equality comparison for float and double tensors.

PiperOrigin-RevId: 635455030",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 14:54:11,"tensorflow/core/framework/tensor_matcher.cc, tensorflow/core/framework/tensor_matcher_test.cc",tensorflower-gardener,False
"Print mismatches for UnorderedElements() of different sizes.

Changes the behavior of UnorderedElements()/UnorderedElementsAreArray() to print items-without-matchers and matchers-without-items in the case where the actual and expected are different sizes.

PiperOrigin-RevId: 635451316",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 14:35:58,tensorflow/compiler/jit/node_matchers_test.cc,tensorflower-gardener,False
"[xla:ffi] Fix msan error for //xla/tests:custom_call_test_cpu.

PiperOrigin-RevId: 635414868",Penporn Koanantakool,penporn@google.com,2024-05-20 11:23:22,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/call_frame.cc",penpornk,False
"compat: Update forward compatibility horizon to 2024-05-20

PiperOrigin-RevId: 635385257",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 09:02:19,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1868.

PiperOrigin-RevId: 635385236",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 09:02:16,tensorflow/core/public/version.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 635370016",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 07:48:27,"tensorflow/core/runtime_fallback/conversion/BUILD, tensorflow/core/runtime_fallback/conversion/conversion.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 635350042",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 06:04:13,"tensorflow/dtensor/mlir/BUILD, tensorflow/dtensor/mlir/function_renaming.cc, tensorflow/dtensor/mlir/handle_cross_cluster_dependencies.cc, tensorflow/dtensor/mlir/handle_sparsetensors.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 635317185",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 02:44:28,tensorflow/compiler/mlir/quantization/stablehlo/python/pywrap_quantization_lib.cc,tensorflower-gardener,False
"Refactor common test code to a util

PiperOrigin-RevId: 635307400",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-20 01:27:52,"tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test_util.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test_util.h, tensorflow/core/tfrt/kernels/BUILD, tensorflow/core/tfrt/kernels/ifrt_program_ops_test.cc",tensorflower-gardener,False
"Migrate coord grpc client and service to use absl libraries (mutex, thread annotation, status) directly.

PiperOrigin-RevId: 635277739",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-19 21:12:09,"third_party/xla/xla/tsl/distributed_runtime/rpc/coordination/BUILD, third_party/xla/xla/tsl/distributed_runtime/rpc/coordination/grpc_coordination_client.cc, third_party/xla/xla/tsl/distributed_runtime/rpc/coordination/grpc_coordination_service_impl.cc, third_party/xla/xla/tsl/distributed_runtime/rpc/coordination/grpc_coordination_service_impl.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 635255967",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-19 18:08:14,tensorflow/core/common_runtime/optimized_function_graph_info.h,tensorflower-gardener,False
"Cleanup dependency on tracing.h

PiperOrigin-RevId: 635253325",Clive Verghese,cliveverghese@google.com,2024-05-19 17:52:52,"tensorflow/core/common_runtime/BUILD, tensorflow/core/common_runtime/base_collective_executor.cc, tensorflow/core/common_runtime/direct_session.cc, tensorflow/core/common_runtime/executor.cc, tensorflow/core/common_runtime/executor_test.cc, tensorflow/core/common_runtime/process_util.cc, tensorflow/core/common_runtime/single_threaded_executor_test.cc, tensorflow/core/common_runtime/threadpool_device.cc",cliveverghese,False
"Update GraphDef version to 1867.

PiperOrigin-RevId: 635189739",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-19 09:03:48,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-19

PiperOrigin-RevId: 635189458",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-19 09:02:23,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"[XLA] Error out when encountering errors during flag parsing

Currently we crash on unknown flags left after XLA_FLAGS parsing, but all the
errors are just silently ignored. This leaves a large footgun which ignores
failed flags.

PiperOrigin-RevId: 635098018",George Karpenkov,cheshire@google.com,2024-05-18 21:14:58,"third_party/xla/xla/parse_flags_from_env.cc, third_party/xla/xla/parse_flags_from_env.h, third_party/xla/xla/parse_flags_from_env_test.cc, third_party/xla/xla/service/gpu_compilation_environment.cc, third_party/xla/xla/service/gpu_compilation_environment_test.cc",cheshire,False
"disable flaky mwms_pjrt_gpu_test_xla_2gpu test

PiperOrigin-RevId: 635064164",Edward Schwartz,schwartzedward@google.com,2024-05-18 16:40:22,tensorflow/python/distribute/BUILD,SeeForTwo,False
"Automated Code Change

PiperOrigin-RevId: 635054554",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 15:16:33,"third_party/xla/third_party/tsl/tsl/profiler/lib/BUILD, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_collection.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_collection.h, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_controller.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_controller.h, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_factory_test.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_lock.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_lock.h, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_lock_test.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_session.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_session.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 635053948",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 15:11:37,tensorflow/dtensor/cc/dtensor_device.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 635041988",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 13:27:11,tensorflow/tools/api/tests/convert_from_multiline.cc,tensorflower-gardener,False
"Extract `ExecutionStreamIds` from `Thunks` instead of the now-deprecated `GpuBackendConfig::operation_queue_id`.

PiperOrigin-RevId: 635038291",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 13:00:07,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_executable.cc",tensorflower-gardener,False
"Move `ForAllThunks` to its own file.

`ForAllThunks` is currently unused, and the new version has a few improvements:
* For `Thunks` that have nested `Thunks`, e.g. `ConditionalThunk`, it invokes `fn` on both the parent `Thunk` and all nested children. The previous version would only invoke `fn` on the nested children.
* It discovers nested children in all `Thunk` types, including `AddressComputationThunks` and `CommandBufferThunks`.
* It uses more modern types -- e.g. `absl::FunctionRef`.

PiperOrigin-RevId: 635036109",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 12:40:53,"third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk.h, third_party/xla/xla/service/gpu/runtime/for_all_thunks.cc, third_party/xla/xla/service/gpu/runtime/for_all_thunks.h, third_party/xla/xla/service/gpu/runtime/for_all_thunks_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 635015194",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 10:10:50,"tensorflow/core/common_runtime/device_mgr.h, tensorflow/core/common_runtime/direct_session.h, tensorflow/core/common_runtime/direct_session_test.cc, tensorflow/core/common_runtime/dynamic_device_mgr.cc, tensorflow/core/common_runtime/function.cc",tensorflower-gardener,False
"Add unit test coverage for IFRT call op kernel impl

PiperOrigin-RevId: 635013418",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 10:00:30,"tensorflow/core/tfrt/ifrt/testdata/BUILD, tensorflow/core/tfrt/kernels/BUILD, tensorflow/core/tfrt/kernels/ifrt_program_ops_test.cc",tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-18

PiperOrigin-RevId: 635005488",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 09:02:22,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1866.

PiperOrigin-RevId: 635005462",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 09:02:15,tensorflow/core/public/version.h,tensorflower-gardener,False
"Fix nightly build / cmake build error due to missing argument

PiperOrigin-RevId: 634986604",Jae H. Yoo,jaeyoo@google.com,2024-05-18 07:01:40,tensorflow/lite/tools/evaluation/utils.cc,jaeyoo,False
"Fix keras model saving error into TF SavedModel format.

Now that keras 3 doesn't support model saving format TF SavedModel directly via `model.save()`, we need to use `tf.saved_model.save()` to save the model.

PiperOrigin-RevId: 634985205",Jae H. Yoo,jaeyoo@google.com,2024-05-18 06:53:18,tensorflow/lite/python/util_test.py,jaeyoo,False
"Automated Code Change

PiperOrigin-RevId: 634980543",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 06:25:10,third_party/xla/xla/pjrt/distributed/topology_util.cc,tensorflower-gardener,False
"Add ReadFileTraceMetadata function to support trace viewer processes list reading

PiperOrigin-RevId: 634977692",Yin Zhang,yinzz@google.com,2024-05-18 06:03:51,"tensorflow/core/profiler/convert/trace_viewer/BUILD, tensorflow/core/profiler/convert/trace_viewer/trace_events.cc, tensorflow/core/profiler/convert/trace_viewer/trace_events.h, third_party/xla/third_party/tsl/tsl/lib/io/BUILD",zzzaries,False
"[XLA] Support more cases in IotaTileAssignment::Transpose.

PiperOrigin-RevId: 634960053",Ce Zheng,zce@google.com,2024-05-18 03:55:53,"third_party/xla/xla/hlo/ir/BUILD, third_party/xla/xla/hlo/ir/tile_assignment.cc, third_party/xla/xla/tests/tile_assignment_test.cc",cezheng,False
"[xla:ffi] Fix return types in `xla::ffi::Expected<T, E>`.

PiperOrigin-RevId: 634947036",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 02:24:31,third_party/xla/xla/ffi/api/api.h,tensorflower-gardener,False
"In PjRtStreamExecutorBuffer::Delete, fix a bug causing memory corruption.

The bug is that we don't wait for events using the buffer on the Compute stream, and also the definition events. This can cause a race condition where the buffer is deleted before it is read/written, which can lead to memory corruptions.

For events on the compute stream, the fix is to schedule the deallocation on the compute stream.
For the definition events, the fix is to wait for them on a stream in a stream pool if they are not defined on the compute stream.

Added a fixed-size stream pool to avoid the overhead and deadlock that could be introduced by BorrowStreamFromPool, since we previously saw deadlocks between the cuStreamCreate and other cuda calls like cuMemHostAlloc.

This change probably wouldn't be needed if all writes are scheduled on the compute stream, but that is not the case today. We have a lot of usages of the h2d and d2d stream.

PiperOrigin-RevId: 634944963",Yifan Jiang,yifanjiang@google.com,2024-05-18 02:08:01,"third_party/xla/xla/pjrt/local_device_state.cc, third_party/xla/xla/pjrt/local_device_state.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",yifjiang,False
"[XLA:SPMD] Support partitioning kCall.

PiperOrigin-RevId: 634944833",Tongfei Guo,tongfei@google.com,2024-05-18 02:07:04,"third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/spmd/spmd_partitioner.h, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc",Tongfei-Guo,False
"Fix tf.lite's lite_v2_test by using the new Keras 3 API.

Wrapping TF quantization functions inside Keras 3 layers is required.

PiperOrigin-RevId: 634943217",Jae H. Yoo,jaeyoo@google.com,2024-05-18 01:56:48,tensorflow/lite/python/lite_v2_test.py,jaeyoo,False
"Adopts the syntax 'xla_tpu_auto_spmd_partitioning_memory_budget_ratio=-1.2' where the new '-' sign indicates that we are disabling the soft memory constraint.

PiperOrigin-RevId: 634942516",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 01:51:22,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_option.h",tensorflower-gardener,False
"Migrate coord service and tests to use absl libraries (mutex, thread annotation, status) directly.

PiperOrigin-RevId: 634935787",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-18 01:06:43,"third_party/xla/xla/tsl/distributed_runtime/coordination/BUILD, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent_test.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_error_util_test.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_recoverable_job_test.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_test.cc",tensorflower-gardener,False
"Tag `//xla/tools/hlo_opt:hlo_opt_gpu` with the `gpu` tag to avoid building on CPU builds of XLA

PiperOrigin-RevId: 634922729",David Dunleavy,ddunleavy@google.com,2024-05-17 23:59:09,third_party/xla/xla/tools/hlo_opt/BUILD,ddunl,False
"Use StreamExecutorInterface::CreateEvent to create events in send & recv thunks.

PiperOrigin-RevId: 634901606",Kyle Lucke,klucke@google.com,2024-05-17 22:26:16,"tensorflow/compiler/jit/kernels/BUILD, tensorflow/compiler/jit/kernels/xla_ops.cc, tensorflow/compiler/jit/xla_host_recv_device_context.cc, tensorflow/compiler/jit/xla_host_recv_device_context.h, tensorflow/compiler/jit/xla_host_send_device_context.cc, tensorflow/compiler/jit/xla_host_send_device_context.h, tensorflow/compiler/jit/xla_host_send_recv_device_context_test.cc, third_party/xla/xla/executable_run_options.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/service/gpu/runtime/send_recv_thunk.cc, third_party/xla/xla/service/gpu/runtime/send_recv_thunk.h",klucke,False
"Integrate LLVM at llvm/llvm-project@1e5f29af81a5

Updates LLVM usage to match
[1e5f29af81a5](https://github.com/llvm/llvm-project/commit/1e5f29af81a5)

PiperOrigin-RevId: 634900249",Fangrui Song,maskray@google.com,2024-05-17 22:19:57,third_party/llvm/workspace.bzl,MaskRay,False
"Fix Flatbuffer's upstream error on `GetTemporaryPointer()`

PiperOrigin-RevId: 634885829",Jae H. Yoo,jaeyoo@google.com,2024-05-17 21:23:09,"RELEASE.md, tensorflow/lite/tools/cmake/modules/flatbuffers.cmake, third_party/flatbuffers/workspace.bzl",jaeyoo,False
"[XLA:CPU] Remove unnecessary include of absl/log/check.h.

This resolves naming conflicts with tsl and absl.

PiperOrigin-RevId: 634883049",Sara Smoot,sarasmoot@google.com,2024-05-17 21:12:34,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/onednn_softmax.cc",sgerrard,False
"Remove reference to `mlir::Operations` in `Thunks`.

The `mlir::Operation` in `Thunk` (`Thunk::op_`) is never set to a value different from `nullptr`.

Conveniently, this also removes the need for `Thunk::ClearCompileTimeInfo`, which in turn leaves `ForAllThunks` (in `compile_module_to_llvm_ir.cc`) unused.

I'm doing this first so that I can then (a) move `ForAllThunks` to its own file, and (b) change its behavior to actually iterate over all `Thunks`: for example, `ForAllThunks` currently does not iterate over the `embedded_thunk` in `AddressComputationThunk`. This behavior will be safer to change after there's no remaining users of the function.

PiperOrigin-RevId: 634879646",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 21:01:03,"third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/copy_thunk.h, third_party/xla/xla/service/gpu/runtime/kernel_thunk.h, third_party/xla/xla/service/gpu/runtime/memset_thunk.h, third_party/xla/xla/service/gpu/runtime/thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.h, third_party/xla/xla/service/gpu/runtime/while_thunk.cc",tensorflower-gardener,False
"Improve errors upon service shutdown.

PiperOrigin-RevId: 634859665",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 19:46:46,"third_party/xla/xla/tsl/distributed_runtime/coordination/BUILD, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.h, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.h, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_test.cc",tensorflower-gardener,False
"Use default relative error tolerance for Cbrt.

PiperOrigin-RevId: 634859424",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 19:45:50,third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_f32_or_smaller.cc,tensorflower-gardener,False
"[xla:python] NFC: Fix all warnings in xla_compiler.cc

PiperOrigin-RevId: 634854042",Eugene Zhulenev,ezhulenev@google.com,2024-05-17 19:25:05,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/xla_compiler.cc",ezhulenev,False
"Integrate LLVM at llvm/llvm-project@371eccd5dfed

Updates LLVM usage to match
[371eccd5dfed](https://github.com/llvm/llvm-project/commit/371eccd5dfed)

PiperOrigin-RevId: 634844947",Dmitri Gribenko,dmitrig@google.com,2024-05-17 18:53:22,third_party/llvm/workspace.bzl,gribozavr,False
"Remove duplicate test macros from TSL

`tsl/platform/test.h` used to define a macro `DISABLED_ON_GPU_ROCM` which also exists in
`xla/tests/test_macros.h`. This led to build failures if both headers were included.

Since `test_macros.h` contains a huge set of similar macros let's remove the one
from `platform/test.h` and use `test_macros.h` everywhere.

I'm also fixing a CUDA include issue along the way.

PiperOrigin-RevId: 634844088",Henning Becker,hebecker@google.com,2024-05-17 18:50:03,"tensorflow/core/common_runtime/gpu/BUILD, tensorflow/core/common_runtime/gpu/gpu_device_test.cc, third_party/xla/third_party/tsl/tsl/platform/test.h, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/conv_layout_normalization_test.cc",beckerhe,False
"[Function inlining] Add flag to enable pruning before function calls are inlined.

Currently, the behavior of lowered functional (""V2"") control flow is subtly different from V1 control flow. In V1 control flow, the fetches for a `Session::Run()` call will determine whether or not  operations within the loop will be pruned. However, in V2 control flow, pruning may not always occur for multi-device functions, because the graph is partitioned (inserting stateful Send/Recv nodes) into multiple sub-functions, before the individual sub-functions are pruned.
While this should not affect the correctness of the execution, it may cause unnecessary computations and data transfers.

To address this problem, we introduce a new flag to enable pruning when inlining function calls, including as part of control flow V2 lowering, which inlines the condition and body functions of while loops, and true and false branches of conditionals.

Set `TF_FLAG_ENABLE_FUNCTION_PRUNING_BEFORE_INLINING=1` to enable this option.

PiperOrigin-RevId: 634842835",Derek Murray,mrry@google.com,2024-05-17 18:45:53,"tensorflow/core/common_runtime/BUILD, tensorflow/core/common_runtime/function.cc, tensorflow/core/common_runtime/function_def_utils.cc, tensorflow/core/common_runtime/function_def_utils.h, tensorflow/core/common_runtime/lower_function_call_op.cc, tensorflow/core/common_runtime/lower_function_call_op_test.cc, tensorflow/core/common_runtime/lower_while_op_test.cc, tensorflow/core/config/flag_defs.h, tensorflow/core/config/flags_api_wrapper.cc, tensorflow/core/framework/function_testlib.cc, tensorflow/core/framework/function_testlib.h, tensorflow/python/flags_pybind.pyi",mrry,False
"[XLA:GPU][NFC] Print reachability between two instructions on VLOG.

PiperOrigin-RevId: 634825414",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-17 17:49:46,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/collective_combiner_utils.h",golechwierowicz,False
"PR #12637: [ROCm] Fix build break due to 63c33b and f5ab2a4

Imported from GitHub PR https://github.com/openxla/xla/pull/12637

Copybara import of the project:

--
9a090b699df98d7c2a27311fbf353d4a0390e87f by Harsha HS <harsha.havanurshamsundara@amd.com>:

[ROCm] Fix build break due to 63c33b and f5ab2a4

Merging this change closes #12637

PiperOrigin-RevId: 634819780",Harsha H S,hsharsha@users.noreply.github.com,2024-05-17 17:31:41,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/runtime/BUILD",hsharsha,False
"[IFRT] Allow kReuseInput in RemapArrays if the number of input arrays is 1

`xla::ifrt::Client::RemapArrays()` allows `kReuseInput` for projection (view).
Previously, it expected the number of input arrays and output arrays is both 1.
This restriction has been relaxed to expecting only the number of input arrays
to be 1 because each of output arrays can be considered a projection of the
input arrays. In theory, the user could run N `RemapArrays()` for 1:1 remapping
to get 1:N remapping anyway to bypass the previous restriction, making the
restriction not effective.

PiperOrigin-RevId: 634818012",Hyeontaek Lim,hyeontaek@google.com,2024-05-17 17:25:43,"third_party/xla/xla/python/ifrt/client.h, third_party/xla/xla/python/ifrt/remap_impl_test_lib.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_remap.cc",hyeontaek,False
"Migrate away from llvm::StringRef::equals

Note that llvm::StringRef::equals has been deprecated upstream.

PiperOrigin-RevId: 634817679",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 17:24:47,"tensorflow/compiler/mlir/lite/stablehlo/odml_converter/transforms/outline_composites.cc, tensorflow/compiler/mlir/lite/utils/perception_ops_utils.cc, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/bridge/convert_tf_quant_ops_to_mhlo.cc, tensorflow/compiler/mlir/quantization/tensorflow/cc/constant_fold.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_custom_aggregation_ops.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/lift_hashtable_ops_as_args.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/prepare_lifting.cc, tensorflow/compiler/mlir/quantization/tensorflow/utils/tf_to_xla_attribute_utils.cc, tensorflow/compiler/mlir/tensorflow/transforms/executor_tpuv1_island_coarsening.cc, tensorflow/compiler/mlir/tensorflow/transforms/tfg-to-tfe.cc, tensorflow/compiler/mlir/tensorflow/utils/export_utils.cc",tensorflower-gardener,False
"disables `detect_odr_violation` for `validator_runner_test`

Runtimes-on-demand is causing AddressSanitizer to be unhappy with `validator_runner_test` due to some ODR violation. Given that we don't use what's causing this error, we're turning it off.

PiperOrigin-RevId: 634817533",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 17:24:20,tensorflow/lite/experimental/acceleration/mini_benchmark/BUILD,tensorflower-gardener,False
"Fix up some unreachable code warnings on mobile platforms

PiperOrigin-RevId: 634816157",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 17:19:21,"tensorflow/lite/kernels/internal/optimized/cpu_check.cc, tensorflow/lite/kernels/kernel_util.cc",tensorflower-gardener,False
"[stream_executor:host] Rework HostExecutor to avoid depending on LLVM by default

PiperOrigin-RevId: 634815409",Eugene Zhulenev,ezhulenev@google.com,2024-05-17 17:16:56,"third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_execution_engine.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/host/host_kernel.cc, third_party/xla/xla/stream_executor/host/host_kernel.h, third_party/xla/xla/stream_executor/host/host_kernel_test.cc, third_party/xla/xla/stream_executor/host/jit_host_kernel_function.cc, third_party/xla/xla/stream_executor/host/jit_host_kernel_function.h",ezhulenev,False
"Make returned future immdiately ready if it is TPU used only.
In such case, the variable
tensor is obtained at runtime through the returned name instead
and there is no need to wait for the restored tensor to be ready.

PiperOrigin-RevId: 634812708",Deqiang Chen,deqiangc@google.com,2024-05-17 17:07:52,tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc,deqiangc,False
"[XLA:GPU][NFC] Make SymbolicTile's `DestructureSummation` util more idiomatic.

PiperOrigin-RevId: 634805719",Benjamin Chetioui,bchetioui@google.com,2024-05-17 16:45:52,third_party/xla/xla/service/gpu/model/symbolic_tile.cc,bchetioui,False
"Integrate Triton up to 25b4212a9

PiperOrigin-RevId: 634797641",Goran Flegar,gflegar@google.com,2024-05-17 16:15:25,"third_party/triton/temporary/fix_register_constraints.patch, third_party/triton/temporary/fp8_splat.patch, third_party/triton/temporary/series.bzl, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/temporary/fix_register_constraints.patch, third_party/xla/third_party/triton/temporary/fp8_splat.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/workspace.bzl",gflegar,False
"Clean-up TFLite benchmark tools TFLite resolver.

PiperOrigin-RevId: 634795383",Quentin Khan,qkhan@google.com,2024-05-17 16:07:00,tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc,qukhan,False
"Integrate LLVM at llvm/llvm-project@a68d20e98605

Updates LLVM usage to match
[a68d20e98605](https://github.com/llvm/llvm-project/commit/a68d20e98605)

PiperOrigin-RevId: 634786916",Dmitri Gribenko,dmitrig@google.com,2024-05-17 15:35:02,third_party/llvm/workspace.bzl,gribozavr,False
"[XLA:GPU] Add support for destructuring collapsing reshapes in symbolic tiles.

Take a reshape `[6,8] reshape([48])`. The indexing map going through this\
reshape from output to input would be\
&nbsp;&nbsp;&nbsp;&nbsp;`(d0, d1) -> (d0 * 8 + d1)`.\
Previously to this change, there was no support for extracting sizes and\
strides from a multivariate expression.

Deriving a `size_map` for the indexing map above is as simple as creating a map\
&nbsp;&nbsp;&nbsp;&nbsp;`(s0, s1) -> (s0 * s1)`,\
which is easy enough. However, deriving a `stride_map` for the expression is\
complicated. Conceptually, the stride of the composite expression should\
correspond to the stride of the minormost dimension involved in the reshape\
along which we capture more than a single element.

This holds because there are restrictions on what a valid tiling can be when\
going through a collapse. Let `s` be an `n`-dimensional shape that is fully\
collapsed. In order to be propagated successfully through the collapse, the\
pattern of the tiling of `s` has to look like\
&nbsp;&nbsp;&nbsp;&nbsp;`(1*, partial_dim?, full_dims*, 1*)`\
where `full_dims` are dimensions that are captured completely, and\
`partial_dim` is a dimension that can be captured with an arbitrary tile.\
This restriction is necessary to ensure that the gap between two elements\
captured in the expression is always the same (i.e., the set of elements can\
be described using a single `stride` and is thus a tile).

Based on the above, algorithm for extracting the `stride` could therefore be\
represented as a series of nested `if` statements\
&nbsp;&nbsp;&nbsp;&nbsp;`if size0 != 1 then stride0 else (if size1 != 1 then stride1 else ...)`\
where `{size,stride}i` corresponds to the `i-th` major {size,stride}.

We implement a utility function that allows us to generate `if` statements as\
affine expressions.

PiperOrigin-RevId: 634784163",Benjamin Chetioui,bchetioui@google.com,2024-05-17 15:23:50,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_test.cc",bchetioui,False
"PR #12520: [GPU] Add new flag xla_gpu_exclude_nondeterministic_ops.

Imported from GitHub PR https://github.com/openxla/xla/pull/12520

It's more granular than the existing --xla_gpu_deterministic_ops because it allows doing an autotuning compilation with non-deterministic ops disabled.

--xla_gpu_deterministic_ops is a superset of --xla_gpu_exclude_nondeterministic_ops, so --xla_gpu_deterministic_ops=true will be setting --xla_gpu_exclude_nondeterministic_ops=true too.
Copybara import of the project:

--
4e2837457dc426154bf80f321c001c916a7d3677 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Add new flag xla_gpu_exclude_nondeterministic_ops.

Merging this change closes #12520

PiperOrigin-RevId: 634756524",Ilia Sergachev,isergachev@nvidia.com,2024-05-17 13:59:40,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/determinism_test.cc, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc, third_party/xla/xla/xla.proto",sergachev,False
"IsSimplifiedScatter should also return false if update_window_dims is unsorted.

We started relying on that with LayoutNormalization creating Scatters that
don't have sorted update_window_dims, and want ScatterSimplifier to clean this
up.

PiperOrigin-RevId: 634748724",Adrian Kuegel,akuegel@google.com,2024-05-17 13:40:31,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/scatter_simplifier.cc, third_party/xla/xla/service/scatter_simplifier_test.cc",akuegel,False
"Integrate LLVM at llvm/llvm-project@5a20a07fce88

Updates LLVM usage to match
[5a20a07fce88](https://github.com/llvm/llvm-project/commit/5a20a07fce88)

PiperOrigin-RevId: 634736134",Dmitri Gribenko,dmitrig@google.com,2024-05-17 13:11:38,third_party/llvm/workspace.bzl,gribozavr,False
"Automated Code Change

PiperOrigin-RevId: 634731291",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 12:58:27,"third_party/xla/third_party/tsl/tsl/platform/env.cc, third_party/xla/third_party/tsl/tsl/platform/env.h, third_party/xla/third_party/tsl/tsl/platform/errors.cc, third_party/xla/third_party/tsl/tsl/platform/errors.h, third_party/xla/third_party/tsl/tsl/platform/errors_test.cc, third_party/xla/third_party/tsl/tsl/platform/file_system.cc, third_party/xla/third_party/tsl/tsl/platform/file_system.h, third_party/xla/third_party/tsl/tsl/platform/file_system_helper.cc, third_party/xla/third_party/tsl/tsl/platform/file_system_helper.h, third_party/xla/third_party/tsl/tsl/platform/null_file_system.h, third_party/xla/third_party/tsl/tsl/platform/ram_file_system.h, third_party/xla/third_party/tsl/tsl/platform/retrying_file_system.h, third_party/xla/third_party/tsl/tsl/platform/retrying_file_system_test.cc, third_party/xla/third_party/tsl/tsl/platform/retrying_utils.cc, third_party/xla/third_party/tsl/tsl/platform/retrying_utils.h, third_party/xla/third_party/tsl/tsl/platform/retrying_utils_test.cc, third_party/xla/third_party/tsl/tsl/platform/status.cc, third_party/xla/third_party/tsl/tsl/platform/status.h, third_party/xla/third_party/tsl/tsl/platform/status_matchers.cc, third_party/xla/third_party/tsl/tsl/platform/status_matchers.h, third_party/xla/third_party/tsl/tsl/platform/status_matchers_test.cc, third_party/xla/third_party/tsl/tsl/platform/status_test.cc, third_party/xla/third_party/tsl/tsl/platform/status_to_from_proto.cc, third_party/xla/third_party/tsl/tsl/platform/status_to_from_proto.h, third_party/xla/third_party/tsl/tsl/platform/statusor_test.cc",tensorflower-gardener,False
"Fix dependencies in ROCM Triton emitter

PiperOrigin-RevId: 634730178",Henning Becker,hebecker@google.com,2024-05-17 12:54:46,third_party/xla/xla/service/gpu/BUILD,beckerhe,False
"PR #12515: [ROCm] Fix build break introduced in ffa7bb5 and df736d7

Imported from GitHub PR https://github.com/openxla/xla/pull/12515

Fix build break introduced in ffa7bb5 and df736d7
Copybara import of the project:

--
499687ea87e38be681cb978d15ebd314377623c4 by Harsha HS <harsha.havanurshamsundara@amd.com>:

Fix build break introduced in ffa7bb5 and df736d7

Merging this change closes #12515

PiperOrigin-RevId: 634713247",Harsha H S,hsharsha@users.noreply.github.com,2024-05-17 11:30:35,third_party/xla/xla/service/gpu/ir_emitter_triton_rocm.cc,hsharsha,False
"Automated Code Change

PiperOrigin-RevId: 634707918",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 11:04:13,"tensorflow/lite/kernels/parse_example/example_proto_fast_parsing.h, tensorflow/lite/kernels/parse_example/parse_example.cc",tensorflower-gardener,False
"Followup to Scatter Layout normalization

The code already implicitly assumes that ScatterSimplifier has run before. We
cannot normalize if there are more than 1 ""scatter"" (batch) dimensions. Add a
check for that and adjust a test case that would in fact be incorrectly
normalized (but hidden from the verifier by running ScatterSimplifier
afterwards).

PiperOrigin-RevId: 634695331",Adrian Kuegel,akuegel@google.com,2024-05-17 10:12:45,"third_party/xla/xla/service/layout_normalization.cc, third_party/xla/xla/service/layout_normalization_test.cc",akuegel,False
"[XLA:GPU] Support fusion of dynamic-slice into triton gemm.

This change fuses dynamic-slice into triton gemm kernels provided the slice is taken along the major-most dimension, leaving all other dimensions the same. No further fusion occurs in operands of the dynamic slice, meaning the resulting triton gemm must take in all operands of the dynamic slice as parameters.

Autotuning can handle dynamic-slice just fine, because of the instruction's semantics, which ensures that it never reads out of bounds (the offsets are clamped to a valid region).

The original author of this CL is jvstokes and I did a comprehensive refactor.

PiperOrigin-RevId: 634690002",Tamás Danyluk,tdanyluk@google.com,2024-05-17 09:51:08,"third_party/xla/xla/service/gpu/gemm_fusion_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis_test.cc, third_party/xla/xla/service/gpu/triton_tiling_propagation.cc",tdanyluk,False
"Fix compiler errors in TFLite XNNPack delegate weight_cache_test.

PiperOrigin-RevId: 634689677",Quentin Khan,qkhan@google.com,2024-05-17 09:49:37,tensorflow/lite/delegates/xnnpack/weight_cache_test.cc,qukhan,False
"Fix various code style and build issues in stream_executor/rocm

- Adding namespace to `string` -> `std::string` (Not sure why this compiled in the first place)
- Remove unused local variables
- Avoid unintended fallthrough in switch statement
- Fix member variable initialization order in a constructor
- Avoid read of unintialized variable

PiperOrigin-RevId: 634684537",Henning Becker,hebecker@google.com,2024-05-17 09:26:53,"third_party/xla/xla/stream_executor/rocm/BUILD, third_party/xla/xla/stream_executor/rocm/rocm_blas.cc, third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc, third_party/xla/xla/stream_executor/rocm/rocm_driver.cc, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/rocm/rocm_platform.cc, third_party/xla/xla/stream_executor/rocm/rocm_platform.h",beckerhe,False
"Automated Code Change

PiperOrigin-RevId: 634682199",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 09:16:07,"tensorflow/core/kernels/batching_util/adaptive_shared_batch_scheduler.h, tensorflow/core/kernels/batching_util/shared_batch_scheduler.h",tensorflower-gardener,False
"Update GraphDef version to 1865.

PiperOrigin-RevId: 634680889",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 09:09:34,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-17

PiperOrigin-RevId: 634680645",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 09:08:25,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"PR #11767: Add SYCL build script

Imported from GitHub PR https://github.com/openxla/xla/pull/11767

This is a sub PR of https://github.com/openxla/xla/pull/9042, it adds a script to build xla with `--config=sycl`.
Here is how to use:
```bash
workspace=$1
xla_path=$workspace/xla
cd $workspace
git clone -b yang/ci https://github.com/Intel-tensorflow/xla xla
bash $xla_path/build_tools/sycl/build.sh $workspace
```
Copybara import of the project:

--
d811bba1548f0c983da473a0940b1ea3d8b2c436 by Sheng, Yang <yang.sheng@intel.com>:

Add SYCL build script

--
0c2500b703b73bc340ccc9e3817c7ce54cc8d718 by Sheng, Yang <yang.sheng@intel.com>:

change path

Merging this change closes #11767

PiperOrigin-RevId: 634676627",Sheng Yang,yang.sheng@intel.com,2024-05-17 08:51:10,"third_party/xla/build_tools/configure/configure.py, third_party/xla/build_tools/sycl/build.sh, third_party/xla/build_tools/sycl/build_xla.sh, third_party/xla/build_tools/sycl/clean.sh, third_party/xla/build_tools/sycl/install_bazel.sh, third_party/xla/build_tools/sycl/install_oneapi.sh",ShengYang1,False
"Fix ROCm XLA profiling code

- Add missing dependencies to make the layering check happy
- Add missing cast to function call to make latest clang happy
- Add missing mutex_lock to fix thread safety analysis error
- Replace flat_hash_map by a node_hash_map since the ValueType is not moveable or copyable.

PiperOrigin-RevId: 634676567",Henning Becker,hebecker@google.com,2024-05-17 08:50:51,"third_party/xla/xla/backends/profiler/gpu/BUILD, third_party/xla/xla/backends/profiler/gpu/rocm_collector.cc",beckerhe,False
"Integrate LLVM at llvm/llvm-project@5b7088c3619e

Updates LLVM usage to match
[5b7088c3619e](https://github.com/llvm/llvm-project/commit/5b7088c3619e)

PiperOrigin-RevId: 634675819",Dmitri Gribenko,dmitrig@google.com,2024-05-17 08:47:11,third_party/llvm/workspace.bzl,gribozavr,False
"Move unique_indices from Gather to Scatter where it belongs.

Somehow the attribute unique_indices ended up in the documentation for Gather,
but it is an attribute for Scatter.

PiperOrigin-RevId: 634675288",Adrian Kuegel,akuegel@google.com,2024-05-17 08:44:40,third_party/xla/docs/operation_semantics.md,akuegel,False
"Exclude //xla/service/gpu/... targets for CPU CI runs.

PiperOrigin-RevId: 634674988",Thomas Joerg,tjoerg@google.com,2024-05-17 08:43:01,third_party/xla/.kokoro/linux/build.sh,thomasjoerg,False
"Disable MultiOutputLoopFeedingMap with MLIR emitters.

We don't support nested fusions. This creates one because the
map gets wrapped in a fusion, and the computation already
contains a fusion.

PiperOrigin-RevId: 634668045",Johannes Reifferscheid,jreiffers@google.com,2024-05-17 08:11:09,third_party/xla/xla/tests/multioutput_fusion_test.cc,jreiffers,False
"ROCm dependency fixes in service/gpu

Adding some more direct dependencies to make the layering check happy.

PiperOrigin-RevId: 634667868",Henning Becker,hebecker@google.com,2024-05-17 08:09:53,third_party/xla/xla/service/gpu/BUILD,beckerhe,False
"Automated Code Change

PiperOrigin-RevId: 634667656",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 08:08:45,third_party/xla/xla/python/py_array.cc,tensorflower-gardener,False
"Add missing ROCm dependency in gpu/runtime

`:convolution_thunk` includes `rocm_config.h`, hence we need to depend
on `rocm_headers` to make the layering check happy.

PiperOrigin-RevId: 634661039",Henning Becker,hebecker@google.com,2024-05-17 07:38:41,third_party/xla/xla/service/gpu/runtime/BUILD,beckerhe,False
"Disable NCCL persistent plan allocator on ROCm

It had already been disabled for OSS builds, this is only making
sure it's also disabled when `PLATFORM_GOOGLE` is set to true.

It's a non-functional change - just some ugly macro hackery.

PiperOrigin-RevId: 634659230",Henning Becker,hebecker@google.com,2024-05-17 07:30:53,third_party/xla/xla/service/gpu/runtime/nccl_api.cc,beckerhe,False
"Fix TF Grappler ROCm build issue

The `gcnArch` property had been deprecated for a while (at least for 4 years).
`gcnArchName` is the replacement and since it's already available for so
long it shouldn't break anyone.

PiperOrigin-RevId: 634656093",Henning Becker,hebecker@google.com,2024-05-17 07:15:33,tensorflow/core/grappler/clusters/utils.cc,beckerhe,False
"Fix scatter bounds checks for unsigned indices.

I accidentally used sle where we need ule, resulting in incorrect
results for values >= 2**31 / 2**63.

PiperOrigin-RevId: 634651640",Johannes Reifferscheid,jreiffers@google.com,2024-05-17 06:57:48,"third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir_test.cc",jreiffers,False
"Revive the PLATFORM_GOOGLE code in the ROCm wrappers

The ROCm wrappers is basically a hand-written implementation layer library.

We bypass it when `PLATFORM_GOOGLE` is set and just statically link the ROCm
and HIP libraries instead. The bypass code was broken since we didn't use it
for a long time.

So this CL is fixing a bunch of issues with the code and makes it work with
the latest ROCm version.

PiperOrigin-RevId: 634650804",Henning Becker,hebecker@google.com,2024-05-17 06:53:06,"third_party/xla/xla/stream_executor/rocm/hipsparse_wrapper.h, third_party/xla/xla/stream_executor/rocm/rocblas_wrapper.h, third_party/xla/xla/stream_executor/rocm/roctracer_wrapper.h",beckerhe,False
"Add missing ROCm dependencies in xla/tests

All the changed targets include `rocm_config.h`,
therefore they need to depend on `:rocm_headers`
directly to pass the layering check.

PiperOrigin-RevId: 634643380",Henning Becker,hebecker@google.com,2024-05-17 06:14:09,third_party/xla/xla/tests/BUILD,beckerhe,False
"Fix string-replace mistake in ROCm code

This was introduced by the `xla::Status`/`absl::Status` cleanup by accident.

PiperOrigin-RevId: 634641828",Henning Becker,hebecker@google.com,2024-05-17 06:05:43,third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc,beckerhe,False
"Normalize layouts for Scatter.

Unfortunately this requires to temporarily use unsorted update_window_dims
attribute. ScatterSimplifier can turn this into valid HLO again.

PiperOrigin-RevId: 634641295",Adrian Kuegel,akuegel@google.com,2024-05-17 06:03:21,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/gather_scatter_utils.cc, third_party/xla/xla/service/gather_simplifier_test.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/layout_normalization.cc, third_party/xla/xla/service/layout_normalization_test.cc, third_party/xla/xla/service/scatter_simplifier_test.cc",akuegel,False
"Typos fixing in TF doc

The documentation has been updated by correcting typos and grammatical errors. Please have a look. Thank you!",sushreebarsa,84765720+sushreebarsa@users.noreply.github.com,2024-05-17 06:00:26,tensorflow/python/ops/array_ops.py,sushreebarsa,False
"Move variable declaration into preprocessor branch

This avoid warnings about unused variables when the ROCm branch is taken.

PiperOrigin-RevId: 634637222",Henning Becker,hebecker@google.com,2024-05-17 05:39:00,third_party/xla/xla/service/gpu/make_batch_pointers.cc,beckerhe,False
"[IFRT] Use llvm::DenseSet instead of llvm::SmallSet when verifying devices.

PiperOrigin-RevId: 634633826",Ionel Gog,icgog@google.com,2024-05-17 05:18:36,"third_party/xla/xla/python/ifrt/ir/ifrt_dialect.cc, third_party/xla/xla/python/ifrt/ir/ifrt_ops.cc",ICGog,False
"Merge pull request #67038 from tensorflow:dependabot/pip/werkzeug-3.0.3

PiperOrigin-RevId: 634633697",TensorFlower Gardener,gardener@tensorflow.org,2024-05-17 05:31:31,"requirements_lock_3_10.txt, requirements_lock_3_11.txt, requirements_lock_3_12.txt, requirements_lock_3_9.txt",tensorflower-gardener,False
"Open source pybind lib for populating sparse core layouts.

PiperOrigin-RevId: 634632061",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 05:08:30,"tensorflow/BUILD, tensorflow/core/tpu/kernels/BUILD, tensorflow/python/BUILD, tensorflow/python/tpu/BUILD, tensorflow/python/tpu/_pywrap_sparse_core_layout.pyi, tensorflow/python/tpu/pywrap_sparse_core_layout.cc, tensorflow/tools/def_file_filter/symbols_pybind.txt, third_party/xla/third_party/tsl/tools/def_file_filter/symbols_pybind.txt",tensorflower-gardener,False
"Enable weight-only quantization with StableHLO opset in TF Quantizer

This CL integrates StableHLO weight-only quantization preset to TF Quantizer API. The weight-only quantization is enabled when the quantization method is set to `METHOD_STATIC_RANGE_WEIGHT_ONLY_INT8` and opset is set to `quant_opts_pb2.STABLEHLO`.

PiperOrigin-RevId: 634614727",Doyeon Kim,doyeonkim@google.com,2024-05-17 03:24:39,"tensorflow/compiler/mlir/quantization/stablehlo/cc/config.cc, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto, tensorflow/compiler/mlir/quantization/tensorflow/python/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.py",doyeonkim0,False
"Minor change to add logic for finding all lines with same id.

PiperOrigin-RevId: 634605755",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 02:37:16,"tensorflow/core/profiler/utils/xplane_utils.h, third_party/xla/third_party/tsl/tsl/profiler/utils/xplane_utils.cc, third_party/xla/third_party/tsl/tsl/profiler/utils/xplane_utils.h",tensorflower-gardener,False
"Clean up the build tags for the gpu runner test target. Removes this test from *san due to this: go/cuda#sanitizers-for-cuda-host-code.

PiperOrigin-RevId: 634604218",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 02:28:59,tensorflow/core/tfrt/gpu/kernel/BUILD,tensorflower-gardener,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/edb0d2c6f5e343c83ea121817dc2599ad5453d5c.

PiperOrigin-RevId: 634597659",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-17 01:47:39,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Fix the unused return value error in XNNPACK weightcache test.

PiperOrigin-RevId: 634592513",Jae H. Yoo,jaeyoo@google.com,2024-05-17 01:25:13,tensorflow/lite/delegates/xnnpack/weight_cache_test.cc,jaeyoo,False
"Integrate LLVM at llvm/llvm-project@c86a53d75995

Updates LLVM usage to match
[c86a53d75995](https://github.com/llvm/llvm-project/commit/c86a53d75995)

PiperOrigin-RevId: 634569842",Fangrui Song,maskray@google.com,2024-05-16 23:54:03,third_party/llvm/workspace.bzl,MaskRay,False
"Remove unnecessary flags from XLA ARM build now that hermetic Python has landed

In a followup I will check the disabled ARM tests to see which can be reenabled after this change.

PiperOrigin-RevId: 634555688",David Dunleavy,ddunleavy@google.com,2024-05-16 22:56:08,third_party/xla/.kokoro/linux/build.sh,ddunl,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634545999",Kyle Lucke,klucke@google.com,2024-05-16 22:20:27,"third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/cpu_compiler.h, third_party/xla/xla/service/cpu/cpu_executable.cc, third_party/xla/xla/service/cpu/cpu_executable.h, third_party/xla/xla/service/cpu/cpu_layout_assignment.cc, third_party/xla/xla/service/cpu/cpu_layout_assignment.h, third_party/xla/xla/service/cpu/cpu_transfer_manager.cc, third_party/xla/xla/service/cpu/cpu_transfer_manager.h, third_party/xla/xla/service/cpu/cpu_xfeed.cc, third_party/xla/xla/service/cpu/cpu_xfeed.h, third_party/xla/xla/service/cpu/dot_op_emitter.cc, third_party/xla/xla/service/cpu/dot_op_emitter.h, third_party/xla/xla/service/cpu/ir_emitter.cc, third_party/xla/xla/service/cpu/ir_emitter.h, third_party/xla/xla/service/cpu/ir_function.cc, third_party/xla/xla/service/cpu/ir_function.h, third_party/xla/xla/service/cpu/mlir_emitter.cc, third_party/xla/xla/service/cpu/mlir_emitter.h, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.h, third_party/xla/xla/service/cpu/onednn_memory_util.cc, third_party/xla/xla/service/cpu/onednn_memory_util.h, third_party/xla/xla/service/cpu/onednn_ops_rewriter.cc, third_party/xla/xla/service/cpu/onednn_ops_rewriter.h, third_party/xla/xla/service/cpu/onednn_rewriter.h, third_party/xla/xla/service/cpu/parallel_task_assignment.cc",klucke,False
"Fix typo `s/Recieved/Received/`.

PiperOrigin-RevId: 634543297",Daniel Kenji Toyama,kenjitoyama@google.com,2024-05-16 22:11:32,tensorflow/python/checkpoint/functional_saver.py,kenjitoyama,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634541223",Kyle Lucke,klucke@google.com,2024-05-16 22:04:34,"third_party/xla/xla/array.h, third_party/xla/xla/layout_util.cc, third_party/xla/xla/layout_util.h, third_party/xla/xla/literal.cc, third_party/xla/xla/literal.h, third_party/xla/xla/literal_comparison.cc, third_party/xla/xla/literal_comparison.h, third_party/xla/xla/literal_test.cc, third_party/xla/xla/literal_util.h, third_party/xla/xla/map_util.h, third_party/xla/xla/protobuf_util.cc, third_party/xla/xla/protobuf_util.h, third_party/xla/xla/service_interface.h, third_party/xla/xla/shape_layout.cc, third_party/xla/xla/shape_layout.h, third_party/xla/xla/shape_tree.h, third_party/xla/xla/shape_util.cc, third_party/xla/xla/shape_util.h, third_party/xla/xla/shape_util_test.cc, third_party/xla/xla/sharding_op_util.cc, third_party/xla/xla/sharding_op_util.h, third_party/xla/xla/status_macros.cc, third_party/xla/xla/status_macros.h, third_party/xla/xla/status_macros_test.cc, third_party/xla/xla/statusor.h, third_party/xla/xla/test_helpers.h, third_party/xla/xla/text_literal_reader.cc, third_party/xla/xla/text_literal_writer.cc, third_party/xla/xla/text_literal_writer.h, third_party/xla/xla/util.cc, third_party/xla/xla/util.h",klucke,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634534302",Kyle Lucke,klucke@google.com,2024-05-16 21:42:21,"third_party/xla/xla/service/algebraic_simplifier.cc, third_party/xla/xla/service/algebraic_simplifier.h, third_party/xla/xla/service/all_gather_combiner.cc, third_party/xla/xla/service/all_gather_decomposer.cc, third_party/xla/xla/service/all_reduce_combiner.cc, third_party/xla/xla/service/all_reduce_contiguous.cc, third_party/xla/xla/service/allocation_tracker.cc, third_party/xla/xla/service/allocation_tracker.h, third_party/xla/xla/service/ar_crs_combiner.cc, third_party/xla/xla/service/ar_crs_combiner.h, third_party/xla/xla/service/backend.cc, third_party/xla/xla/service/backend.h, third_party/xla/xla/service/batchnorm_expander.cc, third_party/xla/xla/service/bfloat16_conversion_folding.cc, third_party/xla/xla/service/bfloat16_propagation.cc, third_party/xla/xla/service/bfloat16_propagation.h, third_party/xla/xla/service/buffer_assignment.cc, third_party/xla/xla/service/buffer_assignment.h, third_party/xla/xla/service/buffer_assignment_test.cc, third_party/xla/xla/service/call_graph.cc, third_party/xla/xla/service/call_graph.h, third_party/xla/xla/service/call_graph_test.cc, third_party/xla/xla/service/call_inliner.cc, third_party/xla/xla/service/collective_combiner_utils.h, third_party/xla/xla/service/collective_ops_utils.h, third_party/xla/xla/service/collective_permute_decomposer.cc, third_party/xla/xla/service/collective_pipeliner.cc, third_party/xla/xla/service/collective_pipeliner.h, third_party/xla/xla/service/compilation_environments.cc, third_party/xla/xla/service/compilation_environments.h, third_party/xla/xla/service/compile_only_service.h, third_party/xla/xla/service/computation_placer.cc, third_party/xla/xla/service/computation_placer.h, third_party/xla/xla/service/conditional_canonicalizer.cc, third_party/xla/xla/service/conditional_code_motion.cc, third_party/xla/xla/service/conditional_to_select.cc, third_party/xla/xla/service/convert_async_collectives_to_sync.cc, third_party/xla/xla/service/convert_async_collectives_to_sync.h, third_party/xla/xla/service/convert_async_collectives_to_sync_test.cc, third_party/xla/xla/service/convolution_group_converter.cc, third_party/xla/xla/service/copy_insertion.cc, third_party/xla/xla/service/copy_insertion.h, third_party/xla/xla/service/cpu_gpu_shape_verifier.cc, third_party/xla/xla/service/cpu_gpu_shape_verifier.h, third_party/xla/xla/service/defuser.cc, third_party/xla/xla/service/dfs_hlo_visitor_with_default_test.cc, third_party/xla/xla/service/dot_decomposer.cc, third_party/xla/xla/service/dot_dimension_merger.cc, third_party/xla/xla/service/dump.cc, third_party/xla/xla/service/dynamic_dimension_inference.cc, third_party/xla/xla/service/dynamic_dimension_inference.h, third_party/xla/xla/service/dynamic_dimension_inference_test.cc, third_party/xla/xla/service/dynamic_padder.cc, third_party/xla/xla/service/dynamic_padder_test.cc, third_party/xla/xla/service/eigh_expander.cc, third_party/xla/xla/service/eigh_expander.h, third_party/xla/xla/service/executable.cc, third_party/xla/xla/service/executable.h, third_party/xla/xla/service/execution_tracker.cc, third_party/xla/xla/service/execution_tracker.h, third_party/xla/xla/service/export_hlo.h, third_party/xla/xla/service/flatten_call_graph.cc, third_party/xla/xla/service/float_normalization.cc, third_party/xla/xla/service/gather_expander_test.cc, third_party/xla/xla/service/generic_transfer_manager.cc, third_party/xla/xla/service/generic_transfer_manager.h, third_party/xla/xla/service/gpu_compilation_environment.cc, third_party/xla/xla/service/gpu_compilation_environment.h, third_party/xla/xla/service/hlo_alias_analysis.cc, third_party/xla/xla/service/hlo_alias_analysis.h, third_party/xla/xla/service/hlo_computation_test.cc, third_party/xla/xla/service/hlo_cost_analysis.cc, third_party/xla/xla/service/hlo_cost_analysis.h, third_party/xla/xla/service/hlo_dataflow_analysis.cc, third_party/xla/xla/service/hlo_dataflow_analysis.h, third_party/xla/xla/service/hlo_dataflow_analysis_test.cc, third_party/xla/xla/service/hlo_dce.cc, third_party/xla/xla/service/hlo_dce.h, third_party/xla/xla/service/hlo_domain_map.cc, third_party/xla/xla/service/hlo_domain_map.h, third_party/xla/xla/service/hlo_domain_remover.cc, third_party/xla/xla/service/hlo_domain_remover.h, third_party/xla/xla/service/hlo_domain_test.cc, third_party/xla/xla/service/hlo_domain_verifier.cc, third_party/xla/xla/service/hlo_graph_dumper.cc, third_party/xla/xla/service/hlo_instruction_test.cc, third_party/xla/xla/service/hlo_module_config_test.cc, third_party/xla/xla/service/hlo_module_group_metadata.cc, third_party/xla/xla/service/hlo_module_group_metadata.h, third_party/xla/xla/service/hlo_module_group_util.cc, third_party/xla/xla/service/hlo_module_group_util.h, third_party/xla/xla/service/hlo_module_util.cc, third_party/xla/xla/service/hlo_parser.cc, third_party/xla/xla/service/hlo_parser.h, third_party/xla/xla/service/hlo_pass_fix.h, third_party/xla/xla/service/hlo_pass_interface.h, third_party/xla/xla/service/hlo_pass_pipeline.cc, third_party/xla/xla/service/hlo_pass_pipeline.h, third_party/xla/xla/service/hlo_pass_pipeline_test.cc, third_party/xla/xla/service/hlo_rematerialization.cc, third_party/xla/xla/service/hlo_replication_analysis.cc, third_party/xla/xla/service/hlo_replication_analysis.h, third_party/xla/xla/service/hlo_value_semantics_analysis.cc, third_party/xla/xla/service/hlo_value_semantics_analysis.h, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/hlo_verifier.h, third_party/xla/xla/service/hlo_verifier_test.cc, third_party/xla/xla/service/host_memory_transfer_asyncifier.cc, third_party/xla/xla/service/host_offload_legalize.cc, third_party/xla/xla/service/host_offloader.cc, third_party/xla/xla/service/host_offloader.h, third_party/xla/xla/service/indexed_array_analysis.cc, third_party/xla/xla/service/indexed_array_analysis.h, third_party/xla/xla/service/latency_hiding_scheduler.cc, third_party/xla/xla/service/latency_hiding_scheduler.h, third_party/xla/xla/service/layout_assignment.cc, third_party/xla/xla/service/layout_assignment.h, third_party/xla/xla/service/layout_assignment_test.cc, third_party/xla/xla/service/layout_normalization.cc, third_party/xla/xla/service/llvm_compiler.h, third_party/xla/xla/service/logical_buffer_analysis.cc, third_party/xla/xla/service/logical_buffer_analysis.h, third_party/xla/xla/service/map_inliner.cc, third_party/xla/xla/service/mapped_ptr_container_sorter.h, third_party/xla/xla/service/memory_space_propagation_test.cc, third_party/xla/xla/service/p2p_schedule_preparation.cc, third_party/xla/xla/service/qr_expander.cc, third_party/xla/xla/service/reduce_decomposer.cc, third_party/xla/xla/service/reduce_scatter_combiner.cc, third_party/xla/xla/service/reduce_window_rewriter.cc, third_party/xla/xla/service/reduce_window_rewriter.h, third_party/xla/xla/service/reshape_decomposer.cc, third_party/xla/xla/service/reshape_mover_test.cc, third_party/xla/xla/service/service.cc, third_party/xla/xla/service/service.h, third_party/xla/xla/service/service_executable_run_options.h, third_party/xla/xla/service/shape_inference.cc, third_party/xla/xla/service/shaped_buffer_test.cc, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation.h, third_party/xla/xla/service/slice_sinker.cc, third_party/xla/xla/service/source_map_util.h, third_party/xla/xla/service/space_to_batch_converter.cc, third_party/xla/xla/service/stochastic_convert_decomposer.cc, third_party/xla/xla/service/sub_byte_normalization.cc, third_party/xla/xla/service/topk_rewriter.cc, third_party/xla/xla/service/tpu_computation_placer.cc, third_party/xla/xla/service/tpu_computation_placer.h, third_party/xla/xla/service/transfer_manager.cc, third_party/xla/xla/service/transfer_manager.h, third_party/xla/xla/service/transpose_folding.cc, third_party/xla/xla/service/tree_reduction_rewriter.cc, third_party/xla/xla/service/tuple_points_to_analysis.cc, third_party/xla/xla/service/tuple_points_to_analysis.h, third_party/xla/xla/service/while_loop_all_reduce_code_motion.cc, third_party/xla/xla/service/while_loop_concat_code_motion.cc, third_party/xla/xla/service/while_loop_constant_sinking.cc",klucke,False
"Express tests tolerances for exhaustive tests relative to the accuracy and subnormal boundary of the data type.

The following table shows the default absolute and relative error tolerances for each numeric datatype.

| Type             | atol before | rtol before | atol after | rtol after |
| ---------------- | ----------- | ---------- | ----------- | --------- |
| double           | 1e-4        | 1e-4       | 4.45e-308   | 1.11e-14 |
| float            | 1e-4        | 1e-4       | 2.35e-38    | 5.96e-6  |
| float16          | 1e-3        | 1e-3       | 1.22e-4     | 5e-4     |
| bfloat16         | 2e-3        | 2e-2       | 2.35e-38    | 1.6e-2   |
| complex<double>  | 1e-4        | 1e-4       | 4.45e-308   | 1.11e-14 |
| complex<float>   | 1e-4        | 1e-4       | 2.35e-38    | 5.96e-6  |

PiperOrigin-RevId: 634532580",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 21:36:41,"third_party/xla/xla/tests/exhaustive/BUILD, third_party/xla/xla/tests/exhaustive/exhaustive_op_test_utils.h, third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_complex.cc, third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_f32_or_smaller.cc, third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_f64.cc",tensorflower-gardener,False
"Remove the test only tag from odml converter target.

PiperOrigin-RevId: 634530469",Luke Boyer,lukeboyer@google.com,2024-05-16 21:29:49,tensorflow/compiler/mlir/lite/stablehlo/odml_converter/BUILD,LukeBoyer,False
"Integrate LLVM at llvm/llvm-project@a383b3cca338

Updates LLVM usage to match
[a383b3cca338](https://github.com/llvm/llvm-project/commit/a383b3cca338)

PiperOrigin-RevId: 634527229",Fangrui Song,maskray@google.com,2024-05-16 21:19:27,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",MaskRay,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634524626",Kyle Lucke,klucke@google.com,2024-05-16 21:11:24,"third_party/xla/xla/backends/profiler/gpu/cupti_buffer_events.cc, third_party/xla/xla/backends/profiler/gpu/cupti_tracer.cc, third_party/xla/xla/backends/profiler/gpu/device_tracer_cuda.cc, third_party/xla/xla/backends/profiler/gpu/device_tracer_rocm.cc, third_party/xla/xla/client/lib/math.cc, third_party/xla/xla/client/lib/svd.cc, third_party/xla/xla/client/lib/tridiagonal.cc, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_api.h, third_party/xla/xla/hlo/evaluator/hlo_evaluator.cc, third_party/xla/xla/hlo/evaluator/hlo_evaluator.h, third_party/xla/xla/hlo/evaluator/hlo_evaluator_typed_visitor.h, third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc, third_party/xla/xla/stream_executor/cuda/cuda_driver.cc, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc, third_party/xla/xla/stream_executor/rocm/rocm_driver.cc, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/tools/hlo_bisect/hlo_bisect_state.cc, third_party/xla/xla/tools/hlo_bisect/hlo_bisect_state.h, third_party/xla/xla/tools/hlo_bisect/hlo_bisect_utils.cc, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.h",klucke,False
"Remove broken TSL tests from `TARGET_FILTERS`, tag them as `no_oss` instead

They will be fixed post TSL move

PiperOrigin-RevId: 634523661",David Dunleavy,ddunleavy@google.com,2024-05-16 21:08:37,"third_party/xla/.kokoro/linux/build.sh, third_party/xla/third_party/tsl/tsl/platform/BUILD, third_party/xla/third_party/tsl/tsl/platform/cloud/BUILD",ddunl,False
"Introduce ExecutionStreamAssignment.

`ExecutionStreamAssignments` represent a mapping from `HloInstructions` to `ExecutionStreamIds`. Asynchronous calls (`async-start`, `async-update`, and `async-done`) result in the target computations being assigned new `ExecutionStreamIds` to support concurrent execution.

PiperOrigin-RevId: 634520855",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 21:00:48,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/execution_stream_assignment.cc, third_party/xla/xla/service/gpu/execution_stream_assignment.h, third_party/xla/xla/service/gpu/execution_stream_assignment_test.cc",tensorflower-gardener,False
"[xla] Update XLA custom call documentation to use XLA FFI

Now when XLA FFI is supported on both XLA:GPU and XLA:CPU backends update custom call documentation to new XLA FFI APIs instead of a mix of legacy ones.

PiperOrigin-RevId: 634519378",Eugene Zhulenev,ezhulenev@google.com,2024-05-16 20:56:06,third_party/xla/docs/custom_call.md,ezhulenev,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634511028",Kyle Lucke,klucke@google.com,2024-05-16 20:30:16,"third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.cc, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.h, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/distributed/client.cc, third_party/xla/xla/pjrt/distributed/client.h, third_party/xla/xla/pjrt/distributed/client_server_test.cc, third_party/xla/xla/pjrt/distributed/topology_util.cc, third_party/xla/xla/pjrt/distributed/topology_util.h, third_party/xla/xla/pjrt/distributed/util.h, third_party/xla/xla/pjrt/gpu/gpu_helpers.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc, third_party/xla/xla/service/gpu/runtime/annotation.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_p2p_thunk_common.cc",klucke,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634508957",Kyle Lucke,klucke@google.com,2024-05-16 20:23:57,"third_party/xla/xla/backends/interpreter/compiler.cc, third_party/xla/xla/backends/interpreter/compiler.h, third_party/xla/xla/backends/profiler/cpu/metadata_collector.cc, third_party/xla/xla/backends/profiler/plugin/plugin_tracer.cc, third_party/xla/xla/backends/profiler/plugin/plugin_tracer.h, third_party/xla/xla/backends/profiler/tpu/tpu_tracer.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util.h, third_party/xla/xla/mlir/utils/error_util.h, third_party/xla/xla/mlir_hlo/README.md, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.cc, third_party/xla/xla/service/gpu/fusions/reduction.cc, third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc, third_party/xla/xla/service/heap_simulator/heap_simulator.cc, third_party/xla/xla/service/heap_simulator/heap_simulator.h, third_party/xla/xla/stream_executor/device_memory_allocator.h, third_party/xla/xla/stream_executor/host/host_execution_engine.cc, third_party/xla/xla/stream_executor/lazy_op_runner.h, third_party/xla/xla/tools/hlo_opt/opt_main.cc, third_party/xla/xla/translate/mhlo_to_hlo/translate.cc, third_party/xla/xla/tsl/distributed_runtime/preemption/preemption_sync_manager.cc, third_party/xla/xla/tsl/distributed_runtime/rpc/coordination/grpc_coordination_service_impl.h, third_party/xla/xla/tsl/distributed_runtime/rpc/grpc_util.h, third_party/xla/xla/tsl/util/use_cudnn.cc",klucke,False
"Move schema_fbs_with_mutable to mlir/lite/schema.

PiperOrigin-RevId: 634500044",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 19:54:12,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/flatbuffer_export.cc, tensorflow/compiler/mlir/lite/flatbuffer_import.cc, tensorflow/compiler/mlir/lite/flatbuffer_operator.cc, tensorflow/compiler/mlir/lite/flatbuffer_operator.h, tensorflow/compiler/mlir/lite/schema/BUILD, tensorflow/lite/schema/BUILD",tensorflower-gardener,False
"Fix typo in comment.

PiperOrigin-RevId: 634495833",Anshuman Goswami,anshumang@google.com,2024-05-16 19:38:38,tensorflow/core/common_runtime/eager/custom_device_op_handler.cc,anshumang,False
"[xla_client] Port all custom calls used in test to FFI

- Remove legacy custom calls and always use FFI for xla_client tests.
- Add a little bit more documentation to cover custom call registration process

PiperOrigin-RevId: 634485582",Eugene Zhulenev,ezhulenev@google.com,2024-05-16 19:03:46,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/custom_call_for_test.pyx, third_party/xla/xla/python/custom_calls_testlib.cc, third_party/xla/xla/python/typed_ffi_custom_call_for_test.cc, third_party/xla/xla/python/xla_client_test.py",ezhulenev,False
"Allow overriding some methods in all_gather_decomposer.

PiperOrigin-RevId: 634483343",Tongfei Guo,tongfei@google.com,2024-05-16 18:58:06,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/all_gather_decomposer.cc, third_party/xla/xla/service/all_gather_decomposer.h",Tongfei-Guo,False
"Reverts c031655ca9514e7946bb87eda17cf5932c381a8b

PiperOrigin-RevId: 634478686",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 18:42:20,"tensorflow/compiler/mlir/lite/tests/optimize.mlir, tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td",tensorflower-gardener,False
"Add missing rocm_config.h include to amdgpu_compiler.cc

rocm_config.h defines `TF_ROCM_VERSION` which is used in `amdgpu_compiler.cc`.

PiperOrigin-RevId: 634476794",Henning Becker,hebecker@google.com,2024-05-16 18:35:55,third_party/xla/xla/service/gpu/amdgpu_compiler.cc,beckerhe,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634474219",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 18:28:50,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634473357",Kyle Lucke,klucke@google.com,2024-05-16 18:26:47,"third_party/xla/xla/pjrt/exceptions.h, third_party/xla/xla/pjrt/host_callback_test.cc, third_party/xla/xla/pjrt/interpreter_device.cc, third_party/xla/xla/pjrt/interpreter_device.h, third_party/xla/xla/pjrt/layout_mode.cc, third_party/xla/xla/pjrt/layout_mode.h, third_party/xla/xla/pjrt/local_device_state.cc, third_party/xla/xla/pjrt/local_device_state.h, third_party/xla/xla/pjrt/mlir_to_hlo.cc, third_party/xla/xla/pjrt/mlir_to_hlo.h, third_party/xla/xla/pjrt/pjrt_c_api_client.cc, third_party/xla/xla/pjrt/pjrt_c_api_client.h, third_party/xla/xla/pjrt/pjrt_client.cc, third_party/xla/xla/pjrt/pjrt_client.h, third_party/xla/xla/pjrt/pjrt_client_test.cc, third_party/xla/xla/pjrt/pjrt_compiler.cc, third_party/xla/xla/pjrt/pjrt_compiler.h, third_party/xla/xla/pjrt/pjrt_compiler_test.cc, third_party/xla/xla/pjrt/pjrt_executable.cc, third_party/xla/xla/pjrt/pjrt_executable.h, third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/pjrt/pjrt_layout.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client_test.cc, third_party/xla/xla/pjrt/status_casters.h, third_party/xla/xla/pjrt/stream_executor_executable.cc, third_party/xla/xla/pjrt/tf_pjrt_client.cc, third_party/xla/xla/pjrt/tf_pjrt_client.h, third_party/xla/xla/pjrt/tracked_device_buffer.cc, third_party/xla/xla/pjrt/tracked_device_buffer.h, third_party/xla/xla/pjrt/tracked_device_buffer_test.cc, third_party/xla/xla/pjrt/transpose.cc, third_party/xla/xla/pjrt/transpose.h, third_party/xla/xla/pjrt/utils.cc, third_party/xla/xla/pjrt/utils.h",klucke,False
"Add a command line parameter in benchmark_tool to set the XNNPack cache file.

PiperOrigin-RevId: 634470123",Quentin Khan,qkhan@google.com,2024-05-16 18:17:07,"tensorflow/lite/acceleration/configuration/configuration.proto, tensorflow/lite/acceleration/configuration/configuration_generated.h, tensorflow/lite/acceleration/configuration/testdata/configuration.proto_prev, tensorflow/lite/core/acceleration/configuration/c/xnnpack_plugin.cc, tensorflow/lite/tools/delegates/BUILD, tensorflow/lite/tools/delegates/xnnpack_delegate_provider.cc, tensorflow/lite/tools/delegates/xnnpack_delegate_provider_test.cc, tensorflow/lite/tools/evaluation/BUILD, tensorflow/lite/tools/evaluation/utils.cc, tensorflow/lite/tools/evaluation/utils.h, tensorflow/lite/tools/tool_params.h",qukhan,False
"Enables additional solver output if we're removing user shardings, which usually implies internal testing / debugging.

PiperOrigin-RevId: 634469824",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 18:16:07,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc,tensorflower-gardener,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634467593",Kyle Lucke,klucke@google.com,2024-05-16 18:09:30,"third_party/xla/xla/hlo/ir/dfs_hlo_visitor.cc, third_party/xla/xla/hlo/ir/dfs_hlo_visitor.h, third_party/xla/xla/hlo/ir/dfs_hlo_visitor_with_default.h, third_party/xla/xla/hlo/ir/dynamic_parameter_binding.cc, third_party/xla/xla/hlo/ir/dynamic_parameter_binding.h, third_party/xla/xla/hlo/ir/hlo_computation.cc, third_party/xla/xla/hlo/ir/hlo_computation.h, third_party/xla/xla/hlo/ir/hlo_input_output_alias_config.cc, third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h, third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/hlo/ir/hlo_instructions.h, third_party/xla/xla/hlo/ir/hlo_module.cc, third_party/xla/xla/hlo/ir/hlo_module.h, third_party/xla/xla/hlo/ir/hlo_module_metadata.cc, third_party/xla/xla/hlo/ir/hlo_module_metadata.h, third_party/xla/xla/hlo/ir/hlo_schedule.cc, third_party/xla/xla/hlo/ir/hlo_schedule.h, third_party/xla/xla/hlo/ir/hlo_sharding.cc, third_party/xla/xla/hlo/ir/hlo_sharding.h, third_party/xla/xla/hlo/ir/hlo_sharding_metadata.cc, third_party/xla/xla/hlo/ir/hlo_sharding_metadata.h, third_party/xla/xla/hlo/ir/tile_assignment.cc, third_party/xla/xla/hlo/ir/tile_assignment.h",klucke,False
"[XLA:GPU] Remove filter checking if an indexing map is tileable in `SymbolicTile`.

Symbolic tiles are now robust and well-reasoned enough that the filter should
no longer be necessary.

PiperOrigin-RevId: 634460882",Benjamin Chetioui,bchetioui@google.com,2024-05-16 17:51:11,third_party/xla/xla/service/gpu/model/symbolic_tile.cc,bchetioui,False
"Make buffer_comparator_kernel target a gpu_kernel_library

PiperOrigin-RevId: 634458480",Henning Becker,hebecker@google.com,2024-05-16 17:44:06,third_party/xla/xla/service/gpu/BUILD,beckerhe,False
"Change DebugString call to proto2::TextFormat::PrintToString.

PiperOrigin-RevId: 634454849",Matthias Kramm,kramm@google.com,2024-05-16 17:33:57,tensorflow/core/ops/compat/op_compatibility_lib.h,matthiaskramm,False
"Modify docker pull backoff in CI

PiperOrigin-RevId: 634452150",Michael Hudgins,michaelhudgins@google.com,2024-05-16 17:25:56,ci/official/utilities/setup_docker.sh,MichaelHudgins,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc

PiperOrigin-RevId: 634448673",Kuy Mainwaring,kuym@google.com,2024-05-16 17:16:10,third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/model/gpu_performance_model_base.h

PiperOrigin-RevId: 634448529",Kuy Mainwaring,kuym@google.com,2024-05-16 17:15:46,third_party/xla/xla/service/gpu/model/gpu_performance_model_base.h,kuym,False
"Remove duplicate dependency from PJRT test

A dependency from `se_gpu_pjrt_compiler_aot_test` to `amdgpu_compiler_impl`
had been recently added - I believe by accident.

The test shouldn't generally depend on the AMDGPU compiler - only if it's
a ROCm build in which case the dependency is already there.

PiperOrigin-RevId: 634448333",Henning Becker,hebecker@google.com,2024-05-16 17:15:21,third_party/xla/xla/pjrt/gpu/BUILD,beckerhe,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/model/indexing_analysis.cc

PiperOrigin-RevId: 634447146",Kuy Mainwaring,kuym@google.com,2024-05-16 17:12:03,third_party/xla/xla/service/gpu/model/indexing_analysis.cc,kuym,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/model/indexing_test_utils.h

PiperOrigin-RevId: 634446637",Kuy Mainwaring,kuym@google.com,2024-05-16 17:10:37,third_party/xla/xla/service/gpu/model/indexing_test_utils.cc,kuym,False
"[XLA:GPU] #includes cleanup for xla/service/gpu/tests/gemm_rewrite_test.cc, nop_custom_call_test.cc

PiperOrigin-RevId: 634446511",Kuy Mainwaring,kuym@google.com,2024-05-16 17:10:17,"third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc, third_party/xla/xla/service/gpu/tests/nop_custom_call_test.cc",kuym,False
"Removed all the visibilities to `//learning/infra/mira/distributed` in MLRT.

PiperOrigin-RevId: 634432048",Dateng Lin,datenglin@google.com,2024-05-16 16:36:42,"tensorflow/compiler/mlir/tfrt/ir/mlrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/mlrt/BUILD",,False
Update mkl bf16 lists,Gauri1 Deshpande,gauri1.deshpande@intel.com,2024-05-16 17:02:02,tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h,gaurides,True
"[XLA:GPU] [NFC] Better error message for slow autotuned kernels

PiperOrigin-RevId: 634430923",George Karpenkov,cheshire@google.com,2024-05-16 16:33:04,third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc,cheshire,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634424923",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 16:18:42,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@e27f9bb31984

Updates LLVM usage to match
[e27f9bb31984](https://github.com/llvm/llvm-project/commit/e27f9bb31984)

PiperOrigin-RevId: 634398955",Dmitri Gribenko,dmitrig@google.com,2024-05-16 15:11:03,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",gribozavr,False
"Use StreamExecutorInterface::CreateEvent to create stream_executor::Events.

PiperOrigin-RevId: 634390248",Kyle Lucke,klucke@google.com,2024-05-16 14:47:56,"tensorflow/core/common_runtime/device/device_event_mgr.cc, tensorflow/core/tpu/kernels/tpu_execute_op.cc, tensorflow/core/tpu/kernels/tpu_reshard_variables_op.cc",klucke,False
"[XLA:GPU][NFC] Remove unused includes in `symbolic_tile.h`.

PiperOrigin-RevId: 634387169",Benjamin Chetioui,bchetioui@google.com,2024-05-16 14:39:25,third_party/xla/xla/service/gpu/model/symbolic_tile.h,bchetioui,False
"[XLA:GPU] Introduce TiledHloComputation

TiledHloComputation is a wrapper around a vector of TiledHloInstructions. It provides a convenient way to access the instructions and the root instruction.

PiperOrigin-RevId: 634387167",Oleg Shyshkov,shyshkov@google.com,2024-05-16 14:39:25,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc, third_party/xla/xla/service/gpu/model/tiled_hlo_computation.h",olegshyshkov,False
"[XLA:GPU][NFC] Print non-trivial reduction for all-reduce key.

PiperOrigin-RevId: 634387161",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-16 14:39:23,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/all_reduce_key.cc",golechwierowicz,False
"Add a new test case in pjrt_util_test

PiperOrigin-RevId: 634381150",Deqiang Chen,deqiangc@google.com,2024-05-16 14:22:23,"tensorflow/core/tfrt/common/BUILD, tensorflow/core/tfrt/common/pjrt_util_test.cc",deqiangc,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634380668",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 14:20:54,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Merge pull request #66087 from Intel-tensorflow:amin/int8-fp32-matmul-fusion

PiperOrigin-RevId: 634375704",TensorFlower Gardener,gardener@tensorflow.org,2024-05-16 14:43:11,"tensorflow/core/kernels/mkl/BUILD, tensorflow/core/kernels/mkl/mkl_fused_ops_test.cc, tensorflow/core/kernels/mkl/mkl_kernel_util.cc, tensorflow/core/kernels/mkl/mkl_kernel_util.h, tensorflow/core/kernels/mkl/mkl_matmul_op_fused.cc, tensorflow/core/kernels/mkl/mkl_matmul_ops_common.h, tensorflow/core/kernels/mkl/mkl_qmatmul_op.cc, tensorflow/core/kernels/mkl/mkl_qmatmul_op_test.cc, tensorflow/core/kernels/mkl/onednn_fused_matmul_ops_test.cc, tensorflow/core/ops/mkl_nn_ops.cc",tensorflower-gardener,False
"PR #12494: [ROCM] GPU performance cost model specs for MI300

Imported from GitHub PR https://github.com/openxla/xla/pull/12494

@ddunl  @xla-rotation  : would you take a look please?
Copybara import of the project:

--
265d19a155907357fe89ff4e0f5dbbe52f329c4c by Ruturaj4 <ruturaj.vaidya@amd.com>:

[ROCm] set performance cost model specifications for mi300

--
0f0a6fa282bf4ce729d8f4d570fa9a1d6f8fad50 by Ruturaj4 <ruturaj.vaidya@amd.com>:

[ROCm] set performance cost model specifications for mi100 and mi200

Merging this change closes #12494

PiperOrigin-RevId: 634375698",Ruturaj Vaidya,ruturaj.vaidya@amd.com,2024-05-16 14:07:34,"third_party/xla/xla/service/gpu/model/gpu_performance_model_base.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.h, third_party/xla/xla/stream_executor/device_description.h",Ruturaj4,False
"PR #12550: [ROCM] Avoid hard coded specifications for mi300 transpose fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/12550

Copybara import of the project:

--
426c2bee41800651ab191d830865c210d9f2cbea by Ruturaj4 <ruturaj.vaidya@amd.com>:

[ROCm] Avoid hard coded code for mi300 tranpose fusion

Merging this change closes #12550

PiperOrigin-RevId: 634374108",Ruturaj Vaidya,ruturaj.vaidya@amd.com,2024-05-16 14:03:07,"third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose.h",Ruturaj4,False
"[XLA:GPU] Use IndexingMap's simplifier in tiling

PiperOrigin-RevId: 634360780",Tamás Danyluk,tdanyluk@google.com,2024-05-16 13:27:06,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_test.cc",tdanyluk,False
"PR #11895: Offloading 3/3: enable rematerialization using xla flags

Imported from GitHub PR https://github.com/openxla/xla/pull/11895

This enables activation offloading automatically on GPU through HLO Rematerialization.
There is one xla flag needed to trigger rematerialization offloading:
1. A bool to enable host memory offloading. It's false by default to disable the offloading.

The other information is achieved by querying the GPU device:
2. Memory bandwidth in bytes per second.
3. The number of floating point operations on a device.

Copybara import of the project:

--
46b6232dd0c9dd34d7b170f049e6074ccee002bd by Jane Liu <janeliu@nvidia.com>:

Offloading 3/3: enable rematerialization using a bool xla flag.
Query the memory bandwidth and flops from GPUs.

Merging this change closes #11895

PiperOrigin-RevId: 634360725",Jane Liu,janeliu@nvidia.com,2024-05-16 13:26:52,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/xla.proto",zhenying-liu,False
"Add a function to get delegate options using the C API.

- Remove redundant helper function.
- Store the weight cache path inside the delegate and update the internal
  options object to use it.

PiperOrigin-RevId: 634354940",Quentin Khan,qkhan@google.com,2024-05-16 13:09:31,"tensorflow/lite/core/kernels/BUILD, tensorflow/lite/core/kernels/register_test.cc, tensorflow/lite/delegates/xnnpack/BUILD, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.h, tensorflow/lite/delegates/xnnpack/xnnpack_delegate_test.h",qukhan,False
"[XLA:GPU] Remove GOOGLE_CUDA and TENSORFLOW_USE_ROCM defines from gemm_algorithm_picker.

These defines are not needed since the BUILD target is anyway guarded by if_gpu_is_configured.

PiperOrigin-RevId: 634353818",Thomas Joerg,tjoerg@google.com,2024-05-16 13:06:41,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker.h",thomasjoerg,False
"XNNPack weight cache: make logging message format consistent across the module.

PiperOrigin-RevId: 634349913",Quentin Khan,qkhan@google.com,2024-05-16 12:58:45,tensorflow/lite/delegates/xnnpack/weight_cache.cc,qukhan,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634330969",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 12:18:00,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Use apply_indexing for input index computations.

For this to work, we need a folder, so add that too. We kind of
rely on the folder to work most of the time (for caching of
instructions). There may be some dragons here, I'll probably rewrite
that stuff at some point.

This works around the remaining known miscompiles. The issue
must be somewhere in LLVM and be related to GEPs with subtractions,
but I lack the skills and resources to actually track it down.

PiperOrigin-RevId: 634326550",Johannes Reifferscheid,jreiffers@google.com,2024-05-16 12:09:48,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.td",jreiffers,False
"Merge pull request #67683 from Intel-tensorflow:aimran/oneDNN_3.4.1

PiperOrigin-RevId: 634320860",TensorFlower Gardener,gardener@tensorflow.org,2024-05-16 12:10:56,"tensorflow/workspace2.bzl, third_party/mkl_dnn/mkldnn_v1.BUILD, third_party/xla/third_party/tsl/third_party/mkl_dnn/mkldnn_v1.BUILD",tensorflower-gardener,False
"XNNPack weight cache provider: update the internal options object to keep track of the cache path.

PiperOrigin-RevId: 634308967",Quentin Khan,qkhan@google.com,2024-05-16 11:28:56,"tensorflow/lite/delegates/xnnpack/BUILD, tensorflow/lite/delegates/xnnpack/weight_cache.h, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc",qukhan,False
"Optionally dump the MLIR compilation pipeline steps.

This is used as an input to mlir_replay. Note that GPU-specific ops are
not implemented in the interpreter yet (at HEAD).

PiperOrigin-RevId: 634304231",Johannes Reifferscheid,jreiffers@google.com,2024-05-16 11:09:20,"third_party/xla/xla/mlir/tools/mlir_replay/public/BUILD, third_party/xla/xla/mlir/tools/mlir_replay/public/compiler_trace_instrumentation.cc, third_party/xla/xla/mlir/tools/mlir_replay/public/compiler_trace_instrumentation.h, third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.h",jreiffers,False
"[XLA:GPU] Remove GOOGLE_CUDA and TENSORFLOW_USE_ROCM guards from hlo_fusion_analysis.

This is a pure HLO pass that does not require a GPU.

PiperOrigin-RevId: 634303515",Thomas Joerg,tjoerg@google.com,2024-05-16 11:06:44,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc",thomasjoerg,False
"XNNPack weight cache provider: refactor code.

PiperOrigin-RevId: 634291787",Quentin Khan,qkhan@google.com,2024-05-16 10:31:26,"tensorflow/lite/delegates/xnnpack/weight_cache.cc, tensorflow/lite/delegates/xnnpack/weight_cache.h",qukhan,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634288224",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 10:17:53,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #12501: [NFC] Fix mistypes in scatter expander.

Imported from GitHub PR https://github.com/openxla/xla/pull/12501

Copybara import of the project:

--
97b50d47877dd3dc46535c6fa34f0e449ee57bfe by Ilia Sergachev <isergachev@nvidia.com>:

[NFC] Fix mistypes in scatter expander.

Merging this change closes #12501

PiperOrigin-RevId: 634285954",Ilia Sergachev,isergachev@nvidia.com,2024-05-16 10:09:03,"third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/scatter_expander.cc, third_party/xla/xla/service/scatter_expander.h, third_party/xla/xla/service/scatter_expander_test.cc",sergachev,False
"Automated Code Change

PiperOrigin-RevId: 634285627",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 10:08:01,tensorflow/core/lib/monitoring/BUILD,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 634279450",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 09:45:20,tensorflow/compiler/mlir/init_mlir.cc,tensorflower-gardener,False
"[XLA:GPU] Remove GpuStatus.

XLA should not include any platform specific headers in XLA header files. This change moves us one step closer to this goal by getting rid of type aliases in `gpu_types.h`.

PiperOrigin-RevId: 634278649",Aliia Khasanova,aliia@google.com,2024-05-16 09:41:44,"third_party/xla/xla/stream_executor/cuda/BUILD, third_party/xla/xla/stream_executor/cuda/cuda_driver.cc, third_party/xla/xla/stream_executor/cuda/cuda_driver.h, third_party/xla/xla/stream_executor/cuda/cuda_event.cc, third_party/xla/xla/stream_executor/gpu/gpu_driver.h, third_party/xla/xla/stream_executor/gpu/gpu_types.h, third_party/xla/xla/stream_executor/rocm/rocm_driver.cc, third_party/xla/xla/stream_executor/rocm/rocm_driver.h, third_party/xla/xla/stream_executor/rocm/rocm_event.cc",,False
"compat: Update forward compatibility horizon to 2024-05-16

PiperOrigin-RevId: 634268459",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 09:02:17,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1864.

PiperOrigin-RevId: 634268437",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 09:02:12,tensorflow/core/public/version.h,tensorflower-gardener,False
"[XLA:GPU] Use IndexingMap::RemoveUnusedSymbols instead of WithoutRangeVars

PiperOrigin-RevId: 634264428",Tamás Danyluk,tdanyluk@google.com,2024-05-16 08:47:06,third_party/xla/xla/service/gpu/model/symbolic_tile.cc,tdanyluk,False
"[XLA:GPU] Remove preprocessor `#if GOOGLE_CUDA`s and similar from GemmRewriter pass.

PiperOrigin-RevId: 634263367",Thomas Joerg,tjoerg@google.com,2024-05-16 08:42:41,third_party/xla/xla/service/gpu/gemm_rewriter.cc,thomasjoerg,False
"[XLA] [NFC] Serialize all autotuning results

The previous logic for filtering by-module wasn't correct, as instructions
could be modified after autotuning, resuling in not all relevant information
serialized.

This could result in excessive data serialized, but autotuning results are very
small compared to the module size and the compiled artifact.

PiperOrigin-RevId: 634259538",George Karpenkov,cheshire@google.com,2024-05-16 08:28:46,"third_party/xla/xla/service/gpu/autotuner_util.cc, third_party/xla/xla/service/gpu/autotuner_util.h, third_party/xla/xla/service/gpu/gpu_compiler.cc",cheshire,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634257201",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 08:18:56,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #12538: [GPU] Fix OSS compilation of previously disabled tests.

Imported from GitHub PR https://github.com/openxla/xla/pull/12538

Copybara import of the project:

--
78d74154a1693426014eef2940e759d1e36902ed by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix OSS compilation of previously disabled tests.

Merging this change closes #12538

PiperOrigin-RevId: 634248275",Ilia Sergachev,isergachev@nvidia.com,2024-05-16 07:41:51,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/triton_support_test.cc",sergachev,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634224863",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 06:19:11,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update to Triton version that contains previously patched fixes.

PiperOrigin-RevId: 634216731",Christian Sigg,csigg@google.com,2024-05-16 05:45:26,"third_party/triton/temporary/mma_limit_pred.patch, third_party/triton/temporary/series.bzl, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/temporary/mma_limit_pred.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/workspace.bzl",chsigg,False
"[IFRT] Wrap RemapPlan::mappings with shared_ptr

`xla::ifrt::RemapPlan`'s `mappings` is frequently reused across different
`xla::ifrt::RemapPlan`. It can be costly to keep a copy of `mappings` for each
plan if the mappings is not trivially small.

This change wraps `mappings` with `std::shared_ptr` so that it can be shared
more cheaply across multiple plans.

PiperOrigin-RevId: 634214931",Hyeontaek Lim,hyeontaek@google.com,2024-05-16 05:38:14,"third_party/xla/xla/python/ifrt/remap_impl_test_lib.cc, third_party/xla/xla/python/ifrt/remap_plan.cc, third_party/xla/xla/python/ifrt/remap_plan.h, third_party/xla/xla/python/ifrt/remap_plan_test.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_remap.cc",hyeontaek,False
"Propagate error to output if the input buffer has error.

PiperOrigin-RevId: 634195071",Jieying Luo,jieying@google.com,2024-05-16 04:25:01,"third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",jyingl3,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634193569",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 04:17:31,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Check for `GetEnableMemories()` outside `PyDeviceList::PopulateMemoryKindInfo()`

Checking `GetEnableMemories()` inside `PyDeviceList::PopulateMemoryKindInfo()` causes the memory kind to be built/cached based on the value of `enable_memories` at the time the method was called for the first time. This is problematic when users later change the value of `enable_memories` but reuse the same device list.

This CL fixes the problem by making `PyDeviceList::MemoryKinds()` and `PyDeviceList::DefaultMemoryKind()` always check for `GetEnableMemories()` outside the cached method to make it behave correctly even if `enable_memories` changes.

PiperOrigin-RevId: 634191502",Junwhan Ahn,junwhan@google.com,2024-05-16 04:08:19,third_party/xla/xla/python/py_device_list.cc,junwhanahn,False
"Reverts adf106883e61d1c0d5583b08491fec91cd74420e

PiperOrigin-RevId: 634170429",Anlun Xu,anlunx@google.com,2024-05-16 02:55:33,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/nvptx_compiler.cc",anlunx,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/76dfd9f8757c12739429c8178d1b0c5167862ae7.

PiperOrigin-RevId: 634168734",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 02:48:21,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634161496",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 02:17:36,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[P0] Clean up unused dependency on xla_data.proto.h.

This is attempting to fix this error:
```
File already exists in database: xla/xla_data.proto.
```

PiperOrigin-RevId: 634144823",Yang Chen,yangchen@google.com,2024-05-16 01:16:05,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/attribute_map.cc",yangustc07,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634129215",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-16 00:17:38,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[Cleanup] Update all instances of tfrt::t:: to use tfrt::tfrt_tensor

PiperOrigin-RevId: 634128347",Samuel Agyakwa,sagyakwa@google.com,2024-05-16 00:14:33,tensorflow/compiler/mlir/tfrt/ir/tfrt_fallback_sync.cc,sagyakwa,False
"Integrate LLVM at llvm/llvm-project@e1ed138a67a9

Updates LLVM usage to match
[e1ed138a67a9](https://github.com/llvm/llvm-project/commit/e1ed138a67a9)

PiperOrigin-RevId: 634127563",Fangrui Song,maskray@google.com,2024-05-16 00:11:34,third_party/llvm/workspace.bzl,MaskRay,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634123462",Kyle Lucke,klucke@google.com,2024-05-15 23:57:44,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_dot_handler.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_runner.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_strategy.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc",klucke,False
"Make compiler/jit targets use StreamExecutorInterface::CreateEvent to create stream_executor::Events.

PiperOrigin-RevId: 634109825",Kyle Lucke,klucke@google.com,2024-05-15 23:18:44,"tensorflow/compiler/jit/BUILD, tensorflow/compiler/jit/xla_device_context.cc, tensorflow/compiler/jit/xla_launch_util.cc, tensorflow/compiler/jit/xla_tpu_device.cc",klucke,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634104645",Kyle Lucke,klucke@google.com,2024-05-15 23:00:29,"third_party/xla/xla/service/llvm_ir/dynamic_update_slice_util.cc, third_party/xla/xla/service/llvm_ir/dynamic_update_slice_util.h, third_party/xla/xla/service/llvm_ir/kernel_support_library.cc, third_party/xla/xla/service/llvm_ir/kernel_support_library.h, third_party/xla/xla/service/llvm_ir/llvm_util.cc, third_party/xla/xla/service/llvm_ir/loop_emitter.cc, third_party/xla/xla/service/llvm_ir/loop_emitter.h, third_party/xla/xla/service/llvm_ir/sort_util.cc, third_party/xla/xla/service/llvm_ir/sort_util.h, third_party/xla/xla/tools/dumped_computation_to_operation_list.cc, third_party/xla/xla/tools/extract_collective_operations.cc, third_party/xla/xla/tools/hlo_control_flow_flattening.cc, third_party/xla/xla/tools/hlo_control_flow_flattening.h, third_party/xla/xla/tools/hlo_extractor.cc, third_party/xla/xla/tools/prepare_reference_module.cc, third_party/xla/xla/tools/prepare_reference_module.h, third_party/xla/xla/tools/run_hlo_module.cc, third_party/xla/xla/tools/run_hlo_module.h, third_party/xla/xla/translate/hlo_to_mhlo/hlo_function_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_function_importer.h, third_party/xla/xla/translate/hlo_to_mhlo/hlo_module_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_module_importer.h, third_party/xla/xla/translate/hlo_to_mhlo/hlo_to_mlir_hlo.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_to_mlir_hlo.h, third_party/xla/xla/translate/hlo_to_mhlo/hlo_utils.h",klucke,False
"Add pattern to fuse quant weights into transpose conv.

PiperOrigin-RevId: 634102361",Luke Boyer,lukeboyer@google.com,2024-05-15 22:52:18,"tensorflow/compiler/mlir/lite/tests/optimize.mlir, tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td",LukeBoyer,False
"Use StreamExecutorInterface::CreateEvent in event_pool.cc.

PiperOrigin-RevId: 634095995",Kyle Lucke,klucke@google.com,2024-05-15 22:29:59,third_party/xla/xla/pjrt/event_pool.cc,klucke,False
"Use hermetic Python in TSL and XLA

PiperOrigin-RevId: 634094641",Vadym Matsishevskyi,vam@google.com,2024-05-15 22:25:35,"tensorflow/opensource_only.files, third_party/llvm/toolchains.patch, third_party/py/BUILD, third_party/py/non_hermetic/BUILD, third_party/py/non_hermetic/BUILD.tpl, third_party/py/non_hermetic/README, third_party/py/non_hermetic/python_configure.bzl, third_party/py/python_init_pip.bzl, third_party/py/python_init_repositories.bzl, third_party/py/python_init_rules.bzl, third_party/py/python_init_toolchains.bzl, third_party/py/python_repo.bzl, third_party/xla/WORKSPACE, third_party/xla/opensource_only.files, third_party/xla/requirements_lock_3_11.txt, third_party/xla/third_party/py/BUILD, third_party/xla/third_party/py/non_hermetic/BUILD, third_party/xla/third_party/py/non_hermetic/BUILD.tpl, third_party/xla/third_party/py/non_hermetic/README, third_party/xla/third_party/py/non_hermetic/python_configure.bzl, third_party/xla/third_party/py/python_init_pip.bzl, third_party/xla/third_party/py/python_init_repositories.bzl, third_party/xla/third_party/py/python_init_rules.bzl, third_party/xla/third_party/py/python_init_toolchains.bzl, third_party/xla/third_party/py/python_repo.bzl, third_party/xla/third_party/tsl/WORKSPACE, third_party/xla/third_party/tsl/opensource_only.files, third_party/xla/third_party/tsl/requirements_lock_3_11.txt, third_party/xla/third_party/tsl/third_party/py/BUILD, third_party/xla/third_party/tsl/third_party/py/non_hermetic/BUILD, third_party/xla/third_party/tsl/third_party/py/non_hermetic/BUILD.tpl, third_party/xla/third_party/tsl/third_party/py/non_hermetic/README, third_party/xla/third_party/tsl/third_party/py/non_hermetic/python_configure.bzl, third_party/xla/third_party/tsl/third_party/py/python_init_pip.bzl, third_party/xla/third_party/tsl/third_party/py/python_init_repositories.bzl, third_party/xla/third_party/tsl/third_party/py/python_init_rules.bzl, third_party/xla/third_party/tsl/third_party/py/python_init_toolchains.bzl, third_party/xla/third_party/tsl/third_party/py/python_repo.bzl, third_party/xla/third_party/tsl/workspace2.bzl, third_party/xla/xla/lit.bzl, third_party/xla/xla/mlir_hlo/tests/BUILD",vam-google,False
"Add a pattern to lower a stablehlo.composite with `jax.image.resize` in `nearest` mode to a tflite.resize_nearest_neighbor op.

PiperOrigin-RevId: 634092342",Vamsi Manchala,vamsimanchala@google.com,2024-05-15 22:17:55,"tensorflow/compiler/mlir/lite/stablehlo/tests/composite-lowering.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_patterns.td",vamsimanchala,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634092262",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 22:17:36,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Change to add attribute before building

Avoids issues when converting to properties early (which happens along most
generated build paths today and should be all in future).

PiperOrigin-RevId: 634086476",Jacques Pienaar,jpienaar@google.com,2024-05-15 21:59:41,tensorflow/compiler/mlir/tensorflow/transforms/rewrite_tpu_embedding_ops.cc,jpienaar,False
"Updating schema location.

PiperOrigin-RevId: 634084054",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 21:51:31,tensorflow/lite/experimental/acceleration/mini_benchmark/build_defs.bzl,tensorflower-gardener,False
"[XLA:GPU] Clang-tidy cleanup for shadowed class member in xla/service/gpu/tests/gpu_fused_mha_test.cc

PiperOrigin-RevId: 634083594",Kuy Mainwaring,kuym@google.com,2024-05-15 21:49:50,third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc,kuym,False
"gpu_delegate: Allow broadcast of [1, 1] to [1, x, y, z]

PiperOrigin-RevId: 634083568",Terry Heo,terryheo@google.com,2024-05-15 21:49:45,"tensorflow/lite/tools/versioning/gpu_compatibility.cc, tensorflow/lite/tools/versioning/gpu_compatibility_test.cc",terryheo,False
"[Multi-host GPU]Add a utility function to build GpuTopologyProto from GlobalTopologyProto.

PiperOrigin-RevId: 634081336",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 21:42:40,"third_party/xla/xla/pjrt/distributed/BUILD, third_party/xla/xla/pjrt/distributed/topology_util.cc, third_party/xla/xla/pjrt/distributed/topology_util.h, third_party/xla/xla/pjrt/distributed/topology_util_test.cc",tensorflower-gardener,False
"Updates the benchmarking tool documentation with discovery text about flex ops, more information about flex ops, and an additional section regarding creating a custom version of the app with user-supplied custom ops.

PiperOrigin-RevId: 634078145",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 21:32:56,tensorflow/lite/tools/benchmark/README.md,tensorflower-gardener,False
"Disable some tests that time out on certain platforms.

PiperOrigin-RevId: 634076395",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 21:27:18,"third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/dot_operation_test.cc, third_party/xla/xla/tests/reduce_window_test.cc, third_party/xla/xla/tests/transfer_manager_test.cc",tensorflower-gardener,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/ac3f51614db030270303c593a41f46bea68dab3d.

PiperOrigin-RevId: 634067000",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 20:59:36,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"[xla:spmd] Fix a problem in generating code for concat that requires padding.

When an internal concat operand requires padding, previously, we don't zero out
the padded elements and the generated code produces incorrect results.

Fix two existing tests.

PiperOrigin-RevId: 634066344",Bixia Zheng,bixia@google.com,2024-05-15 20:57:38,"third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc",bixia1,False
"Make it possible to lower fp8 `tt.splat`.

Before the fix, `tt.splat` was lowered to e.g.
```
%14 = ""llvm.mlir.constant""() <{value = 0.000000e+00 : f8E4M3FNUZ}> : () -> f8E4M3FNUZ
```
which LLVM rejected.

Translating the result type through typeConverter is what is done in other similar places. It results in
```
%14 = ""llvm.mlir.constant""() <{value = 0.000000e+00 : f8E4M3FNUZ}> : () -> i8
```
and it's accepted by LLVM. During the MLIR to LLVM lowering, the fp8 value is converted to i8 with the correct binary representation.

The `isFloat()` function that is updated happened to have just one caller (in ArithConstantSplatOpConversion)

PiperOrigin-RevId: 634065311",Alexander Lyashuk,crem@google.com,2024-05-15 20:54:54,"third_party/triton/temporary/fp8_splat.patch, third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/fp8_splat.patch, third_party/xla/third_party/triton/temporary/series.bzl",mooskagh,False
"Integrate LLVM at llvm/llvm-project@45726c1a3a3d

Updates LLVM usage to match
[45726c1a3a3d](https://github.com/llvm/llvm-project/commit/45726c1a3a3d)

PiperOrigin-RevId: 634063221",Fangrui Song,maskray@google.com,2024-05-15 20:48:34,third_party/llvm/workspace.bzl,MaskRay,False
"[Testing] Code Coverage: Increase Code Coverage of //third_party/tensorflow/core/runtime_fallback/util to at least 75%

PiperOrigin-RevId: 634063098",Sania Nagpal,sanianagpal@google.com,2024-05-15 20:48:13,tensorflow/core/runtime_fallback/util/attr_util_test.cc,sanianagpal,False
upgrading oneDNN version 3.4.1,Ashiq Imran,ashiq.imran@intel.com,2024-05-15 21:04:28,"tensorflow/workspace2.bzl, third_party/mkl_dnn/mkldnn_v1.BUILD",ashiqimranintel,True
"Update ops-related pbtxt files.

PiperOrigin-RevId: 634053943",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 20:18:59,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[xla:ffi] Add support for FFI execution context to PjRtCpuClient

Add a test for passing arbitrary user data via execution context side channel to XLA FFI handlers registered for a HOST platform

PiperOrigin-RevId: 634053080",Eugene Zhulenev,ezhulenev@google.com,2024-05-15 20:15:58,"third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client_test.cc, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/ir_emitter.cc, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.cc, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.h",ezhulenev,False
"Make TpuExecutor use StreamExecutorInterface to create Events.

PiperOrigin-RevId: 634048195",Kyle Lucke,klucke@google.com,2024-05-15 20:00:24,"third_party/xla/xla/stream_executor/tpu/c_api_defn.h, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc",klucke,False
"When computing the set of reduced times, keep just the latest one if multiple primitives enter the liveness profile consecutively.

PiperOrigin-RevId: 634047168",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 19:57:19,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory_test.cc",tensorflower-gardener,False
"PR #12439: [GPU] Multinode support for multihost_hlo_runner

Imported from GitHub PR https://github.com/openxla/xla/pull/12439

This PR adds multinode support to the multihost_hlo_runner. To use, there is a new command line argument `address` for the address of the coordinator/root node.

Example usage with SLURM:
```
bazel run //xla/tools/multihost_hlo_runner:hlo_runner_main -- \
  --task_id=${SLURM_PROCID} \
  --num_nodes=${SLURM_NTASKS} \
  --address=""${SLURM_LAUNCH_NODE_IPADDR}:12345"" \
  ...
  ```
Copybara import of the project:

--
ad1705053185c32abbf4d917f2b1fd669d5b6893 by Trevor Morris <tmorris@nvidia.com>:

Multinode changes for hlo_runner_main

Merging this change closes #12439

PiperOrigin-RevId: 634040710",Trevor Morris,tmorris@nvidia.com,2024-05-15 19:33:15,"third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/hlo_runner_main.cc",trevor-m,False
"[XLA:GPU] Error out early on missing autotuning cache when required

This is technically a performance optimization: we would still error out later
on otherwise, but after recompiling & running a bunch of modules, hence no test.

PiperOrigin-RevId: 634039337",George Karpenkov,cheshire@google.com,2024-05-15 19:27:54,third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc,cheshire,False
"Bump ODML to target StableHLO v1.0.0

PiperOrigin-RevId: 634038627",Kevin Gleason,gleasonk@google.com,2024-05-15 19:25:04,"tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_to_vhlo.cc, tensorflow/lite/core/macros.h",GleasonK,False
"Fix a bug in `validate_colocate` when a variable is not created in a strategy scope.

In some cases `v._distribute_strategy` can be None, which was causing an AttributeError when trying to check if the `extended` field matched the expected value.

PiperOrigin-RevId: 634034018",CJ Carey,cjcarey@google.com,2024-05-15 19:08:32,tensorflow/python/distribute/distribute_utils.py,,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634033147",Kyle Lucke,klucke@google.com,2024-05-15 19:05:58,"third_party/xla/xla/python/pjrt_ifrt/pjrt_array.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_tuple.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_tuple.h",klucke,False
"[PJRT:CPU] Bump the stack size for the CPU client thread pool to 8MB.

2MB was found to be causing crashes in JAX linear algebra tests that call into lapack/blas.
OpenBLAS appears to have fairly large stack size requirements.

PiperOrigin-RevId: 634031821",Peter Hawkins,phawkins@google.com,2024-05-15 19:02:34,third_party/xla/xla/pjrt/cpu/cpu_client.cc,hawkinsp,False
"Reduces the # of memory constraints to a subset of times (instead of all possible times).

PiperOrigin-RevId: 634015658",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 18:15:21,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory_test.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc",tensorflower-gardener,False
"Disable pjrt runner for scatter test as it fails on some cases

PiperOrigin-RevId: 634014544",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 18:12:00,third_party/xla/xla/tests/BUILD,tensorflower-gardener,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634012954",Kyle Lucke,klucke@google.com,2024-05-15 18:07:53,"third_party/xla/xla/tests/client_library_test_base.cc, third_party/xla/xla/tests/client_library_test_base.h, third_party/xla/xla/tests/compute_constant_test.cc, third_party/xla/xla/tests/conv_depthwise_test.cc, third_party/xla/xla/tests/grouped_convolution_test.cc, third_party/xla/xla/tests/hlo_test_base.cc, third_party/xla/xla/tests/hlo_test_base.h, third_party/xla/xla/tests/literal_test_util.cc, third_party/xla/xla/tests/llvm_compiler_test.cc, third_party/xla/xla/tests/llvm_irgen_test_base.cc, third_party/xla/xla/tests/llvm_irgen_test_base.h, third_party/xla/xla/tests/local_client_test_base.cc, third_party/xla/xla/tests/local_client_test_base.h, third_party/xla/xla/tests/test_utils.cc, third_party/xla/xla/tests/test_utils.h, third_party/xla/xla/tests/verified_hlo_module.cc, third_party/xla/xla/tests/verified_hlo_module.h, third_party/xla/xla/tests/xla_hlo_profile_test.cc",klucke,False
"Move Event creation into StreamExecutorInterface.

This is the first step in eliminating the pimpl pattern from Events.  Backward references made me had to temporarily eliminate the event target.  Eventually having Event inherit from EventInterface will enable it to be separated out again.

PiperOrigin-RevId: 634012404",Kyle Lucke,klucke@google.com,2024-05-15 18:06:22,"third_party/xla/xla/service/gpu/gpu_transfer_manager.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/copy_thunk.cc, third_party/xla/xla/service/gpu/runtime/copy_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.h, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h",klucke,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634010613",Kyle Lucke,klucke@google.com,2024-05-15 18:01:43,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/collective_permute_cycle_decomposer.cc, third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/cusolver_context.cc, third_party/xla/xla/service/gpu/dot_sparsity_rewriter.cc, third_party/xla/xla/service/gpu/fusion_wrapper.cc, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/memory_space_assignment/algorithm.cc, third_party/xla/xla/service/memory_space_assignment/algorithm.h, third_party/xla/xla/service/memory_space_assignment/allocation.cc, third_party/xla/xla/service/memory_space_assignment/allocation.h, third_party/xla/xla/service/memory_space_assignment/cost_analysis_test.cc, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer.cc, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer.h, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer_test.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.h, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",klucke,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 634006752",Kyle Lucke,klucke@google.com,2024-05-15 17:50:36,third_party/xla/xla/python/ifrt/tuple.h,klucke,False
"Remove unused Stream methods and includes in stream.h.

PiperOrigin-RevId: 633995201",Kyle Lucke,klucke@google.com,2024-05-15 17:15:15,third_party/xla/xla/stream_executor/stream.h,klucke,False
"Use absl/numeric/bits.h for bit manipulation.

This reduces code duplication and allows us to reuse optimized code.

PiperOrigin-RevId: 633986138",David Majnemer,majnemer@google.com,2024-05-15 16:47:15,"tensorflow/compiler/jit/BUILD, tensorflow/compiler/jit/device_util.h, tensorflow/core/common_runtime/gpu/gpu_bfc_allocator_test.cc, tensorflow/core/framework/BUILD, tensorflow/core/framework/types.h, tensorflow/core/lib/strings/BUILD, tensorflow/core/lib/strings/ordered_code.cc, third_party/xla/third_party/tsl/tsl/framework/bfc_allocator.h, third_party/xla/third_party/tsl/tsl/lib/core/BUILD, third_party/xla/third_party/tsl/tsl/lib/core/bitmap.cc, third_party/xla/third_party/tsl/tsl/lib/core/bits.h",majnemer,False
"Use absl::Status instead of xla::Status now that they're identical.

PiperOrigin-RevId: 633984152",Kyle Lucke,klucke@google.com,2024-05-15 16:39:57,third_party/xla/xla/python/ifrt_proxy/common/ifrt_service.proto,klucke,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633982202",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 16:33:22,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU] Pass the CUDA / ROCm toolkit version explicitly for autotuning and GEMM rewriting.

This allows to remove more `#if GOOGLE_CUDA` preprocessor directives from HLO passes.

PiperOrigin-RevId: 633980533",Thomas Joerg,tjoerg@google.com,2024-05-15 16:28:03,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_algorithm_picker_test.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.h, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/gemm_rewriter.h, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/service/gpu/tests/gemm_broadcast_folding_rewrite_test.cc, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc",thomasjoerg,False
"Fix a batch of ClangTidy issues.

Mostly naming, some includes, some miscellaneous other style guide
violations.

PiperOrigin-RevId: 633980451",Johannes Reifferscheid,jreiffers@google.com,2024-05-15 16:27:48,"third_party/xla/xla/mlir/tools/mlir_bisect/BUILD, third_party/xla/xla/mlir/tools/mlir_bisect/bisect_lib.cc, third_party/xla/xla/mlir/tools/mlir_bisect/mlir_bisect.cc, third_party/xla/xla/mlir/tools/mlir_bisect/test_passes.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/BUILD, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/arith.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/bufferization.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/linalg.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/memref.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/util.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/vector.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter_value.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter_value.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter_value_util.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/registration.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tensor_or_memref.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tensor_or_memref.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tests/interpreter_value_test.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tests/tensor_or_memref_test.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/mlir_interpreter_runner.cc, third_party/xla/xla/mlir/tools/mlir_replay/BUILD, third_party/xla/xla/mlir/tools/mlir_replay/mlir_replay.cc, third_party/xla/xla/mlir/tools/mlir_replay/mlir_replay_lib.cc, third_party/xla/xla/mlir/tools/mlir_replay/public/BUILD, third_party/xla/xla/mlir/tools/mlir_replay/public/execution_trace_utils.cc, third_party/xla/xla/mlir/tools/mlir_replay/public/execution_trace_utils_test.cc",jreiffers,False
"In `xla::ShardingPropagation`, remove users and the parameters in the called computations in `already_inferred_from_operands` when clearing the cache.

Before this cl, shardings may not be completely propagated.

PiperOrigin-RevId: 633978152",Zixuan Jiang,zixuanjiang@google.com,2024-05-15 16:18:31,"third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation_test.cc",ZixuanJiang,False
"Optimize gradient of `tf.reshape()` when one input dimension is dynamic.

Previously, if there was any unknown dimension in the shape of the input to `tf.reshape()` the gradient function would add a `tf.shape()` op that would introduce a data dependency on the input tensor, potentially keeping it live until the backward pass. However, in most cases* when only one of the input dimensions is unknown (e.g. a dynamic batch size) we can use the ability to pass a wildcard `-1` dimension to the `tf.reshape()` in the gradient function, and eliminate the data dependency.

(* Except when one or more of the input dimensions is 0, in which case the semantics of the wildcard are surprising, and resolve to 1.)

PiperOrigin-RevId: 633973978",Derek Murray,mrry@google.com,2024-05-15 16:04:03,"tensorflow/python/ops/array_grad.py, tensorflow/python/ops/array_grad_test.py",mrry,False
"Add unit test for async_value_tensor.

PiperOrigin-RevId: 633965643",Deqiang Chen,deqiangc@google.com,2024-05-15 15:34:54,"tensorflow/core/tfrt/common/BUILD, tensorflow/core/tfrt/common/async_value_tensor_test.cc",deqiangc,False
"PR #9827: [ROCm] Stream executor API logging API

Imported from GitHub PR https://github.com/openxla/xla/pull/9827

Separated from https://github.com/openxla/xla/pull/9593.

This adds a low-overhead ability to log stream executor API calls, for testing purposes (unit tests can enable the functionality and use it to verify that high-level operations result in correct sequences of low-level calls). At present, this only covers BlasGemm / BlasLt calls on ROCm backend.
Copybara import of the project:

--
41732ac48c5383f33d428fe76fcebe02506d5b52 by Eugene Kuznetsov <eugene.kuznetsov@amd.com>:

Stream executor API logging API

Merging this change closes #9827

PiperOrigin-RevId: 633955314",ekuznetsov139,nameless@fastmail.fm,2024-05-15 14:59:50,"third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/rocm/hip_blas_lt.cc, third_party/xla/xla/stream_executor/rocm/rocm_blas.cc, third_party/xla/xla/stream_executor/rocm/rocm_blas.h, third_party/xla/xla/stream_executor/stream_executor_interface.h",ekuznetsov139,False
"Fix wrong register constraints produced for some types in WGMMAWaitGroupOpPattern

This is a minimal patch to unblock folks. I'll work on polishing it up and upstreaming a proper fix to OpenAI.

PiperOrigin-RevId: 633955310",Goran Flegar,gflegar@google.com,2024-05-15 14:59:49,"third_party/triton/temporary/fix_register_constraints.patch, third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/fix_register_constraints.patch, third_party/xla/third_party/triton/temporary/series.bzl",gflegar,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633945444",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 14:20:39,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[PJRT:CPU] Provide a compile-time thread pool.

The OneDNN matmul rewriter starts a thread pool if one wasn't provided as a compile option, spawning many threads per compilation. If we pass a preexisting thread pool, we can save the cost of creating and tearing down threads.

PiperOrigin-RevId: 633942672",Peter Hawkins,phawkins@google.com,2024-05-15 14:10:41,third_party/xla/xla/pjrt/cpu/cpu_client.cc,hawkinsp,False
"PR #10803: Expose CompiledMemoryStats on CPU and GPU

Imported from GitHub PR https://github.com/openxla/xla/pull/10803

[CompiledMemoryStats](https://github.com/openxla/xla/blob/01073cf10b57c64615483545bfb34fb9ae0d3c06/xla/pjrt/pjrt_executable.h#L269-L269) is supposed to summarize the amount of memory required to run a given executable. Buffer-related fields in CompiledMemoryStats are currently missing for both the GPU and the CPU backend. This PR computes the missing fields using the executable's underlying [BufferAssignment](https://github.com/openxla/xla/blob/50c6489cb058881cc65622605c9c55029abebc5b/xla/service/buffer_assignment.h#L491) / buffer allocations.

# Example
```python
import jax
import jax.numpy as jnp

def f(a, b):
    ms = jnp.sum(a, axis=1, keepdims=True) / a.shape[1]
    return a * jax.lax.rsqrt(ms) + b

a0 = jax.random.uniform(jax.random.PRNGKey(0), (128, 128))
b0 = jax.random.uniform(jax.random.PRNGKey(0), (128, 128))
f_jit = jax.jit(f, donate_argnums=(0,))

print(f_jit.lower(a0, b0).compile().memory_analysis())
# CompiledMemoryStats(
#     generated_code_size_in_bytes=5792,
#     argument_size_in_bytes=131072,
#     output_size_in_bytes=65536,
#     alias_size_in_bytes=65536,
#     temp_size_in_bytes=512,
#     host_generated_code_size_in_bytes=0,
#     host_argument_size_in_bytes=0,
#     host_output_size_in_bytes=0,
#     host_alias_size_in_bytes=0,
#     host_temp_size_in_bytes=0)
```
Note the use of `donate_argnums=(0,)` which allows XLA to modify the first input buffer in-place and reuse it as the output. This is reflected in `alias_size_in_bytes` -- without buffer donation that number is zero.

# Open questions
- Does this match the semantics for the TPU backend?
- `dynamic_cast`-ing on `gpu::Executable` ain't great. Do we want `Executable`s to expose their buffer allocations publicly (i.e. GpuExecutable's [GetAllocations](https://github.com/openxla/xla/blob/f6ce6c11ceac904c9c4840fcec5f1ee715291425/xla/service/gpu/gpu_executable.h#L164) but for all Executables)?
Copybara import of the project:

--
f9ae2c4e367aed813af74ae50edfd27a6f9304eb by Georg Stefan Schmid <gschmid@nvidia.com>:

Expose CompiledMemoryStats on CPU and GPU

Merging this change closes #10803

PiperOrigin-RevId: 633937384",Georg Stefan Schmid,gschmid@nvidia.com,2024-05-15 13:51:16,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/pjrt_executable.cc, third_party/xla/xla/pjrt/pjrt_executable.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/buffer_assignment.h, third_party/xla/xla/service/cpu/cpu_executable.h, third_party/xla/xla/service/executable.h, third_party/xla/xla/service/gpu/gpu_executable.h",gspschmid,False
"PR #9666: [ROCm] Fused convolution+bias+activation

Imported from GitHub PR https://github.com/openxla/xla/pull/9666

This PR enables MIOpen convolution+bias+activation fusion for ROCm and updates fusion unit tests accordingly.
Copybara import of the project:

--
bd5be494abe6621dfd2c4ebcca4f8992077d8a89 by Eugene Kuznetsov <eugene.kuznetsov@amd.com>:

Switch to NHWC for ROCm and F16

--
8792f892770aba54e38a5352d9bec1d003e341d3 by Eugene Kuznetsov <eugene.kuznetsov@amd.com>:

Fused convolution+bias+activation

Merging this change closes #9666

PiperOrigin-RevId: 633923105",ekuznetsov139,nameless@fastmail.fm,2024-05-15 12:58:51,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/amdgpu_compiler.cc, third_party/xla/xla/service/gpu/cudnn_fused_conv_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_fused_conv_rewriter.h, third_party/xla/xla/service/gpu/cudnn_fused_conv_rewriter_test.cc, third_party/xla/xla/service/gpu/gpu_layout_assignment.cc, third_party/xla/xla/service/gpu/runtime/convolution_thunk.cc, third_party/xla/xla/stream_executor/dnn.cc, third_party/xla/xla/stream_executor/dnn.h, third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc, third_party/xla/xla/stream_executor/rocm/rocm_dnn.h, third_party/xla/xla/stream_executor/rocm/rocm_helpers.cu.cc, third_party/xla/xla/tests/convolution_test.cc",ekuznetsov139,False
"Revive MLIR interpreter.

This is needed for debugging MLIR emitters. So far, the new GPU ops aren't
supported. This just reverts the deletion, with a few changes:

- removal of depreacted dialects (gml_st, thlo, lhlo, deallocation, xla CPU, xla rt)
- adjustments for upstream changes (expand_shape, vector combiners, scf.parallel)
- removal of mhlo ComputeReshapeShape
- replacement of tsl::Status with absl::Status
- move it out of mlir_hlo and adjust to TF style guide (...mostly)

The tooling still needs to be hooked up to the GPU compiler.

Reverts changelist 568496965

PiperOrigin-RevId: 633922803",Johannes Reifferscheid,jreiffers@google.com,2024-05-15 12:57:51,"third_party/xla/xla/mlir/tools/mlir_bisect/BUILD, third_party/xla/xla/mlir/tools/mlir_bisect/README.md, third_party/xla/xla/mlir/tools/mlir_bisect/bisect_lib.cc, third_party/xla/xla/mlir/tools/mlir_bisect/bisect_lib.h, third_party/xla/xla/mlir/tools/mlir_bisect/mlir_bisect.cc, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/BUILD, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/func.cc, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/general.cc, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/scf.cc, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/BUILD, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/erase-op-without-results.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/inline-scf-while.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/reduce-scf-forall-bounds.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/replace-op-with-constant.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/replace-op-with-value.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/replace-operand-with-constant.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/return-operands-of-terminator-operands.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/rewrites/tests/truncate-function.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/test_passes.cc, third_party/xla/xla/mlir/tools/mlir_bisect/test_passes.h, third_party/xla/xla/mlir/tools/mlir_bisect/tests/BUILD, third_party/xla/xla/mlir/tools/mlir_bisect/tests/bisect.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/tests/no-bug.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/tests/snapshot.mlir, third_party/xla/xla/mlir/tools/mlir_bisect/tests/snapshot.mlir.pb, third_party/xla/xla/mlir/tools/mlir_interpreter/BUILD, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/BUILD, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/affine.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/arith.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/bufferization.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/builtin.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/comparators.h, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/complex.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/cwise_math.h, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/func.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/linalg.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/math.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/memref.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/mhlo.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/mhlo_binary_cwise.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/mhlo_unary_cwise.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/scf.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tensor.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/BUILD, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/affine/apply.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/affine/minmax.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/bitcast.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/cmpf.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/cmpi.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/constant.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/extf.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/fptosi.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/index_cast.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/int_math.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/minmax.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/negf.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/remf.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/select.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/sitofp.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/uitofp.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/arith/vector_math.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/bufferization/alloc_tensor.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/bufferization/clone.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/bufferization/to_memref.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/bufferization/to_tensor.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/builtin/unrealized_conversion_cast.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/complex/complex.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/func/call.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/broadcast.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/dot.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/fill.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/generic.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/map.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/matmul.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/reduce.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/transpose.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/linalg/vecmat.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/math/math.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/alloc.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/collapse_shape.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/copy.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/dim.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/expand_shape.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/get_global.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/invalid.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/load.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/memref/subview.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/bitcast_convert.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/broadcast_in_dim.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/case.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/clamp.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/compare.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/complex_math.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/concatenate.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/constant.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/convert.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/dot.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/dot_general.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/dynamic_slice.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/dynamic_update_slice.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/float_math.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/gather.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/int_math.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/iota.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/pad.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/reduce.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/reshape.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/scatter.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/select.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/slice.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/sort.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/subtract.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/transpose.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/tuple.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/mhlo/while.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/scf/for.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/scf/forall.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/scf/if.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/scf/parallel.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/scf/while.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/collapse_shape.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/dim.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/empty.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/expand_shape.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/extract.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/extract_slice.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/from_elements.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/generate.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/insert.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/insert_slice.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/tensor/pad.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/bitcast.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/broadcast.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/compressstore.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/constant_mask.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/contract.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/create_mask.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/expandload.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/extract.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/extract_strided_slice.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/extractelement.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/flat_transpose.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/fma.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/gather.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/insert.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/insert_strided_slice.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/insertelement.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/invalid.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/load.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/maskedload.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/maskedstore.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/multi_reduction.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/outerproduct.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/reduction.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/shape_cast.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/shuffle.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/splat.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/store.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/transfer_read.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/transfer_write.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/transpose.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/type_cast.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/tests/vector/vscale.mlir, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/util.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/util.h, third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/vector.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/BUILD, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter_value.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter_value.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/interpreter_value_util.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/registration.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/registration.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tensor_or_memref.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tensor_or_memref.h, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tests/BUILD, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tests/interpreter_value_test.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/framework/tests/tensor_or_memref_test.cc, third_party/xla/xla/mlir/tools/mlir_interpreter/mlir_interpreter_runner.cc, third_party/xla/xla/mlir/tools/mlir_replay/BUILD, third_party/xla/xla/mlir/tools/mlir_replay/README.md, third_party/xla/xla/mlir/tools/mlir_replay/mlir_replay.cc, third_party/xla/xla/mlir/tools/mlir_replay/mlir_replay_lib.cc, third_party/xla/xla/mlir/tools/mlir_replay/mlir_replay_lib.h, third_party/xla/xla/mlir/tools/mlir_replay/public/BUILD, third_party/xla/xla/mlir/tools/mlir_replay/public/compiler_trace.proto, third_party/xla/xla/mlir/tools/mlir_replay/public/execution_trace.proto, third_party/xla/xla/mlir/tools/mlir_replay/public/execution_trace_utils.cc, third_party/xla/xla/mlir/tools/mlir_replay/public/execution_trace_utils.h, third_party/xla/xla/mlir/tools/mlir_replay/public/execution_trace_utils_test.cc",jreiffers,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633910995",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 12:17:36,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 633909924",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 12:14:14,tensorflow/lite/tools/evaluation/stages/utils/image_metrics_test.cc,tensorflower-gardener,False
"[Triton] Bring back a test to show that TF32 is not supported for 8-bit or less types with F32.

PiperOrigin-RevId: 633894011",Mohammed Anany,manany@google.com,2024-05-15 11:31:17,third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc,Moerafaat,False
"PR #12436: [XLA:CPU][oneDNN] Enable Matmul + BiasAdd + Elu / Tanh / Relu6 fusions for onednn

Imported from GitHub PR https://github.com/openxla/xla/pull/12436

This PR enables MatMul  fusions with different activations viz. Elu, Tanh and Relu6.
Copybara import of the project:

--
9895b022aa66ee0f1040d0f6e557382c9dd77b99 by Gauri1 Deshpande <gauri1.deshpande@intel.com>:

Enable Matmul + BiasAdd + Elu / Tanh / Relu6 fusions for onednn

--
c277c70da3a1bbe05d0d637ec2d4e9ce220f7f3f by Gauri1 Deshpande <gauri1.deshpande@intel.com>:

address review comments - sort name, remove default layout and remove default attributes

Merging this change closes #12436

PiperOrigin-RevId: 633881207",gaurides,gauri1.deshpande@intel.com,2024-05-15 10:40:54,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/backend_config.proto, third_party/xla/xla/service/cpu/onednn_matmul.cc, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/service/cpu/onednn_ops_rewriter.cc, third_party/xla/xla/service/cpu/onednn_pattern_utils.h, third_party/xla/xla/service/pattern_matcher.h, third_party/xla/xla/tests/onednn_matmul_test.cc",gaurides,False
"Introduce reference implementation of DRQ (dynamically quantized) TransposeConv with per-channel quantization

PiperOrigin-RevId: 633877445",Artsiom Ablavatski,artsiom@google.com,2024-05-15 10:25:10,"tensorflow/lite/kernels/internal/reference/transpose_conv.h, tensorflow/lite/kernels/transpose_conv.cc, tensorflow/lite/kernels/transpose_conv_test.cc",ablavatski,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633876272",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 10:19:26,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix ROCm build after TypedKernel change

PiperOrigin-RevId: 633874819",Henning Becker,hebecker@google.com,2024-05-15 10:11:15,"third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/redzone_allocator_kernel_rocm.cu.cc",beckerhe,False
"[XLA:GPU] Migrate while loop extraction to utility function.

PiperOrigin-RevId: 633860340",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-15 09:04:45,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/double_buffer_loop_unrolling_test.cc",golechwierowicz,False
"Update GraphDef version to 1863.

PiperOrigin-RevId: 633859985",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 09:03:37,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-15

PiperOrigin-RevId: 633859960",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 09:03:30,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 633857603",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 08:53:14,"tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/analysis/resource_alias_analysis.cc, tensorflow/compiler/mlir/tensorflow/analysis/resource_alias_analysis.h, tensorflow/compiler/mlir/tensorflow/analysis/resource_dataflow.h, tensorflow/compiler/mlir/tensorflow/analysis/resource_value_typed_analyzer.cc, tensorflow/compiler/mlir/tensorflow/analysis/resource_value_typed_analyzer.h, tensorflow/compiler/mlir/tensorflow/analysis/side_effect_analysis.cc, tensorflow/compiler/mlir/tensorflow/analysis/side_effect_analysis.h",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633851744",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 08:27:19,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #12463: [ROCm] Fix build break in `xla/service/gpu/runtime/convolution_thunk.cc`

Imported from GitHub PR https://github.com/openxla/xla/pull/12463

Fix build break introduced in db8f9c0cf2bf08b171aec2cbe3da2fcb074a6207
Copybara import of the project:

--
42d5839ffb47362a7f6789ba98ef50b31189dccc by Harsha HS <harsha.havanurshamsundara@amd.com>:

[ROCm] Fix build break in `xla/service/gpu/runtime/convolution_thunk.cc`

--
fd95e342a4e8de6c8348df3576510584a0020150 by Harsha HS <harsha.havanurshamsundara@amd.com>:

Gaurd header using TENSORFLOW_USE_ROCM

Merging this change closes #12463

PiperOrigin-RevId: 633851634",Harsha H S,hsharsha@users.noreply.github.com,2024-05-15 08:26:40,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/convolution_thunk.cc",hsharsha,False
"PR #12328: Make shared cache read/write logic more clearly for transpose mlir emitter

Imported from GitHub PR https://github.com/openxla/xla/pull/12328

Current transpose mlir emitter allocate shared cache with shape 32x1x32 for transpose 2-1-0. But the read indices of shared cache are {0, y, x} as [this line](https://github.com/openxla/xla/blob/main/xla/service/gpu/fusions/transpose_mlir.cc#L190) shows, which is not compatible with 32x1x32 shape. What's strange is that transpose 2-1-0 can run successfully using transpose mlir emitter. I find the reason is that lower tensor pass use [linear index](https://github.com/openxla/xla/blob/main/xla/service/gpu/fusions/mlir/lower_tensors.cc#L148) to access shared cache, which is lucky to get right result. For example, the strides of 32x1x32 are {32, 32, 1}, and the linear index of {0, y ,x} is 0 * 32 + y * 32 + 32.
I am not sure if it is as expected or just mistake. If reviewer think no need of this PR, feel free to close.
Copybara import of the project:

--
bfb21798ee518dc11293a5683669add619a38e53 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

make shared cache read/write logic more clearly for transpose mlir emitter

--
0c9033334835bc8a14310e5ee059489cea7b5309 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

refactor

--
5554110835fc18207fb466587c1aeb20c3a542fe by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

pad shared cache

--
8c17818baa1e2477952df15e412a6463f73106ab by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

include missing file

Merging this change closes #12328

PiperOrigin-RevId: 633848774",lingzhi98,103185827+lingzhi98@users.noreply.github.com,2024-05-15 08:13:45,"third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc",lingzhi98,False
"[XLA:GPU] Remove unused sleep kernel

Nothing is using the sleep kernel, so let's remove it

PiperOrigin-RevId: 633838040",Henning Becker,hebecker@google.com,2024-05-15 07:24:47,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/sleep_kernel.cu.cc, third_party/xla/xla/service/gpu/sleep_kernel.h",beckerhe,False
"Add core selector support for TFRT+IFRT serving on tensorflow serving

PiperOrigin-RevId: 633836270",Siqiao Wu,siqiaowu@google.com,2024-05-15 07:16:34,tensorflow/core/tfrt/ifrt/ifrt_config.proto,SiqiaoWu1993,False
"Use min subgroup size when 16 is not supported

PiperOrigin-RevId: 633835830",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 07:14:36,"tensorflow/lite/delegates/gpu/common/BUILD, tensorflow/lite/delegates/gpu/common/gpu_info.cc, tensorflow/lite/delegates/gpu/common/gpu_info.h, tensorflow/lite/delegates/gpu/common/tasks/BUILD, tensorflow/lite/delegates/gpu/common/tasks/conv_generic.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 633835586",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 07:13:28,tensorflow/core/platform/file_system_test.cc,tensorflower-gardener,False
"Fixed the test failure.

PiperOrigin-RevId: 633829720",Dateng Lin,datenglin@google.com,2024-05-15 06:47:32,tensorflow/core/tfrt/ifrt/ifrt_model_context.h,,False
"Automated Code Change

PiperOrigin-RevId: 633826568",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 06:31:50,third_party/xla/xla/tsl/concurrency/concurrent_vector_test.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633823815",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 06:17:37,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 633817088",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 05:41:38,"tensorflow/tools/benchmark/BUILD, tensorflow/tools/benchmark/benchmark_model.cc, tensorflow/tools/benchmark/benchmark_model.h, tensorflow/tools/benchmark/benchmark_model_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 633809834",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 05:04:15,"third_party/xla/xla/BUILD, third_party/xla/xla/frontend_attributes.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633801239",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 04:17:42,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633777654",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 02:17:56,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"#tf-data Support random access for the unbatch dataset.

PiperOrigin-RevId: 633761597",Yang Chen,yangchen@google.com,2024-05-15 00:52:44,"tensorflow/core/kernels/data/experimental/BUILD, tensorflow/core/kernels/data/experimental/unbatch_dataset_op.cc, tensorflow/python/data/kernel_tests/BUILD, tensorflow/python/data/kernel_tests/unbatch_test.py",yangustc07,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633754444",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-15 00:19:42,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@f89b1b8a6806

Updates LLVM usage to match
[f89b1b8a6806](https://github.com/llvm/llvm-project/commit/f89b1b8a6806)

PiperOrigin-RevId: 633748740",Fangrui Song,maskray@google.com,2024-05-14 23:57:21,third_party/llvm/workspace.bzl,MaskRay,False
"[XLA:GPU] Clang-tidy cleanup for xla/service/gpu/... for const-correctness

PiperOrigin-RevId: 633747545",Kuy Mainwaring,kuym@google.com,2024-05-14 23:52:32,"third_party/xla/xla/service/gpu/cublas_pad_for_gemms.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_transpose_fusion.cc, third_party/xla/xla/service/gpu/gpu_conv_rewriter.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.cc",kuym,False
"Expands the test coverage of GetReducedIntervals(), since this is now the preferred way of interacting with the Memory Term Reducer.

PiperOrigin-RevId: 633746142",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 23:46:46,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory_test.cc,tensorflower-gardener,False
"Clean unnecessary include and definition from kernel.h.

PiperOrigin-RevId: 633739642",Kyle Lucke,klucke@google.com,2024-05-14 23:21:09,"third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/stream_search_test.cc, third_party/xla/xla/stream_executor/kernel.cc, third_party/xla/xla/stream_executor/kernel.h, third_party/xla/xla/stream_executor/stream.cc",klucke,False
"Remove references to unused tags in XLA build script

PiperOrigin-RevId: 633738393",David Dunleavy,ddunleavy@google.com,2024-05-14 23:15:59,third_party/xla/.kokoro/linux/build.sh,ddunl,False
"tf_host_callback in tfrt/ifrt use DeviceMgr instead of StaticDeviceMgr
for better generality and not owning the DeviceMgr since that
can be owned/created in fallback_request

PiperOrigin-RevId: 633734973",Deqiang Chen,deqiangc@google.com,2024-05-14 23:03:02,"tensorflow/core/tfrt/fallback/fallback_state.h, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h, tensorflow/core/tfrt/ifrt/tf_host_callback.cc, tensorflow/core/tfrt/ifrt/tf_host_callback.h, tensorflow/core/tfrt/runtime/runtime.h, tensorflow/core/tfrt/saved_model/BUILD, tensorflow/core/tfrt/saved_model/saved_model.cc, tensorflow/core/tfrt/tfrt_session/tfrt_session.cc",deqiangc,False
"Eliminate deprecated Create methods, and use the KernelFactory methods everywhere.

PiperOrigin-RevId: 633726272",Kyle Lucke,klucke@google.com,2024-05-14 22:31:17,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/buffer_comparator.cc, third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/kernels/topk_kernel.cc, third_party/xla/xla/service/gpu/make_batch_pointers.cc, third_party/xla/xla/service/gpu/stream_executor_util.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel_cuda.cu.cc, third_party/xla/xla/stream_executor/gpu/redzone_allocator_kernel_cuda.cc, third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_kernel_test.cc, third_party/xla/xla/stream_executor/kernel.cc, third_party/xla/xla/stream_executor/kernel.h, third_party/xla/xla/stream_executor/kernel_test.cc, third_party/xla/xla/stream_executor/typed_kernel_factory.h",klucke,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633723992",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 22:24:32,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU] Clang-tidy fixes for gpu_norm_runner.h, in_place_dynamic_update_slice_mlir.h, tiling_util.h and indexing_analysis.h

PiperOrigin-RevId: 633722707",Kuy Mainwaring,kuym@google.com,2024-05-14 22:19:41,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/tiling_util.h, third_party/xla/xla/service/gpu/gpu_norm_runner.h, third_party/xla/xla/service/gpu/model/indexing_analysis.h",kuym,False
"Remove StreamExecutorInterface::AllocateStream in favor of making CreateStream do the necessary work.

PiperOrigin-RevId: 633722475",Kyle Lucke,klucke@google.com,2024-05-14 22:18:47,"tensorflow/c/experimental/stream_executor/stream_executor.cc, third_party/xla/xla/backends/interpreter/executor.h, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/gpu/gpu_stream.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream.cc, third_party/xla/xla/stream_executor/stream.h, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.h, third_party/xla/xla/stream_executor/tpu/tpu_executor_init_fns.inc",klucke,False
"Fix NPE bug in XContextStatsAccessor::GetStat() when stats_metadata_ is nullptr.
Refactor preprocess_xplane to enforce nullability as part of type.

PiperOrigin-RevId: 633717014",Bryan Massoth,bmassoth@google.com,2024-05-14 22:00:17,"third_party/xla/third_party/tsl/tsl/profiler/utils/BUILD, third_party/xla/third_party/tsl/tsl/profiler/utils/preprocess_xplane.cc, third_party/xla/third_party/tsl/tsl/profiler/utils/preprocess_xplane.h, third_party/xla/third_party/tsl/tsl/profiler/utils/preprocess_xplane_test.cc",bmass02,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/runtime/sequential_thunk.cc

PiperOrigin-RevId: 633708120",Kuy Mainwaring,kuym@google.com,2024-05-14 21:29:23,third_party/xla/xla/service/gpu/runtime/sequential_thunk.cc,kuym,False
"Fix build error for third_party/tensorflow/core/tfrt/gpu.

PiperOrigin-RevId: 633704451",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 21:18:46,"tensorflow/core/tfrt/gpu/kernel/BUILD, tensorflow/core/tfrt/gpu/kernel/gpu_runner_test.cc",tensorflower-gardener,False
"Remove `gpu_any` tag in favor of `requires-gpu-nvidia`

This also enables v100 tests.

We now use the same sets of tags for gpu tests between internal and external, modulo the extra tags for local execution of gpu tests.

PiperOrigin-RevId: 633700962",David Dunleavy,ddunleavy@google.com,2024-05-14 21:07:59,"third_party/xla/.kokoro/linux/build.sh, third_party/xla/third_party/tsl/tsl/platform/default/build_config_root.bzl, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/xla.bzl",ddunl,False
"PR #12465: [GPU] Fix handling of xla_gpu_require_complete_aot_autotune_results flag.

Imported from GitHub PR https://github.com/openxla/xla/pull/12465

Copybara import of the project:

--
4a050dce154b924b98134294f3f15ffce35bdcbb by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix handling of xla_gpu_require_complete_aot_autotune_results flag.

Merging this change closes #12465

PiperOrigin-RevId: 633690035",Ilia Sergachev,isergachev@nvidia.com,2024-05-14 20:33:54,third_party/xla/xla/debug_options_flags.cc,sergachev,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633686615",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 20:24:17,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA] Fix incorrect comment.

PiperOrigin-RevId: 633677008",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-14 19:52:34,third_party/xla/xla/xla.proto,dimitar-asenov,False
"Create basic server coverage and model tests.

PiperOrigin-RevId: 633672834",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 19:37:00,tensorflow/compiler/mlir/quantization/stablehlo/python/BUILD,tensorflower-gardener,False
"Add unbounded dynamism test for AllToAllOp.

PiperOrigin-RevId: 633671113",Gunhyun Park,gunhyun@google.com,2024-05-14 19:31:06,"third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder.h, third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/runtime/fft_thunk.cc

PiperOrigin-RevId: 633670507",Kuy Mainwaring,kuym@google.com,2024-05-14 19:28:42,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/fft_thunk.cc",kuym,False
"Cleanup change: tf::Status is an alias for absl::Status.
Add tests

PiperOrigin-RevId: 633667291",Rohit Upadhyaya,rohitju@google.com,2024-05-14 19:17:34,"tensorflow/core/tfrt/utils/BUILD, tensorflow/core/tfrt/utils/error_util.cc, tensorflow/core/tfrt/utils/error_util.h, tensorflow/core/tfrt/utils/error_util_test.cc",rohitju,False
"Reduce messages from sharding_utils.cc

PiperOrigin-RevId: 633662509",Deqiang Chen,deqiangc@google.com,2024-05-14 19:01:51,tensorflow/core/tfrt/ifrt/sharding_utils.cc,deqiangc,False
"[XLA:GPU] Remove the deprecated xla flag `--xla_gpu_simplify_all_fp_conversions`.

Use `--xla_allow_excess_precision` instead.

PiperOrigin-RevId: 633659944",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-14 18:54:14,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/xla.proto",dimitar-asenov,False
"Update visibility in third_party/tensorflow/python/platform/BUILD.

PiperOrigin-RevId: 633657239",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 18:44:50,tensorflow/python/platform/BUILD,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633649526",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 18:22:48,"tensorflow/core/ops/compat/ops_history_v2/Abort.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Abs.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AccumulateNV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AccumulatorApplyGradient.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AccumulatorNumAccumulated.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AccumulatorSetGlobalStep.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AccumulatorTakeGradient.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Acos.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Acosh.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Add.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AddManySparseToTensorsMap.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AddN.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AddSparseToTensorsMap.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AddV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AdjustContrast.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AdjustContrastv2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AdjustHue.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AdjustSaturation.pbtxt, tensorflow/core/ops/compat/ops_history_v2/All.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AllCandidateSampler.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AllToAll.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Angle.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousHashTable.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousIterator.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousIteratorV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousIteratorV3.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousMemoryCache.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousMultiDeviceIterator.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousMultiDeviceIteratorV3.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousMutableDenseHashTable.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousMutableHashTable.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousMutableHashTableOfTensors.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousRandomSeedGenerator.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AnonymousSeedGenerator.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Any.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyAdaMax.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyAdadelta.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyAdagrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyAdagradDA.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyAdagradV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyAdam.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyAddSign.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyCenteredRMSProp.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyFtrl.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyFtrlV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyGradientDescent.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyMomentum.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyPowerSign.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyProximalAdagrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyProximalGradientDescent.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApplyRMSProp.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApproxTopK.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ApproximateEqual.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ArgMax.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ArgMin.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AsString.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Asin.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Asinh.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Assert.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssertCardinalityDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssertNextDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssertPrevDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Assign.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssignAdd.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssignAddVariableOp.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssignSub.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssignSubVariableOp.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssignVariableOp.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AssignVariableXlaConcatND.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Atan.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Atan2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Atanh.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AudioSpectrogram.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AudioSummary.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AudioSummaryV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AutoShardDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AvgPool.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AvgPool3D.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AvgPool3DGrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/AvgPoolGrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BandedTriangularSolve.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Barrier.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BarrierClose.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BarrierIncompleteSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BarrierInsertMany.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BarrierReadySize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BarrierTakeMany.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Batch.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchCholesky.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchCholeskyGrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchDatasetV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchFFT.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchFFT2D.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchFFT3D.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchFunction.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchIFFT.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchIFFT2D.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchIFFT3D.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatMul.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatMulV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatMulV3.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixBandPart.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixDeterminant.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixDiag.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixDiagPart.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixInverse.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixSetDiag.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixSolve.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixSolveLs.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchMatrixTriangularSolve.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchNormWithGlobalNormalization.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchNormWithGlobalNormalizationGrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchSelfAdjointEig.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchSelfAdjointEigV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchSvd.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchToSpace.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BatchToSpaceND.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselI0.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselI0e.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselI1.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselI1e.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselJ0.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselJ1.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselK0.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselK0e.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselK1.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselK1e.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselY0.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BesselY1.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Betainc.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BiasAdd.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BiasAddGrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BiasAddV1.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Bincount.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Bitcast.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BitwiseAnd.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BitwiseOr.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BitwiseXor.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BlockLSTM.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BlockLSTMGrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BlockLSTMGradV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BlockLSTMV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesAggregateStats.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesBucketize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesCalculateBestFeatureSplit.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesCalculateBestFeatureSplitV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesCalculateBestGainsPerFeature.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesCenterBias.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesCreateEnsemble.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesCreateQuantileStreamResource.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesDeserializeEnsemble.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesEnsembleResourceHandleOp.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesExampleDebugOutputs.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesFlushQuantileSummaries.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesGetEnsembleStates.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesMakeQuantileSummaries.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesMakeStatsSummary.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesPredict.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesQuantileStreamResourceAddSummaries.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesQuantileStreamResourceDeserialize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesQuantileStreamResourceFlush.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesQuantileStreamResourceGetBucketBoundaries.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesQuantileStreamResourceHandleOp.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesSerializeEnsemble.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesSparseAggregateStats.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesSparseCalculateBestFeatureSplit.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesTrainingPredict.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesUpdateEnsemble.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BoostedTreesUpdateEnsembleV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BroadcastArgs.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BroadcastGradientArgs.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BroadcastTo.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Bucketize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/BytesProducedStatsDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CSRSparseMatrixComponents.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CSRSparseMatrixToDense.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CSRSparseMatrixToSparseTensor.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CSVDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CSVDatasetV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CTCBeamSearchDecoder.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CTCGreedyDecoder.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CTCLoss.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CTCLossV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CacheDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CacheDatasetV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Case.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Cast.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Ceil.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CheckNumerics.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CheckNumericsV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Cholesky.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CholeskyGrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ChooseFastestBranchDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ChooseFastestDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ClipByValue.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CloseSummaryWriter.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollateTPUEmbeddingMemory.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveAllToAllV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveAllToAllV3.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveAssignGroupV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveBcastRecv.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveBcastRecvV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveBcastSend.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveBcastSendV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveGather.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveGatherV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveInitializeCommunicator.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectivePermute.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveReduce.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveReduceScatterV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveReduceV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CollectiveReduceV3.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CombinedNonMaxSuppression.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Complex.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComplexAbs.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CompositeTensorVariantFromComponents.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CompositeTensorVariantToComponents.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CompressElement.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComputeAccidentalHits.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComputeBatchSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComputeDedupDataSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComputeDedupDataSizeV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComputeDedupDataTupleMask.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComputeDedupDataTupleMaskV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Concat.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConcatOffset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConcatV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConcatenateDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConditionalAccumulator.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConfigureAndInitializeGlobalTPU.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConfigureDistributedTPU.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConfigureTPUEmbedding.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConfigureTPUEmbeddingHost.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConfigureTPUEmbeddingMemory.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conj.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConjugateTranspose.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConnectTPUEmbeddingHosts.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Const.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConsumeMutexLock.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ControlTrigger.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv2D.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv2DBackpropFilter.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv2DBackpropFilterV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv2DBackpropInput.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv2DBackpropInputV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv3D.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv3DBackpropFilter.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv3DBackpropFilterV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv3DBackpropInput.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Conv3DBackpropInputV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConvertToCooTensor.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConvertToListOfSparseCoreCooTensors.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ConvertToSparseCoreCsrWrappedCooTensor.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Copy.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CopyHost.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CopyToMesh.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CopyToMeshGrad.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Cos.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Cosh.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CountUpTo.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CreateSummaryDbWriter.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CreateSummaryFileWriter.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CropAndResize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CropAndResizeGradBoxes.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CropAndResizeGradImage.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Cross.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CrossReplicaSum.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNN.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNBackprop.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNBackpropV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNBackpropV3.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNCanonicalToParams.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNCanonicalToParamsV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNParamsSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNParamsToCanonical.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNParamsToCanonicalV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CudnnRNNV3.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Cumprod.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Cumsum.pbtxt, tensorflow/core/ops/compat/ops_history_v2/CumulativeLogsumexp.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DTensorRestoreV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DTensorSetGlobalTPUArray.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DataFormatDimMap.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DataFormatVecPermute.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DataServiceDataset.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DataServiceDatasetV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DataServiceDatasetV3.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DataServiceDatasetV4.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DatasetCardinality.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DatasetFingerprint.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DatasetFromGraph.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DatasetToGraph.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DatasetToGraphV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DatasetToSingleElement.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DatasetToTFRecord.pbtxt, tensorflow/core/ops/compat/ops_history_v2/Dawsn.pbtxt, tensorflow/core/ops/compat/ops_history_v2/DebugGradientIdentity.pbtxt",tensorflower-gardener,False
"Remove unused translate_tf_dialect.

PiperOrigin-RevId: 633647120",Arturo Schmidt,arturoschmidt@google.com,2024-05-14 18:15:31,"tensorflow/compiler/mlir/BUILD, tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/tests/mlir2graphdef/simple_tf_dialect_op.mlir, tensorflow/compiler/mlir/tensorflow/translate/BUILD, tensorflow/compiler/mlir/tensorflow/translate/translate_tf_dialect_op.cc",rocketas,False
"Add a flag to override the GEMM autotuner with a specified textproto configuration.

This makes it easier to debug issues with Triton, since [persisted autotuning](https://openxla.org/xla/persisted_autotuning) does not offer a workflow that would be efficient enough:

- `--xla_gpu_dump_autotune_results_to=` doesn't work if the autotuner crashes, so we would need to construct the cache manually from the logs; furthermore, the cache only applies to a specific HW, so we can't use it to override the autotuner on a different GPU
- `--xla_gpu_load_autotune_results_from=` reads a file so we need to copy the file into the source tree, and modify the BUILD file to include it into the build; with this new flag, we can just copy the flag from the VLOG without having to fiddle around with any files

PiperOrigin-RevId: 633638219",Goran Flegar,gflegar@google.com,2024-05-14 17:52:12,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/xla.proto",gflegar,False
"[XLA] Account for private stack allocations in HloRematerialization

Buffer assignment allocates a single stack for all asynchronous computations, which persists for the entire duration of the program. We need to account for this by adjusting the memory limit.

PiperOrigin-RevId: 633632062",Vlad Sytchenko,vsytch@google.com,2024-05-14 17:33:13,"third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/hlo_rematerialization.cc, third_party/xla/xla/service/hlo_rematerialization.h, third_party/xla/xla/service/hlo_rematerialization_test.cc",vsytch,False
"Add a typedef to allow users to easily create the correct Factory type to create a TypedKernel.

PiperOrigin-RevId: 633629571",Kyle Lucke,klucke@google.com,2024-05-14 17:25:34,third_party/xla/xla/stream_executor/kernel.h,klucke,False
"Support converting strings to unsigned integer types in `tf.strings.to_number`.

PiperOrigin-RevId: 633628312",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 17:22:16,"tensorflow/core/kernels/string_to_number_op.cc, tensorflow/core/ops/parsing_ops.cc, tensorflow/python/ops/string_ops.py",tensorflower-gardener,False
"Integrate StableHLO at openxla/stablehlo@797bee21

PiperOrigin-RevId: 633621411",Kevin Gleason,gleasonk@google.com,2024-05-14 17:03:21,"tensorflow/compiler/mlir/lite/stablehlo/tests/compose-uniform-quantized-type.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/quantization/common/attrs_and_constraints_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize/quantize_same_scale.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize/quantize_weight_only.mlir, third_party/stablehlo/temporary.patch, third_party/stablehlo/workspace.bzl, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/workspace.bzl, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_base.td, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.td, third_party/xla/xla/mlir_hlo/mhlo/transforms/map_stablehlo_to_hlo_op.h, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-stablehlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/mhlo-quant-legalize-to-int.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/ops.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/stablehlo-legalize-to-hlo.mlir",GleasonK,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633607491",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 16:17:42,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Lift Kernel::Create and TypedKernel::Create methods out into separate factory objects to remove circular dependencies.

Existing Create methods left in place until all uses are eliminated.

PiperOrigin-RevId: 633601919",Kyle Lucke,klucke@google.com,2024-05-14 15:59:27,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_custom_kernel_benchmarks.cc, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_custom_kernel_test.cc, third_party/xla/xla/service/gpu/kernels/topk_custom_kernel_test.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/kernel_thunk.cc, third_party/xla/xla/service/gpu/stream_executor_util.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer_test.cc, third_party/xla/xla/stream_executor/gpu/gpu_kernel_test.cc, third_party/xla/xla/stream_executor/kernel.h, third_party/xla/xla/stream_executor/kernel_factory.h, third_party/xla/xla/stream_executor/typed_kernel_factory.h",klucke,False
"PR #12433: [GPU] Make cuDNN fusion test run on H100.

Imported from GitHub PR https://github.com/openxla/xla/pull/12433

Copybara import of the project:

--
856f1ddb05b0cecf1092aa3547611274b27f0796 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Make cuDNN fusion test run on H100.

Merging this change closes #12433

PiperOrigin-RevId: 633592263",Ilia Sergachev,isergachev@nvidia.com,2024-05-14 15:22:56,third_party/xla/xla/service/gpu/fusions/BUILD,sergachev,False
"[XLA:GPU] Add utility functions to iterate over instructions matching opcode.

PiperOrigin-RevId: 633577273",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-14 14:25:41,"third_party/xla/xla/hlo/utils/BUILD, third_party/xla/xla/hlo/utils/hlo_query.h, third_party/xla/xla/hlo/utils/hlo_query_test.cc",golechwierowicz,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633575662",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 14:18:11,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Avoid FindIndex function by using the inverse permutation.

Let p be a permutation. FindIndex(p, x) should return y where x = p[y].
This is equivalent to p^-1[x] = p^-1[p[y]] = y, so y = p^-1[x].

PiperOrigin-RevId: 633572618",Adrian Kuegel,akuegel@google.com,2024-05-14 14:04:41,"third_party/xla/xla/service/layout_normalization.cc, third_party/xla/xla/service/layout_normalization_test.cc",akuegel,False
"Integrate Triton up to [@4caedc2](https://github.com/openai/triton/commits/4caedc2a51f5c81f7b63212b9bcb76b430102913)

PiperOrigin-RevId: 633565503",Christian Sigg,csigg@google.com,2024-05-14 13:33:36,"third_party/triton/temporary/pipelining.patch, third_party/triton/temporary/series.bzl, third_party/triton/temporary/support_ceil_op.patch, third_party/triton/workspace.bzl, third_party/triton/xla_extensions/env_vars.patch, third_party/triton/xla_extensions/series.bzl, third_party/triton/xla_extensions/sparse_dot_base.patch, third_party/triton/xla_extensions/sparse_dot_fixes_y24w17.patch, third_party/triton/xla_extensions/sparse_dot_nvgpu.patch, third_party/triton/xla_extensions/sparse_dot_passes.patch, third_party/xla/third_party/triton/temporary/pipelining.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/support_ceil_op.patch, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/third_party/triton/xla_extensions/env_vars.patch, third_party/xla/third_party/triton/xla_extensions/series.bzl, third_party/xla/third_party/triton/xla_extensions/sparse_dot_base.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w17.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_nvgpu.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_passes.patch, third_party/xla/xla/service/gpu/ir_emitter_triton_cuda.cc, third_party/xla/xla/service/gpu/tests/sparse_add_layout.mlir",chsigg,False
"Integrate LLVM at llvm/llvm-project@e6d3a4212d20

Updates LLVM usage to match
[e6d3a4212d20](https://github.com/llvm/llvm-project/commit/e6d3a4212d20)

PiperOrigin-RevId: 633561628",Dmitri Gribenko,dmitrig@google.com,2024-05-14 13:16:08,third_party/llvm/workspace.bzl,gribozavr,False
"[XLA:GPU] Introduce `GpuCompiler::GetToolkit` method for subclasses to provide the CUDA or ROCm versions.

Remove all `#if GOOGLE_CUDA` and friends from gpu_compiler.cc

PiperOrigin-RevId: 633548576",Thomas Joerg,tjoerg@google.com,2024-05-14 12:20:31,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/amdgpu_compiler.cc, third_party/xla/xla/service/gpu/amdgpu_compiler.h, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_compiler.h, third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/service/gpu/nvptx_compiler.h, third_party/xla/xla/tests/llvm_compiler_test.cc",thomasjoerg,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633547952",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 12:17:35,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@79a6a7e28fff

Updates LLVM usage to match
[79a6a7e28fff](https://github.com/llvm/llvm-project/commit/79a6a7e28fff)

PiperOrigin-RevId: 633538634",Dmitri Gribenko,dmitrig@google.com,2024-05-14 11:36:11,"third_party/llvm/workspace.bzl, third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch",gribozavr,False
"PR #12434: [GPU] Fix OSS compilation problems in a previously disabled test.

Imported from GitHub PR https://github.com/openxla/xla/pull/12434

Copybara import of the project:

--
723c9bb29adfcc33c015b74f90ce8024c2f79255 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix OSS compilation problems in a previously disabled test.

Merging this change closes #12434

PiperOrigin-RevId: 633533757",Ilia Sergachev,isergachev@nvidia.com,2024-05-14 11:13:51,third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc,sergachev,False
"Canonicalize affine expression trees in simplifier.

I don't know where the current non-determinism comes from, but this should
fix it.

The particular order is not important, but it being canonical is. These
expressions are used for codegen in the new emitters, so the simplification
must be deterministic.

PiperOrigin-RevId: 633531399",Johannes Reifferscheid,jreiffers@google.com,2024-05-14 11:04:35,"third_party/xla/xla/service/gpu/fusions/concatenate_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/concatenate_test.cc, third_party/xla/xla/service/gpu/fusions/input_slices_test.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/loop_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/scatter_test.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/transpose_test.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map_test.cc, third_party/xla/xla/service/gpu/model/indexing_test_utils.cc",jreiffers,False
"Move `BuildAttributesMap()` to a common place

So that both CPU and GPU code can reuse the same implementation. At the moment each uses its own version that are identical.

PiperOrigin-RevId: 633522046",Leo Heinsaar,heinsaar@google.com,2024-05-14 10:30:39,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/attribute_map.cc, third_party/xla/xla/ffi/attribute_map.h, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.h, third_party/xla/xla/tests/BUILD",heinsaar,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633517388",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 10:17:43,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[Triton] Limit visibility of original bit-width computation during computing mma and dot_operand layouts to not propagate through predicates. Predicates are not supported for these layouts during lowering from TritonGPU to LLVM and cause crashes.

PiperOrigin-RevId: 633513652",Mohammed Anany,manany@google.com,2024-05-14 10:08:23,"third_party/triton/temporary/mma_limit_pred.patch, third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/mma_limit_pred.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",Moerafaat,False
"Fix sparse dot metadata loader

Metadata loader was using incorrect warp assignment, which resulted in incorrect addresses with num_warps>4. This was previously missed, as the autotuner rarely selected such configs.

PiperOrigin-RevId: 633513110",Sergey Kozub,sergeykozub@google.com,2024-05-14 10:07:12,"third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch",sergeykozub,False
"Fix tile size for matmuls with 8-bit operands in autotuner

The result of `GetExhaustiveTritonConfigs` is cached in the autotuner class instance, so should not depend on the input dot instruction. Therefore, removing the `has_8_bit_operand` parameter from the method signature.
Instead, adjust the `block_k` attribute in the config normalization phase.

Additionally, treat 8-bit floating point types in the same manner as integer types.

PiperOrigin-RevId: 633506809",Sergey Kozub,sergeykozub@google.com,2024-05-14 09:52:44,"third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.h",sergeykozub,False
"Update GraphDef version to 1862.

PiperOrigin-RevId: 633487039",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 09:02:34,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-14

PiperOrigin-RevId: 633487032",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 09:02:33,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"[XLA:GPU] Refactor inputPrecision condition for Triton to use HloAnyOf without requiring adaptors

PiperOrigin-RevId: 633484897",Mohammed Anany,manany@google.com,2024-05-14 08:53:21,third_party/xla/xla/service/gpu/ir_emitter_triton.cc,Moerafaat,False
"PR #11563: [NVIDIA GPU] Improve GPU collective matmul to support all-gather having multiple users

Imported from GitHub PR https://github.com/openxla/xla/pull/11563

We have identified another optimization opportunity for gpt-3 using collective matmul, in the backward pass, the all-gather has multiple dot users but current spmd will duplicate multiple collective matmul loops. We'd like this transformation:
before:
```
  //                       input
  //                       /    |
  //                      /     |
  //                     AG    windowed loop
  //                     /
  //                    /
  //                   dot

```
after:
```
  //                       input
  //                       |
  //                       |
  //                     windowed loop
  //                       |
  //                       |
  //                      dot
```
This is advantageous since the chained dot can fully utilize all the resource on the GPU while comm is hidden by the first collective matmul loop.

We introduced an option to turn off CM loop duplication in SPMD and rewrite the graph to desired pattern in the gpu_windowed_einsum_handler pass.
Copybara import of the project:

--
986ac94ab44d31f6d11ec6f135f6cfb2e5636d80 by TJ <tjx@nvidia.com>:

Moved most of changes to gpu pass

--
44e81df91c235cac635f334c89d1d8a117ac6511 by TJ <tjx@nvidia.com>:

Added e2e test for windowed einsum
Minimized unit test hlo

--
8fc24a479de7515f532f36de8ffbcce49516c154 by TJ <tjx@nvidia.com>:

Added explanations for spmd tests and dot_handler to skip multiple
consumers

--
142d84d54db2b6291484443e43913d86c44a485c by TJ <tjx@nvidia.com>:

move windowed einsum test to stateful_rng_spmd_partitioner_test

--
8b9fc43746136b40a814d93bf8086a687490fd7f by TJ <tjx@nvidia.com>:

Changed e2e test back to include reducescatter

Merging this change closes #11563

PiperOrigin-RevId: 633483864",TJ Xu,tjx@nvidia.com,2024-05-14 08:48:26,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_windowed_einsum_handler.cc, third_party/xla/xla/service/gpu/gpu_windowed_einsum_handler.h, third_party/xla/xla/service/gpu/gpu_windowed_einsum_handler_test.cc, third_party/xla/xla/service/spmd/dot_handler.cc, third_party/xla/xla/service/spmd/spmd_partitioner.h, third_party/xla/xla/service/spmd/stateful_rng_spmd_partitioner.h, third_party/xla/xla/service/spmd/stateful_rng_spmd_partitioner_test.cc, third_party/xla/xla/tests/collective_ops_test_e2e.cc",Tixxx,False
"Automated Code Change

PiperOrigin-RevId: 633477369",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 08:19:17,"tensorflow/lite/delegates/gpu/common/data_type_test.cc, tensorflow/lite/delegates/gpu/common/flops_util.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633477018",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 08:17:37,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Improve documentation of mlir ops.

PiperOrigin-RevId: 633462768",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 07:11:15,"tensorflow/compiler/mlir/tensorflow/ir/host_runtime/tfrt_ops.td, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_mlrt_ops.td",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633451656",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 06:19:02,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add AlgebraicSimplifier pass directly in front of HloConstantFolding.

We have cases with DynamicSlice(Broadcast) which can be simplified away which
would otherwise be constant folded. The HloEvaluator is really slow for
DynamicSlice and Slice, as it will evalute the whole first operand, so if we
can simplify it away, it will help.

PiperOrigin-RevId: 633445573",Adrian Kuegel,akuegel@google.com,2024-05-14 05:48:43,third_party/xla/xla/service/gpu/gpu_compiler.cc,akuegel,False
"Support reusing calibration data if exists

Calibration is the most time-consuming step in quantization. This cl will help avoiding it in case of users already quantized it before and the changes in configuration if have doesn't affect the calibration results.

PiperOrigin-RevId: 633435225",Thai Nguyen,thaink@google.com,2024-05-14 04:54:14,"tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/component.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/component.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/statistics.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/statistics.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/insert_calibration_statistics_saver.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.td, tensorflow/compiler/mlir/quantization/stablehlo/python/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test_base.py, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/insert_calibration_statistics_saver_with_skipping.mlir, tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.py",thaink,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633428831",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 04:19:27,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"gpu_delegate: Update ADD / MUL broadcast support

4D + 3D works with broadcast when 4D batch is 1.

PiperOrigin-RevId: 633426993",Terry Heo,terryheo@google.com,2024-05-14 04:09:52,"tensorflow/lite/tools/versioning/gpu_compatibility.cc, tensorflow/lite/tools/versioning/gpu_compatibility_test.cc",terryheo,False
"Integrate LLVM at llvm/llvm-project@e6b2197a89f5

Updates LLVM usage to match
[e6b2197a89f5](https://github.com/llvm/llvm-project/commit/e6b2197a89f5)

PiperOrigin-RevId: 633423574",Fangrui Song,maskray@google.com,2024-05-14 03:52:17,third_party/llvm/workspace.bzl,MaskRay,False
"Improve test coverage of fallback_state.cc

PiperOrigin-RevId: 633415502",Kuangyuan Chen,chky@google.com,2024-05-14 03:12:26,"tensorflow/core/tfrt/fallback/BUILD, tensorflow/core/tfrt/fallback/fallback_state_test.cc",cky9301,False
"Add some internal change.

PiperOrigin-RevId: 633410091",Siqiao Wu,siqiaowu@google.com,2024-05-14 02:53:26,"tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_executable_registry_test.cc",SiqiaoWu1993,False
"Mark `gpu_sparse_dot_test` as `no_oss` due to missing dep

PiperOrigin-RevId: 633408111",David Dunleavy,ddunleavy@google.com,2024-05-14 02:39:55,third_party/xla/xla/service/gpu/tests/BUILD,ddunl,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633404455",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 02:17:41,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[PJRT:IFRT] Remove overload of PjRtLoadedExecutable::Create() that takes an unique_ptr argument.

Cleanup only, NFC intended.

PiperOrigin-RevId: 633393546",Peter Hawkins,phawkins@google.com,2024-05-14 01:19:47,"third_party/xla/xla/python/pjrt_ifrt/pjrt_compiler.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.h",hawkinsp,False
"Move Trace CommandBuffer creation into TraceCommandBufferFactory to remove circular dependencies.

PiperOrigin-RevId: 633380264",Kyle Lucke,klucke@google.com,2024-05-14 00:23:26,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/command_buffer.h, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer_test.cc, third_party/xla/xla/stream_executor/trace_command_buffer_factory.cc, third_party/xla/xla/stream_executor/trace_command_buffer_factory.h",klucke,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633379311",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-14 00:18:54,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Migrate coord agent and service to use absl  mutex/condvar libraries directly + some clang fixes.

PiperOrigin-RevId: 633373388",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 23:54:33,"third_party/xla/xla/tsl/distributed_runtime/coordination/BUILD, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.h, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.h",tensorflower-gardener,False
"Add some internal change.

PiperOrigin-RevId: 633369641",Siqiao Wu,siqiaowu@google.com,2024-05-13 23:38:50,"tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_restore_tensor_registry_test.cc",SiqiaoWu1993,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/runtime/convolution_thunk.cc

PiperOrigin-RevId: 633365188",Kuy Mainwaring,kuym@google.com,2024-05-13 23:21:02,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/convolution_thunk.cc",kuym,False
"Use `--nobuild_tests_only` even on ARM builds of XLA

PiperOrigin-RevId: 633363011",David Dunleavy,ddunleavy@google.com,2024-05-13 23:12:57,third_party/xla/.kokoro/linux/build.sh,ddunl,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc

PiperOrigin-RevId: 633362802",Kuy Mainwaring,kuym@google.com,2024-05-13 23:12:02,"third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.h",kuym,False
"#tf-buildcop Fix test timeout.

Error:
```
//tensorflow/core/data/service/snapshot:snapshot_stream_writer_checkpoint_test TIMEOUT in 3 out of 3 in 96.0s
  Stats over 3 runs: max = 96.0s, min = 66.2s, avg = 79.4s, dev = 12.4s
  tensorflow/core/data/service/snapshot/snapshot_stream_writer_checkpoint_test/test.log
  tensorflow/core/data/service/snapshot/snapshot_stream_writer_checkpoint_test/test_attempts/attempt_1.log
  tensorflow/core/data/service/snapshot/snapshot_stream_writer_checkpoint_test/test_attempts/attempt_2.log
```
PiperOrigin-RevId: 633362798",Yang Chen,yangchen@google.com,2024-05-13 23:12:02,tensorflow/core/data/service/snapshot/BUILD,yangustc07,False
"Stop generating corert const ops in tf_to_tfrt

PiperOrigin-RevId: 633361967",Kuangyuan Chen,chky@google.com,2024-05-13 23:08:46,"tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/const_tensor.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/control_flow.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/decompose_resource_op.mlir, tensorflow/compiler/mlir/tfrt/transforms/tf_to_tfrt.cc",cky9301,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/copy.h

PiperOrigin-RevId: 633361839",Kuy Mainwaring,kuym@google.com,2024-05-13 23:08:23,third_party/xla/xla/service/gpu/fusions/copy.h,kuym,False
"[IFRT] Rename XlaProgram to HloProgram, move it from PJRT-IFRT to IFRT.

HLO programs represented in MLIR are independent of PJRT or XLA as a compiler, so they don't belong in PJRT-IFRT.

Also rename the Python binding API from get_xla_program to get_hlo_program, but this API is not used yet.

Cleanup; no functional changes intended.

PiperOrigin-RevId: 633356170",Peter Hawkins,phawkins@google.com,2024-05-13 22:48:45,"tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/ifrt/hlo/BUILD, third_party/xla/xla/python/ifrt/hlo/hlo_program.cc, third_party/xla/xla/python/ifrt/hlo/hlo_program.h, third_party/xla/xla/python/ifrt/hlo/hlo_program_serdes.cc, third_party/xla/xla/python/ifrt/hlo/hlo_program_serdes_test.cc, third_party/xla/xla/python/ifrt/ir/tests/BUILD, third_party/xla/xla/python/ifrt/ir/tests/executable_impl_test_lib.cc, third_party/xla/xla/python/ifrt_proxy/common/BUILD, third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/pjrt_compiler.cc, third_party/xla/xla/python/pjrt_ifrt/xla_compiler.cc, third_party/xla/xla/python/pjrt_ifrt/xla_compiler.h, third_party/xla/xla/python/pjrt_ifrt/xla_executable_impl_test_lib.cc, third_party/xla/xla/python/py_client.cc, third_party/xla/xla/python/py_program.cc, third_party/xla/xla/python/xla_client_test.py, third_party/xla/xla/python/xla_extension/ifrt_programs.pyi",hawkinsp,False
"Integrate LLVM at llvm/llvm-project@a6d7828f4c50

Updates LLVM usage to match
[a6d7828f4c50](https://github.com/llvm/llvm-project/commit/a6d7828f4c50)

PiperOrigin-RevId: 633354390",Fangrui Song,maskray@google.com,2024-05-13 22:41:41,third_party/llvm/workspace.bzl,MaskRay,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633349564",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 22:25:03,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Move #include <stddef.h> outside of ifdef.

PiperOrigin-RevId: 633342149",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 21:59:52,"tensorflow/lite/kernels/internal/optimized/integer_ops/depthwise_conv_3x3_filter.h, tensorflow/lite/kernels/internal/optimized/integer_ops/depthwise_conv_hybrid_3x3_filter.h",tensorflower-gardener,False
"Remove EmitErrorReporter class, since it isn't used.

PiperOrigin-RevId: 633338523",Fergus Henderson,fergus@google.com,2024-05-13 21:46:48,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/emit_error_reporter.cc, tensorflow/compiler/mlir/lite/emit_error_reporter.h",fergushenderson,False
"[xla] NFC: Delete deprecated flags and remains of xla runtime

PiperOrigin-RevId: 633338202",Eugene Zhulenev,ezhulenev@google.com,2024-05-13 21:45:39,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/gpu_executable.h, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/xla.proto",ezhulenev,False
"Add TFExecutorGraphPruningPass to TF dialect to executor export pipeline

This is to prune out unused ops/nodes in the graph. This doesn't affect correctness but in some cases will drastically reduce memory/network usage and improve performance depending on the number and type of dead nodes that are pruned.

PiperOrigin-RevId: 633337115",Swachhand Lokhande,swachhand@google.com,2024-05-13 21:41:53,"tensorflow/compiler/mlir/tf2xla/api/v2/BUILD, tensorflow/compiler/mlir/tf2xla/api/v2/testdata/func_with_dead_ops.mlir, tensorflow/compiler/mlir/tf2xla/api/v2/tf_dialect_to_executor.cc, tensorflow/compiler/mlir/tf2xla/api/v2/tf_dialect_to_executor_test.cc",swachhandl,False
"Enable JAX memory tests for GPUs and CPUs

PjRt GPU and CPU has recently gotten memory space support with just one memory space per device, so enabling relevant JAX memory tests. Most tests cannot be enabled yet because they rely on `unpinned_host`, so only enabling `ShardingMemoriesTest` for now.

PiperOrigin-RevId: 633335638",Junwhan Ahn,junwhan@google.com,2024-05-13 21:36:43,third_party/xla/xla/python/xla_client.py,junwhanahn,False
"Fix a potential memory corruption in PJRT GPU client. Make sure the staging buffer outlives the memcpys to and from the staging buffer.

PiperOrigin-RevId: 633329702",Yifan Jiang,yifanjiang@google.com,2024-05-13 21:18:03,third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc,yifjiang,False
"No public description

PiperOrigin-RevId: 633328239",Sania Nagpal,sanianagpal@google.com,2024-05-13 21:13:17,"tensorflow/core/tfrt/runtime/BUILD, tensorflow/core/tfrt/runtime/stream_test.cc",sanianagpal,False
"Update comment to reflect placement

PiperOrigin-RevId: 633322446",Mason Chang,masonchang@google.com,2024-05-13 20:55:49,tensorflow/core/common_runtime/placer.cc,changm,False
"[XLA:SPACE_TO_BATCH] correctly propagate on dot

PiperOrigin-RevId: 633322160",Blake Hechtman,blakehechtman@google.com,2024-05-13 20:55:14,"third_party/xla/xla/service/space_to_batch_converter.cc, third_party/xla/xla/service/space_to_batch_converter_test.cc",blakehechtman,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633320442",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 20:49:17,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Allow ifrt.Call of functions that consists only of ifrt.Reshard ops.

PiperOrigin-RevId: 633319317",Ionel Gog,icgog@google.com,2024-05-13 20:45:54,"third_party/xla/xla/python/ifrt/ir/constants.h, third_party/xla/xla/python/ifrt/ir/ifrt_interfaces.cc",ICGog,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/runtime/address_computation_thunk.h

PiperOrigin-RevId: 633318572",Kuy Mainwaring,kuym@google.com,2024-05-13 20:42:45,third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h,kuym,False
"[xla:cpu] Fix msan warnings from arguments coming from jit compiled function

PiperOrigin-RevId: 633317729",Eugene Zhulenev,ezhulenev@google.com,2024-05-13 20:39:34,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.cc",ezhulenev,False
"Eliminate CommandBuffer::Create method in favor of the CreateCommandBuffer on StreamExecutorInterface.  This is a step of reducing circular dependencies between command_buffer.h and stream_executor_interface.h.

PiperOrigin-RevId: 633314618",Kyle Lucke,klucke@google.com,2024-05-13 20:29:47,"third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk.cc, third_party/xla/xla/stream_executor/command_buffer.cc, third_party/xla/xla/stream_executor/command_buffer.h, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer_test.cc",klucke,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/triton.cc

PiperOrigin-RevId: 633311473",Kuy Mainwaring,kuym@google.com,2024-05-13 20:19:45,third_party/xla/xla/service/gpu/fusions/triton.cc,kuym,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/mlir/convert_xla_gpu_pure_call_ops.cc

PiperOrigin-RevId: 633311058",Kuy Mainwaring,kuym@google.com,2024-05-13 20:18:39,third_party/xla/xla/service/gpu/fusions/mlir/convert_xla_gpu_pure_call_ops.cc,kuym,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/mlir/lower_tensors.cc

PiperOrigin-RevId: 633310993",Kuy Mainwaring,kuym@google.com,2024-05-13 20:18:29,third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc,kuym,False
"PR #12049: Detect when we are running on an NVIDIA simulator and check that we pull the device description from gpu_specs.

Imported from GitHub PR https://github.com/openxla/xla/pull/12049

This helps when testing the compiler on new hardware platforms. The simulator may have nonsensical values for a few fields in the device description (such as device_memory_size == -1), so we want to use a hard-coded device description that contains the correct values.
Copybara import of the project:

--
1a488e45b3a7d0f7729fde9c28915c40188d17b3 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

On Nvidia simulation, fail if target config hasn't been supplied using --xla_gpu_target_config_filename.

Merging this change closes #12049

PiperOrigin-RevId: 633310642",Dimitris Vardoulakis,dvardoulakis@nvidia.com,2024-05-13 20:17:38,third_party/xla/xla/service/gpu/gpu_compiler.cc,dimvar,False
"Migrate coord utils to use absl libraries directly + some clang fixes.

PiperOrigin-RevId: 633310000",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 20:15:51,"third_party/xla/xla/tsl/distributed_runtime/coordination/BUILD, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_error_util.h, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_rpc_handler.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_rpc_handler.h",tensorflower-gardener,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/tiling_util.h

PiperOrigin-RevId: 633308984",Kuy Mainwaring,kuym@google.com,2024-05-13 20:12:44,third_party/xla/xla/service/gpu/fusions/tiling_util.cc,kuym,False
"Integrate LLVM at llvm/llvm-project@1066eb554770

Updates LLVM usage to match
[1066eb554770](https://github.com/llvm/llvm-project/commit/1066eb554770)

PiperOrigin-RevId: 633306010",Fangrui Song,maskray@google.com,2024-05-13 20:03:00,third_party/llvm/workspace.bzl,MaskRay,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/transpose_test.cc

PiperOrigin-RevId: 633303182",Kuy Mainwaring,kuym@google.com,2024-05-13 19:53:59,third_party/xla/xla/service/gpu/fusions/transpose_test.cc,kuym,False
"Propagate status from sparse reduction op to avoid crash.

Fixes #65865

PiperOrigin-RevId: 633296435",Antonio Sanchez,cantonios@google.com,2024-05-13 19:29:26,"tensorflow/core/kernels/BUILD, tensorflow/core/kernels/sparse_reduce_op.cc",cantonios,False
"Fix C++ dtor bypass virtual call dispatch lint.

PiperOrigin-RevId: 633295761",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 19:26:49,third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc,tensorflower-gardener,False
"Keep identity ops that have the same input/output device assignment on the same devices

PiperOrigin-RevId: 633290991",Mason Chang,masonchang@google.com,2024-05-13 19:11:09,"tensorflow/core/common_runtime/placer.cc, tensorflow/core/common_runtime/placer_test.cc",changm,False
"Fix populate of supported_subgroup_sizes

PiperOrigin-RevId: 633290357",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 19:09:05,tensorflow/lite/delegates/gpu/cl/cl_device.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633284964",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 18:53:10,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"manual dims must be excluded when computing the new tile assignment, or
num_new_tiles will always be > NumTiles() + 1 and sharding propagation will
infinitely reassign the same partial manual shardings.

PiperOrigin-RevId: 633282263",Parker Schuh,parkers@google.com,2024-05-13 18:44:31,"third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util_test.cc",pschuh,False
"Add fields to GpuTopology for multi-host support.

PiperOrigin-RevId: 633280790",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 18:39:45,"third_party/xla/xla/pjrt/gpu/gpu_topology.cc, third_party/xla/xla/pjrt/gpu/gpu_topology.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",tensorflower-gardener,False
"Prevent heartbeat cancelled errors at shutdown.

Clients disconnect before the service shuts down. However, there is a short time window where the clients send out heartbeat RPCs right before shutting down, which might reach the server after it shuts down.

PiperOrigin-RevId: 633273384",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 18:18:18,third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc,tensorflower-gardener,False
"Implement basic memory space support for PjRt CPU

This CL implements minimal memory support for PjRt CPU so that memory space APIs can be used consistently across device types. Like GPU, each CPU device for now has just one memory space kind (`device`) and all memory space flavors of transfer APIs redirect the calls to the corresponding versions that take a device instead, assuming that there's only one device to which each memory space is attached.

PiperOrigin-RevId: 633272982",Junwhan Ahn,junwhan@google.com,2024-05-13 18:17:14,"third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/cpu/cpu_client_test.cc",junwhanahn,False
"Add an option (set to false by default, for now) and support for adding strategies for dot operators that trigger windowed einsum.

PiperOrigin-RevId: 633271761",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 18:13:32,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_dot_handler.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_option.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_option.h",tensorflower-gardener,False
"[XLA] [NFC] Remove unused var

PiperOrigin-RevId: 633265210",George Karpenkov,cheshire@google.com,2024-05-13 17:55:23,third_party/xla/xla/service/gpu/gpu_compiler.cc,cheshire,False
"Teach `xla_test` about the interpreter backend, fail on unknown backends

PiperOrigin-RevId: 633263903",David Dunleavy,ddunleavy@google.com,2024-05-13 17:51:53,third_party/xla/xla/tests/build_defs.bzl,ddunl,False
"Remove unused constant from stream_executor_pimpl.h.

PiperOrigin-RevId: 633263139",Kyle Lucke,klucke@google.com,2024-05-13 17:49:31,third_party/xla/xla/stream_executor/stream_executor_pimpl.h,klucke,False
"[XLA] [NFC] Factor out MaybeOwning into a separate class.

PiperOrigin-RevId: 633260396",George Karpenkov,cheshire@google.com,2024-05-13 17:41:29,"third_party/xla/xla/BUILD, third_party/xla/xla/literal.cc, third_party/xla/xla/literal.h, third_party/xla/xla/maybe_owning.h, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/util_test.cc",cheshire,False
"[pjrt][xla:ffi] Add XLA FFI execution context to PjRt ExecuteContext

- Extend PjRt ExecuteContext base class to always include XLA FFI execution context so that end-users can pass data to FFI handlers.

- Add an end-to-end test to SE GPU PjrtClient.

PJRT C API changes will be in the followup PRs.

PiperOrigin-RevId: 633255392",Eugene Zhulenev,ezhulenev@google.com,2024-05-13 17:27:27,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc, third_party/xla/xla/pjrt/pjrt_executable.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.h",ezhulenev,False
"Fix typo in TFLite conversion doc.

PiperOrigin-RevId: 633250884",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 17:14:07,tensorflow/lite/g3doc/models/convert/index.md,tensorflower-gardener,False
"Teach `xla_test` about specific GPU backends

Inspired by https://github.com/openxla/xla/pull/11753

PiperOrigin-RevId: 633247596",David Dunleavy,ddunleavy@google.com,2024-05-13 17:05:25,"third_party/xla/.kokoro/linux/build.sh, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/tests/build_defs.bzl, third_party/xla/xla/tools/hlo_opt/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/BUILD",ddunl,False
"[xla:ffi] Unify external and internal user data registration and use i64 type ids

- treat external and internal user data uniformly as an opaque pointer + optional deleter
- use the same i64 TypeId for internal and external types to avoid expensive string comparison on a hot path

PiperOrigin-RevId: 633234788",Eugene Zhulenev,ezhulenev@google.com,2024-05-13 16:23:16,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/execution_context.cc, third_party/xla/xla/ffi/execution_context.h, third_party/xla/xla/ffi/execution_context_test.cc, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_test.cc, third_party/xla/xla/service/gpu/custom_call_test.cc",ezhulenev,False
"Remove StreamExecutorInterface from all the non-static CommandBuffer methods.

Each CommandBuffer class is uniquely tied to a specific StreamExecutorInterface (parent_), which is tracked as member data.

PiperOrigin-RevId: 633233717",Kyle Lucke,klucke@google.com,2024-05-13 16:19:44,"third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/stream_executor/command_buffer.h, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer.cc, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer.h, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer_test.cc",klucke,False
"Don't fail diagnostic if the severity isn't error.

If a pass emits a warning, then the status will be set to `UnknownError` causing pipelines to fail. But we shouldn't if a pass/pattern just emits a warning.

PiperOrigin-RevId: 633233147",Bart Chrzaszcz,bartchr@google.com,2024-05-13 16:17:46,third_party/xla/third_party/tsl/tsl/framework/mlir/status_scoped_diagnostic_handler.cc,bartchr808,False
"Remvoe unused, unimplemented methods on XlaInterpreterExecutor.

PiperOrigin-RevId: 633233078",Kyle Lucke,klucke@google.com,2024-05-13 16:17:33,third_party/xla/xla/backends/interpreter/executor.h,klucke,False
"[XLA:GPU] Rename LoopDoubleBufferTransformer to DoubleBufferLoopUnrolling.

PiperOrigin-RevId: 633228767",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-13 16:02:53,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/double_buffer_loop_unrolling.cc, third_party/xla/xla/service/gpu/double_buffer_loop_unrolling.h, third_party/xla/xla/service/gpu/double_buffer_loop_unrolling_test.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc",golechwierowicz,False
"Reverts 28bf7478c8481648dc3900e0ab52a5e0887f5145

PiperOrigin-RevId: 633223628",Vladyslav Tsilytskyi,tsilytskyi@google.com,2024-05-13 15:44:40,"third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_execution_engine.cc, third_party/xla/xla/stream_executor/host/host_execution_engine.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/host/host_kernel.cc, third_party/xla/xla/stream_executor/host/host_kernel.h, third_party/xla/xla/stream_executor/host/host_kernel_test.cc",tvladyslav,False
"PR #12228: [GPU] Fix hang with cudnn layer norm by moving build phase to Initialize()

Imported from GitHub PR https://github.com/openxla/xla/pull/12228

The first time that a NormThunk is executed, it will build a cudnn execution plan. This build step can hang if a NCCL collective is running at the same time. To fix this, I've moved the build step to take place during thunk initialization. We only observe this hang when using cudnn 9.

Here's a backtrace from the hang that will be fixed:
```
Thread 585 (Thread 0x7fb9391ff640 (LWP 41364) ""main.py""):
#0  0x00007fd3d17cffd9 in ?? () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007fd3d17da24f in pthread_rwlock_wrlock () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x00007fd070967dfe in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#3  0x00007fd0709c928a in ?? () from /lib/x86_64-linux-gnu/libcuda.so.1
#4  0x00007f1970d76102 in ?? () from /lib/x86_64-linux-gnu/libcudnn_engines_precompiled.so.9.1.0
#5  0x00007f1970f2c999 in ?? () from /lib/x86_64-linux-gnu/libcudnn_engines_precompiled.so.9.1.0
#6  0x00007f1970a7d4ab in ?? () from /lib/x86_64-linux-gnu/libcudnn_engines_precompiled.so.9.1.0
#7  0x00007f1970d0a9cb in ?? () from /lib/x86_64-linux-gnu/libcudnn_engines_precompiled.so.9.1.0
#8  0x00007fce60b2a98c in cudnn::backend::ExecutionPlan::finalize_internal() () from /lib/x86_64-linux-gnu/libcudnn_graph.so.9.1.0
#9  0x00007fce60aefbb1 in cudnn::backend::Descriptor::finalize() () from /lib/x86_64-linux-gnu/libcudnn_graph.so.9.1.0
#10 0x00007fce60b15bec in cudnnBackendFinalize () from /lib/x86_64-linux-gnu/libcudnn_graph.so.9.1.0
#11 0x00007fd2521b8f39 in cudnn_frontend::ExecutionPlanBuilder_v8::build() () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
#12 0x00007fd2521734ba in stream_executor::gpu::(anonymous namespace)::GetExecPlanFromHeuristics(cudnn_frontend::OperationGraph_v8&&, stream_executor::gpu::(anonymous namespace)::CudnnHandle const&, bool) () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
#13 0x00007fd25216ff9b in stream_executor::gpu::CudnnSupport::NormRunnerFromDesc(stream_executor::Stream*, stream_executor::dnn::AlgorithmDesc const&, stream_executor::dnn::NormKind, double, stream_executor::dnn::TensorDescriptor const&, stream_executor::dnn::TensorDescriptor const&, stream_executor::dnn::TensorDescriptor const&, std::optional<stream_executor::dnn::TensorDescriptor>, std::optional<stream_executor::dnn::TensorDescriptor>, std::optional<stream_executor::dnn::TensorDescriptor>, std::optional<stream_executor::dnn::TensorDescriptor>, std::optional<stream_executor::dnn::TensorDescriptor>, std::optional<stream_executor::dnn::TensorDescriptor>) () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
#14 0x00007fd24e36b88b in stream_executor::dnn::NormOp::RunnerFromAlgorithmDesc(stream_executor::dnn::AlgorithmDesc const&, stream_executor::dnn::NormOp::Config, stream_executor::Stream*) () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
#15 0x00007fd24e36ae37 in stream_executor::dnn::LazyOpRunner<stream_executor::dnn::NormOp>::GetOrCreateRunner(stream_executor::dnn::NormOp::Config, stream_executor::Stream*)::{lambda()#1}::operator()() const () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
#16 0x00007fd24e36adbc in void absl::lts_20230802::base_internal::CallOnceImpl<stream_executor::dnn::LazyOpRunner<stream_executor::dnn::NormOp>::GetOrCreateRunner(stream_executor::dnn::NormOp::Config, stream_executor::Stream*)::{lambda()#1}>(std::atomic<unsigned int>*, absl::lts_20230802::base_internal::SchedulingMode, stream_executor::dnn::LazyOpRunner<stream_executor::dnn::NormOp>::GetOrCreateRunner(stream_executor::dnn::NormOp::Config, stream_executor::Stream*)::{lambda()#1}&&) () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
#17 0x00007fd24e36a9bd in stream_executor::dnn::LazyOpRunner<stream_executor::dnn::NormOp>::GetOrCreateRunner(stream_executor::dnn::NormOp::Config, stream_executor::Stream*) () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
#18 0x00007fd24e369d29 in xla::gpu::RunGpuNorm(xla::gpu::GpuNormConfig const&, stream_executor::DeviceMemoryBase const&, stream_executor::DeviceMemoryBase const&, stream_executor::DeviceMemoryBase const&, std::optional<stream_executor::DeviceMemoryBase>, std::optional<stream_executor::DeviceMemoryBase>, std::optional<stream_executor::DeviceMemoryBase>, std::optional<stream_executor::DeviceMemoryBase>, std::optional<stream_executor::DeviceMemoryBase>, std::optional<stream_executor::DeviceMemoryBase>, stream_executor::DeviceMemoryBase const&, stream_executor::Stream*, xla::gpu::RunNormOptions) () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
#19 0x00007fd24e368be6 in xla::gpu::NormThunk::ExecuteOnStream(xla::gpu::Thunk::ExecuteParams const&) () from /usr/local/lib/python3.10/dist-packages/jaxlib/xla_extension.so
```
Copybara import of the project:

--
f53533087ba1ddcf65ad7cc6268ee89de4690d15 by Trevor Morris <tmorris@nvidia.com>:

Fix hang with cudnn layer norm by moving cudnn init to Initialize()

Merging this change closes #12228

PiperOrigin-RevId: 633220207",Trevor Morris,tmorris@nvidia.com,2024-05-13 15:31:43,"third_party/xla/xla/service/gpu/gpu_norm_runner.cc, third_party/xla/xla/service/gpu/gpu_norm_runner.h, third_party/xla/xla/service/gpu/runtime/norm_thunk.cc, third_party/xla/xla/service/gpu/runtime/norm_thunk.h",trevor-m,False
"PR #12255: [GPU] Fix FMHA hangs by moving compilation to thunk initialization.

Imported from GitHub PR https://github.com/openxla/xla/pull/12255

Applies the same fix as in https://github.com/openxla/xla/pull/12228 to FMHA.
Copybara import of the project:

--
70a42828f86711a0e83a2eb37ee52833e1768187 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix FMHA hangs by moving compilation to thunk initialization.

Merging this change closes #12255

PiperOrigin-RevId: 633217196",Ilia Sergachev,isergachev@nvidia.com,2024-05-13 15:20:14,"third_party/xla/xla/service/gpu/gpu_fused_mha_runner.cc, third_party/xla/xla/service/gpu/gpu_fused_mha_runner.h, third_party/xla/xla/service/gpu/runtime/fused_mha_thunk.cc, third_party/xla/xla/service/gpu/runtime/fused_mha_thunk.h",sergachev,False
"Reshape multi-dimensional constants to 1d.

The LLVM lowering doesn't support arbitrary shapes.

PiperOrigin-RevId: 633203497",Johannes Reifferscheid,jreiffers@google.com,2024-05-13 14:30:48,"third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_tensors.mlir",jreiffers,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633199826",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 14:17:38,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU] Add flag for fully unrolling while loops

PiperOrigin-RevId: 633196820",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-13 14:05:18,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/xla.proto",golechwierowicz,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633175341",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 12:25:26,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Do not deinitialize XNNPack in `TfLiteXNNPackDelegateWeightsCacheDelete`.

PiperOrigin-RevId: 633174598",Quentin Khan,qkhan@google.com,2024-05-13 12:22:08,tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc,qukhan,False
"Enable VLOGging of pass pipelines in mlir_fusion_emitter.

PiperOrigin-RevId: 633174085",Johannes Reifferscheid,jreiffers@google.com,2024-05-13 12:19:07,third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc,jreiffers,False
"Fix weight cache test typo in XNNPack delegate.

PiperOrigin-RevId: 633168188",Quentin Khan,qkhan@google.com,2024-05-13 11:51:36,tensorflow/lite/delegates/xnnpack/weight_cache_test.cc,qukhan,False
"Disable cache invalidation logic for mlir emitters.

We have logic to estimate the impact of certain ops on IR size. This problem is
fixed with the MLIR emitters, so we don't need it for them.

PiperOrigin-RevId: 633160564",Adrian Kuegel,akuegel@google.com,2024-05-13 11:11:08,third_party/xla/xla/service/gpu/model/gpu_hlo_cost_analysis.cc,akuegel,False
"Reduce input sizes in ReductionTest.

The interpreter is very slow for some of these (up to ~45 seconds
in unoptimized builds). With this change, runtime goes down to at
most ~1 second per test case. At this point, sharding is no longer
helpful (since the fixed setup cost dominates), so we can disable
it.

PiperOrigin-RevId: 633158930",Johannes Reifferscheid,jreiffers@google.com,2024-05-13 11:03:57,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",jreiffers,False
"When no weight cache is provided to XNNPack, create one to share packed weights between operations.

PiperOrigin-RevId: 633158328",Quentin Khan,qkhan@google.com,2024-05-13 11:02:10,"tensorflow/lite/core/c/common.h, tensorflow/lite/core/interpreter_builder.cc, tensorflow/lite/core/subgraph.cc, tensorflow/lite/core/subgraph.h, tensorflow/lite/delegates/xnnpack/BUILD, tensorflow/lite/delegates/xnnpack/weight_cache.cc, tensorflow/lite/delegates/xnnpack/weight_cache.h, tensorflow/lite/delegates/xnnpack/weight_cache_schema.fbs, tensorflow/lite/delegates/xnnpack/weight_cache_schema_generated.h, tensorflow/lite/delegates/xnnpack/weight_cache_test.cc, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.h, tensorflow/lite/tflite_with_xnnpack.cc, tensorflow/opensource_only.files",qukhan,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633149675",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 10:18:13,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add reduction group support.

After this, all legacy fusions are supported by MLIR emitters. Currently, there
is still one failure in the JAX test suite, but it is not a reduction fusion.

PiperOrigin-RevId: 633147696",Johannes Reifferscheid,jreiffers@google.com,2024-05-13 10:08:38,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.h, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",jreiffers,False
"[XLA:GPU] [NFC] Propagate Status from allocation failures properly

Do not attempt to wrap/rewrap Status, as that loses the attached stack trace, and causes further errors.

PiperOrigin-RevId: 633145137",George Karpenkov,cheshire@google.com,2024-05-13 09:57:51,third_party/xla/xla/service/gpu/gpu_executable.cc,cheshire,False
"[XLA] Change default hlo-bisect output format to hlo

PiperOrigin-RevId: 633139592",George Karpenkov,cheshire@google.com,2024-05-13 09:28:48,third_party/xla/xla/tools/hlo_bisect/hlo_bisect.cc,cheshire,False
"[XLA:NFC] Support generating LLVM CPU output for hlo-opt

PiperOrigin-RevId: 633137810",George Karpenkov,cheshire@google.com,2024-05-13 09:19:29,"third_party/xla/xla/tools/hlo_opt/BUILD, third_party/xla/xla/tools/hlo_opt/cpu_llvm.hlo, third_party/xla/xla/tools/hlo_opt/cpu_opt.cc",cheshire,False
"compat: Update forward compatibility horizon to 2024-05-13

PiperOrigin-RevId: 633133741",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 09:02:12,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1861.

PiperOrigin-RevId: 633133739",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 09:02:12,tensorflow/core/public/version.h,tensorflower-gardener,False
"Use atomic add for BF16 types on cuda devices which support it.

This should make Scatter with BF16 type faster.

PiperOrigin-RevId: 633131419",Adrian Kuegel,akuegel@google.com,2024-05-13 08:51:28,"third_party/xla/xla/service/gpu/ir_emitter_nested.cc, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/scatter_bf16.hlo",akuegel,False
"PR #12253: Do not dump autotuner PTX to stdout when --xla_dump_hlo_as_* are set

Imported from GitHub PR https://github.com/openxla/xla/pull/12253

Without this change then when `--xla_dump_hlo_as_proto=true --xla_dump_to=/some/real/path` is set, the autotuner dumps PTX to stdout.
Copybara import of the project:

--
9149682143373bd17d4dc57635ba34b146e3b358 by Olli Lupton <olupton@nvidia.com>:

Do not dump autotuning PTX to stdout when --xla_dump_hlo_as_* are set

Merging this change closes #12253

PiperOrigin-RevId: 633126913",Olli Lupton,olupton@nvidia.com,2024-05-13 08:29:13,third_party/xla/xla/service/gpu/autotuner_compile_util.cc,olupton,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633125572",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 08:22:23,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add a pattern for removing results of index_switch ops without users.

This just matches on index switches with only unused results. Ideally
this would become a canonicalization pattern instead.

index_switch will be used in the reduction group lowering.

PiperOrigin-RevId: 633121827",Johannes Reifferscheid,jreiffers@google.com,2024-05-13 08:05:28,"third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_tensors.mlir",jreiffers,False
"Support nested tuples.

I thought I could get away with not doing this, but I finally
gave up.

PiperOrigin-RevId: 633120834",Johannes Reifferscheid,jreiffers@google.com,2024-05-13 08:02:03,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.h, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc",jreiffers,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633100257",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 06:17:51,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Nit: Fix a copy-and-paste mistake

PiperOrigin-RevId: 633077237",Junwhan Ahn,junwhan@google.com,2024-05-13 03:58:00,third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc,junwhanahn,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633059504",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 02:17:50,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 633052567",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 01:25:22,tensorflow/python/lib/io/BUILD,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 633052438",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 01:23:56,"tensorflow/compiler/mlir/quantization/tensorflow/calibrator/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_saver_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_saver_op_test.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633043663",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-13 00:17:27,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633015414",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 20:17:40,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Move the eligible intervening Bitcast between AR and DS ahead of AR to enable RS fusion.

The parsing codes for ReduceScatter fusion does not allow an intervening Bitcast between AR and DS. This cl detects such pattern and moves the Bitcast before AR and the Bitcast converts the original AR input to the target shape. This is done only when the Bitcast shape matches DS' shape, namely eligible for RS fusion.

PiperOrigin-RevId: 633007028",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 19:07:53,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/collective_opt_utils.cc, third_party/xla/xla/service/collective_opt_utils.h",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 633000529",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 18:18:11,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632984609",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 16:17:36,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632969748",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 14:17:34,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632957705",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 12:37:35,tensorflow/compiler/mlir/quantization/tensorflow/passes/merge_initializer_function_ops_to_main.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632956569",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 12:30:18,"tensorflow/compiler/mlir/lite/python/BUILD, tensorflow/compiler/mlir/lite/python/flatbuffer_to_mlir.cc, tensorflow/compiler/mlir/lite/python/jax_to_tfl_flatbuffer.h, tensorflow/compiler/mlir/lite/python/saved_model_to_tfl_flatbuffer.cc, tensorflow/compiler/mlir/lite/python/saved_model_to_tfl_flatbuffer.h, tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc, tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.h",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632955024",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 12:17:32,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632939515",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 10:17:30,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update GraphDef version to 1860.

PiperOrigin-RevId: 632928716",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 09:02:15,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-12

PiperOrigin-RevId: 632928714",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 09:02:14,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632922087",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 08:18:02,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632903772",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 06:17:30,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632887461",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 04:19:00,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632870583",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 02:18:33,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632855312",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-12 00:17:27,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
