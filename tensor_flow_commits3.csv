Commit Message,Name,Email,Updated at,Files Changed,Contributor,All Checks Passed
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632840520",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 22:18:09,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
Address review comments.,mdfaijul,md.faijul.amin@intel.com,2024-05-11 20:41:38,"tensorflow/core/kernels/mkl/mkl_kernel_util.h, tensorflow/core/kernels/mkl/mkl_matmul_op_fused.cc, tensorflow/core/kernels/mkl/mkl_matmul_ops_common.h, tensorflow/core/kernels/mkl/onednn_fused_matmul_ops_test.cc",mdfaijul,True
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632825429",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 20:17:33,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632809422",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 18:18:58,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632793301",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 16:18:05,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632777181",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 14:18:30,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632771839",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 13:34:19,tensorflow/core/common_runtime/eager/attr_builder_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632768963",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 13:12:00,third_party/xla/xla/tsl/c/tsl_status.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632767931",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 13:04:10,tensorflow/core/grappler/utils/scc_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632764388",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 12:38:05,tensorflow/core/kernels/uniform_quant_ops/tensor_utils.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632761523",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 12:18:01,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632755789",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 11:34:31,"tensorflow/tools/optimization/BUILD, tensorflow/tools/optimization/optimization_pass_runner.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632754608",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 11:26:02,"tensorflow/compiler/mlir/tfrt/BUILD, tensorflow/compiler/mlir/tfrt/translate/tfrt_compile_options.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632733012",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 09:06:12,"tensorflow/compiler/mlir/tools/kernel_gen/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/tools/kernel-gen-opt/kernel-gen-opt.cc",tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-11

PiperOrigin-RevId: 632732569",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 09:03:40,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1859.

PiperOrigin-RevId: 632732566",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 09:03:39,tensorflow/core/public/version.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632728281",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 08:35:48,tensorflow/core/common_runtime/function.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632728220",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 08:35:24,"tensorflow/dtensor/mlir/BUILD, tensorflow/dtensor/mlir/annotate_global_shape.cc, tensorflow/dtensor/mlir/cluster_function_conversion.cc, tensorflow/dtensor/mlir/collectives.cc, tensorflow/dtensor/mlir/collectives.h, tensorflow/dtensor/mlir/collectives_common.cc, tensorflow/dtensor/mlir/collectives_common.h, tensorflow/dtensor/mlir/constant_folding.cc, tensorflow/dtensor/mlir/dce.cc, tensorflow/dtensor/mlir/designate_resource_handle_mesh.cc, tensorflow/dtensor/mlir/device_mesh_cluster_coarsening.cc, tensorflow/dtensor/mlir/device_utils.cc, tensorflow/dtensor/mlir/dtensor_allreduce_combine_optimization.cc, tensorflow/dtensor/mlir/dtensor_allreduce_scatter_optimization.cc, tensorflow/dtensor/mlir/dtensor_allreduce_sum_optimization.cc, tensorflow/dtensor/mlir/dtensor_collective_type_lowering.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632725414",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 08:18:34,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632720008",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 07:46:29,tensorflow/core/common_runtime/executor.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632705214",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 06:17:58,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632695092",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 05:14:57,tensorflow/core/common_runtime/next_pluggable_device/c/tf_rendezvous_c_api_test.cc,tensorflower-gardener,False
"[XLA:HOST_OFFLOAD] Add Copy to the list of movable opcodes between host to
device and dynamic slice.

PiperOrigin-RevId: 632690123",Blake Hechtman,blakehechtman@google.com,2024-05-11 04:48:24,third_party/xla/xla/service/host_offloader.cc,blakehechtman,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632684444",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 04:17:59,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Raise a runtime error when trying to convert the `jax.Array` wrapped by `jax.core.Token` to a numpy array, as it is an internal implementation detail and the buffer has XLA token shape.

PiperOrigin-RevId: 632682906",Yue Sheng,yueshengys@google.com,2024-05-11 04:07:18,"third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/xla_client.py",yueshengys,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632664629",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 02:17:41,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Go: Update generated wrapper functions for TensorFlow ops.

PiperOrigin-RevId: 632649155",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 00:47:02,tensorflow/go/op/wrappers.go,tensorflower-gardener,False
"[XLA:TPU] Refactor HandleInputStreaming to process tuples using ForEachSubshape

Previously, tuples in parameters were separately processed from non tuple parameters. This cleans up the code to handle both tuple and non tuple parameters with one block.

PiperOrigin-RevId: 632648325",Jackson Stokes,jacksonstokes@google.com,2024-05-11 00:42:49,third_party/xla/xla/service/host_offloader.cc,jvstokes,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632644501",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 00:22:44,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automatically scales all memory terms in the Mixed ILP to percentage values (100.0 = full capacity)

PiperOrigin-RevId: 632642143",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-11 00:10:45,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc,tensorflower-gardener,False
"Change tfrt_session to set GPU-needed graph_execution_options if TFRTSessionFactory has use_gpu set to true.

PiperOrigin-RevId: 632638199",Chris Minge,chrisminge@google.com,2024-05-10 23:52:29,"tensorflow/core/tfrt/tfrt_session/tfrt_session.cc, tensorflow/core/tfrt/tfrt_session/tfrt_session.h",CMinge,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/loop_mlir.cc

PiperOrigin-RevId: 632637580",Kuy Mainwaring,kuym@google.com,2024-05-10 23:49:15,third_party/xla/xla/service/gpu/fusions/loop_mlir.cc,kuym,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc

PiperOrigin-RevId: 632637273",Kuy Mainwaring,kuym@google.com,2024-05-10 23:47:39,"third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc",kuym,False
"Introduced Op `GetTpuTaskId` and `UpdateTaskIdAndGlobalCoreArray`.

PiperOrigin-RevId: 632634113",Dateng Lin,datenglin@google.com,2024-05-10 23:32:32,"tensorflow/core/api_def/base_api/api_def_GetTpuTaskId.pbtxt, tensorflow/core/api_def/base_api/api_def_UpdateTaskIdAndGlobalCoreArray.pbtxt, tensorflow/core/ops/compat/ops_history_v2/GetTpuTaskId.pbtxt, tensorflow/core/ops/compat/ops_history_v2/UpdateTaskIdAndGlobalCoreArray.pbtxt, tensorflow/core/tpu/ops/tpu_embedding_ops.cc",,False
"[XLA:TPU] Fix erroneous copy being inserted under scan loop output streaming.

Previously, the streamed tensor was being copied to host before the dynamic update slice that is supposed to handle the data transfer. This fixes that.

PiperOrigin-RevId: 632614368",Jackson Stokes,jacksonstokes@google.com,2024-05-10 22:07:22,"third_party/xla/xla/service/host_offloader.cc, third_party/xla/xla/service/host_offloader.h, third_party/xla/xla/service/host_offloader_test.cc",jvstokes,False
"Improve wording in documentation

PiperOrigin-RevId: 632609457",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 21:49:27,tensorflow/python/framework/importer.py,tensorflower-gardener,False
"Implement optional memory space support for PjRt stream executor and use it to add memory space support to GPU

This CL implements an optional interface that allows PjRt stream executor implementations to add basic memory space support. The simplest form is one memory space per device, which requires just a memory space implementation and nothing else (memory space variants of transfer methods fall back to the corresponding device versions if the memory space is associated with just one device). More sophisticated mapping is possible, but requires overriding methods that take a memory space as a destination.

Using the above, this CL also adds basic memory space support for SE:GPU. Right now, there's just one memory kind, HBM (`StreamExecutorGpuHbmMemorySpace`), and every PjRt GPU device has a corresponding HBM memory space as its default memory space. While this does not bring any new feature, it simplifies the framework and runtime support since the caller does no longer need to check whether the underlying implementation supports memory space or not.

PiperOrigin-RevId: 632606133",Junwhan Ahn,junwhan@google.com,2024-05-10 21:35:45,"tensorflow/compiler/jit/xla_launch_util.cc, tensorflow/core/common_runtime/eager/context_distributed_manager.cc, tensorflow/core/common_runtime/gpu/gpu_device.cc, third_party/xla/xla/examples/axpy/stablehlo_compile_test.cc, third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler.cc, third_party/xla/xla/pjrt/interpreter_device.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client_test.cc, third_party/xla/xla/pjrt/stream_executor_executable.h, third_party/xla/xla/service/gpu/BUILD",junwhanahn,False
"Introduce an interface around basic HLO costing functionality that can be used by MSA's cost analysis.

We also implement the interface using HloCostAnalysis, which makes this is refactor.

PiperOrigin-RevId: 632594966",Ryan M. Lefever,lefever@google.com,2024-05-10 20:54:46,"third_party/xla/xla/service/memory_space_assignment/BUILD, third_party/xla/xla/service/memory_space_assignment/algorithm.cc, third_party/xla/xla/service/memory_space_assignment/cost_analysis.cc, third_party/xla/xla/service/memory_space_assignment/cost_analysis.h, third_party/xla/xla/service/memory_space_assignment/cost_analysis_test.cc, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer.cc, third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer_test.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc, third_party/xla/xla/service/memory_space_assignment/prefetch_interval_picker_test.cc, third_party/xla/xla/service/memory_space_assignment/testing_utils.h",sparc1998,False
"[TF] Forward ""__dict__"" attribute request to the wrapped object of a `_TupleWrapper`

PiperOrigin-RevId: 632588564",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 20:30:54,"tensorflow/python/module/module_test.py, tensorflow/python/trackable/data_structures.py",tensorflower-gardener,False
"Eliminate the need for StreamExecutorInterface::GetStreamImplementation by having each Executor override CreateStream.

PiperOrigin-RevId: 632586577",Kyle Lucke,klucke@google.com,2024-05-10 20:23:58,"tensorflow/c/experimental/stream_executor/stream_executor.cc, third_party/xla/xla/backends/interpreter/executor.h, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream.cc, third_party/xla/xla/stream_executor/stream.h, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.h",klucke,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632585274",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 20:18:19,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU] Emit matrix-vector multiplication as GemmFusion

PiperOrigin-RevId: 632583916",Anlun Xu,anlunx@google.com,2024-05-10 20:13:18,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/nvptx_compiler.cc",anlunx,False
"Throw errors for KV delete.

PiperOrigin-RevId: 632581343",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 20:03:17,third_party/xla/xla/python/xla.cc,tensorflower-gardener,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/reduction.cc

PiperOrigin-RevId: 632575986",Kuy Mainwaring,kuym@google.com,2024-05-10 19:42:43,"third_party/xla/xla/service/gpu/fusions/reduction.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.h",kuym,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/thunk_util.cc

PiperOrigin-RevId: 632574132",Kuy Mainwaring,kuym@google.com,2024-05-10 19:35:16,third_party/xla/xla/service/gpu/fusions/thunk_util.cc,kuym,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/scatter_mlir.h

PiperOrigin-RevId: 632569321",Kuy Mainwaring,kuym@google.com,2024-05-10 19:17:24,third_party/xla/xla/service/gpu/fusions/scatter_mlir.h,kuym,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/input_slices_mlir.h

PiperOrigin-RevId: 632569082",Kuy Mainwaring,kuym@google.com,2024-05-10 19:16:27,third_party/xla/xla/service/gpu/fusions/input_slices_mlir.h,kuym,False
"Revert: [XLA:GPU] Store fusion_roots and fusion_heroes as HloInstructionAdaptor in HloFusionAnalysis.

Internal tests are failing.

Reverts 73a3f15becb844358808b7c6686b15fe5d0baecf

PiperOrigin-RevId: 632560511",Oleg Shyshkov,shyshkov@google.com,2024-05-10 18:46:17,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/concatenate.cc, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/reduction.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.h, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/fusion_analysis_cache_test.cc",olegshyshkov,False
"Make OP_REQUIRES_OK* macros work correctly regardless of lifetime of the status argument, and add unit tests.

As part of this, we clarify that OP_REQUIRES_OK_ASYNC only evaluates its CALLBACK macro argument in the non-OK case, and we also clarify that OP_REQUIRES_OK expectes a single expression convertible to absl::Status, despite its variable arguments. Following a previous change [1] this was already implied, but prior to that change, multiple explicit constructor arguments for absl::Status would have been accepted, too. It appears (though we have no proof) that this was never an intended feature.

This is the second attempt at this change. The previous one had an error that is now fixed: we failed to notice the requirement for the CALLBACK argument to only be evaluated in the failure case, and the previous attempt evaluated it unconditionally. This was a behaviour change in cases where the evaluation of the CALLBACK expression itself has side effects. (Concretely, the side effect was a call of absl::Cleanup::Release.) In this version, we retain `(CALLBACK)();` in the top-level macro expansion rather than passing `(CALLBACK)` into the helper function.

This corrects earlier changes to OP_REQUIES_OK and OP_REQUIES_OK_ASYNC (e.g. [2]), which took a reference but did not extend the lifetime of potential intermediate temporaries. This would cause problems in situations where a short-lived status was passed in as something other than a prvalue, for example:

  struct T {
    const absl::Status& f() const { return s; }
    absl::Status s;
  };

  OP_REQUIRES_OK(T().f());

This becomes

  const absl::Status& _s(T().f());

which is instantly a dangling reference. (The added unit test catches this case when run under ASAN.)

To fix this, we move operations on user-provided arguments into a helper function, and ensure that the user-provided arguments are only used inside a single function call expression. All temporaries remain alive for the duration of the function call.

PiperOrigin-RevId: 632556916",Thomas Köppe,tkoeppe@google.com,2024-05-10 18:34:29,"tensorflow/core/framework/BUILD, tensorflow/core/framework/op_requires.h, tensorflow/core/framework/op_requires_test.cc",tkoeppe,False
"[ReplicaGroupV2] Define compressed replica group list (IotaReplicaGroupList) and migrate collective generation in SPMD to use this format whenever possible.

In final stage of the SPMD partitioner, the partitioner goes from a sharding to a set of replica groups. It generates replica groups by ""merging"" devices along certain dimensions of the original sharding. If sharding provided is of HloShardingV2 type, it is possible to generate replica groups in a compressed format via reshapes and transposes of the V2 sharding.

This change also speeds up cloning of collective instruction by migrating CollectiveDeviceList to store pointers to replica groups.

PiperOrigin-RevId: 632556619",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 18:33:44,"third_party/xla/xla/hlo/ir/collective_device_list.cc, third_party/xla/xla/hlo/ir/collective_device_list.h, third_party/xla/xla/hlo/ir/tile_assignment.cc, third_party/xla/xla/hlo/ir/tile_assignment.h, third_party/xla/xla/hlo/utils/hlo_sharding_util.h, third_party/xla/xla/service/spmd/BUILD, third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/spmd/spmd_partitioner.h, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc, third_party/xla/xla/service/spmd/spmd_partitioner_util.cc, third_party/xla/xla/service/spmd/spmd_partitioner_util.h, third_party/xla/xla/service/spmd/spmd_partitioner_util_test.cc",tensorflower-gardener,False
"Reverts 9760d8855f3270d5ff8a42293d26a04a56c42d88

PiperOrigin-RevId: 632552411",Yue Sheng,yueshengys@google.com,2024-05-10 18:19:35,"third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/python/py_array.cc",yueshengys,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/concatenate_mlir.cc

PiperOrigin-RevId: 632549987",Kuy Mainwaring,kuym@google.com,2024-05-10 18:11:30,"third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/concatenate_mlir.h",kuym,False
"Simplify JAX lowering rules for cumulative sum

Rely on XLA decomposition.

# JAX GPU microbenchmarks

285us for cumsum over 1e8 elements

449us for cumsum over 1e8 elements.

# JAX CPU microbenchmarks:

1.8s vs. 0.7s for 50 iterations over cumsum over 1e7 elements

PiperOrigin-RevId: 632547166",George Karpenkov,cheshire@google.com,2024-05-10 18:02:47,third_party/xla/xla/python/xla_client.py,cheshire,False
"Migrate deprecated types to their replacements.

PiperOrigin-RevId: 632546994",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 18:02:18,"tensorflow/core/kernels/nn_ops_test.cc, tensorflow/core/kernels/ops_testutil.h, tensorflow/core/kernels/parse_tensor_test.cc, tensorflow/core/kernels/ragged_cross_op.cc, tensorflow/core/kernels/reduce_join_op.cc, tensorflow/core/kernels/reduction_ops_common.cc, tensorflow/core/kernels/reduction_ops_common.h, tensorflow/core/kernels/reshape_util.cc, tensorflow/core/kernels/resource_variable_ops.cc, tensorflow/core/kernels/restore_op_test.cc, tensorflow/core/kernels/restore_v2_op_test.cc, tensorflow/core/kernels/reverse_op.cc, tensorflow/core/kernels/roll_op.cc, tensorflow/core/kernels/scoped_allocator_ops_test.cc, tensorflow/core/kernels/sdca_internal.h, tensorflow/core/kernels/searchsorted_op.cc, tensorflow/core/kernels/segment_reduction_ops_test.cc, tensorflow/core/kernels/serialize_sparse_op.cc, tensorflow/core/kernels/slice_op.cc, tensorflow/core/kernels/spacetobatch_functor.cc, tensorflow/core/kernels/spacetobatch_op.cc",tensorflower-gardener,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc

PiperOrigin-RevId: 632543717",Kuy Mainwaring,kuym@google.com,2024-05-10 17:52:26,"third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h",kuym,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/input_slices.cc

PiperOrigin-RevId: 632543408",Kuy Mainwaring,kuym@google.com,2024-05-10 17:51:29,third_party/xla/xla/service/gpu/fusions/input_slices.cc,kuym,False
"Give `xla_cc_test` a `use_gpu` option instead of manually specifying tags

PiperOrigin-RevId: 632538556",David Dunleavy,ddunleavy@google.com,2024-05-10 17:35:41,"third_party/xla/xla/backends/profiler/gpu/BUILD, third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/stream_executor/cuda/BUILD, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/tests/BUILD, third_party/xla/xla/xla.bzl",ddunl,False
"Make usages of Eigen::array compatible with std::array.

Eigen::array is no longer necessary, so will be deprecated/removed and replaced
with `std::array`.  The main difference is the constructor - currently Eigen::array
allows `array(a, b, c, ...)` construction, whereas `std::array` requires an initializer
list.  We also need to remove any direct access to the `Eigen::array::values`
internal parameter, in favor of regular index access.
PiperOrigin-RevId: 632535916",Antonio Sanchez,cantonios@google.com,2024-05-10 17:27:47,"tensorflow/core/distributed_runtime/BUILD, tensorflow/core/distributed_runtime/master_test.cc, tensorflow/core/kernels/gather_nd_op_gpu.cu.cc, tensorflow/core/kernels/image/adjust_contrast_op.cc, tensorflow/core/kernels/parameterized_truncated_normal_op_gpu.cu.cc, tensorflow/core/kernels/random_binomial_op.cc, tensorflow/core/kernels/sparse_tensor_dense_matmul_op.cc, third_party/xla/third_party/tsl/tsl/framework/convolution/eigen_spatial_convolutions_test.cc",cantonios,False
"[xla:ffi] Add xla::ffi::ExecutionContext to ExecutableRunOptions

PiperOrigin-RevId: 632526699",Eugene Zhulenev,ezhulenev@google.com,2024-05-10 16:58:00,"third_party/xla/xla/executable_run_options.cc, third_party/xla/xla/executable_run_options.h, third_party/xla/xla/ffi/api/BUILD, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/execution_context.h, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_api.h, third_party/xla/xla/ffi/ffi_test.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/custom_call_test.cc",ezhulenev,False
"Fix segment reduction overflow.

The `nsegments` argument type must be the same as the `segment_ids`
(since the latter are just indices into `nsegments`).  For large
inputs that would overflow `Index` (`long`) but still fit into `int64_t`,
this was previously causing a uncaught failure, since it would pass
the validation checks that used `int64_t`, but then would result in
a negative value when it's actually used.

Fixes #64023.

PiperOrigin-RevId: 632523124",Antonio Sanchez,cantonios@google.com,2024-05-10 16:44:14,"tensorflow/core/kernels/segment_reduction_ops_impl.h, tensorflow/python/kernel_tests/math_ops/segment_reduction_ops_test.py",cantonios,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632516152",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 16:17:54,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #11912: [GPU] Support pointwise floor and ceil in GEMM fusions.

Imported from GitHub PR https://github.com/openxla/xla/pull/11912

For this to work with Triton openxla/triton will need to include https://github.com/openai/triton/commit/62706e8c518c8c56e56460a43732d8e375217860.
Copybara import of the project:

--
37efe4abc9caae6033ac1aabcf1799f2f3c1b0c2 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Triton: support elementwise floor and ceil.

--
7a21cb770cdb08bdb4504fb23c4dc1d31126c01f by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] cuDNN fusions: support elementwise floor and ceil.

Merging this change closes #11912

PiperOrigin-RevId: 632495980",Ilia Sergachev,isergachev@nvidia.com,2024-05-10 14:58:28,"third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/softmax_rewriter_triton_test.cc, third_party/xla/xla/service/gpu/triton_support.cc, third_party/xla/xla/service/gpu/triton_support_test.cc",sergachev,False
"Make unroller utility functions static.

PiperOrigin-RevId: 632495173",Farzin Houshmand,farzinh@google.com,2024-05-10 14:54:26,"third_party/xla/xla/service/scan_loop_accumulator_input_unification.cc, third_party/xla/xla/service/while_loop_unroller.cc, third_party/xla/xla/service/while_loop_unroller.h, third_party/xla/xla/service/while_loop_unroller_test.cc",farzinhoushmand,False
"[XLA:GPU/CPU] Enable tree reduction rewriter for reduce-window on GPU and CPU

>10x difference in performance when compiling tf.cumsum

For a tf.cumsum over 1e6 elements on A6000 GPU:

Without this patch: ~466ms
With the patch: 40us

This is faster than TF native implementation.

The value of splitting is chosen heuristically.

PiperOrigin-RevId: 632491764",George Karpenkov,cheshire@google.com,2024-05-10 14:37:52,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/reduce_window_rewriter_execution_test.cc, third_party/xla/xla/xla.proto",cheshire,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632488647",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 14:24:53,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix GEMM autotuner on Hopper

Triton only generates MMA v3 (sm90+) dots when ENABLE_MMA_V3 env is set, and this env.var is controlled by --xla_gpu_enable_triton_hopper flag in XLA.
The autotuner now correctly uses this flag.

PiperOrigin-RevId: 632482062",Sergey Kozub,sergeykozub@google.com,2024-05-10 13:53:43,third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc,sergeykozub,False
"[XLA] [NFC] Upstream ReduceWindowRewriter pass

PiperOrigin-RevId: 632478633",George Karpenkov,cheshire@google.com,2024-05-10 13:35:26,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/reduce_window_rewriter.cc, third_party/xla/xla/service/reduce_window_rewriter.h, third_party/xla/xla/service/reduce_window_rewriter_test.cc",cheshire,False
"Read ENABLE_MMA_V3 env in sparse dot emitter (in line with the dense dot).
This has to be reverted when/if ENABLE_MMA_V3 env is removed in Triton.

PiperOrigin-RevId: 632478189",Sergey Kozub,sergeykozub@google.com,2024-05-10 13:33:09,"third_party/triton/xla_extensions/series.bzl, third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch, third_party/xla/third_party/triton/xla_extensions/series.bzl, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w19.patch",sergeykozub,False
"Integrate LLVM at llvm/llvm-project@fc57f88f0074

Updates LLVM usage to match
[fc57f88f0074](https://github.com/llvm/llvm-project/commit/fc57f88f0074)

PiperOrigin-RevId: 632473772",Benjamin Kramer,kramerb@google.com,2024-05-10 13:12:42,third_party/llvm/workspace.bzl,d0k,False
"[XLA] Refactor `BackendConfigWrapper` and add tests.

This change:
- Folds `HloInstruction::GetBackendConfigInternal` into `BackendConfigWrapper` where is really belongs.
- Removes `mutable` from `HloInstruction::backend_config_`.
- Changes `BackendConfigWrapper` to use constructors wherever possible, instead of methods, so that the need for synchronization is reduced.
- Improves the documentation to correctly reflect that this class is symmetric with respect to which of its defining members was initialized first and which is the cache.
- Adds tests to ensure the new implementation is thread-safe.

PiperOrigin-RevId: 632469201",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-10 12:50:26,"third_party/xla/xla/hlo/ir/BUILD, third_party/xla/xla/hlo/ir/backend_config.cc, third_party/xla/xla/hlo/ir/backend_config.h, third_party/xla/xla/hlo/ir/backend_config_test.cc, third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h",dimitar-asenov,False
"[XLA:GPU][MLIR-Based emitters] Use xla_gpu.apply_indexing instead of affine.apply.

PiperOrigin-RevId: 632464860",Alexander Belyaev,pifon@google.com,2024-05-10 12:27:25,"third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/simplify_affine.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/simplify_affine.mlir",pifon2a,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632463386",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 12:17:54,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Tool to process a HloModuleMetadataProto dump.

When debugging compile time regressions, it can be helpful to use the flag
--xla_dump_module_metadata. This change adds a tool that can process such a
dump and print the individual pass timings in sorted order, so that it is
easier to spot possible reasons for the regression.

PiperOrigin-RevId: 632459077",Adrian Kuegel,akuegel@google.com,2024-05-10 11:55:37,"third_party/xla/xla/tools/BUILD, third_party/xla/xla/tools/hlo_module_metadata_processor.cc",akuegel,False
"[XLA:GPU] Store fusion_roots and fusion_heroes as HloInstructionAdaptor in HloFusionAnalysis.

HloFusionAnalysis works on fused and unfused HLO, so it's more logical to instruction adaptors that point to the fusion adaptor.

PiperOrigin-RevId: 632443793",Oleg Shyshkov,shyshkov@google.com,2024-05-10 10:38:56,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/concatenate.cc, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/reduction.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.h, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/fusion_analysis_cache_test.cc",olegshyshkov,False
"[Triton] Cherry picking changes to support elementwise ceil op.

PiperOrigin-RevId: 632443597",Mohammed Anany,manany@google.com,2024-05-10 10:38:14,"third_party/triton/temporary/series.bzl, third_party/triton/temporary/support_ceil_op.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/support_ceil_op.patch",Moerafaat,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632439925",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 10:22:09,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #11762: [GPU] Enable nccl comm split by default

Imported from GitHub PR https://github.com/openxla/xla/pull/11762

With https://github.com/openxla/xla/pull/11761 NCCL comm split will be available for multiprocess applications. Using that change, I tested a variety of PAXML and T5X workloads. I found no crashes, hangs, or performance regressions and a good amount of memory savings depending on the model. I tested many more workloads aside from these four, but there was no interesting results since they only used a single communicator.

| Workload                                                                 | Mem diff (MiB) | Speedup |
| ------------------------------------------------------------------------ | ------------- | --------- |
| paxml llama70b evaluate 16xh100 bfloat16 bs-4 ici--1-8-1 dcn--1-2-1      | 0 | 0.9915 |
| paxml GPT3 train 8xh100 bfl16 bs-4 ici--4-1-2                            | \-320 | 1.0029 |
| paxml GPT3 train 8xh100 bfl16 bs-8 ici--1-4-2                            | \-1252 |  1.0026 |
| paxml GPT3pp train 16xh100 bf16 bs-8 ici--2-2-1-2                        | \-2990 | 0.9947 |

Copybara import of the project:

--
a336c41e11ed95bf067ae6c8bebeb167698ddfbb by Trevor Morris <tmorris@nvidia.com>:

Enable nccl comm split by default

Merging this change closes #11762

PiperOrigin-RevId: 632439750",Trevor Morris,tmorris@nvidia.com,2024-05-10 10:21:31,third_party/xla/xla/debug_options_flags.cc,trevor-m,False
"Automated Code Change

PiperOrigin-RevId: 632432383",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 09:47:12,tensorflow/core/tfrt/utils/utils.h,tensorflower-gardener,False
"[XLA:GPU][IndexAnalysis] Remove indexing_context.h. It is not used.

PiperOrigin-RevId: 632431640",Alexander Belyaev,pifon@google.com,2024-05-10 09:42:51,third_party/xla/xla/service/gpu/model/indexing_context.h,pifon2a,False
"Automated Code Change

PiperOrigin-RevId: 632428851",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 09:30:00,tensorflow/core/distributed_runtime/coordination/coordination_service_barrier_proxy.cc,tensorflower-gardener,False
"Fix xla_gpu.atomic_rmw lowering for complex<?> arguments.

It is not possible to directly bitcast a complex to an int, so we have to go
through an alloca.

PiperOrigin-RevId: 632428309",Johannes Reifferscheid,jreiffers@google.com,2024-05-10 09:27:11,"third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_tensors.mlir",jreiffers,False
"Support scatter with unsigned indices.

PiperOrigin-RevId: 632428123",Johannes Reifferscheid,jreiffers@google.com,2024-05-10 09:26:21,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir_test.cc",jreiffers,False
"Update GraphDef version to 1858.

PiperOrigin-RevId: 632423004",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 09:03:17,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-10

PiperOrigin-RevId: 632422543",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 09:01:52,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Make `ProtoToHumanReadableJson` return `StatusOr<string>`.

This is consistent with all the callers and simplifies the callers.

PiperOrigin-RevId: 632413886",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-10 08:22:51,"third_party/xla/third_party/tsl/tsl/platform/default/BUILD, third_party/xla/third_party/tsl/tsl/platform/default/human_readable_json.cc, third_party/xla/third_party/tsl/tsl/platform/human_readable_json.h, third_party/xla/xla/hlo/ir/BUILD, third_party/xla/xla/hlo/ir/backend_config.cc",dimitar-asenov,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632412883",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 08:17:48,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix missing include.

Reverts 9bb485ebe8fc68b7750081c3a95b66c35c51a2e7

PiperOrigin-RevId: 632405040",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-10 07:44:25,"third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_custom_kernel_benchmarks.cc",dimitar-asenov,False
"[xla:ffi] Add Python-based tests for type-safe custom calls on CPU platform

Implements #10062. This change only adds test cases, all other changes required for Python support are already merged.

PiperOrigin-RevId: 632404716",Adam Banaś,adambanas@google.com,2024-05-10 07:42:35,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/typed_ffi_custom_call_for_test.cc, third_party/xla/xla/python/xla_client_test.py",Adam-Banas,False
"PR #11570: [ROCm] FileCheck fixes

Imported from GitHub PR https://github.com/openxla/xla/pull/11570

This PR patches several FileCheck pattern tests so that they pass on ROCm.
Copybara import of the project:

--
0edeabdf23fb01e21c5984b4a8f902a720b5820e by Eugene Kuznetsov <eugene.kuznetsov@amd.com>:

ROCm FileCheck pattern fixes

Merging this change closes #11570

PiperOrigin-RevId: 632400776",ekuznetsov139,nameless@fastmail.fm,2024-05-10 07:24:33,"third_party/xla/xla/service/gpu/tests/add_preds.hlo, third_party/xla/xla/service/gpu/tests/fused_scatter.hlo, third_party/xla/xla/service/gpu/tests/launch_dimensions.hlo, third_party/xla/xla/service/gpu/tests/reduce_atomic_min.hlo, third_party/xla/xla/service/gpu/tests/reduce_column_layout_change.hlo, third_party/xla/xla/service/gpu/tests/reduce_large_row_to_scalar.hlo",ekuznetsov139,False
"Merge pull request #44950 from Intel-tensorflow:yimei/fuse_old_bn

PiperOrigin-RevId: 632398564",TensorFlower Gardener,gardener@tensorflow.org,2024-05-10 07:21:50,"tensorflow/python/tools/BUILD, tensorflow/python/tools/optimize_for_inference.py, tensorflow/python/tools/optimize_for_inference_lib.py, tensorflow/python/tools/optimize_for_inference_test.py",tensorflower-gardener,False
"Consider TPUPartitionedCall in GraphFuncOp::getCalledFunction

PiperOrigin-RevId: 632388206",Eunjae Kim,eunjaekim@google.com,2024-05-10 06:26:22,tensorflow/core/ir/ops.cc,eunjaekim-0,False
"Don't generate task library docs for TF Lite

This is untested but should remove the Task library docs from the generated Java API reference.

Also fixed a while/walrus statement so that a variable referenced later always exists.

PiperOrigin-RevId: 632388177",Mark McDonald,macd@google.com,2024-05-10 06:26:14,tensorflow/lite/g3doc/tools/build_java_api_docs.py,markmcd,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632387484",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 06:21:34,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632374309",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 05:07:55,third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632373137",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 05:02:04,"third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/kernels/custom_kernel_fusion_pattern.cc, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_custom_kernel.cc, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_custom_kernel_benchmarks.cc, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_fusion.cc, third_party/xla/xla/service/gpu/kernels/topk_kernel.cc, third_party/xla/xla/service/gpu/kernels/topk_kernel_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632372596",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 04:59:14,tensorflow/core/profiler/lib/BUILD,tensorflower-gardener,False
"Add RemapArraysOp to IFT IR.

This op is the IFRT IR equivalent of `xla::ifrt::Client::RemapArrays`.

PiperOrigin-RevId: 632369908",Ionel Gog,icgog@google.com,2024-05-10 04:43:27,"third_party/xla/xla/python/ifrt/ir/ifrt_dialect.cc, third_party/xla/xla/python/ifrt/ir/ifrt_dialect.td, third_party/xla/xla/python/ifrt/ir/ifrt_ops.cc, third_party/xla/xla/python/ifrt/ir/ifrt_ops.td, third_party/xla/xla/python/ifrt/ir/tests/BUILD, third_party/xla/xla/python/ifrt/ir/tests/ifrt_verify_donation.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_remap_arrays.mlir, third_party/xla/xla/python/ifrt/ir/transforms/ifrt_verify_donation_pass.cc",ICGog,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632365091",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 04:17:37,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/fusions/loop.cc

PiperOrigin-RevId: 632364243",Kuy Mainwaring,kuym@google.com,2024-05-10 04:12:06,third_party/xla/xla/service/gpu/fusions/loop.cc,kuym,False
"Make the id of CustomAggregator op deterministic

The id is set as:
`<function name>_<arg or result>_<arg/result index>_<calibration_method>`
The critical point here is to make the composite function name deterministic. It is done by making sorting the functions by their names.

PiperOrigin-RevId: 632361313",Thai Nguyen,thaink@google.com,2024-05-10 03:56:21,"tensorflow/compiler/mlir/quantization/common/BUILD, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.cc, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.h, tensorflow/compiler/mlir/quantization/common/lift_as_function_call_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/pass_pipeline.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/lift_quantizable_spots_as_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/pre_calibration_component.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/lift_quantizable_spots_as_functions.mlir, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_custom_aggregation_ops.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/issue_ids_of_custom_aggregation_ops.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/lift_quantizable_spots_as_functions.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/passes.h, tensorflow/compiler/mlir/quantization/tensorflow/quantize_passes.cc, tensorflow/compiler/mlir/quantization/tensorflow/tests/insert_custom_aggregation_ops.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/issue_ids_of_custom_aggregation_ops.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/lift_quantizable_spots_as_functions.mlir",thaink,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632354225",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 03:18:48,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Do not restore layouts proto string when restoring model

PiperOrigin-RevId: 632347737",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 02:52:57,"tensorflow/python/tpu/BUILD, tensorflow/python/tpu/tpu_embedding_v3_utils.py",tensorflower-gardener,False
"Add simplification pattern to prefer mul(x, 1/const) over div(x, const)

PiperOrigin-RevId: 632340540",Luke Boyer,lukeboyer@google.com,2024-05-10 02:16:27,"tensorflow/compiler/mlir/lite/stablehlo/odml_converter/BUILD, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/tests/shlo_simplify.mlir, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/transforms/shlo_simplify.cc, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/transforms/shlo_simplify.td",LukeBoyer,False
"Allow setting operand_shapes_with_layout on custom call instruction.

PiperOrigin-RevId: 632339759",Tongfei Guo,tongfei@google.com,2024-05-10 02:12:20,third_party/xla/xla/hlo/ir/hlo_instructions.h,Tongfei-Guo,False
"[PJRT C] Add layouts extension to GPU plugin and use `PjRtClient::GetDefaultLayout` in dlpack as it's been supported on PJRT C API.

PiperOrigin-RevId: 632329798",Yue Sheng,yueshengys@google.com,2024-05-10 01:20:45,"third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_internal.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/dlpack.cc",yueshengys,False
"Extract `xla::ShardingPropagation::CanonicalizeLayouts()` as a util function.

PiperOrigin-RevId: 632328252",Zixuan Jiang,zixuanjiang@google.com,2024-05-10 01:13:57,"third_party/xla/xla/hlo/utils/BUILD, third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util.h, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation.h",ZixuanJiang,False
"Add space between ""version"" and the actual version

PiperOrigin-RevId: 632323650",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-10 00:56:25,tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_to_vhlo.cc,mlevesquedion,False
"Remove the default `PjRtBuffer::CopyRawToHostFuture` implementation

It is infeasible to implement `CopyRawToHostFuture` correctly in the base `PjRtBuffer` class just with other public methods because keeping the underlying buffer alive requires knowing about internal representation of a buffer. Instead, this CL removes the buggy default implementation and lets it always return an `UNIMPLEMENTED` error.

PiperOrigin-RevId: 632323555",Junwhan Ahn,junwhan@google.com,2024-05-10 00:56:10,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/pjrt_client.cc, third_party/xla/xla/pjrt/pjrt_client.h",junwhanahn,False
"[XLA:TPU] Support output streaming and refactor TryOutputStreaming into a bottoms-up approach.

Previously, output streaming took a top-down approach which indiscriminately checks if a MoveToHost custom call would trace down to an output marked with host memory space. This did not work when a dynamic-update-slice existed between the MTH call and the output. This CL fixes this problem by handling output streaming before other MTH calls, while also improving efficiency with the bottoms-up approach so we only trace a single path in the graph.

PiperOrigin-RevId: 632318740",Jackson Stokes,jacksonstokes@google.com,2024-05-10 00:33:20,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/host_offloader.cc, third_party/xla/xla/service/host_offloader.h, third_party/xla/xla/service/host_offloader_test.cc",jvstokes,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632315735",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-10 00:20:23,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Reverts e9476d0fd503f95377b76b47798bf0829085709b

PiperOrigin-RevId: 632295759",Terry Heo,terryheo@google.com,2024-05-09 22:58:14,"tensorflow/lite/tools/versioning/gpu_compatibility.cc, tensorflow/lite/tools/versioning/gpu_compatibility_test.cc",terryheo,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/gpu_schedule_postprocessing.cc

PiperOrigin-RevId: 632293724",Kuy Mainwaring,kuym@google.com,2024-05-09 22:49:59,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_schedule_postprocessing.cc",kuym,False
"Internal code change

PiperOrigin-RevId: 632293423",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 22:48:42,tensorflow/core/framework/BUILD,tensorflower-gardener,False
"Go: Update generated wrapper functions for TensorFlow ops.

PiperOrigin-RevId: 632292573",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 22:45:12,tensorflow/go/op/wrappers.go,tensorflower-gardener,False
"Remove LOG(WARNING) line, this is creating a lot of logspam.

PiperOrigin-RevId: 632291817",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 22:41:46,tensorflow/core/profiler/convert/hlo_proto_to_memory_visualization_utils.cc,tensorflower-gardener,False
"Moves the fatal ""auto-sharding solver timed out"" message until after the total runtime is printed.

PiperOrigin-RevId: 632291594",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 22:40:59,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632287948",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 22:29:07,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[xla] optimize_input_output_buffer_alias: only alias if buffers are in same memory space

PiperOrigin-RevId: 632280100",Emilio Cota,ecg@google.com,2024-05-09 22:00:06,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/optimize_input_output_buffer_alias.cc, third_party/xla/xla/service/optimize_input_output_buffer_alias_test.cc",cota,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/gpu_compiler.cc

PiperOrigin-RevId: 632280018",Kuy Mainwaring,kuym@google.com,2024-05-09 21:59:53,third_party/xla/xla/service/gpu/gpu_compiler.cc,kuym,False
"Clean up todos on ifrt core selection

PiperOrigin-RevId: 632273775",Siqiao Wu,siqiaowu@google.com,2024-05-09 21:38:45,"tensorflow/compiler/mlir/tensorflow/ir/host_runtime/tfrt_ops.td, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/mlrt/kernel/BUILD, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc",SiqiaoWu1993,False
"Adds the necessary logic for the creation, deletion and for checking the readiness of a `BasicStringArray`, a simple `ifrt::Array` implementation that wraps a local (or host) string buffer.

PiperOrigin-RevId: 632270272",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 21:26:31,"third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.cc, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.h, third_party/xla/xla/python/pjrt_ifrt/basic_string_array_test.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.h",tensorflower-gardener,False
"Use int32 when apply canonicalization on converting Pack op to Reshape op

PiperOrigin-RevId: 632270101",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 21:26:02,"tensorflow/compiler/mlir/tensorflow/ir/tf_ops_n_z.cc, tensorflow/compiler/mlir/tensorflow/tests/canonicalize.mlir",tensorflower-gardener,False
"Make all methods on StreamExecutor overrides.

PiperOrigin-RevId: 632268587",Kyle Lucke,klucke@google.com,2024-05-09 21:20:33,"third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h",klucke,False
"Modify the GatherV2 xla kernels to default to returning a constant of 0 if any of the dimensions is 0.
Modify the TensorListSetItem to check dimensions and return the unmodified list in the event the update dimension is larger since DynamicUpdateSlice would fail.
These changes are to match the behaviour of the MLIR bridge.

PiperOrigin-RevId: 632265516",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 21:10:22,"tensorflow/compiler/mlir/tensorflow/ir/tf_generated_ops.td, tensorflow/compiler/mlir/tf2xla/api/v2/legalize_tf_test.cc, tensorflow/compiler/tests/gather_nd_op_test.py, tensorflow/compiler/tf2xla/kernels/BUILD, tensorflow/compiler/tf2xla/kernels/gather_op.cc, tensorflow/compiler/tf2xla/kernels/tensor_list_utils.cc, tensorflow/core/api_def/base_api/api_def_GatherV2.pbtxt, tensorflow/core/kernels/gather_op_test.cc",tensorflower-gardener,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/elemental_ir_emitter.cc

PiperOrigin-RevId: 632264434",Kuy Mainwaring,kuym@google.com,2024-05-09 21:06:59,third_party/xla/xla/service/gpu/elemental_ir_emitter.cc,kuym,False
"Properly implement`PjRtStreamExecutorBuffer::CopyRawToHostFuture` for PjRt GPU

The current implementation of `CopyRawToHostFuture` does not implement the exact promised semantics because it does not acquire the buffer hold inline. So if one enqueues `CopyRawToHostFuture` and immediately deletes the source PjRt buffer, this will cause use-after-free in the current implementation even though it is not supposed to be.

This CL changes the `PjRtStreamExecutorClient` to take a future of the host buffer destination, instead of an eager pointer, and updates both the eager and the future versions to use this new method. The implementation always acquires a usage hold inline before enqueueing transfers to avoid the use-after-free problem mentioned above.

`StreamExecutorGpuClientTest.CopyRawToHostFuture` has been updated to exercise the case where the buffer is immediately dropped after the transfer is enqueued.

PiperOrigin-RevId: 632263676",Junwhan Ahn,junwhan@google.com,2024-05-09 21:04:44,"third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",junwhanahn,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632258601",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 20:48:44,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Reverts a01c5c6252ae859c18ad1e489981d867a3c4b519

PiperOrigin-RevId: 632254775",Samuel Agyakwa,sagyakwa@google.com,2024-05-09 20:36:35,"tensorflow/core/common_runtime/next_pluggable_device/BUILD, tensorflow/core/common_runtime/next_pluggable_device/direct_plugin_op_kernel.h, tensorflow/core/common_runtime/next_pluggable_device/plugin_op_kernel_helper.h",sagyakwa,False
"[IFRT] Implement RemapArrays API

We introduce `ifrt::Client::RemapArrays()`

* It takes `N` input arrays, returns `M` output arrays, performing is a
shard-level scatter-gather. It is a generalization of existing shard-level
APIs: `Client::AssembleArrayFromSingleDeviceArrays()`,
`Array::DisassembleIntoSingleDeviceArrays()`, and
`Array::FullyReplicatedShard()`.
* It is metadata-only operation.
No shard from the input can be used twice (no replication). No shard will have
its location changed (no transfer). However, some shards from the input may be
not used in any of the output arrays and be discarded.
PiperOrigin-RevId: 632253093",Hyeontaek Lim,hyeontaek@google.com,2024-05-09 20:32:13,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/client.cc, third_party/xla/xla/python/ifrt/client.h, third_party/xla/xla/python/ifrt/mock.cc, third_party/xla/xla/python/ifrt/mock.h, third_party/xla/xla/python/ifrt/remap_impl_test_lib.cc, third_party/xla/xla/python/ifrt/remap_plan.cc, third_party/xla/xla/python/ifrt/remap_plan.h, third_party/xla/xla/python/ifrt/remap_plan.proto, third_party/xla/xla/python/ifrt/remap_plan_test.cc, third_party/xla/xla/python/ifrt/sharding_test_util.cc, third_party/xla/xla/python/ifrt_proxy/client/array.cc, third_party/xla/xla/python/ifrt_proxy/client/array.h, third_party/xla/xla/python/ifrt_proxy/client/client.cc, third_party/xla/xla/python/ifrt_proxy/client/client.h, third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.cc, third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.h, third_party/xla/xla/python/ifrt_proxy/common/BUILD, third_party/xla/xla/python/ifrt_proxy/common/ifrt_service.proto, third_party/xla/xla/python/ifrt_proxy/integration_tests/BUILD, third_party/xla/xla/python/ifrt_proxy/integration_tests/register_pjrt_cpu_for_ifrt_api_tests.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.h, third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_remap.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_remap.h, third_party/xla/xla/python/py_compile_only_client.cc",hyeontaek,False
"Make XLA Python 3.13-ready.

PiperOrigin-RevId: 632250231",Vadym Matsishevskyi,vam@google.com,2024-05-09 20:22:42,"third_party/xla/xla/python/pjit.cc, third_party/xla/xla/python/py_array.cc",vam-google,False
"Migrate changelist field in Task proto to int64.

PiperOrigin-RevId: 632245255",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 20:05:39,tensorflow/core/profiler/protobuf/task.proto,tensorflower-gardener,False
"#tf-data-service Pass accelerator device info to alternative data transfer clients.

PiperOrigin-RevId: 632229720",Matt Callanan,mpcallanan@google.com,2024-05-09 19:11:22,"tensorflow/core/data/service/client/data_service_client.cc, tensorflow/core/data/service/client/data_service_client.h, tensorflow/core/data/service/client/data_service_client_test.cc, tensorflow/core/data/service/data_transfer.h, tensorflow/core/data/service/test_cluster.h, tensorflow/core/data/service/worker_client.cc, tensorflow/core/data/service/worker_client.h, tensorflow/core/data/service/worker_client_test.cc, tensorflow/core/framework/dataset.h, tensorflow/core/kernels/data/experimental/data_service_dataset_op.cc",mpcallanan,False
"Accumulate shape product in int64 to prevent integer overflow.

PiperOrigin-RevId: 632228089",Tom Ward,tomward@google.com,2024-05-09 19:05:45,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch",tomwardio,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/triton_fusion_analysis.cc

PiperOrigin-RevId: 632227475",Kuy Mainwaring,kuym@google.com,2024-05-09 19:04:08,third_party/xla/xla/service/gpu/triton_fusion_analysis.cc,kuym,False
"Fix outline composites to remove ops in proper order

PiperOrigin-RevId: 632224834",Luke Boyer,lukeboyer@google.com,2024-05-09 18:56:43,tensorflow/compiler/mlir/lite/stablehlo/odml_converter/transforms/outline_composites.cc,LukeBoyer,False
"Extend Attribute Scalars by their unsigned types

PiperOrigin-RevId: 632222737",Paweł Paruzel,paruzelp@google.com,2024-05-09 18:49:11,"third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/call_frame.h, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.cc",pparuzel,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/gemm_rewriter.cc

PiperOrigin-RevId: 632221053",Kuy Mainwaring,kuym@google.com,2024-05-09 18:43:37,third_party/xla/xla/service/gpu/gemm_rewriter.cc,kuym,False
"Eliminate a helper method on StreamExecutor used in only one place.

PiperOrigin-RevId: 632220870",Kyle Lucke,klucke@google.com,2024-05-09 18:43:03,third_party/xla/xla/stream_executor/stream_executor_pimpl.h,klucke,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632216657",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 18:30:56,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"When an HLO module is manually partitioned, infer a mesh shape to use rather than using the provided one. This wiill throw an error if auto-sharding infers multiple mesh shapes, but try_multiple_mesh_shapes=true.

PiperOrigin-RevId: 632213465",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 18:22:09,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_test.cc",tensorflower-gardener,False
"[NFC] Fix a typo.

PiperOrigin-RevId: 632211820",Bixia Zheng,bixia@google.com,2024-05-09 18:16:42,"third_party/xla/xla/service/collective_pipeliner.cc, third_party/xla/xla/service/collective_pipeliner.h, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.cc",bixia1,False
"Update DUCC to commit:aa46a4c21e440b3d416c16eca3c96df19c74f316

PiperOrigin-RevId: 632209124",Antonio Sanchez,cantonios@google.com,2024-05-09 18:09:19,"third_party/ducc/workspace.bzl, third_party/xla/third_party/tsl/third_party/ducc/workspace.bzl",cantonios,False
"[XLA:GPU] Clang-tidy fixes for xla/service/gpu/ir_emitter_unnested.cc

PiperOrigin-RevId: 632204822",Kuy Mainwaring,kuym@google.com,2024-05-09 17:57:26,third_party/xla/xla/service/gpu/ir_emitter_unnested.cc,kuym,False
"[IFRT] Rename `xla::ifrt::IoCallable` to `xla::ifrt::CustomCall`

Based on a discussion on the expected semantics of ""I/O callable"", we change
its name to ""IFRT custom call"" (""IfrtCustomCall"" wherever a single word is
preferred) in the IFRT API level. Its C++ type name will use
`xla::ifrt::CustomCall` as the prefix instead of `xla::ifrt::IoCallable`.

A high-level API that uses IFRT custom call may use a different name depending
on what features they offer.

PiperOrigin-RevId: 632200290",Hyeontaek Lim,hyeontaek@google.com,2024-05-09 17:44:17,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/custom_call_program.cc, third_party/xla/xla/python/ifrt/custom_call_program.h, third_party/xla/xla/python/ifrt/custom_call_program.proto, third_party/xla/xla/python/ifrt/custom_call_program_serdes.cc, third_party/xla/xla/python/ifrt/custom_call_program_serdes_test.cc",hyeontaek,False
"Add `bzl_libraries` to XLA

PiperOrigin-RevId: 632191909",David Dunleavy,ddunleavy@google.com,2024-05-09 17:20:29,"third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/build_defs.bzl, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/build_defs.bzl, third_party/xla/xla/tsl/BUILD, third_party/xla/xla/tsl/tsl.bzl, third_party/xla/xla/tsl/tsl.default.bzl, third_party/xla/xla/xla.bzl",ddunl,False
Update NCHW data format unit test,Yimei Sun,yimei.sun@intel.com,2024-05-09 17:18:26,tensorflow/python/tools/optimize_for_inference_test.py,yimeisun123,True
"Raise error when weight decay is set in TPUEmbeddingV2.

PiperOrigin-RevId: 632188699",Ziyin Huang,ziyinh@google.com,2024-05-09 17:10:53,"tensorflow/python/tpu/tpu_embedding_v3.py, tensorflow/python/tpu/tpu_embedding_v3_test.py",pineapplejuice233,False
"Test FFI Custom Call dimensions

PiperOrigin-RevId: 632179711",Paweł Paruzel,paruzelp@google.com,2024-05-09 16:43:13,third_party/xla/xla/tests/custom_call_test.cc,pparuzel,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632172505",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 16:18:54,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Revert gpu_delegate: Update GPU MUL compatibility checker

Reverts 0a1a2f68de95cda539858eaf1dddbe512dbac4db

PiperOrigin-RevId: 632164821",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 15:52:59,tensorflow/lite/tools/versioning/gpu_compatibility.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632140188",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 14:17:57,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Reverts f9919953244be9cc85e2e9c96751fa0ad63aaa5d

PiperOrigin-RevId: 632133418",Peter Hawkins,phawkins@google.com,2024-05-09 13:48:13,"third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/python/py_array.cc",hawkinsp,False
"[XLA:FFI] Add a `BufferShape` alias.

This change introduces a `BufferShape` alias for custom call users' convenience. This new alias eliminates the need for verbose code such as `using Shape = decltype(Buffer<PrimitiveType::F32>::dimensions)`.

PiperOrigin-RevId: 632119253",Adam Banaś,adambanas@google.com,2024-05-09 12:47:51,third_party/xla/xla/ffi/ffi.h,Adam-Banas,False
"Automated Code Change

PiperOrigin-RevId: 632113739",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 12:20:34,third_party/xla/xla/tsl/distributed_runtime/rpc/grpc_util.h,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632113484",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 12:19:11,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632107629",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 11:49:27,"tensorflow/dtensor/mlir/device_mesh_cluster_coarsening.cc, tensorflow/dtensor/mlir/dtensor_multi_device_expansion.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632103808",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 11:27:58,tensorflow/core/kernels/sparse/transpose_op.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632099660",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 11:05:19,tensorflow/dtensor/mlir/restore_shape_inference.cc,tensorflower-gardener,False
"Cover Result<T> with buffer aliases

PiperOrigin-RevId: 632095141",Paweł Paruzel,paruzelp@google.com,2024-05-09 10:41:06,third_party/xla/xla/ffi/api/ffi.h,pparuzel,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632090531",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 10:17:50,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632084206",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 09:47:23,tensorflow/c/eager/c_api_unified_experimental.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632084077",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 09:46:49,third_party/xla/xla/hlo/evaluator/hlo_evaluator.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632080560",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 09:27:36,tensorflow/dtensor/mlir/expansions/reduce_spmd_expander.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632078825",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 09:17:56,third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632078392",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 09:16:15,third_party/xla/xla/stream_executor/tpu/tpu_executor.cc,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-09

PiperOrigin-RevId: 632075211",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 09:01:57,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1857.

PiperOrigin-RevId: 632075210",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 09:01:57,tensorflow/core/public/version.h,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632066521",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 08:18:03,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 632064028",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 08:05:52,tensorflow/c/eager/c_api.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632042689",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 06:17:33,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Change weight-only PTQ to use symmetric quantization

This is to conform to the constraints of zero points being zero on rhs of quantized stablehlo.dot_general op. (dot_general C15 in https://github.com/openxla/stablehlo/blob/main/docs/spec.md#constraints-29)

PiperOrigin-RevId: 632036603",Doyeon Kim,doyeonkim@google.com,2024-05-09 05:44:20,"tensorflow/compiler/mlir/quantization/stablehlo/ops/stablehlo_op_quant_spec.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/insert_weight_param.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/insert_weight_param.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions_weight_only.mlir",doyeonkim0,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 632021485",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 04:18:09,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"gpu_delegate: Update GPU MUL compatibility checker

ADD, MUL only works when two inputs has the same number of dimension on GPU.
Make sure if the condition is checked properly.

PiperOrigin-RevId: 632015698",Terry Heo,terryheo@google.com,2024-05-09 03:44:16,tensorflow/lite/tools/versioning/gpu_compatibility.cc,terryheo,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631998285",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 02:17:52,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix shape mismatch when handling reshape in SPMD partitioner.

1. Move shape check for reshape from `HloInstruction::CreateShape` into the constructor, so that illegal reshape is caught at creation time from clone.
2. Enhance `hlo_sharding_util::ReshapeSharding`. It can handle the cases where
* `source_shape_size % source_tile_size == 0`
* `source_shape_size % target_shape_size == 0`
* `(source_tile_size % target_shape_size != 0) || (target_shape_size % source_tile_size != 0)`
3. Enhance `SpmdPartitioningVisitor::HandleReshape`. Unify the two cases in one lambda function. It attempts the original output sharding and then the desired output sharding.

PiperOrigin-RevId: 631996882",Zixuan Jiang,zixuanjiang@google.com,2024-05-09 02:09:10,"third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util_test.cc, third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc",ZixuanJiang,False
"[hlo] Verify that aliased parameters and results have identical layouts in the entry computation layout

PiperOrigin-RevId: 631994475",Eugene Zhulenev,ezhulenev@google.com,2024-05-09 01:56:55,"third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/hlo_verifier_test.cc",ezhulenev,False
"[mhlo] Remove called computation and execution thread from async_update and async_done
For consistency with HLO counterpart get called computation and execution thread by following the async chain.

PiperOrigin-RevId: 631993921",Eugene Zhulenev,ezhulenev@google.com,2024-05-09 01:53:48,"third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder.h, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.cc, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.td, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-stablehlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/ops.mlir, third_party/xla/xla/translate/hlo_to_mhlo/tests/import.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/import_async.hlotxt, third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc, third_party/xla/xla/translate/mhlo_to_hlo/tests/export.mlir",ezhulenev,False
"[xla:ffi] Add xla::ffi::ExecutionContext to pass user data to FFI handlers at run time

There are two kinds of data that can be added to execution context:
1. Opaque pointers with a deleter for users that register context types that are can be defined in shared libraries and can't depend on XLA internals
2. Types ExecutionContext::UserData for FFI handlers in the same process

Next step is to plumb execution context all the way up to xla::ExecuteOptions and PjRt

PiperOrigin-RevId: 631993077",Eugene Zhulenev,ezhulenev@google.com,2024-05-09 01:49:27,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/api/BUILD, third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/api/c_api_internal.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/execution_context.cc, third_party/xla/xla/ffi/execution_context.h, third_party/xla/xla/ffi/execution_context_test.cc, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_api.h, third_party/xla/xla/ffi/ffi_test.cc",ezhulenev,False
"[stream_executor:host] Rolling back HostExecutionEngine addition due to some binary size issues.

Reverts 15f8f10f345aa41475cd3b6cf2f162a2fb1aa152

PiperOrigin-RevId: 631984996",Penporn Koanantakool,penporn@google.com,2024-05-09 01:08:23,"third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_execution_engine.cc, third_party/xla/xla/stream_executor/host/host_execution_engine.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/host/host_kernel.cc, third_party/xla/xla/stream_executor/host/host_kernel.h, third_party/xla/xla/stream_executor/host/host_kernel_test.cc",penpornk,False
"[XLA:Python] Fix a memory corruption bug in the tp_name attribute of ArrayImpl and PjitFunction for Python 3.10 or earlier.

This works around https://github.com/python/cpython/issues/89478, which was fixed in Python 3.11.

PiperOrigin-RevId: 631984256",Peter Hawkins,phawkins@google.com,2024-05-09 01:04:40,"third_party/xla/xla/python/pjit.cc, third_party/xla/xla/python/py_array.cc",hawkinsp,False
"PR #12154: Scaling without Type Conversion for FP8 GEMMs

Imported from GitHub PR https://github.com/openxla/xla/pull/12154

Enables the fusion of the scaling of the result of an FP8 GEMM without subsequent type conversion into the Custom Call.
Copybara import of the project:

--
eb45e08558bb36c437be69d05421126b4252de94 by Philipp Hack <phack@nvidia.com>:

Fuses the scaling of the result of an FP8 GEMM into the Custom Call.

--
2ba2373862a73e954bd255a0df0eb93b0f5b43b5 by Philipp Hack <phack@nvidia.com>:

Fuses the scaling of the result of an FP8 GEMM into the Custom Call.

--
c7944fc3b2b7fdc45a06d058dea856fff2bd7e15 by Philipp Hack <phack@nvidia.com>:

Fuses the scaling of the result of an FP8 GEMM into the Custom Call.

Merging this change closes #12154

PiperOrigin-RevId: 631981184",Philipp Hack,phack@nvidia.com,2024-05-09 00:51:49,"third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc",philipphack,False
"Integrate StableHLO at openxla/stablehlo@8ba7728d

PiperOrigin-RevId: 631980341",Abhinav Gunjal,agunjal@google.com,2024-05-09 00:47:53,"tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf-quant.mlir, third_party/stablehlo/temporary.patch, third_party/stablehlo/workspace.bzl, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/workspace.bzl, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/mhlo-quant-legalize-to-int.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/ops.mlir",abhigunj,False
"Extend internal Span with more member functions

PiperOrigin-RevId: 631979198",Paweł Paruzel,paruzelp@google.com,2024-05-09 00:42:19,third_party/xla/xla/ffi/api/ffi.h,pparuzel,False
"Fixes `heap use after free` in passing a python `list()` as an `absl::Span` by passing as a `std::vector` instead

PiperOrigin-RevId: 631977962",Anshuman Goswami,anshumang@google.com,2024-05-09 00:36:05,third_party/xla/xla/python/xla.cc,anshumang,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631973755",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-09 00:17:47,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Introduce std::complex<T> as a new DataType

PiperOrigin-RevId: 631968244",Paweł Paruzel,paruzelp@google.com,2024-05-08 23:56:21,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/ffi.h",pparuzel,False
"[xla] NFC: Add tests for async custom call host offloader memory space propagation

PiperOrigin-RevId: 631967931",Eugene Zhulenev,ezhulenev@google.com,2024-05-08 23:54:52,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/host_offloader_test.cc",ezhulenev,False
"Update flatbuffers to 24.3.25

PiperOrigin-RevId: 631967585",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 23:53:23,"tensorflow/lite/acceleration/configuration/configuration_generated.h, tensorflow/lite/delegates/gpu/cl/compiled_program_cache_generated.h, tensorflow/lite/delegates/gpu/cl/serialization_generated.h, tensorflow/lite/delegates/gpu/common/gpu_model_generated.h, tensorflow/lite/delegates/gpu/common/task/serialization_base_generated.h, tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h, tensorflow/lite/schema/conversion_metadata_generated.h, tensorflow/lite/schema/schema_generated.h, tensorflow/lite/tools/cmake/modules/flatbuffers.cmake, tensorflow/tools/ci_build/release/requirements_common.txt, tensorflow/tools/pip_package/setup.py, tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt, third_party/flatbuffers/workspace.bzl",tensorflower-gardener,False
"Remove mlir roundtrip.

PiperOrigin-RevId: 631959980",Arturo Schmidt,arturoschmidt@google.com,2024-05-08 23:23:32,"tensorflow/compiler/mlir/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/BUILD, tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/tests/roundtrip-tf-executor.mlir, tensorflow/compiler/mlir/tensorflow/translate/BUILD, tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_pass.cc, tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_pass.h, tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_pass_registration.cc, tensorflow/python/BUILD",rocketas,False
"For nested full-to-shard we must also exclude SPMDShardToFullShape
because the hlo->sharding() and operand->sharding() will have conflicting
values for IsManualSubgroup().

PiperOrigin-RevId: 631952777",Parker Schuh,parkers@google.com,2024-05-08 22:59:57,"third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc",pschuh,False
"No public description

PiperOrigin-RevId: 631952018",Wilsin Gosti,wilsin@google.com,2024-05-08 22:57:12,tensorflow/core/data/dataset_utils.cc,wilsingosti,False
"Extends the TFLite Benchmarker to support multiple signatures.

PiperOrigin-RevId: 631947318",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 22:39:01,"tensorflow/lite/core/signature_runner.h, tensorflow/lite/testdata/string_input_model_with_signature.bin, tensorflow/lite/tools/benchmark/BUILD, tensorflow/lite/tools/benchmark/README.md, tensorflow/lite/tools/benchmark/benchmark_test.cc, tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc, tensorflow/lite/tools/benchmark/benchmark_tflite_model.h",tensorflower-gardener,False
"Configure autograph to not convert `tf_keras` code.

Fixes https://github.com/keras-team/tf-keras/issues/777

PiperOrigin-RevId: 631941146",Fabien Hertschuh,fhertschuh@google.com,2024-05-08 22:19:27,tensorflow/python/autograph/core/config.py,hertschuh,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631940651",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 22:18:01,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Unify StreamExecutorInterface::GetSymbol and StreamExecutor::GetUntypedSymbol.

PiperOrigin-RevId: 631936160",Kyle Lucke,klucke@google.com,2024-05-08 22:03:02,"third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/stream_executor/cuda/cuda_executor.cc, third_party/xla/xla/stream_executor/gpu/gpu_executor.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/rocm/rocm_executor.cc, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h",klucke,False
"[xla] NFC: Add tests for async custom call buffer assignment

PiperOrigin-RevId: 631935435",Eugene Zhulenev,ezhulenev@google.com,2024-05-08 22:00:44,third_party/xla/xla/service/buffer_assignment_test.cc,ezhulenev,False
"#tf-data Restores the `seed_generator_` and three seeds in global_shuffle_dataset_op.cc to ensure the iterator can generate the same result after restoring

PiperOrigin-RevId: 631932883",Jim Lin,jimlintw@google.com,2024-05-08 21:52:19,"tensorflow/core/kernels/data/experimental/global_shuffle_dataset_op.cc, tensorflow/core/kernels/data/iterator_ops.cc, tensorflow/python/data/experimental/kernel_tests/global_shuffle_test.py",jimlinntu,False
"[XLA:SPMD] Use the default way to call once and shard barrier custom-call registration instead of always linking it.

PiperOrigin-RevId: 631928144",Tongfei Guo,tongfei@google.com,2024-05-08 21:36:19,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/spmd/BUILD, third_party/xla/xla/service/spmd/shard_barrier_partitioner.cc",Tongfei-Guo,False
"Add missing absl random bit_gen_ref target

PiperOrigin-RevId: 631920259",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 21:10:07,"third_party/absl/system.absl.random.BUILD, third_party/xla/third_party/tsl/third_party/absl/system.absl.random.BUILD",tensorflower-gardener,False
"Reverts 4382439b2d4c6be4f93c509905513200d8ac7a5b

PiperOrigin-RevId: 631919121",Vamsi Manchala,vamsimanchala@google.com,2024-05-08 21:06:22,tensorflow/lite/g3doc/examples/keras/keras_jax_backend_to_tfl.ipynb,vamsimanchala,False
"[PJRT] Remove method alias PjRtClient::GetFullTopologyForCompilation.

PiperOrigin-RevId: 631915115",Peter Hawkins,phawkins@google.com,2024-05-08 20:54:23,third_party/xla/xla/pjrt/pjrt_client.h,hawkinsp,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631903263",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 20:18:19,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix stale comment on CreateSplitIntoIslandPerOpPass.

PiperOrigin-RevId: 631897585",Arturo Schmidt,arturoschmidt@google.com,2024-05-08 20:01:22,tensorflow/compiler/mlir/tensorflow/transforms/passes.h,rocketas,False
"Internal change, only affects BUILD files.

PiperOrigin-RevId: 631894583",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 19:52:37,tensorflow/lite/experimental/acceleration/mini_benchmark/BUILD,tensorflower-gardener,False
"Some preparation changes for enabling async dispatch on JAX CPU.

To prevent too much parallelism for non-parallel computations, we add a enqueue event to make sure next computation won't be enqueued until last one is done per user thread.

In `~PyArray_Storage()`, we now release the Python GIL then destroy the underlying buffer to prevent deadlock caused by interactions between argument donations and host callbacks on CPU backend.

PiperOrigin-RevId: 631887633",Yue Sheng,yueshengys@google.com,2024-05-08 19:28:46,"third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/python/py_array.cc",yueshengys,False
"Integrate LLVM at llvm/llvm-project@3a8316216807

Updates LLVM usage to match
[3a8316216807](https://github.com/llvm/llvm-project/commit/3a8316216807)

PiperOrigin-RevId: 631878634",Benjamin Kramer,kramerb@google.com,2024-05-08 19:00:34,"tensorflow/compiler/mlir/quantization/tensorflow/tests/quantize.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/quantize_drq.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/quantize_xla.mlir, third_party/llvm/workspace.bzl, third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-stablehlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/stablehlo-legalize-to-hlo.mlir",d0k,False
"Fix ""moving a temporary object prevents copy elision [-Werror,-Wpessimizing-move]"" error when compiling gpu_fused_mha_test with clang.

PiperOrigin-RevId: 631876424",Kyle Lucke,klucke@google.com,2024-05-08 18:53:23,third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc,klucke,False
"Make sure all TfLiteOperator's fields are initialized at construction

Field inplace_operator wasn't being initialized, most likely an omission.

PiperOrigin-RevId: 631875486",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 18:50:01,"tensorflow/lite/core/c/BUILD, tensorflow/lite/core/c/operator.cc",tensorflower-gardener,False
"Add pattern match and composite outlining for GELU.

PiperOrigin-RevId: 631871121",Luke Boyer,lukeboyer@google.com,2024-05-08 18:36:44,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/common/tfl_pass_config.h, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/BUILD, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/odml_converter_main.cc, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/passes.h, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/passes.td, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/tests/outline_composites.mlir, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/transforms/outline_composites.cc, tensorflow/compiler/mlir/lite/stablehlo/tests/composite-lowering.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_patterns.td, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_utils.td, tensorflow/compiler/mlir/lite/tf_tfl_passes.cc",LukeBoyer,False
"Fix asan error due to additional error logging

PiperOrigin-RevId: 631870090",Deqiang Chen,deqiangc@google.com,2024-05-08 18:33:36,tensorflow/core/tfrt/mlrt/interpreter/execute.cc,deqiangc,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631864481",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 18:18:22,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Reverts 604adec95479d271b86d993965a660ad6932d736

PiperOrigin-RevId: 631863025",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 18:14:22,"tensorflow/lite/g3doc/examples/keras/BUILD, tensorflow/lite/g3doc/examples/keras/keras_jax_backend_to_tfl.ipynb",tensorflower-gardener,False
"Jax to TFLite colab example,

PiperOrigin-RevId: 631830189",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 16:38:18,tensorflow/lite/g3doc/examples/jax_conversion/jax_to_tflite_resnet50.ipynb,tensorflower-gardener,False
"Fix a header path in libtensorflow_cpu.sh.

PiperOrigin-RevId: 631825696",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 16:24:57,tensorflow/tools/ci_build/windows/libtensorflow_cpu.sh,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631824538",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 16:20:53,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Limit runtime determined PTX version by compile time CUDA version

The previously introduced new PTX version logic determines
the supported PTX version based on the `ptxas` tool version at runtime.

If a user has a CUDA toolkit installed that is newer than what
XLA was compiled with we might set a PTX version that is not
supported by XLA/LLVM.

To avoid that this change determines the PTX version from the
minimum of both the compile time and the runtime CUDA version.

PiperOrigin-RevId: 631823378",Henning Becker,hebecker@google.com,2024-05-08 16:17:26,"third_party/xla/xla/service/gpu/llvm_gpu_backend/BUILD, third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc",beckerhe,False
"Add an example to demonstrate Keras(with JAX backend) to TFLite.

PiperOrigin-RevId: 631821076",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 16:09:15,"tensorflow/lite/g3doc/examples/keras/BUILD, tensorflow/lite/g3doc/examples/keras/keras_jax_backend_to_tfl.ipynb",tensorflower-gardener,False
"[GPU] Fix an issue with deallocating memory from the different allocator.

PiperOrigin-RevId: 631795671",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 14:38:32,"third_party/xla/xla/stream_executor/integrations/BUILD, third_party/xla/xla/stream_executor/integrations/tf_allocator_adapter.h, third_party/xla/xla/stream_executor/integrations/tf_allocator_adapter_test.cc",tensorflower-gardener,False
"This is an automatic update to a device compatibility allowlist.

PiperOrigin-RevId: 631794758",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 14:34:08,tensorflow/lite/experimental/acceleration/compatibility/gpu_compatibility.bin,tensorflower-gardener,False
"PR #11567: Allowing permutations of terms in //xla/service/gpu/fusions:transpose_mlir_test

Imported from GitHub PR https://github.com/openxla/xla/pull/11567

This expands the pattern matcher used by  //xla/service/gpu/fusions:transpose_mlir_test, so that it reports a match even if some terms are permuted. (Without the change, I see two subtests of this test fail on ROCm. With the change, the test passes there.)
Copybara import of the project:

--
72cfce5bc6c642475ffb79ce2c3c65ae86f9262a by Eugene Kuznetsov <eugene.kuznetsov@amd.com>:

Allowing permutations of terms in //xla/service/gpu/fusions:transpose_mlir_test

Merging this change closes #11567

PiperOrigin-RevId: 631792404",ekuznetsov139,nameless@fastmail.fm,2024-05-08 14:26:10,"third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc, third_party/xla/xla/service/gpu/model/indexing_test_utils.cc, third_party/xla/xla/service/gpu/model/indexing_test_utils.h",ekuznetsov139,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631790707",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 14:18:27,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"#tensorflow Skip failing test.

Error message:
```
[ RUN      ] QuantizedInstanceNormTest.TestClamp
tensorflow/core/kernels/quantized_instance_norm_test.cc:120: Failure
Expected: (max_diff()) <= (0.1), actual: 0.165527 vs 0.1
2024-05-06 18:40:43.391840: I tensorflow/core/kernels/quantized_instance_norm_test.cc:121] max diff 0.165527
[  FAILED  ] QuantizedInstanceNormTest.TestClamp (3 ms)
```
PiperOrigin-RevId: 631788097",Yang Chen,yangchen@google.com,2024-05-08 14:07:30,"tensorflow/core/kernels/BUILD, tensorflow/core/kernels/quantized_instance_norm_test.cc",yangustc07,False
"Make Blas version optional in HloAlgorithmDenylist

Most cuDNN algorithms nowadays don't call cuBlas kernels anymore,
so the Blas version is often not relevant when adding a new entry
to the denylist.

So this change makes it possible to leave the blas version field empty and it will just match any blas version.

It also does various cleanups:

- Consistent includes and dependencies
- Usage of GMock matchers in the tests
- Reenabling MSAN (works fine)

The original behaviour stays intact, so it shouldn't break any user of the denylist feature.

PiperOrigin-RevId: 631755311",Henning Becker,hebecker@google.com,2024-05-08 11:38:19,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/data/hlo_algorithm_denylist.pbtxt, third_party/xla/xla/service/gpu/hlo_algorithm_denylist.cc, third_party/xla/xla/service/gpu/hlo_algorithm_denylist.h, third_party/xla/xla/service/gpu/hlo_algorithm_denylist_test.cc",beckerhe,False
"Move fuel consumption point to an earlier stage in the cudnn fused convolution rewriter

The call to `ConsumeFuel` happened after `EnsureIfConvBiasActivation` had already rewritten
the convolution instruction. In order to effectively use `ConsumeFuel` for model
bisection I'm moving the check to before any changes are made to the instruction.

PiperOrigin-RevId: 631755068",Henning Becker,hebecker@google.com,2024-05-08 11:37:18,third_party/xla/xla/service/gpu/cudnn_fused_conv_rewriter.cc,beckerhe,False
"Automated Code Change

PiperOrigin-RevId: 631751925",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 11:23:44,third_party/xla/xla/pjrt/cpu/cpu_client.h,tensorflower-gardener,False
"PR #11241: [XLA:CPU] Enable BMM+Mul+Add for bf16

Imported from GitHub PR https://github.com/openxla/xla/pull/11241

This PR enable BatchMatmul + Mul + Add fusion for BF16 and also fixes a bug for the same.
Copybara import of the project:

--
abdbf9b89925c8553296122c846327b6dffa86ce by Kanvi Khanna <kanvi.khanna@intel.com>:

Enable BMM+Mul+Add for bf16

--
6674ac76b868f0399731d6185287eec76244df3a by Kanvi Khanna <kanvi.khanna@intel.com>:

fix test

--
8fb80082e8c545e007ab7a2d363eb7b7c251fd07 by Kanvi Khanna <kanvi.khanna@intel.com>:

address review comment, fix test, format

Merging this change closes #11241

PiperOrigin-RevId: 631745536",Kanvi Khanna,kanvi.khanna@intel.com,2024-05-08 11:01:49,"third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/tests/onednn_matmul_test.cc",kanvi-nervana,False
"PR #12224: [GPU] Fix handling of flags in the cuDNN FMHA test.

Imported from GitHub PR https://github.com/openxla/xla/pull/12224

The test got broken by https://github.com/openxla/xla/commit/8799ff0f4b2aa3437a9963f7c9968ee361a62fd7, this commit fixes it.
Copybara import of the project:

--
80528497321ee6020126b15035050f4c1a0beea9 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix handling of flags in the cuDNN FMHA test.

Merging this change closes #12224

PiperOrigin-RevId: 631744108",Ilia Sergachev,isergachev@nvidia.com,2024-05-08 10:57:47,"third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc",sergachev,False
"PR #12161: Test for deserialization of GPU executables

Imported from GitHub PR https://github.com/openxla/xla/pull/12161

This patch tests that serialization and deserialization of GPU executables
(e.g., for JAX compilation cache) succeeds.

The test covers the fix in [PR 12184](https://github.com/openxla/xla/pull/12184).

For completeness, PR 12184 fixes a problem where executable would be serialized
as ExecutableAndOptionsProto by PjRtStreamExecutorClient::SerializeExecutable, but
StreamExecutorGpuClient::DeserializeExecutable would first try to deserialize
as StreamExecutorExecutableProto and sometimes succeed, reading mangled data.
The test in this patch exercises one such example.
Copybara import of the project:

--
818765f7b1f5f7282d3f2756b2a03ac556201a6c by Jaroslav Sevcik <jsevcik@nvidia.com>:

Avoid deserializing GPU executables as StreamExecutorExecutableProto

Merging this change closes #12161

PiperOrigin-RevId: 631740399",Jaroslav Sevcik,jsevcik@nvidia.com,2024-05-08 10:46:18,third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler_aot_test.cc,jaro-sevcik,False
"Automated Code Change

PiperOrigin-RevId: 631736319",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 10:35:16,third_party/xla/xla/python/xla_compiler.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 631734629",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 10:30:26,"third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/kernel.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631729371",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 10:18:21,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 631714909",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 09:45:38,tensorflow/core/common_runtime/hierarchical_tree_broadcaster.cc,tensorflower-gardener,False
"Reverts f5ff2338e773ff179f53c9dc82870625d2a8d908

PiperOrigin-RevId: 631709823",Taehee Jeong,taeheej@google.com,2024-05-08 09:31:04,"tensorflow/compiler/tests/xla_ops_test.py, tensorflow/compiler/tf2xla/ops/BUILD, tensorflow/compiler/tf2xla/ops/xla_ops.cc",teijeong,False
"[XLA:GPU] Fix includes for collective_pipeliner.cc

PiperOrigin-RevId: 631705493",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-08 09:12:42,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/collective_pipeliner.cc",golechwierowicz,False
"compat: Update forward compatibility horizon to 2024-05-08

PiperOrigin-RevId: 631703379",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 09:03:22,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1856.

PiperOrigin-RevId: 631703016",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 09:02:11,tensorflow/core/public/version.h,tensorflower-gardener,False
"[XLA] Make HloReplicationAnalysis handle kOptimizationBarrier.

PiperOrigin-RevId: 631700466",Jinliang Wei,jlwei@google.com,2024-05-08 08:50:41,"third_party/xla/xla/service/hlo_replication_analysis.cc, third_party/xla/xla/service/hlo_replication_analysis_test.cc",jinliangwei,False
"PR #12243: Add Support for FP8 Data Types in cudnn_fusion_compiler.

Imported from GitHub PR https://github.com/openxla/xla/pull/12243

Copybara import of the project:

--
cee34b537bf34ba3413fa39d01f3267b50eb344a by Elfie Guo <elfieg@nvidia.com>:

Add support for FP8 datatype in cudnn_fusion_compiler.

Merging this change closes #12243

PiperOrigin-RevId: 631697234",Elfie Guo,elfieg@nvidia.com,2024-05-08 08:35:33,"third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc",elfiegg,False
"Automated Code Change

PiperOrigin-RevId: 631696961",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 08:33:57,tensorflow/tools/optimization/optimization_pass_runner.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631692930",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 08:17:31,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #12223: [GPU][NFC] Remove some uses of the deprecated runtime executable flag.

Imported from GitHub PR https://github.com/openxla/xla/pull/12223

Copybara import of the project:

--
64be02d67df35156d4ee55ce0d3fbe80eff148ea by Ilia Sergachev <isergachev@nvidia.com>:

[GPU][NFC] Remove some uses of the deprecated runtime executable flag.

Merging this change closes #12223

PiperOrigin-RevId: 631688048",Ilia Sergachev,isergachev@nvidia.com,2024-05-08 07:56:51,"third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter_test.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc",sergachev,False
"Disable numerically unstable cuDNN engine 14 for certain convolutions

A customer reported a numerical issue on V100 with cuDNN 9 that I as was able
to track down to a single convolution and cuDNN engine.

Using random data with this convolution gives me reasonable results, so it's not yet clear to me if this is a cuDNN issue or just unfortunate numerics.

For the time being let's disable the algorithm for this one convolution. The customer confirmed that it is fixing their issue.

PiperOrigin-RevId: 631681829",Henning Becker,hebecker@google.com,2024-05-08 07:26:37,third_party/xla/xla/service/gpu/hlo_algorithm_denylist.cc,beckerhe,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631667114",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 06:18:29,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add folding for integer types and all splat kinds for div op.

PiperOrigin-RevId: 631664574",Luke Boyer,lukeboyer@google.com,2024-05-08 06:05:52,"tensorflow/compiler/mlir/lite/stablehlo/odml_converter/folders.cc, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/tests/shlo_simplify.mlir",LukeBoyer,False
"Add Slice in `IsSupportedConstantExpression()` in `xla::HloConstantSplitter`.

A slice of a constant expression is also a constant expression.

PiperOrigin-RevId: 631659602",Zixuan Jiang,zixuanjiang@google.com,2024-05-08 05:40:18,"third_party/xla/xla/hlo/transforms/hlo_constant_splitter.cc, third_party/xla/xla/hlo/transforms/hlo_constant_splitter_test.cc",ZixuanJiang,False
"[HLO] Allow zero-operand kAfterAll

PiperOrigin-RevId: 631644903",Kevin Gleason,gleasonk@google.com,2024-05-08 04:18:11,"third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h, third_party/xla/xla/translate/mhlo_to_hlo/tests/export.mlir, third_party/xla/xla/translate/mhlo_to_hlo/tests/export_and_check_layouts.mlir",GleasonK,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631622965",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 02:17:41,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix variable naming pattern for quantization utility files.

Along with other readability fixes:

* Remove obsolete TODOs
* Raname obscure names
* Include missing header files.

PiperOrigin-RevId: 631619242",Dan Suh,dansuh@google.com,2024-05-08 01:56:46,"tensorflow/compiler/mlir/lite/quantization/ir/ConvertSimQuant.cc, tensorflow/compiler/mlir/quantization/common/ir/UniformSupport.cc, tensorflow/compiler/mlir/quantization/common/ir/UniformSupport.h, tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.cc",dansuh17,False
"Add `WaitAtBarrier` with subset of nodes to `DistributedRuntimeCoordinationServiceClient` and plumb that up to the JAX API layer.

PiperOrigin-RevId: 631617749",Anshuman Goswami,anshumang@google.com,2024-05-08 01:47:58,"third_party/xla/xla/pjrt/distributed/BUILD, third_party/xla/xla/pjrt/distributed/client.cc, third_party/xla/xla/pjrt/distributed/client.h, third_party/xla/xla/pjrt/distributed/client_server_test.cc, third_party/xla/xla/python/xla.cc, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_extension/__init__.pyi",anshumang,False
"Update DUCC to commit:15246e40cfa880c079606ce49bbf629b07fcf9cb

PiperOrigin-RevId: 631602828",Antonio Sanchez,cantonios@google.com,2024-05-08 00:33:44,"third_party/ducc/ducc.BUILD, third_party/ducc/workspace.bzl, third_party/xla/third_party/tsl/third_party/ducc/ducc.BUILD, third_party/xla/third_party/tsl/third_party/ducc/workspace.bzl",cantonios,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631599038",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-08 00:17:45,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Remove func_use_fallback_tensor in tf_to_tfrt

PiperOrigin-RevId: 631594233",Kuangyuan Chen,chky@google.com,2024-05-07 23:59:45,"tensorflow/compiler/mlir/tfrt/runtime_fallback/runtime_fallback_executor.cc, tensorflow/compiler/mlir/tfrt/tests/batch_function_lowering.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/attributes.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/basic.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/control_flow.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/decompose_resource_op.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/device_conversion.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/fallback.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/func_use_fallback_tensor.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/tf_to_corert_pipeline.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/tf_to_corert_pipeline_refvar.mlir, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/whileop.mlir, tensorflow/compiler/mlir/tfrt/tests/xla_launch_fallback.mlir, tensorflow/compiler/mlir/tfrt/tests/xla_launch_lowering.mlir, tensorflow/compiler/mlir/tfrt/transforms/tf_to_tfrt.cc, tensorflow/compiler/mlir/tfrt/transforms/tfrt_pipeline_options.h, tensorflow/compiler/mlir/tfrt/translate/import_model.cc",cky9301,False
"Add additional logging when unwinding error in mlrt

PiperOrigin-RevId: 631592577",Deqiang Chen,deqiangc@google.com,2024-05-07 23:53:22,"tensorflow/core/tfrt/graph_executor/graph_executor.cc, tensorflow/core/tfrt/mlrt/interpreter/BUILD, tensorflow/core/tfrt/mlrt/interpreter/async_handle.cc, tensorflow/core/tfrt/mlrt/interpreter/context.h, tensorflow/core/tfrt/mlrt/interpreter/context_test.cc, tensorflow/core/tfrt/mlrt/interpreter/execute.cc, tensorflow/core/tfrt/mlrt/kernel/batch_kernel.cc",deqiangc,False
"Remove unused `tools/ci_build/xla/`

PiperOrigin-RevId: 631579640",David Dunleavy,ddunleavy@google.com,2024-05-07 23:06:31,tensorflow/tools/ci_build/xla/linux/gpu/run_py3.sh,ddunl,False
"Add new `xla_internal` macro to `xla.bzl`

PiperOrigin-RevId: 631579468",David Dunleavy,ddunleavy@google.com,2024-05-07 23:06:03,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/tools/BUILD, third_party/xla/xla/xla.bzl",ddunl,False
"Update schema dependencies.

PiperOrigin-RevId: 631571210",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 22:37:08,"tensorflow/compiler/mlir/lite/quantization/lite/quantize_model.cc, tensorflow/compiler/mlir/lite/quantization/lite/quantize_model.h, tensorflow/compiler/mlir/lite/quantization/lite/quantize_weights.cc, tensorflow/compiler/mlir/lite/quantization/lite/quantize_weights.h, tensorflow/compiler/mlir/lite/quantization/lite/quantize_weights_test.cc, tensorflow/compiler/mlir/lite/sparsity/sparsify_model.h, tensorflow/compiler/mlir/lite/transforms/legalize_tensorlist.cc, tensorflow/compiler/mlir/lite/utils/const_tensor_utils.cc, tensorflow/compiler/mlir/lite/utils/const_tensor_utils.h, tensorflow/compiler/mlir/lite/utils/convert_type.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631565408",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 22:18:09,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix LOGFATAL for logical_buffer access with invalid id

PiperOrigin-RevId: 631562933",Yin Zhang,yinzz@google.com,2024-05-07 22:09:48,tensorflow/core/profiler/convert/hlo_proto_to_memory_visualization_utils.cc,zzzaries,False
"Adjust rtol value for confirming quantization.

Fixed for better readability.
This constraint should be enough to test whether a f32 value dequantized from i8 was changed.

PiperOrigin-RevId: 631559455",Jiyoun (Jen) Ha,jiyounha@google.com,2024-05-07 21:58:43,tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py,chococigar,False
"[xla] functional_hlo_runner_test: add CPU backend

PiperOrigin-RevId: 631557531",Emilio Cota,ecg@google.com,2024-05-07 21:52:26,"third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner_test.cc",cota,False
"Make StreamExecutorMemoryAllocator work in terms of StreamExecutorInterface instead of StreamExecutor.

PiperOrigin-RevId: 631556982",Kyle Lucke,klucke@google.com,2024-05-07 21:50:27,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/backend.cc, third_party/xla/xla/service/shaped_buffer_test.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/device_memory_allocator.cc, third_party/xla/xla/stream_executor/device_memory_allocator.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h, third_party/xla/xla/tests/buffer_donation_test.cc, third_party/xla/xla/tests/cpu_gpu_fusion_test.cc, third_party/xla/xla/tests/dot_operation_test.cc, third_party/xla/xla/tests/dynamic_ops_test.cc, third_party/xla/xla/tests/local_client_execute_test.cc, third_party/xla/xla/tests/local_client_test_base.h, third_party/xla/xla/tests/while_test.cc",klucke,False
"Escape quote character into &quot; when sanitizing HTML

Some ops have quotes in their metadata and if not escaped these lead to errors when rendering a dot graph.

PiperOrigin-RevId: 631544105",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 21:09:49,third_party/xla/xla/service/hlo_graph_dumper.cc,tensorflower-gardener,False
"[XLA:GPU][MLIR-Based emitters] Fix canonicalization patterns for ApplyIndexingOp.

PiperOrigin-RevId: 631526519",Alexander Belyaev,pifon@google.com,2024-05-07 20:20:29,"third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/canonicalize.mlir, third_party/xla/xla/service/gpu/fusions/mlir/tests/invalid.mlir",pifon2a,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631526072",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 20:18:59,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix a test failure that occurs when we add new validation in swisstable.

We can't use swisstable here because this code requires an exception-safe hashtable so switch to std::unordered_map.

PiperOrigin-RevId: 631524388",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 20:13:15,third_party/xla/xla/pjrt/lru_cache.h,tensorflower-gardener,False
"Add metrics to compilesingleop and compilefunction.

PiperOrigin-RevId: 631523608",Arturo Schmidt,arturoschmidt@google.com,2024-05-07 20:10:50,"tensorflow/compiler/tf2xla/BUILD, tensorflow/compiler/tf2xla/xla_compiler.cc",rocketas,False
"[xla] functional_hlo_runner: fix handling of PJRT client with 0 memory spaces

PiperOrigin-RevId: 631512356",Emilio Cota,ecg@google.com,2024-05-07 19:34:40,third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc,cota,False
"[stream_executor:host] Add HostExecutionEngine

This is a part of the ongoing effort https://github.com/openxla/xla/issues/7234
Add:
- RuntimeExecutionEngine class which compiles LLVM IR into kernel. This is a simplified copy-paste from runtime/execution_engine
- HostExecutionEngine virtual base class which contains JIT-compiled function.
- LlvmExecutionEngine, which uses two classes above to compile LLVM IR and store result.
- Dummy CppExecutionEngine for kernels written in C++ and precompiled together with XLA.
- HostKernelTest.LlvmAddition test which verifies only compilation (for now).
PiperOrigin-RevId: 631506020",Vladyslav Tsilytskyi,tsilytskyi@google.com,2024-05-07 19:12:59,"third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_execution_engine.cc, third_party/xla/xla/stream_executor/host/host_execution_engine.h, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/host/host_kernel.cc, third_party/xla/xla/stream_executor/host/host_kernel.h, third_party/xla/xla/stream_executor/host/host_kernel_test.cc",tvladyslav,False
"Modify DirectPluginOpKernelContext constructor to get more type safety

PiperOrigin-RevId: 631505869",Samuel Agyakwa,sagyakwa@google.com,2024-05-07 19:12:24,"tensorflow/core/common_runtime/next_pluggable_device/BUILD, tensorflow/core/common_runtime/next_pluggable_device/direct_plugin_op_kernel.h, tensorflow/core/common_runtime/next_pluggable_device/plugin_op_kernel_helper.h",sagyakwa,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631495967",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 18:41:43,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add keyword ""_partitioned_"" into the partition graph dump filename

PiperOrigin-RevId: 631470588",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 17:31:27,tensorflow/core/common_runtime/process_function_library_runtime.cc,tensorflower-gardener,False
"Fix the bug that disable_table_stacking is not respected in TPUEmbeddingV2.

PiperOrigin-RevId: 631447524",Ziyin Huang,ziyinh@google.com,2024-05-07 16:23:02,"tensorflow/python/tpu/tpu_embedding_v3.py, tensorflow/python/tpu/tpu_embedding_v3_test.py",pineapplejuice233,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631446317",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 16:18:43,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Replace std::shared_ptr::unique() with use_count() == 1

std::shared_ptr::unique() has been removed from c++20
PiperOrigin-RevId: 631443441",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 16:08:14,tensorflow/core/graph/graph.cc,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@1d87465a0a95

Updates LLVM usage to match
[1d87465a0a95](https://github.com/llvm/llvm-project/commit/1d87465a0a95)

PiperOrigin-RevId: 631440895",Benjamin Kramer,kramerb@google.com,2024-05-07 15:59:39,third_party/llvm/workspace.bzl,d0k,False
Merge branch 'master' into yimei/fuse_old_bn,Yimei Sun,yimei.sun@intel.com,2024-05-07 16:04:49,".bazelrc, RELEASE.md, tensorflow/cc/saved_model/BUILD, tensorflow/compiler/aot/codegen.cc, tensorflow/compiler/aot/codegen_test_h.golden, tensorflow/compiler/aot/tfcompile.bzl, tensorflow/compiler/jit/xla_launch_util.cc, tensorflow/compiler/jit/xla_platform_info.cc, tensorflow/compiler/mlir/BUILD, tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/tests/device-transform-gpu.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/device-transform-nnapi.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/e2e/device-transform-nnapi.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/e2e/simple-graph.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/fold-constants-to-subgraph.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/get-alternative-subgraph.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/pick-subgraphs.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/raise-target-subgraphs.mlir, tensorflow/compiler/mlir/lite/flatbuffer_operator.cc, tensorflow/compiler/mlir/lite/ir/tfl_op_interfaces.td, tensorflow/compiler/mlir/lite/ir/tfl_ops.cc, tensorflow/compiler/mlir/lite/ir/tfl_ops.h, tensorflow/compiler/mlir/lite/json_to_flatbuffer.cc, tensorflow/compiler/mlir/lite/quantization/ir/QuantOpsBase.td, tensorflow/compiler/mlir/lite/quantization/lite/BUILD, tensorflow/compiler/mlir/lite/quantization/lite/quantize_model_test.cc, tensorflow/compiler/mlir/lite/quantization/lite/tfl_quantizer.cc, tensorflow/compiler/mlir/lite/quantization/tensorflow/tests/fallback_to_flex_ops_default.mlir, tensorflow/compiler/mlir/lite/quantization/tensorflow/tests/fallback_to_flex_ops_legacy.mlir, tensorflow/compiler/mlir/lite/quantization/tests/import_quant_stats.mlir, tensorflow/compiler/mlir/lite/schema/BUILD, tensorflow/compiler/mlir/lite/schema/README.md, tensorflow/compiler/mlir/lite/schema/schema.fbs, tensorflow/compiler/mlir/lite/sparsity/BUILD, tensorflow/compiler/mlir/lite/sparsity/sparsify_model_test.cc, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/BUILD, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/folders.cc, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/folders.h, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/passes.h, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/passes.td, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/tests/BUILD, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/tests/shlo_simplify.mlir, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/transforms/shlo_simplify.cc, tensorflow/compiler/mlir/lite/stablehlo/odml_to_stablehlo.cc, tensorflow/compiler/mlir/lite/stablehlo/tests/composite-lowering.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/legalize-stablehlo-tfl-composite.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/tfl_legalize_hlo.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/tfl_legalize_hlo_custom_call.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/lite/tests/canonicalize.mlir, tensorflow/compiler/mlir/lite/tests/const-fold.mlir, tensorflow/compiler/mlir/lite/tests/decompose-hybrid-quantization.mlir, tensorflow/compiler/mlir/lite/tests/default_quant_params.mlir, tensorflow/compiler/mlir/lite/tests/end2end/fake_quant_per_channel.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/fake_quant_per_channel_4bit.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/fake_quant_without_identity.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/fake_quant_without_identity_4bit.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/quant_stats.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/unroll_batch_matmul.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/unroll_batch_matmul_disabled.pbtxt, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/BUILD, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/basic_lstm.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/bucketize.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/constants.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/constants_offset.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/custom_op.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/custom_op_offset.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/external_constant.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/import_json.json, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/importer_test_min_max.cc, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/importer_test_min_max.cc.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/legacy_reshape.json, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/lstm.json, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/lstm.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/many_attribute_op.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/math.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/matmul.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/optional.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/optional_input.json, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/quant_stats.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/quantization.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/reshape.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/simple.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/variable.mlir, tensorflow/compiler/mlir/lite/tests/fuse-tftext.mlir, tensorflow/compiler/mlir/lite/tests/insert_call_once_op.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tensorlist.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf-hashtables.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf-no-runtime-verification.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf-variables.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf-while.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf.mlir, tensorflow/compiler/mlir/lite/tests/legalize_jax_random.mlir, tensorflow/compiler/mlir/lite/tests/mlir2flatbuffer/fake_quant.mlir, tensorflow/compiler/mlir/lite/tests/modify_io_nodes.mlir, tensorflow/compiler/mlir/lite/tests/ops.mlir, tensorflow/compiler/mlir/lite/tests/optimize.mlir, tensorflow/compiler/mlir/lite/tests/optimize_batch_matmul.mlir, tensorflow/compiler/mlir/lite/tests/optimize_no_verify.mlir, tensorflow/compiler/mlir/lite/tests/post-quantize-dynamic-range.mlir, tensorflow/compiler/mlir/lite/tests/post-quantize.mlir, tensorflow/compiler/mlir/lite/tests/prepare-composite-functions-tf.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize-dynamic-range.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize-post-training-16bits.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize-post-training.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize-signed.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize.mlir, tensorflow/compiler/mlir/lite/tests/prepare-tf-fake-quant-4bit.mlir, tensorflow/compiler/mlir/lite/tests/prepare-tf-fake-quant.mlir, tensorflow/compiler/mlir/lite/tests/prepare-tf.mlir, tensorflow/compiler/mlir/lite/tests/push-tpose-through-ewise.mlir, tensorflow/compiler/mlir/lite/tests/quantize-dynamic-range-float16.mlir, tensorflow/compiler/mlir/lite/tests/quantize-dynamic-range.mlir, tensorflow/compiler/mlir/lite/tests/quantize-numeric-verify.mlir, tensorflow/compiler/mlir/lite/tests/quantize-variables.mlir, tensorflow/compiler/mlir/lite/tests/quantize.mlir, tensorflow/compiler/mlir/lite/tests/shape-inference.mlir, tensorflow/compiler/mlir/lite/tests/split-merged-operands.mlir, tensorflow/compiler/mlir/lite/tests/tfl_while_outline.mlir, tensorflow/compiler/mlir/lite/tf_tfl_translate.cc, tensorflow/compiler/mlir/lite/tf_to_tfl_flatbuffer.cc, tensorflow/compiler/mlir/lite/transforms/optimize.cc, tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td, tensorflow/compiler/mlir/lite/transforms/prepare_patterns.td, tensorflow/compiler/mlir/lite/transforms/prepare_quantize_helper.h, tensorflow/compiler/mlir/lite/transforms/prepare_tf.cc, tensorflow/compiler/mlir/lite/utils/convert_type.h, tensorflow/compiler/mlir/lite/utils/tftext_utils_test.cc, tensorflow/compiler/mlir/lite/utils/utils.h, tensorflow/compiler/mlir/lite/utils/utils.td, tensorflow/compiler/mlir/python/mlir.cc, tensorflow/compiler/mlir/quantization/common/BUILD, tensorflow/compiler/mlir/quantization/common/ir/QuantOpsBase.td, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.h, tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/config.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/pass_pipeline.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/post_calibration.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/weight_only_ptq.cc, tensorflow/compiler/mlir/quantization/stablehlo/instrumentations/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/instrumentations/save_report.cc, tensorflow/compiler/mlir/quantization/stablehlo/instrumentations/save_report.h, tensorflow/compiler/mlir/quantization/stablehlo/instrumentations/save_report_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize_composite_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/convert_custom_aggregation_op_to_quant_stats.mlir, tensorflow/compiler/mlir/register_common_dialects.cc, tensorflow/compiler/mlir/runlit.cfg.py, tensorflow/compiler/mlir/runlit.site.cfg.py, tensorflow/compiler/mlir/tensorflow/ir/host_runtime/tfrt_ops.td, tensorflow/compiler/mlir/tensorflow/tests/cluster_outlining.mlir, tensorflow/compiler/mlir/tensorflow/tests/convert_to_legacy_compile_and_replicate_attributes.mlir, tensorflow/compiler/mlir/tensorflow/tests/tpu-resource-read-for-write.mlir, tensorflow/compiler/mlir/tensorflow/tests/tpu_cluster_formation.mlir, tensorflow/compiler/mlir/tensorflow/tests/tpu_rewrite.mlir, tensorflow/compiler/mlir/tensorflow/tests/tpu_validate_inputs.mlir, tensorflow/compiler/mlir/tensorflow/tests/xla_validate_inputs.mlir, tensorflow/compiler/mlir/tensorflow/tests/xla_validate_iputs.mlir, tensorflow/compiler/mlir/tensorflow/transforms/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/cluster_outlining.cc, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/tpu_rewrite_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/passes.h, tensorflow/compiler/mlir/tensorflow/transforms/tf_passes.td, tensorflow/compiler/mlir/tensorflow/transforms/tpu_resource_read_for_write.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_validate_inputs.cc, tensorflow/compiler/mlir/tensorflow/transforms/xla_validate_inputs.cc, tensorflow/compiler/mlir/tensorflow/translate/export_graphdef.cc, tensorflow/compiler/mlir/tensorflow/translate/export_graphdef.h, tensorflow/compiler/mlir/tensorflow/translate/export_tf_dialect_op.cc, tensorflow/compiler/mlir/tensorflow/translate/export_tf_dialect_op.h, tensorflow/compiler/mlir/tensorflow/translate/import_model.cc, tensorflow/compiler/mlir/tensorflow/translate/import_model.h, tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_flags.cc, tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_pass.cc, tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate.cc, tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate.h, tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate_registration.cc, tensorflow/compiler/mlir/tensorflow/utils/attribute_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/cluster_util_test.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_attr.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_attr.h, tensorflow/compiler/mlir/tensorflow/utils/convert_tensor.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_tensor.h, tensorflow/compiler/mlir/tensorflow/utils/convert_type.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_type.h, tensorflow/compiler/mlir/tensorflow/utils/export_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/export_utils.h, tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util.cc, tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util.h, tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util_test.cc, tensorflow/compiler/mlir/tensorflow/utils/translate_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/translate_utils.h, tensorflow/compiler/mlir/tensorflow/utils/xla_rewrite_util_test.cc, tensorflow/compiler/mlir/tf2xla/internal/clustering_bridge_passes.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/BUILD, tensorflow/compiler/mlir/tf2xla/internal/passes/clustering_passes.h, tensorflow/compiler/mlir/tf2xla/internal/passes/clustering_passes.td, tensorflow/compiler/mlir/tf2xla/internal/passes/extract_outside_compilation.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/input_lowering_metrics_pass.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_cluster_formation.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_sharding_identification_pass.cc, tensorflow/compiler/mlir/tf2xla/tests/hlo_xla_runtime_pipeline.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf.mlir, tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config_test.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf_patterns.td, tensorflow/compiler/mlir/tf2xla/transforms/test_utils.cc, tensorflow/compiler/mlir/tf2xla/transforms/test_utils.h, tensorflow/compiler/mlir/tf2xla/transforms/tf2xla_rewriter.cc, tensorflow/compiler/mlir/tf2xla/transforms/tf2xla_rewriter.h, tensorflow/compiler/mlir/tf2xla/transforms/tf2xla_rewriter_test.cc, tensorflow/compiler/mlir/tf2xla/transforms/xla_legalize_tf_test.cc, tensorflow/compiler/mlir/tf_mlir_opt_main.cc, tensorflow/compiler/mlir/tfr/integration/tfr_decompose_ctx.cc, tensorflow/compiler/mlir/tfrt/BUILD, tensorflow/compiler/mlir/tfrt/ir/BUILD, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_mlrt_ops.td, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_ops.td, tensorflow/compiler/mlir/tfrt/tests/ifrt/sink_variable_as_named_array.mlir, tensorflow/compiler/mlir/tfrt/tests/mlrt/rewrite_ifrt_load_variable.mlir, tensorflow/compiler/mlir/tfrt/tests/mlrt/tf_to_mlrt.mlir, tensorflow/compiler/mlir/tfrt/transforms/ifrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler.h, tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler_test.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/sink_variable_as_named_array.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/testdata/ifrt_cluster.mlir, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.h, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo_test.cc, tensorflow/compiler/mlir/tfrt/transforms/mlrt/import_model.cc, tensorflow/compiler/mlir/tfrt/transforms/mlrt/tf_to_mlrt.cc, tensorflow/compiler/mlir/tools/kernel_gen/kernel_creator.cc, tensorflow/compiler/mlir/tools/kernel_gen/tests/hlo_to_kernel/add_v2.mlir, tensorflow/compiler/mlir/tools/kernel_gen/tests/hlo_to_kernel/add_v2_unsigned.mlir, tensorflow/compiler/mlir/tools/kernel_gen/tests/hlo_to_kernel/minimum.mlir, tensorflow/compiler/mlir/tools/kernel_gen/tools/kernel-gen-opt/kernel-gen-opt.cc, tensorflow/compiler/mlir/tosa/tests/retain_call_once_funcs.mlir, tensorflow/compiler/mlir/tosa/tests/tf-to-tosa-pipeline.mlir, tensorflow/compiler/mlir/tosa/tests/tfl-to-tosa-pipeline-filtered.mlir, tensorflow/compiler/mlir/tosa/tests/tfl-to-tosa-pipeline.mlir, tensorflow/compiler/mlir/tosa/tests/tfl-to-tosa-stateful.mlir, tensorflow/compiler/mlir/tosa/transforms/legalize_common.cc, tensorflow/compiler/mlir/tosa/transforms/legalize_tf.cc, tensorflow/compiler/mlir/tosa/transforms/legalize_tfl.cc, tensorflow/compiler/tests/xla_ops_test.py, tensorflow/compiler/tf2xla/BUILD, tensorflow/compiler/tf2xla/ops/BUILD, tensorflow/compiler/tf2xla/ops/xla_ops.cc, tensorflow/compiler/tf2xla/xla_compiled_cpu_function.cc, tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h, tensorflow/compiler/tf2xla/xla_compiler.cc, tensorflow/compiler/tf2xla/xla_helpers.cc, tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.cc, tensorflow/core/common_runtime/cost_constants.h, tensorflow/core/common_runtime/gpu/gpu_device.cc, tensorflow/core/common_runtime/gpu/gpu_device.h, tensorflow/core/common_runtime/gpu/gpu_util.cc, tensorflow/core/data/BUILD, tensorflow/core/data/flat_map_utils.cc, tensorflow/core/data/flat_map_utils.h, tensorflow/core/data/service/dispatcher_impl.cc, tensorflow/core/framework/BUILD, tensorflow/core/framework/dataset.cc, tensorflow/core/framework/dataset.h, tensorflow/core/framework/device.h, tensorflow/core/framework/model.cc, tensorflow/core/framework/model.h, tensorflow/core/framework/model_test.cc, tensorflow/core/framework/tensor_slice.h, tensorflow/core/ir/importexport/convert_attributes.cc, tensorflow/core/ir/importexport/convert_attributes.h, tensorflow/core/ir/importexport/convert_tensor.cc, tensorflow/core/ir/importexport/convert_tensor.h, tensorflow/core/ir/importexport/convert_types.cc, tensorflow/core/ir/importexport/convert_types.h, tensorflow/core/ir/importexport/functiondef_export.cc, tensorflow/core/ir/importexport/functiondef_export.h, tensorflow/core/ir/importexport/functiondef_import.cc, tensorflow/core/ir/importexport/graphdef_export.cc, tensorflow/core/ir/importexport/graphdef_export.h, tensorflow/core/ir/importexport/graphdef_import.cc, tensorflow/core/ir/importexport/graphdef_import.h, tensorflow/core/ir/importexport/savedmodel_import.cc, tensorflow/core/ir/importexport/savedmodel_import.h, tensorflow/core/kernels/BUILD, tensorflow/core/kernels/cwise_ops.h, tensorflow/core/kernels/data/BUILD, tensorflow/core/kernels/data/experimental/BUILD, tensorflow/core/kernels/data/experimental/global_shuffle_dataset_op.cc, tensorflow/core/kernels/data/experimental/random_dataset_op.cc, tensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc, tensorflow/core/kernels/data/experimental/unbatch_dataset_op.cc, tensorflow/core/kernels/data/experimental/weighted_flat_map_dataset_op.cc, tensorflow/core/kernels/data/flat_map_dataset_op.cc, tensorflow/core/kernels/data/parallel_batch_dataset_op.cc",yimeisun123,True
Update data format test case to check fusion result only,Yimei Sun,yimei.sun@intel.com,2024-05-07 16:04:06,"tensorflow/python/tools/BUILD, tensorflow/python/tools/optimize_for_inference_test.py",yimeisun123,True
"Removed package visibilities.

PiperOrigin-RevId: 631435363",Dateng Lin,datenglin@google.com,2024-05-07 15:37:45,"tensorflow/compiler/mlir/tfrt/translate/mlrt/BUILD, tensorflow/core/tfrt/mlrt/bytecode/BUILD, tensorflow/core/tfrt/mlrt/interpreter/BUILD, tensorflow/core/tfrt/mlrt/kernel/BUILD",,False
"Reverts a9d16d74e371449f7314afdca0f433f4ac7dcf03

PiperOrigin-RevId: 631430500",Jacques Pienaar,jpienaar@google.com,2024-05-07 15:20:32,"tensorflow/compiler/tests/xla_ops_test.py, tensorflow/compiler/tf2xla/ops/BUILD, tensorflow/compiler/tf2xla/ops/xla_ops.cc",jpienaar,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631414019",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 14:18:13,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU] Extend the current while loop double buffering strategy to unroll the entire loop.

Apply the current double buffering strategy to fully unroll the loop.
This opens up opportunities for:
1. Better compilation time in comparison to unrolling at the framework level.
2. We can get rid of the loop structure if trip count is 1.
3. As a consequence of 2. latency hiding scheduler does not have to worry about iteration optimization barrier.
4. As a consequence of 2. we open up opportunities for strength reduction, and additional algebraic simplifcations.
5. We do not OOM with current buffer assignment scheme due to strict control of predecessors/successors.

PiperOrigin-RevId: 631412931",Greg Olechwierowicz,olechwierowicz@google.com,2024-05-07 14:13:45,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/loop_double_buffer_transformer.cc, third_party/xla/xla/service/gpu/loop_double_buffer_transformer.h, third_party/xla/xla/service/gpu/loop_double_buffer_transformer_test.cc",golechwierowicz,False
"PR #12195: [GPU][NFC] Simplify generation of cuDNN uid-pointer maps.

Imported from GitHub PR https://github.com/openxla/xla/pull/12195

Copybara import of the project:

--
484b7b1e0c74caad30a29e4d7b0dee801830c10e by Ilia Sergachev <isergachev@nvidia.com>:

[GPU][NFC] Simplify generation of cuDNN uid-pointer maps.

Merging this change closes #12195

PiperOrigin-RevId: 631407737",Ilia Sergachev,isergachev@nvidia.com,2024-05-07 13:52:36,third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc,sergachev,False
"Avoid large operands in constant folding.

We already have code that counts the total size of operands. However it still
has a check that the number of users of an operand is 1. This stems from a time
where we tried to evaluate whether constant folding will reduce the total
memory size, so if there was more than 1 user, it should not be counted, as the
operand will remain. But with the current code it makes no sense at all.

PiperOrigin-RevId: 631403307",Adrian Kuegel,akuegel@google.com,2024-05-07 13:32:28,"third_party/xla/xla/service/hlo_constant_folding.cc, third_party/xla/xla/service/hlo_constant_folding_test.cc",akuegel,False
"[XLA:GPU] Fix in-place dynamic update slice emitter for producer-consumer fusion.

For a case when we have a potential dus-producer and bitcast-consumer fusion, the current code wouldn't see that we can use DUS emitter and will use cost model as for loop emitter.

PiperOrigin-RevId: 631391738",Oleg Shyshkov,shyshkov@google.com,2024-05-07 12:46:22,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/copy_fusion.cc, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_test.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.h, third_party/xla/xla/service/gpu/ir_emission_utils.cc, third_party/xla/xla/service/gpu/ir_emission_utils.h",olegshyshkov,False
"Automated Code Change

PiperOrigin-RevId: 631390331",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 12:37:56,"third_party/xla/xla/stream_executor/tpu/BUILD, third_party/xla/xla/stream_executor/tpu/c_api_conversions.cc, third_party/xla/xla/stream_executor/tpu/c_api_conversions.h, third_party/xla/xla/stream_executor/tpu/c_api_conversions_test.cc, third_party/xla/xla/stream_executor/tpu/tpu_executable.cc, third_party/xla/xla/stream_executor/tpu/tpu_executable.h, third_party/xla/xla/stream_executor/tpu/tpu_executable_interface.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.h, third_party/xla/xla/stream_executor/tpu/tpu_node_context.cc, third_party/xla/xla/stream_executor/tpu/tpu_node_context.h, third_party/xla/xla/stream_executor/tpu/tpu_on_demand_compiler.cc, third_party/xla/xla/stream_executor/tpu/tpu_op_executable.cc, third_party/xla/xla/stream_executor/tpu/tpu_op_executable.h, third_party/xla/xla/stream_executor/tpu/tpu_platform.cc, third_party/xla/xla/stream_executor/tpu/tpu_platform.h, third_party/xla/xla/stream_executor/tpu/tpu_platform_id.cc, third_party/xla/xla/stream_executor/tpu/tpu_topology.cc, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager.cc, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager.h, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager_interface.cc, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager_interface.h, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager_registration.cc",tensorflower-gardener,False
"[XLA] Add pattern matchers for AsyncStart and AsyncDone.

PiperOrigin-RevId: 631390204",Victor Stone,victorstone@google.com,2024-05-07 12:37:11,third_party/xla/xla/service/pattern_matcher.h,SandSnip3r,False
"Support MOF with variadic reductions.

I thought this wasn't a thing. It is a thing.

PiperOrigin-RevId: 631387178",Johannes Reifferscheid,jreiffers@google.com,2024-05-07 12:24:08,"third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/mlir/type_util.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",jreiffers,False
"PR #12185: [ROCM] fixing smale build brakes in RedzoneAllocator, rocm_dnn and hip_blas_lt

Imported from GitHub PR https://github.com/openxla/xla/pull/12185

Here are fixes after the following PRs:
- rocm_dnn AllocateOwnedArray: https://github.com/openxla/xla/pull/11654
- hipblas_lt: https://github.com/openxla/xla/issues/11514
- and also RedzoneAllocator: https://github.com/openxla/xla/commit/d8f0c1acdb79c18cdce0a050b1d7c6baa8b9f14b

@xla-rotation: could you please have a look ?

Copybara import of the project:

--
4ad8abec5e0d0135f0844ae9e6acafc10ed84092 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

fixing build brakes

Merging this change closes #12185

PiperOrigin-RevId: 631387016",pemeliya,141146080+pemeliya@users.noreply.github.com,2024-05-07 12:23:16,"third_party/xla/xla/stream_executor/gpu/redzone_allocator_kernel_rocm.cu.cc, third_party/xla/xla/stream_executor/rocm/hip_blas_lt.cc, third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc",pemeliya,False
"[XLA:GPU] Disable cuDNN FMHA by default.

cuDNN FMHA dispatches pattern-matched regions to a FlashAttention kernel by
default. FlashAttention does not preserve numerics, and thus an illegal
optimization to have on by default.

PiperOrigin-RevId: 631384623",Benjamin Chetioui,bchetioui@google.com,2024-05-07 12:11:30,third_party/xla/xla/debug_options_flags.cc,bchetioui,False
"Automated Code Change

PiperOrigin-RevId: 631384217",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 12:09:49,tensorflow/compiler/mlir/tf2xla/internal/mlir_bridge_pass_util.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 631381481",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 12:00:41,tensorflow/core/tpu/tpu_compile.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 631377379",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 11:40:30,tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate.cc,tensorflower-gardener,False
"PR #12193: [GPU] Move workspace to be the last operand of cuDNN FMHA.

Imported from GitHub PR https://github.com/openxla/xla/pull/12193

This will enable a large simplification in a next PR.
Copybara import of the project:

--
ad747544396d4920e60946d7a0f00300f47e07d2 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Move workspace to be the last operand of cuDNN FMHA.

Merging this change closes #12193

PiperOrigin-RevId: 631375088",Ilia Sergachev,isergachev@nvidia.com,2024-05-07 11:28:33,"third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter_test.cc, third_party/xla/xla/service/gpu/cudnn_workspace_rewriter.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc",sergachev,False
"[XLA:GPU][NFC] Make GpuCompilerTest.CollectivePermuteDecompositionAndPipelining less brittle.

Previously, the test was relying on both

1. exact instruction names, and
2. explicit ordering of many pure and re-orderable HLO operations.

Both of these things can not be relied upon for testing, and this came up
as a blocker when trying to remove passes from the pipeline.

This change removes all the matches on exact instruction names and minimizes
the number of instructions that need to be explicitly ordered---while aiming
to preserve the spirit of the test.

PiperOrigin-RevId: 631366357",Benjamin Chetioui,bchetioui@google.com,2024-05-07 10:49:38,third_party/xla/xla/service/gpu/gpu_compiler_test.cc,bchetioui,False
"PR #12199: [XLA:GPU] only enable cudnn fmha dbias on hopper + cudnn 8.9.6

Imported from GitHub PR https://github.com/openxla/xla/pull/12199

Dbias requires hopper + cudnn 8.9.6, hence this PR.
Copybara import of the project:

--
ba4d8f507b1bae75d249fae1bf3d84c4e57199fa by cjkkkk <ske@nvidia.com>:

init

--
68978ddc378c6a5a891187a043fc2a696c45f478 by cjkkkk <ske@nvidia.com>:

fix rewriter test

Merging this change closes #12199

PiperOrigin-RevId: 631362869",Shanbin Ke,ske@nvidia.com,2024-05-07 10:32:19,"third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter_test.cc, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc",Cjkkkk,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631360618",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 10:23:53,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU][NFC] Fix header inclusion in `gpu_compiler_test`.

PiperOrigin-RevId: 631360321",Benjamin Chetioui,bchetioui@google.com,2024-05-07 10:22:43,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_compiler_test.cc",bchetioui,False
"Add support for the --xla_dump_module_metadata flag to GPU backend.

So far, this flag was only used for the TPU backend, but it can be useful for
the GPU backend, too. The module metadata dump contains timing information for
every HLO pass together with the pass name, the pipeline name and whether the
module was changed by the pass.

PiperOrigin-RevId: 631354517",Adrian Kuegel,akuegel@google.com,2024-05-07 09:57:01,third_party/xla/xla/service/gpu/gpu_compiler.cc,akuegel,False
"compat: Update forward compatibility horizon to 2024-05-07

PiperOrigin-RevId: 631341584",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 09:03:09,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1855.

PiperOrigin-RevId: 631341259",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 09:02:09,tensorflow/core/public/version.h,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631331200",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 08:19:13,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[xla:ffi] Port PJRT CPU test to use FFI API

Port cpu_client_test to use FFI API (new, type-safe custom call API).

PiperOrigin-RevId: 631331173",Adam Banaś,adambanas@google.com,2024-05-07 08:19:03,"third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/cpu_client_test.cc",Adam-Banas,False
"[xla:ffi] Port LLVM IR CPU test to use FFI API

Port alias_analysis_test to use FFI API (new, type-safe custom call API).

PiperOrigin-RevId: 631327968",Adam Banaś,adambanas@google.com,2024-05-07 08:05:03,"third_party/xla/xla/service/llvm_ir/BUILD, third_party/xla/xla/service/llvm_ir/alias_analysis_test.cc",Adam-Banas,False
"Add TensorFlow Shape Inference on XlaGather

Copy shape inference logic from Shape inference of Gather in XLA [1]. This makes grappler to properly infer shapes. The Grappler only relies on TensorFlow shape inference, and it invalidates all previously inferred shapes saved in `_output_shapes` attribute.

[1] https://github.com/openxla/xla/blob/3cce1630d278c56d1c0edf0b898cee3be2e01cbc/xla/service/shape_inference.cc#L3862

PiperOrigin-RevId: 631322920",Taehee Jeong,taeheej@google.com,2024-05-07 07:43:40,"tensorflow/compiler/tests/xla_ops_test.py, tensorflow/compiler/tf2xla/ops/BUILD, tensorflow/compiler/tf2xla/ops/xla_ops.cc",teijeong,False
"Move minimum_broadcast_shapes op from CHLO to MHLO

The op is only needed by KernelGen, and must be removed from CHLO as per the Dynamism 101 RFC: https://github.com/openxla/stablehlo/blob/main/rfcs/20230704-dynamism-101.md#p1

PiperOrigin-RevId: 631319464",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-07 07:27:17,"tensorflow/compiler/mlir/tools/kernel_gen/tests/hlo_to_kernel/add_v2.mlir, tensorflow/compiler/mlir/tools/kernel_gen/tests/hlo_to_kernel/add_v2_unsigned.mlir, tensorflow/compiler/mlir/tools/kernel_gen/tests/hlo_to_kernel/minimum.mlir, tensorflow/core/kernels/mlir_generated/op_definitions/add_v2.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/atan2.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/bitwise_and.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/bitwise_or.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/bitwise_xor.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/complex.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/div.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/div_no_nan.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/div_no_nan_cmplx.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/equal.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/floor_div.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/floor_div_float.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/floor_mod.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/floor_mod_float.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/floor_mod_unsigned.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/greater.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/greater_equal.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/left_shift.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/less.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/less_equal.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/logical_and.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/logical_or.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/maximum.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/minimum.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/mul.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/mul_no_nan.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/mul_no_nan_cmplx.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/next_after.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/not_equal.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/polygamma.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/pow.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/right_shift.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/right_shift_unsigned.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/select_v2.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/squared_difference.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/sub.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/truncate_div.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/truncate_div_float.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/xdivy.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/xdivy_cmplx.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/xlog1py.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/xlog1py_cmplx.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/xlogy.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/xlogy_cmplx.mlir.tmpl, tensorflow/core/kernels/mlir_generated/op_definitions/zeta.mlir.tmpl, third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.cc, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.td, third_party/xla/xla/mlir_hlo/mhlo/transforms/chlo_legalize_to_hlo/chlo_legalize_to_hlo_pass.cc, third_party/xla/xla/mlir_hlo/tests/bufferize.mlir, third_party/xla/xla/mlir_hlo/transforms/bufferize.cc, third_party/xla/xla/mlir_hlo/transforms/bufferize_pass.cc, third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",mlevesquedion,False
"Automated Code Change

PiperOrigin-RevId: 631315340",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 07:08:08,"third_party/xla/xla/BUILD, third_party/xla/xla/shape_layout.cc, third_party/xla/xla/shape_util.cc, third_party/xla/xla/shape_util_test.cc, third_party/xla/xla/sharding_op_util.cc, third_party/xla/xla/status_macros.cc, third_party/xla/xla/status_macros.h, third_party/xla/xla/status_macros_test.cc",tensorflower-gardener,False
"Report a failure when detecting single-core TPU graphs in TF2XLA Replicated Phase 1 Bridge

JIT compilation of single-core TPU graphs via Phase 1 Bridge is no longer supported as Pepperjack M1 gets deprecated. This ensures such graphs are no longer passed into the Bridge.

PiperOrigin-RevId: 631309237",Jian Cai,jiancai@google.com,2024-05-07 06:42:22,"tensorflow/compiler/mlir/tensorflow/tests/tpu_validate_inputs.mlir, tensorflow/compiler/mlir/tensorflow/transforms/tpu_validate_inputs.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/testdata/ifrt_cluster.mlir",jcai19,False
"Avoid adding duplicate multi-output fusion outputs.

When the consumer fusion has a parameter as fusion output, it gets replaced
with the clone of the instruction to be fused. In such a case, there is no need
to also add the clone as new fusion output.

PiperOrigin-RevId: 631304933",Adrian Kuegel,akuegel@google.com,2024-05-07 06:22:12,"third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/service/hlo_instruction_test.cc",akuegel,False
"Support MultiOutputFusion producers in the GPU performance model

PiperOrigin-RevId: 631304666",Adrian Kuegel,akuegel@google.com,2024-05-07 06:20:43,"third_party/xla/xla/service/gpu/model/gpu_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_test.cc",akuegel,False
"Automated Code Change

PiperOrigin-RevId: 631302361",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 06:08:33,"tensorflow/core/util/bcast.h, tensorflow/core/util/einsum_op_util.cc, tensorflow/core/util/einsum_op_util.h",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631281680",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 04:19:14,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631259101",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 02:17:54,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Cleanup DotAttention XNNPACK node.

PiperOrigin-RevId: 631255498",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 01:56:31,tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc,tensorflower-gardener,False
"Internal code change

PiperOrigin-RevId: 631243354",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 00:59:09,tensorflow/core/framework/BUILD,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631238254",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-07 00:36:38,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add an optional MemoryKind parameter to IFRT IR shardings.

PiperOrigin-RevId: 631235085",Ionel Gog,icgog@google.com,2024-05-07 00:24:55,"third_party/xla/xla/python/ifrt/ir/BUILD, third_party/xla/xla/python/ifrt/ir/ifrt_dialect.cc, third_party/xla/xla/python/ifrt/ir/ifrt_dialect.td, third_party/xla/xla/python/ifrt/ir/ifrt_interfaces.h, third_party/xla/xla/python/ifrt/ir/ifrt_interfaces.td, third_party/xla/xla/python/ifrt/ir/tests/BUILD, third_party/xla/xla/python/ifrt/ir/tests/ifrt_verify_sharding_specified.mlir",ICGog,False
"Always propagate shardings on kAllReduce.

Before this change, it would ignore partial manual sharding for all-reduce
assigning fullly-replicated sharding to the all-reduce. This fully-replicated
sharding would error out later in SpmdPartitioningVisitor::HandleAllReduce.

After this change, it properly assigns manual shardings to all-reduces allowing
all-reduces which are only partially manual to be emitted.

PiperOrigin-RevId: 631234822",Parker Schuh,parkers@google.com,2024-05-07 00:23:35,"third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation_test.cc",pschuh,False
"Support delayed CPU memory allocation in PjRt CPU.

Major changes:
1. `TrackedTfrtCpuDeviceBuffer` now contains a list of `tsl::AsyncValueRef<MaybeOwningCpuMemory>` instead of `std::shared_ptr<MaybeOwningCpuMemory>`.
2. Adds some buffer metadata info to `TrackedTfrtCpuDeviceBuffer` including `owns_buffers_` and `buffer_sizes_`, to allow construction without allocating CPU memory immediately.
3. Updates other related PjRt CPU methods.

PiperOrigin-RevId: 631207935",Yue Sheng,yueshengys@google.com,2024-05-06 22:42:12,"third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.cc, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer.cc, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer.h, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer_test.cc, third_party/xla/xla/python/py_array.cc",yueshengys,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631200953",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 22:18:14,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Rollback of PR #12076
Rolling back PR #12076: [XLA:CPU][oneDNN] AVX512 vectorization
Reason: Broke JAX Arm CI
```
E     AssertionError: [b""'-prefer-256-bit' is not a recognized feature for this target (ignoring feature)""
```

Reverts 58d6f04ae41c442626f705eb03385c3de50266c0

PiperOrigin-RevId: 631195048",Penporn Koanantakool,penporn@google.com,2024-05-06 21:58:30,third_party/xla/xla/service/cpu/simple_orc_jit.cc,penpornk,False
"Fix unreachable code in TFLite

PiperOrigin-RevId: 631185614",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 21:26:30,"tensorflow/lite/kernels/activations.cc, tensorflow/lite/kernels/pad.cc, tensorflow/lite/kernels/topk_v2.cc, tensorflow/lite/kernels/where.cc",tensorflower-gardener,False
"#tensorflow Skip failing test.

Error message:
```
[ RUN      ] QuantizedInstanceNormTest.TestClamp
tensorflow/core/kernels/quantized_instance_norm_test.cc:120: Failure
Expected: (max_diff()) <= (0.1), actual: 0.165527 vs 0.1
2024-05-06 18:40:43.391840: I tensorflow/core/kernels/quantized_instance_norm_test.cc:121] max diff 0.165527
[  FAILED  ] QuantizedInstanceNormTest.TestClamp (3 ms)
```
PiperOrigin-RevId: 631185292",Yang Chen,yangchen@google.com,2024-05-06 21:25:21,tensorflow/core/kernels/BUILD,yangustc07,False
"Implement Freeze() in IfrtServingExecutable to release mlir module
to saved memory and prevent further compilation of the program.

PiperOrigin-RevId: 631185190",Deqiang Chen,deqiangc@google.com,2024-05-06 21:24:57,"tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.h, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo_test.cc, tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_executable_registry.cc, tensorflow/core/tfrt/ifrt/ifrt_executable_registry.h, tensorflow/core/tfrt/ifrt/ifrt_executable_registry_test.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test.cc",deqiangc,False
"Add `bzl_library` targets to XLA and TSL

PiperOrigin-RevId: 631181194",David Dunleavy,ddunleavy@google.com,2024-05-06 21:12:18,"third_party/xla/third_party/tsl/tsl/platform/BUILD, third_party/xla/third_party/tsl/tsl/platform/default/BUILD, third_party/xla/xla/BUILD",ddunl,False
"Unified the GPU executable proto used in AOT and JIT caching path.

PiperOrigin-RevId: 631179168",Jieying Luo,jieying@google.com,2024-05-06 21:06:23,"third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/stream_executor_executable.cc",jyingl3,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631164835",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 20:22:50,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA] Introduce pass which ensures memory is in the right memory space before performing host compute offload.

PiperOrigin-RevId: 631155209",Victor Stone,victorstone@google.com,2024-05-06 19:51:41,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/host_offloading_prepare.cc, third_party/xla/xla/service/host_offloading_prepare.h, third_party/xla/xla/service/host_offloading_prepare_test.cc",SandSnip3r,False
"Make CommandBuffer use StreamExecutorInterface rather than StreamExecutor.

PiperOrigin-RevId: 631142267",Kyle Lucke,klucke@google.com,2024-05-06 19:07:23,"third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/command_buffer.cc, third_party/xla/xla/stream_executor/command_buffer.h, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer.cc, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer.h, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.h",klucke,False
"Report a failure when detecting top-level compilation marker in TF2XLA Non-eplicated Phase 1 Bridge

This feature is no longer supported as Pepperjack M1 gets deprecated.

PiperOrigin-RevId: 631130047",Jian Cai,jiancai@google.com,2024-05-06 18:30:08,"tensorflow/compiler/mlir/tensorflow/tests/xla_validate_inputs.mlir, tensorflow/compiler/mlir/tensorflow/tests/xla_validate_iputs.mlir, tensorflow/compiler/mlir/tensorflow/transforms/xla_validate_inputs.cc",jcai19,False
"Bump werkzeug from 3.0.1 to 3.0.3

Bumps [werkzeug](https://github.com/pallets/werkzeug) from 3.0.1 to 3.0.3.
- [Release notes](https://github.com/pallets/werkzeug/releases)
- [Changelog](https://github.com/pallets/werkzeug/blob/main/CHANGES.rst)
- [Commits](https://github.com/pallets/werkzeug/compare/3.0.1...3.0.3)

---
updated-dependencies:
- dependency-name: werkzeug
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>",dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2024-05-06 19:21:12,"requirements_lock_3_10.txt, requirements_lock_3_11.txt, requirements_lock_3_12.txt, requirements_lock_3_9.txt",dependabot[bot],False
"Use `ShapeUtil::HumanString` instead of calling `Shape::ToString` directly in `xla_builder.cc`.

PiperOrigin-RevId: 631129722",Gunhyun Park,gunhyun@google.com,2024-05-06 18:29:17,third_party/xla/xla/client/xla_builder.cc,ghpvnist,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631129423",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 18:28:36,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Delete chlo.dynamic_reshape and downstream ops

The downstream ops are [ms]hlo.{compute_reshape_shape,cstr_reshapable}.

The pattern that goes from tf.reshape to chlo.dynamic_reshape appears to be
dead code, and it is the only use of chlo.dynamic_reshape.

compute_reshape_shape and cstr_reshapable do not seem to be generated anywhere,
except when expanding chlo.dynamic_reshape.

Context: https://github.com/openxla/stablehlo/blob/main/rfcs/20230704-dynamism-101.md#p1
PiperOrigin-RevId: 631126637",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-06 18:20:05,"tensorflow/compiler/mlir/tf2xla/tests/legalize-tf.mlir, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf_patterns.td, tensorflow/compiler/mlir/tools/kernel_gen/kernel_creator.cc, third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/mlir_hlo/bindings/c/CMakeLists.txt, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.td, third_party/xla/xla/mlir_hlo/mhlo/analysis/shape_component_analysis.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/CMakeLists.txt, third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_shape_ops_to_standard/hlo_legalize_shape_ops_to_standard.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/map_stablehlo_to_hlo_op.h, third_party/xla/xla/mlir_hlo/mhlo/transforms/mhlo_passes.td, third_party/xla/xla/mlir_hlo/mhlo/transforms/passes.h, third_party/xla/xla/mlir_hlo/mhlo/transforms/rewriters.h, third_party/xla/xla/mlir_hlo/mhlo/transforms/shape_legalize_to_hlo/shape_legalize_to_hlo.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/symbolic_shape_optimization/symbolic_shape_optimization.cc, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-shape-ops-to-standard.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-stablehlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/mhlo_ops_prettyprint.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/shape_cstr_legalize_to_hlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/shape_cstr_legalize_to_hlo_e2e.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/shape_legalize_to_hlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/stablehlo-legalize-to-hlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/symbolic-shape-optimization.mlir, third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",mlevesquedion,False
"Add `MhloDynamicReshape` to XLA client API.

This adds a builder method which generates a `custom_call` to generate the MHLO op `dynamic_reshape`. Because of naming conflict with HLO's existing `DynamicReshape` (it's semantically different from `MhloDynamicReshape`), this op is prefixed with ""Mhlo"". I've also updated the API name for `DynamicBroadcastInDim` to `MhloDynamicBroadcastInDim` to match the names. These are only intended for export to MHLO or StableHLO, and cannot be compiled.

PiperOrigin-RevId: 631123552",Gunhyun Park,gunhyun@google.com,2024-05-06 18:11:05,"third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder.h, third_party/xla/xla/client/xla_builder_test.cc",ghpvnist,False
"Make Kernel classes use StreamExecutorInterface rather than StreamExecutor.

PiperOrigin-RevId: 631115653",Kyle Lucke,klucke@google.com,2024-05-06 17:49:04,"third_party/xla/xla/stream_executor/kernel.cc, third_party/xla/xla/stream_executor/kernel.h",klucke,False
"Turns off `.weighted_flat_map` random access compatibility because it does not work with any other ops that require the parent index mapper to be stateless (like  `.batch` for example)

PiperOrigin-RevId: 631110420",Jim Lin,jimlintw@google.com,2024-05-06 17:34:01,"tensorflow/core/kernels/data/experimental/weighted_flat_map_dataset_op.cc, tensorflow/python/data/experimental/kernel_tests/weighted_flat_map_test.py",jimlinntu,False
"Use StreamExecutorInterface in Event rather than StreamExecutor.

PiperOrigin-RevId: 631110415",Kyle Lucke,klucke@google.com,2024-05-06 17:33:59,"third_party/xla/xla/stream_executor/event.cc, third_party/xla/xla/stream_executor/event.h",klucke,False
"[Triton] Fixing issues with pipelining that cause crashes for some use-cases when num_stages=2.

PiperOrigin-RevId: 631107477",Mohammed Anany,manany@google.com,2024-05-06 17:25:04,"third_party/triton/temporary/pipelining.patch, third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/pipelining.patch, third_party/xla/third_party/triton/temporary/series.bzl",Moerafaat,False
"XProf GPU: Cache CUPTI activity buffer during tracing, process them after tracing is stopped.

PiperOrigin-RevId: 631106601",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 17:22:25,"third_party/xla/xla/backends/profiler/gpu/BUILD, third_party/xla/xla/backends/profiler/gpu/cupti_buffer_events.cc, third_party/xla/xla/backends/profiler/gpu/cupti_buffer_events.h, third_party/xla/xla/backends/profiler/gpu/cupti_collector.cc, third_party/xla/xla/backends/profiler/gpu/cupti_collector.h, third_party/xla/xla/backends/profiler/gpu/cupti_tracer.cc, third_party/xla/xla/backends/profiler/gpu/cupti_tracer.h",tensorflower-gardener,False
"Add integration options in TFRT/IFRT with tensorflow serving.

PiperOrigin-RevId: 631094916",Deqiang Chen,deqiangc@google.com,2024-05-06 16:48:57,"tensorflow/compiler/mlir/tfrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/ifrt/BUILD, tensorflow/core/tfrt/graph_executor/graph_execution_options.cc, tensorflow/core/tfrt/graph_executor/graph_execution_options.h, tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/mlrt/kernel/BUILD, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc, tensorflow/core/tfrt/saved_model/saved_model.cc",deqiangc,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631084752",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 16:18:41,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #12050: [XLA:GPU] Force nccl command buffer to update even memory pointers do not change

Imported from GitHub PR https://github.com/openxla/xla/pull/12050

This PR force command buffer to do cuda graph update if it contains nccl collective operators, because NCCL requires all devices to make the collective call even in the cuda-graph capturing mode.

Copybara import of the project:

--
1834ac6f72efa5882e58914f3001ac5cb7489725 by Shawn Wang <shawnw@nvidia.com>:

force nccl command buffer to update even if memory pointers do not change

Merging this change closes #12050

PiperOrigin-RevId: 631083738",Shawn Wang,shawnw@nvidia.com,2024-05-06 16:15:48,"third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk.cc",shawnwang18,False
"PR #12171: [XLA: GPU] add more checks for barrierCmd unittest

Imported from GitHub PR https://github.com/openxla/xla/pull/12171

Copybara import of the project:

--
30f9abd60c34f01c5fc77f7745275141130afce6 by Shawn Wang <shawnw@nvidia.com>:

add more checks for barrierCmd

Merging this change closes #12171

PiperOrigin-RevId: 631078801",Shawn Wang,shawnw@nvidia.com,2024-05-06 16:04:21,third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_test.cc,shawnwang18,False
"Enhance error message when creating RepeatBufferKernel fails.

PiperOrigin-RevId: 631065576",Ruoxin Sang,rxsang@google.com,2024-05-06 15:32:35,third_party/xla/xla/service/gpu/stream_executor_util.cc,rxsang,False
"PR #12012: Update cuDNN frontend version.

Imported from GitHub PR https://github.com/openxla/xla/pull/12012

Update cuDNN frontend version from 1.2.1 to 1.3.
Copybara import of the project:

--
ea12e3765a225fb360add9d424248ffa0954ce95 by Elfie Guo <elfieg@nvidia.com>:

Update cuDNN frontend version.

Merging this change closes #12012

PiperOrigin-RevId: 631053988",Elfie Guo,elfieg@nvidia.com,2024-05-06 15:06:17,"tensorflow/workspace2.bzl, third_party/xla/workspace2.bzl",elfiegg,False
"Update MHLO README to indicate current status

PiperOrigin-RevId: 631050740",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-06 15:00:00,third_party/xla/xla/mlir_hlo/README.md,mlevesquedion,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631035780",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 14:17:55,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@6217abce86b5

Updates LLVM usage to match
[6217abce86b5](https://github.com/llvm/llvm-project/commit/6217abce86b5)

PiperOrigin-RevId: 631029055",Benjamin Kramer,kramerb@google.com,2024-05-06 13:46:21,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",d0k,False
"[XLA:GPU] Added more logs in the autotuner to allow for better benchmark debugging during crashes.

PiperOrigin-RevId: 631027110",Mohammed Anany,manany@google.com,2024-05-06 13:35:35,third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc,Moerafaat,False
"PR #12031: add gemm autotune log dump

Imported from GitHub PR https://github.com/openxla/xla/pull/12031

This PR adds option to dump all gemm fusion autotune results as AutotuningLogs:
- the dump contains all autotune results for all backends including cublas,cudnn, and triton.
- also add fusion name and count (time of occurrence in a given hlo)
Copybara import of the project:

--
e65340a856101401e9ee56b4ac258cef9c10c517 by Amir Samani <asamani@nvidia.com>:

add gemm autotune log dump

Merging this change closes #12031

PiperOrigin-RevId: 631016170",Amir Samani,asamani@nvidia.com,2024-05-06 12:44:55,"third_party/xla/xla/autotune_results.proto, third_party/xla/xla/autotuning.proto, third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/python/xla_compiler.cc, third_party/xla/xla/python/xla_extension/__init__.pyi, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/autotuner_compile_util.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.h, third_party/xla/xla/xla.proto",Amir-19,False
"Fix reduction group computation for MLIR emitter.

Currently, there are cases where we duplicate reductions into more than
one group. This essentially means the grouping is buggy, since the
goal is to share reads. I will only fix the grouping for the new
emitters, since I can't rule out that the current grouping is actually
better in some cases (and we need to validate the performance for the
new emitters anyway). See OneGroup in reduction_base_test for an
example.

PiperOrigin-RevId: 631012536",Johannes Reifferscheid,jreiffers@google.com,2024-05-06 12:27:32,"third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.h, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.h",jreiffers,False
"[XLA:GPU] Cast bf16 matmuls to fp32 on pre-Ampere GPUs

bf16 matmuls exist on pre-Ampere, but are exceedingly (>4x) slow.

PiperOrigin-RevId: 631011910",George Karpenkov,cheshire@google.com,2024-05-06 12:24:32,"third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/dot_bf16.hlo, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc, third_party/xla/xla/service/gpu/tests/gpu_spmd_e2e_compile_test.cc",cheshire,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 631010743",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 12:18:25,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU] Make symbolic tiles use a single indexing map under the hood

For now, offset_map(), size_map(), and stride_map() return AffineMaps in the existing format, but in a later cl, we'll change them to return IndexingMaps.

PiperOrigin-RevId: 631005166",Tamás Danyluk,tdanyluk@google.com,2024-05-06 11:50:44,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile.cc, third_party/xla/xla/service/gpu/model/symbolic_tile.h",tdanyluk,False
"PR #11967: [XLA:GPU] Add cuDNN flash attention dbias computation and broadcast bias

Imported from GitHub PR https://github.com/openxla/xla/pull/11967

* add cuDNN flash attention dbias computation. make sure dbias only pattern match cases where reduction is done on batch dim. Only bias with [1, N, S, T] is supported.
* add cuDNN broadcast bias support. cuDNN supports broadcast bias, [1, N, S, T], [1, 1, S, T] and [B, 1, S, T] are supported.
Copybara import of the project:

--
0b3c19fba294402b735c1dc091cc57a955f5f334 by cjkkkk <ske@nvidia.com>:

add dbias

--
2d9256c7f4c441824a831f2238ff7fdf2447f7f9 by cjkkkk <ske@nvidia.com>:

remove extra ()

--
31750864e1bbf677cd82a8d4300fdb0a90d86e41 by cjkkkk <ske@nvidia.com>:

directly use rewriter result

Merging this change closes #11967

PiperOrigin-RevId: 630995321",Shanbin Ke,ske@nvidia.com,2024-05-06 11:00:33,"third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter_test.cc, third_party/xla/xla/service/gpu/cudnn_workspace_rewriter.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc, third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc",Cjkkkk,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630987295",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 10:19:27,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@18e7dcb7c576

Updates LLVM usage to match
[18e7dcb7c576](https://github.com/llvm/llvm-project/commit/18e7dcb7c576)

PiperOrigin-RevId: 630983347",Benjamin Kramer,kramerb@google.com,2024-05-06 10:00:04,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",d0k,False
"Don't MOF computations that are already fused.

Like the previous fix for priority fusion, MOF sometimes generates nested
fusions inside reducers, scatter updates, etc. This is not useful and
makes codegen more complex, since it needs to be able to handle such
nested fusions.

PiperOrigin-RevId: 630981603",Johannes Reifferscheid,jreiffers@google.com,2024-05-06 09:51:02,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_fusible.cc, third_party/xla/xla/service/gpu/gpu_fusible.h, third_party/xla/xla/service/gpu/gpu_fusible_test.cc, third_party/xla/xla/service/gpu/multi_output_fusion.cc, third_party/xla/xla/service/gpu/priority_fusion.cc",jreiffers,False
"Rewrite all reductions to race-free in MLIR mode.

The difference in runtimes in the original benchmarks that
motivated this change seem rather large. We can surely
do better than that. Atomics contribute a lot of complexity,
so if possible, we should try to avoid them.

PiperOrigin-RevId: 630977440",Johannes Reifferscheid,jreiffers@google.com,2024-05-06 09:30:01,third_party/xla/xla/service/gpu/tree_reduction_rewriter.cc,jreiffers,False
"Update GraphDef version to 1854.

PiperOrigin-RevId: 630972035",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 09:03:27,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-06

PiperOrigin-RevId: 630971991",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 09:03:14,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Use the correct dependency for the included gpu_init.h header.

We don't need to depend on the _impl target, it is added automatically to all
xla_cc_test targets. Depend on the non-implementation target instead.

PiperOrigin-RevId: 630971158",Adrian Kuegel,akuegel@google.com,2024-05-06 09:00:16,third_party/xla/xla/pjrt/c/BUILD,akuegel,False
"Compute non-fusion computations just once.

PiperOrigin-RevId: 630962946",Johannes Reifferscheid,jreiffers@google.com,2024-05-06 08:19:13,third_party/xla/xla/service/gpu/priority_fusion.cc,jreiffers,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630962765",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 08:18:13,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Do not fuse inside computations that are logically already fused.

Currently, priority fusion generates nested fusion instructions
inside reducers, scatter combiners, etc. This doesn't make sense,
since these instructions are already run inside a fusion, but
easily leads to codegen bugs.

PiperOrigin-RevId: 630956417",Johannes Reifferscheid,jreiffers@google.com,2024-05-06 07:46:32,"third_party/xla/xla/service/gpu/priority_fusion.cc, third_party/xla/xla/service/gpu/priority_fusion_test.cc",jreiffers,False
"Automated Code Change

PiperOrigin-RevId: 630952239",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 07:24:37,"third_party/xla/xla/BUILD, third_party/xla/xla/primitive_util.cc, third_party/xla/xla/primitive_util.h, third_party/xla/xla/primitive_util_test.cc, third_party/xla/xla/printer.cc, third_party/xla/xla/printer.h, third_party/xla/xla/protobuf_util.cc",tensorflower-gardener,False
"PR #12047: Remove redundant HloPassFix in OptimizeHloConvolutionCanonicalization

Imported from GitHub PR https://github.com/openxla/xla/pull/12047

I do not think `ReshapeMover` pass should be wrapped with `HloPassFix` twice

currently:
```c
  [&, &pipeline = pipeline.AddPass<HloPassFix<HloPassPipeline>>()] {
    pipeline.AddPass<HloPassFix<ReshapeMover>>(reshape_mover_options);
    pipeline.AddPass<AlgebraicSimplifier>(options);
  }();
```

I think it should be wrapped only once:

```c
  [&, &pipeline = pipeline.AddPass<HloPassFix<HloPassPipeline>>()] {
    pipeline.AddPass<ReshapeMover>(reshape_mover_options);
    pipeline.AddPass<AlgebraicSimplifier>(options);
  }();
```
Copybara import of the project:

--
ac3c322d769c1cadeefa7705c1e792f5f57bb705 by Alexander Pivovarov <pivovaa@amazon.com>:

Remove redundant HloPassFix in OptimizeHloConvolutionCanonicalization

Merging this change closes #12047

PiperOrigin-RevId: 630947358",Alexander Pivovarov,pivovaa@amazon.com,2024-05-06 07:01:35,"third_party/xla/xla/service/gpu/amdgpu_compiler.cc, third_party/xla/xla/service/gpu/nvptx_compiler.cc",apivovarov,False
"PR #12076: [XLA:CPU][oneDNN] AVX512 vectorization

Imported from GitHub PR https://github.com/openxla/xla/pull/12076

This PR enables AVX512 vectorization on CPUs that have the support. The default target machine features in LLVM include an attribute (`+prefer-256-bit`), as a result LoopVectorization pass produces AVX2 LLVM IR. This PR essentially drops the attribute and this produces AVX512 vectorized code.

Below is the disassembled object code for  **HLO Add** instruction in float32.

### With the PR:
```
Disassembly of section .ltext:

0000000000000000 <parallel_add.3>:
      movq  (%r9), %rax
      movq  0x8(%r9), %rdx
      cmpq  %rdx, %rax
      jae 0xee <parallel_add.3+0xee>
      movq  (%rcx), %rdi
      movq  0x8(%rcx), %rsi
      movq  0x10(%rcx), %r8
      movq  %rax, %r9
      shlq  $0xb, %r9
      leaq  (%rsi,%r9), %rcx
      addq  $0xc0, %rcx
      leaq  (%r8,%r9), %rsi
      addq  $0xc0, %rsi
      addq  %r9, %rdi
      addq  $0xc0, %rdi
      00 00 00 00     nopw  %cs:(%rax,%rax)
      xorl  %r8d, %r8d
      00 00 00        nopw  %cs:(%rax,%rax)
      vmovups -0xc0(%rcx,%r8), %zmm0
      vmovups -0x80(%rcx,%r8), %zmm1
      vmovups -0x40(%rcx,%r8), %zmm2
      vmovups (%rcx,%r8), %zmm3
      vaddps  -0xc0(%rsi,%r8), %zmm0, %zmm0
      vaddps  -0x80(%rsi,%r8), %zmm1, %zmm1
      vaddps  -0x40(%rsi,%r8), %zmm2, %zmm2
      vaddps  (%rsi,%r8), %zmm3, %zmm3
      vmovups %zmm0, -0xc0(%rdi,%r8)
      vmovups %zmm1, -0x80(%rdi,%r8)
      vmovups %zmm2, -0x40(%rdi,%r8)
      vmovups %zmm3, (%rdi,%r8)
      addq  $0x100, %r8             # imm = 0x100
      cmpq  $0x800, %r8             # imm = 0x800
      jne 0x60 <parallel_add.3+0x60>
      incq  %rax
      addq  $0x800, %rcx            # imm = 0x800
      addq  $0x800, %rsi            # imm = 0x800
      addq  $0x800, %rdi            # imm = 0x800
      cmpq  %rdx, %rax
      jne 0x50 <parallel_add.3+0x50>
      vzeroupper
      retq
      00 00 00 00     nopw  %cs:(%rax,%rax)
```

### Without the PR:
```
Disassembly of section .ltext:

0000000000000000 <parallel_add.3>:
      movq  (%r9), %rax
      movq  0x8(%r9), %rdx
      cmpq  %rdx, %rax
      jae 0xcf <parallel_add.3+0xcf>
      movq  (%rcx), %rdi
      movq  0x8(%rcx), %rsi
      movq  0x10(%rcx), %r8
      movq  %rax, %r9
      shlq  $0xb, %r9
      leaq  (%rsi,%r9), %rcx
      addq  $0x60, %rcx
      leaq  (%r8,%r9), %rsi
      addq  $0x60, %rsi
      addq  %r9, %rdi
      addq  $0x60, %rdi
      nopl  (%rax)
      xorl  %r8d, %r8d
      00 00 00        nopw  %cs:(%rax,%rax)
      vmovups -0x60(%rcx,%r8), %ymm0
      vmovups -0x40(%rcx,%r8), %ymm1
      vmovups -0x20(%rcx,%r8), %ymm2
      vmovups (%rcx,%r8), %ymm3
      vaddps  -0x60(%rsi,%r8), %ymm0, %ymm0
      vaddps  -0x40(%rsi,%r8), %ymm1, %ymm1
      vaddps  -0x20(%rsi,%r8), %ymm2, %ymm2
      vaddps  (%rsi,%r8), %ymm3, %ymm3
      vmovups %ymm0, -0x60(%rdi,%r8)
      vmovups %ymm1, -0x40(%rdi,%r8)
      vmovups %ymm2, -0x20(%rdi,%r8)
      vmovups %ymm3, (%rdi,%r8)
      subq  $-0x80, %r8
      cmpq  $0x800, %r8             # imm = 0x800
      jne 0x50 <parallel_add.3+0x50>
      incq  %rax
      addq  $0x800, %rcx            # imm = 0x800
      addq  $0x800, %rsi            # imm = 0x800
      addq  $0x800, %rdi            # imm = 0x800
      cmpq  %rdx, %rax
      jne 0x40 <parallel_add.3+0x40>
      vzeroupper
      retq
      00 00 00        nopw  %cs:(%rax,%rax)
```

Copybara import of the project:

--
78b071e7aac5e9b4c0a5b40a31f05e2f7ada2921 by mdfaijul <md.faijul.amin@intel.com>:

AVX512 vectorization.

Merging this change closes #12076

PiperOrigin-RevId: 630946101",Faijul Amin,md.faijul.amin@intel.com,2024-05-06 06:54:06,third_party/xla/xla/service/cpu/simple_orc_jit.cc,mdfaijul,False
"PR #12131: [XLA:GPU] Clean code of cublasLT workspace size settings.

Imported from GitHub PR https://github.com/openxla/xla/pull/12131

Copybara import of the project:

--
2a2cc13501b2beca205cb573c21ac007e7441b0b by Shawn Wang <shawnw@nvidia.com>:

code clean

Merging this change closes #12131

PiperOrigin-RevId: 630944818",Shawn Wang,shawnw@nvidia.com,2024-05-06 06:46:53,third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.cc,shawnwang18,False
"Automated Code Change

PiperOrigin-RevId: 630944018",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 06:41:18,third_party/xla/third_party/tsl/tsl/framework/tracking_allocator.cc,tensorflower-gardener,False
"PR #11981: [ROCM] fixing pjrt_c_api_gpu_test

Imported from GitHub PR https://github.com/openxla/xla/pull/11981

Fixing platform name CUDA/ROCM

@xla-rotation: could you please have a look?
Copybara import of the project:

--
d114eb0deb691b5cf6907880f26d241a2813f26d by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

fixing the test

Merging this change closes #11981

PiperOrigin-RevId: 630942701",pemeliya,141146080+pemeliya@users.noreply.github.com,2024-05-06 06:33:21,"third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_test.cc",pemeliya,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630940023",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 06:18:12,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add GetParameters() and FusionInstruction() methods to fusion adaptors.

Also let GetRoots() for ProducerConsumer fusion handle the case where producer
is a multi-output fusion.

PiperOrigin-RevId: 630936590",Adrian Kuegel,akuegel@google.com,2024-05-06 05:58:04,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/hlo_traversal.h, third_party/xla/xla/service/gpu/hlo_traversal_test.cc",akuegel,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630922659",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 04:17:58,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630905077",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 02:18:08,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630890677",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-06 00:17:36,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630877377",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 22:18:08,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630863629",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 20:18:20,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630849700",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 18:17:51,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630835870",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 16:17:52,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630809766",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 12:18:29,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630795093",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 10:18:02,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update GraphDef version to 1853.

PiperOrigin-RevId: 630786062",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 09:02:15,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-05

PiperOrigin-RevId: 630786029",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 09:02:07,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630779726",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 08:17:46,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630763294",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 06:18:15,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630748069",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 04:17:42,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630732205",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 02:17:39,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630718883",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-05 00:18:27,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630706437",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 22:17:45,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 630697575",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 20:52:57,third_party/xla/xla/python/ifrt/ir/transforms/spmd_expandable_interface_verification_pass.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630693751",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 20:18:01,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630680557",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 18:17:49,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630667031",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 16:18:01,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630654438",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 14:18:13,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630641706",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 12:17:51,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630627384",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 10:17:29,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 630623085",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 09:42:34,"tensorflow/security/fuzzing/cc/BUILD, tensorflow/security/fuzzing/cc/ParseAttrValue_fuzz.cc, tensorflow/security/fuzzing/cc/bfloat16_fuzz.cc, tensorflow/security/fuzzing/cc/checkpoint_reader_fuzz.cc, tensorflow/security/fuzzing/cc/consume_leading_digits_fuzz.cc",tensorflower-gardener,False
"[XLA:GPU] [NFC] Simplify CUDA/ROCm checks for gemm_rewrite_test

PiperOrigin-RevId: 630623062",George Karpenkov,cheshire@google.com,2024-05-04 09:42:25,"third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc, third_party/xla/xla/stream_executor/device_description.h",cheshire,False
"compat: Update forward compatibility horizon to 2024-05-04

PiperOrigin-RevId: 630618044",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 09:03:16,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1852.

PiperOrigin-RevId: 630618039",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 09:03:14,tensorflow/core/public/version.h,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630611798",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 08:17:45,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 630589728",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 05:49:35,tensorflow/python/autograph/core/BUILD,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630577009",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 04:17:47,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630557132",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 02:17:41,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add a pass to unify the accumulator and the input of the jax.scan loops.

This pass looks at the loops with accumulator patterns and unifies the
accumulation buffer with the input. The accumulation pattern usually comes
from jax.scan function. This transformation is beneficial in the cases where
the scan loop appears inside a loop body which causes a copy of the
accumulation buffer in the outer body.

PiperOrigin-RevId: 630557002",Farzin Houshmand,farzinh@google.com,2024-05-04 02:16:49,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/scan_loop_accumulator_input_unification.cc, third_party/xla/xla/service/scan_loop_accumulator_input_unification.h, third_party/xla/xla/service/scan_loop_accumulator_input_unification_test.cc, third_party/xla/xla/service/while_loop_simplifier.cc, third_party/xla/xla/service/while_loop_simplifier.h",farzinhoushmand,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630538072",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-04 00:21:47,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Some refactoring to WhileLoopUnroller pass.

PiperOrigin-RevId: 630533503",Farzin Houshmand,farzinh@google.com,2024-05-03 23:58:11,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/while_loop_unroller.cc, third_party/xla/xla/service/while_loop_unroller_test.cc",farzinhoushmand,False
"Filter custom_call_schedule when encoding MHLO custom call in StablHLO

PiperOrigin-RevId: 630532138",Kevin Gleason,gleasonk@google.com,2024-05-03 23:50:32,"third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_stablehlo/hlo_legalize_to_stablehlo.cc, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-stablehlo.mlir",GleasonK,False
"Fix Kokoro (broken CMakeLists.txt and deprecated method errors)

PiperOrigin-RevId: 630526449",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-03 23:22:07,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/mlir_hlo/CMakeLists.txt, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.cc, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops_attrs.td, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops_typedefs.td, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_utils.td, third_party/xla/xla/mlir_hlo/mhlo/analysis/CMakeLists.txt, third_party/xla/xla/mlir_hlo/mhlo/transforms/CMakeLists.txt, third_party/xla/xla/mlir_hlo/mhlo/transforms/legalize_to_linalg/legalize_to_linalg.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/legalize_to_standard/legalize_to_standard_patterns.td, third_party/xla/xla/mlir_hlo/mhlo/transforms/map_mhlo_to_scalar_op.h, third_party/xla/xla/mlir_hlo/mhlo/utils/CMakeLists.txt, third_party/xla/xla/mlir_hlo/mhlo/utils/legalize_to_linalg_utils.h, third_party/xla/xla/mlir_hlo/tools/mlir-hlo-opt/CMakeLists.txt",mlevesquedion,False
"[jax] fix call to static_argnames.reserve()

PiperOrigin-RevId: 630518507",Peter Gavin,pgavin@google.com,2024-05-03 22:48:20,third_party/xla/xla/python/pjit.cc,,False
"Support Keras3 model conversion to TFLite.

PiperOrigin-RevId: 630515876",Weiyi Wang,weiyiw@google.com,2024-05-03 22:36:52,"tensorflow/lite/python/BUILD, tensorflow/lite/python/lite.py, tensorflow/lite/python/tflite_keras_util.py, tensorflow/lite/python/util.py",sirakiin,False
"Link PluginProgram's serdes in the common_serdes target.

PiperOrigin-RevId: 630511584",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 22:19:47,third_party/xla/xla/python/ifrt_proxy/common/BUILD,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630511259",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 22:18:15,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Remove StreamExecutor::platform in favor of StreamExecutorInterface::GetPlatform.

PiperOrigin-RevId: 630494314",Kyle Lucke,klucke@google.com,2024-05-03 21:11:15,"third_party/xla/xla/BUILD, third_party/xla/xla/device_util.h, third_party/xla/xla/service/transfer_manager.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h",klucke,False
"[xla:ffi] Added support for token-typed arguments and results

This change is necessary to migrate the custom calls behind
jax.*_callback APIs.

I decided to encode tokens as scalar buffers with void storage type. Another
possibility was to introduce a dedicated argument/return type for tokens
and change all the internals to allow both buffers *and* tokens, but I thought
the extra complexity is not worth it.

PiperOrigin-RevId: 630493298",Sergei Lebedev,slebedev@google.com,2024-05-03 21:07:14,"third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_test.cc, third_party/xla/xla/primitive_util.h",superbobry,False
"Fix typo in tflite conversion documentation.

PiperOrigin-RevId: 630487538",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 20:46:54,tensorflow/lite/g3doc/models/convert/convert_models.md,tensorflower-gardener,False
"Fix keras view source URLs

PiperOrigin-RevId: 630483598",Mark Daoust,markdaoust@google.com,2024-05-03 20:34:35,tensorflow/tools/docs/base_dir.py,MarkDaoust,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630481129",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 20:27:20,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA] Add constant for Host execution thread.

PiperOrigin-RevId: 630480472",Victor Stone,victorstone@google.com,2024-05-03 20:25:09,third_party/xla/xla/hlo/ir/hlo_instruction.h,SandSnip3r,False
"sm90 cutlass kernels require CUDA-12 w/ cutlass v3.4+.

PiperOrigin-RevId: 630479576",Artem Belevich,tra@google.com,2024-05-03 20:21:30,"third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_custom_kernel.cc",Artem-B,False
"Accounts for ParallelMap's initial parallelism maximum buffered bytes

PiperOrigin-RevId: 630475934",Jim Lin,jimlintw@google.com,2024-05-03 20:07:59,"tensorflow/core/framework/dataset.cc, tensorflow/core/framework/dataset.h, tensorflow/core/framework/model.cc, tensorflow/core/framework/model.h, tensorflow/core/framework/model_test.cc, tensorflow/core/kernels/data/BUILD, tensorflow/core/kernels/data/parallel_map_dataset_op.cc, tensorflow/core/kernels/data/parallel_map_dataset_op_test.cc",jimlinntu,False
"Integrate LLVM at llvm/llvm-project@4ad696231bc7

Updates LLVM usage to match
[4ad696231bc7](https://github.com/llvm/llvm-project/commit/4ad696231bc7)

PiperOrigin-RevId: 630472593",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 19:56:11,"tensorflow/compiler/mlir/tosa/tests/tf-to-tosa-pipeline.mlir, tensorflow/compiler/mlir/tosa/tests/tfl-to-tosa-pipeline.mlir, tensorflow/compiler/mlir/tosa/transforms/legalize_common.cc, tensorflow/compiler/mlir/tosa/transforms/legalize_tf.cc, tensorflow/compiler/mlir/tosa/transforms/legalize_tfl.cc, third_party/llvm/generated.patch, third_party/llvm/workspace.bzl, third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/group_reduction_dimensions.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-rng-to-linalg.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-linalg.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/mhlo_canonicalize_scatter.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/symbolic-shape-optimization.mlir, third_party/xla/xla/mlir_hlo/tests/alloc_to_arg.mlir, third_party/xla/xla/mlir_hlo/transforms/CMakeLists.txt, third_party/xla/xla/mlir_hlo/transforms/alloc_to_arg_pass.cc, third_party/xla/xla/mlir_hlo/transforms/passes.h, third_party/xla/xla/mlir_hlo/transforms/test_hlo_transform_dialect_interpreter.cc",tensorflower-gardener,False
"Fix HostOffloader's assumption that an ""annotation"" always has users.

PiperOrigin-RevId: 630463341",Victor Stone,victorstone@google.com,2024-05-03 19:20:25,third_party/xla/xla/service/host_offload_legalize.cc,SandSnip3r,False
"PR #12091: [XLA:CPU][oneDNN] Perf regression fix on matmul weight prepacking.

Imported from GitHub PR https://github.com/openxla/xla/pull/12091

This PR fixes a regression caused by refactoring of weight prepacking. Essentially, the current PR restores the conditions for weight prepacking as before.
(1) Restores weights to have multiple users. Since weights are prepacked only when it can be evaluated as constant it is safe.
(2) Restores the HloEvaluator to evaluate constants recursively.
Copybara import of the project:

--
da6af5e2747e60d0568b0b8432c9de53ec83809f by mdfaijul <md.faijul.amin@intel.com>:

Fix matmul weight prepacking.

Merging this change closes #12091

PiperOrigin-RevId: 630461761",Faijul Amin,md.faijul.amin@intel.com,2024-05-03 19:14:44,third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc,mdfaijul,False
"Fix op profile root/program node metrics that:
- Fix the total time of program node to be closer to the real total time as duty_cycle total time (idle time is not counted still).
- Fix the bandwidth util of program node with adjusted total_time. The util numbers will be slightly smaller now given the increased total time.
- Fix the bandwidth util of root node a bit, the number should be slightly smaller as the divider time used now becomes larger.
- The avgTime of program node is no longer accessible for program node, as we currently cannot get this number correctly.

PiperOrigin-RevId: 630456428",Yin Zhang,yinzz@google.com,2024-05-03 18:57:21,"tensorflow/core/profiler/convert/op_profile_builder.cc, tensorflow/core/profiler/convert/op_profile_builder.h",zzzaries,False
"[XLA] Fix race condition in custom call partitioner registration.

The custom call partitioner registration is not thread-safe. This can lead to a race condition when multiple threads try to register the same partitioner. This CL fixes the race condition by adding a mutex to protect the registration process.

PiperOrigin-RevId: 630453623",David Majnemer,majnemer@google.com,2024-05-03 18:47:23,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/custom_call_sharding_helper.cc",majnemer,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630444494",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 18:18:01,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:SPMD] Do not run shard group propagation if it's CSE prevention.

PiperOrigin-RevId: 630440635",Tongfei Guo,tongfei@google.com,2024-05-03 18:05:40,third_party/xla/xla/service/sharding_propagation.cc,Tongfei-Guo,False
"NFC: Remove LMHLO dialect

PiperOrigin-RevId: 630426450",Eugene Zhulenev,ezhulenev@google.com,2024-05-03 17:19:50,"tensorflow/compiler/mlir/lite/stablehlo/odml_to_stablehlo.cc, tensorflow/compiler/mlir/python/mlir.cc, tensorflow/compiler/mlir/tf_mlir_opt_main.cc, tensorflow/compiler/mlir/tools/kernel_gen/tools/kernel-gen-opt/kernel-gen-opt.cc, third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/mlir_hlo/lhlo/CMakeLists.txt, third_party/xla/xla/mlir_hlo/lhlo/IR/CMakeLists.txt, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_dialect.td, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_ops.cc, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_ops.h, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_ops.td, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_ops_base.td, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_ops_structs.h, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_ops_structs.td, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_structured_interface.cc, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_structured_interface.h, third_party/xla/xla/mlir_hlo/lhlo/IR/lhlo_structured_interface.td, third_party/xla/xla/mlir_hlo/lhlo/transforms/CMakeLists.txt, third_party/xla/xla/mlir_hlo/lhlo/transforms/legalize_to_tensor_op/legalize_to_tensor_op.cc, third_party/xla/xla/mlir_hlo/lhlo/transforms/lhlo_legalize_to_affine/lhlo_legalize_to_affine.cc, third_party/xla/xla/mlir_hlo/lhlo/transforms/lhlo_legalize_to_gpu/lhlo_legalize_to_gpu.cc, third_party/xla/xla/mlir_hlo/lhlo/transforms/lhlo_legalize_to_parallel_loops/lhlo_legalize_to_parallel_loops.cc, third_party/xla/xla/mlir_hlo/lhlo/transforms/lmhlo_passes.td, third_party/xla/xla/mlir_hlo/lhlo/transforms/map_hlo_to_lhlo_op.h, third_party/xla/xla/mlir_hlo/lhlo/transforms/map_lhlo_to_hlo_op.h, third_party/xla/xla/mlir_hlo/lhlo/transforms/map_lmhlo_to_scalar_op.h, third_party/xla/xla/mlir_hlo/lhlo/transforms/passes.h, third_party/xla/xla/mlir_hlo/lhlo/utils/lhlo_utils.h, third_party/xla/xla/mlir_hlo/mhlo/transforms/passes.h, third_party/xla/xla/service/llvm_ir/llvm_util.h",ezhulenev,False
"Reorganizing tfl schema.

PiperOrigin-RevId: 630425831",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 17:18:06,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/ir/tfl_ops.h, tensorflow/compiler/mlir/lite/json_to_flatbuffer.cc, tensorflow/compiler/mlir/lite/quantization/lite/BUILD, tensorflow/compiler/mlir/lite/quantization/lite/quantize_model_test.cc, tensorflow/compiler/mlir/lite/quantization/lite/tfl_quantizer.cc, tensorflow/compiler/mlir/lite/schema/BUILD, tensorflow/compiler/mlir/lite/schema/README.md, tensorflow/compiler/mlir/lite/schema/schema.fbs, tensorflow/compiler/mlir/lite/sparsity/BUILD, tensorflow/compiler/mlir/lite/sparsity/sparsify_model_test.cc, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/BUILD, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/importer_test_min_max.cc, tensorflow/compiler/mlir/lite/tf_tfl_translate.cc, tensorflow/compiler/mlir/lite/tf_to_tfl_flatbuffer.cc, tensorflow/compiler/mlir/lite/transforms/prepare_quantize_helper.h, tensorflow/compiler/mlir/lite/utils/convert_type.h, tensorflow/lite/core/c/c_api_test.cc, tensorflow/lite/schema/BUILD, third_party/flatbuffers/build_defs.bzl",tensorflower-gardener,False
"Use StreamExecutorInterface::GetPlatform rather than deprecated StreamExecutor::platform method.

PiperOrigin-RevId: 630423698",Kyle Lucke,klucke@google.com,2024-05-03 17:11:17,tensorflow/core/tpu/tpu_execute.cc,klucke,False
"[PJRT] Remove the deprecated PjRtClient::LookupDevices() overload that takes a raw int.

Update users to use the PjRtGlobalDeviceId overloads (or to use different APIs).

Fixes a TODO, no functional changes intended. However, the change is in preparation for allowing int64_t sized device IDs, so fixing up users of `int` device IDs is a preparatory step.

PiperOrigin-RevId: 630420985",Peter Hawkins,phawkins@google.com,2024-05-03 17:03:24,"third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/pjrt_c_api_client.cc, third_party/xla/xla/pjrt/pjrt_c_api_client.h, third_party/xla/xla/pjrt/pjrt_client.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client_test.cc, third_party/xla/xla/pjrt/tf_pjrt_client.h",hawkinsp,False
"Updates control dependencies for peeled collective permutes.

PiperOrigin-RevId: 630418304",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 16:54:51,"third_party/xla/xla/service/latency_hiding_scheduler.cc, third_party/xla/xla/service/latency_hiding_scheduler_test.cc",tensorflower-gardener,False
"NFC: Remove lmhlo from mhlo-hlo-opt tool

PiperOrigin-RevId: 630417837",Eugene Zhulenev,ezhulenev@google.com,2024-05-03 16:52:48,"third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/mlir_hlo/tests/Dialect/lhlo/lhlo-legalize-select-and-scatter.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/lhlo/lhlo-legalize-to-affine.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/lhlo/lhlo-legalize-to-gpu.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/lhlo/lhlo-legalize-to-parallel-loops.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/lhlo/lhlo-legalize-to-tensor-op.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/lhlo/ops.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/canonicalize.mlir, third_party/xla/xla/mlir_hlo/tests/collapse_parallel_loops_to_1d_pass.mlir, third_party/xla/xla/mlir_hlo/tests/naive_copy_removal.mlir, third_party/xla/xla/mlir_hlo/tests/tile_loops.mlir, third_party/xla/xla/mlir_hlo/tools/mlir-hlo-opt/mlir-hlo-opt.cc",ezhulenev,False
"Move IFRT ShardingParam to a separate library.

PiperOrigin-RevId: 630414079",Ionel Gog,icgog@google.com,2024-05-03 16:37:02,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/ir/BUILD, third_party/xla/xla/python/ifrt/ir/tests/BUILD, third_party/xla/xla/python/ifrt/ir/transforms/spmd_expanders/BUILD, third_party/xla/xla/python/ifrt/support/BUILD",ICGog,False
"Fix all-reduce bytes_transmitted for ALL_GATHER collectives

PiperOrigin-RevId: 630413612",Clive Verghese,cliveverghese@google.com,2024-05-03 16:35:09,tensorflow/core/profiler/convert/xspace_to_dcn_slack_analysis.cc,cliveverghese,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630409587",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 16:20:18,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"If pre-populated reduced groups are present, make sure to copy over the reduced intervals as well.

PiperOrigin-RevId: 630408147",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 16:13:53,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc,tensorflower-gardener,False
"Fix include cleaner warnings.

PiperOrigin-RevId: 630396185",Quentin Khan,qkhan@google.com,2024-05-03 15:23:56,"tensorflow/lite/examples/label_image/bitmap_helpers.h, tensorflow/lite/examples/label_image/get_top_n.h, tensorflow/lite/examples/label_image/label_image.cc",qukhan,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630382609",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 14:21:49,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #11514: Move cublasLT workspace allocation to buffer assignment

Imported from GitHub PR https://github.com/openxla/xla/pull/11514

Move cublasLT workspace allocation to buffer assignment to support command buffer lowering
Copybara import of the project:

--
7a448b05a54345c0cb15a47c9dc45558255c9656 by Shawn Wang <shawnw@nvidia.com>:

Move cublasLT workspace allocation to buffer assignment to support command buffer lowering

--
16e6efe960d92825bed0a0237a374f7980baf5d2 by Shawn Wang <shawnw@nvidia.com>:

set workspace size

Merging this change closes #11514

PiperOrigin-RevId: 630373419",Shawn Wang,shawnw@nvidia.com,2024-05-03 13:32:36,"third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker_test.cc, third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.cc, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.h, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc, third_party/xla/xla/stream_executor/cuda/cuda_blas_lt.cc, third_party/xla/xla/stream_executor/cuda/cuda_blas_lt.h, third_party/xla/xla/stream_executor/gpu/gpu_blas_lt.h, third_party/xla/xla/stream_executor/rocm/hip_blas_lt.cc, third_party/xla/xla/stream_executor/rocm/hip_blas_lt.h",shawnwang18,False
"[XLA] Raise internal error on mismatched backend config descriptors.

This is more consistent with the original goal of this function. Originally, it crashed if the descriptors mismatched. It was later refactored to avoid the crash and inadvertently changed to simply fall through instead of returning an error. This fallthrough introduced a subtle bug: If the descriptors are mismatching but the stored `proto_` is not empty, the stored `proto_` will be overwritten.

PiperOrigin-RevId: 630368223",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-03 13:03:55,third_party/xla/xla/hlo/ir/hlo_instruction.cc,dimitar-asenov,False
"PR #12041: [XLA:CPU][oneDNN] Gelu Exact patterns and tests

Imported from GitHub PR https://github.com/openxla/xla/pull/12041

This PR adds support for Matmul fusion with Gelu-Exact pattern and tests.
Copybara import of the project:

--
899b5619e7dc2edca4ea169f6fddf41e2a4a54e7 by Kanvi Khanna <kanvi.khanna@intel.com>:

Add Gelu-exact pattern and tests

--
bb912bf4de8471883b1938c61aa5b58245cd5a6f by Kanvi Khanna <kanvi.khanna@intel.com>:

Address review comments

Merging this change closes #12041

PiperOrigin-RevId: 630362540",Kanvi Khanna,kanvi.khanna@intel.com,2024-05-03 12:31:30,"third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/tests/onednn_matmul_test.cc",kanvi-nervana,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630359973",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 12:17:47,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #12046: Use HloPredicateTrue and HloPredicateFalse

Imported from GitHub PR https://github.com/openxla/xla/pull/12046

`xla/utils.h` defines the following functions
```
inline bool HloPredicateTrue(const HloInstruction*) { return true; }
inline bool HloPredicateFalse(const HloInstruction*) { return false; }
```

We can use them instead of inline lambdas
```
[](const HloInstruction*) { return true; }
[](const HloInstruction*) { return false; }

```
Copybara import of the project:

--
723c5a9525a5cf3d540b57601c31373e94992673 by Alexander Pivovarov <pivovaa@amazon.com>:

Use HloPredicateTrue and HloPredicateFalse

Merging this change closes #12046

PiperOrigin-RevId: 630359834",Alexander Pivovarov,pivovaa@amazon.com,2024-05-03 12:16:47,"third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.h, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.cc, third_party/xla/xla/tests/collective_pipeliner_execution_test.cc",apivovarov,False
"Internal configuration change.

PiperOrigin-RevId: 630356334",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 11:58:25,tensorflow/lite/BUILD,tensorflower-gardener,False
"[XLA] Extract BackendConfig-related functionality out of `hlo_instruction.h/cc`.
- `BackendConfigRep` is now in `backend_config.h/cc` and renamed to `BackendConfigWrapper`
- `BackendConfigToRawString` is also moved to `backend_config.h/cc`

PiperOrigin-RevId: 630345325",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-03 10:55:22,"third_party/xla/xla/hlo/ir/BUILD, third_party/xla/xla/hlo/ir/backend_config.cc, third_party/xla/xla/hlo/ir/backend_config.h, third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h",dimitar-asenov,False
"Automated Code Change

PiperOrigin-RevId: 630339622",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 10:25:20,"third_party/xla/third_party/tsl/tsl/platform/BUILD, third_party/xla/third_party/tsl/tsl/platform/coding.cc, third_party/xla/third_party/tsl/tsl/platform/coding.h",tensorflower-gardener,False
"[xla:cpu] Make `HandleCustomCall` support typed FFI

Fixes #10056
Co-authored-by: pparuzel <paruzelp@google.com>
Co-authored-by: Adam-Banas <adambanas@google.com>
PiperOrigin-RevId: 630339013",Leo Heinsaar,heinsaar@google.com,2024-05-03 10:22:07,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_runtime.cc, third_party/xla/xla/service/cpu/cpu_runtime.h, third_party/xla/xla/service/cpu/ir_emitter.cc, third_party/xla/xla/service/cpu/ir_emitter.h, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.cc, third_party/xla/xla/service/cpu/runtime_handle_ffi_call.h, third_party/xla/xla/service/cpu/simple_orc_jit.cc, third_party/xla/xla/service/llvm_ir/ir_builder_mixin.h, third_party/xla/xla/stream_executor/device_memory.h, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/custom_call_test.cc",heinsaar,False
"Automated Code Change

PiperOrigin-RevId: 630338314",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 10:18:03,"tensorflow/lite/tools/evaluation/stages/BUILD, tensorflow/lite/tools/evaluation/stages/image_classification_stage.cc, tensorflow/lite/tools/evaluation/stages/image_classification_stage.h, tensorflow/lite/tools/evaluation/stages/image_preprocessing_stage.cc, tensorflow/lite/tools/evaluation/stages/image_preprocessing_stage.h, tensorflow/lite/tools/evaluation/stages/image_preprocessing_stage_test.cc, tensorflow/lite/tools/evaluation/stages/inference_profiler_stage.cc, tensorflow/lite/tools/evaluation/stages/inference_profiler_stage.h",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630338307",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 10:18:00,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update GraphDef version to 1851.

PiperOrigin-RevId: 630323390",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 09:01:57,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-03

PiperOrigin-RevId: 630323383",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 09:01:56,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630314512",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 08:18:05,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 630299377",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 07:02:30,"third_party/xla/xla/client/lib/arithmetic.cc, third_party/xla/xla/client/lib/arithmetic.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 630295131",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 06:41:44,"tensorflow/lite/testing/BUILD, tensorflow/lite/testing/generate_testspec.cc, tensorflow/lite/testing/generate_testspec_test.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630290508",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 06:17:45,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Reverts 08fdea60bee843ec228eacef8bb37fc62b87108f

PiperOrigin-RevId: 630285152",Adrian Kuegel,akuegel@google.com,2024-05-03 05:48:37,"third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/gpu/fusion_pipeline.cc, third_party/xla/xla/service/gpu/multi_output_fusion_test.cc, third_party/xla/xla/service/hlo_instruction_test.cc",akuegel,False
"Inline single usages of `SymbolTable` to avoid excessive copy.

PiperOrigin-RevId: 630285107",Dan Suh,dansuh@google.com,2024-05-03 05:48:22,tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc,dansuh17,False
"Automated Code Change

PiperOrigin-RevId: 630284457",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 05:44:10,"tensorflow/core/tfrt/utils/debug/BUILD, tensorflow/core/tfrt/utils/debug/node_io_dump_rewriter.cc, tensorflow/core/tfrt/utils/debug/node_io_dump_rewriter_test.cc",tensorflower-gardener,False
"[PJRT C API] Add a new PJRT extension (and related methods) for layouts.

The end goal is to provide new C APIs for layouts and remove the old ones. This is the first cl.

PiperOrigin-RevId: 630270222",Yue Sheng,yueshengys@google.com,2024-05-03 04:30:47,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/CHANGELOG.md, third_party/xla/xla/pjrt/c/pjrt_c_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.h, third_party/xla/xla/pjrt/c/pjrt_c_api_layouts_extension.h, third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.h, third_party/xla/xla/pjrt/pjrt_c_api_client.cc, third_party/xla/xla/pjrt/pjrt_c_api_client.h",yueshengys,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630267806",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 04:18:11,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630246105",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 02:17:59,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"NFC: Move cpu_event to xla/service/cpu

PiperOrigin-RevId: 630234264",Eugene Zhulenev,ezhulenev@google.com,2024-05-03 01:10:53,"third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.cc, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.h, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer.cc, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer.h, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer_test.cc, third_party/xla/xla/runtime/BUILD, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_event.h",ezhulenev,False
"Enable saving quantization report to file.

Impelements `SaveQuantizationReportInstrumentation` to allow analyzing and saving quantization report to file after `QuantizeCompositeFunctionsPass`.
Adds a new config field in `QuantizationConfig` for the users to provide the path to file to save the quantization report.

PiperOrigin-RevId: 630228055",Dan Suh,dansuh@google.com,2024-05-03 00:40:47,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/config.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/post_calibration.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/weight_only_ptq.cc, tensorflow/compiler/mlir/quantization/stablehlo/instrumentations/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/instrumentations/save_report.cc, tensorflow/compiler/mlir/quantization/stablehlo/instrumentations/save_report.h, tensorflow/compiler/mlir/quantization/stablehlo/instrumentations/save_report_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize_composite_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto",dansuh17,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630223148",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 00:17:44,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Adding parameter support for disabling per channel quantization while running quantizer.

PiperOrigin-RevId: 630221603",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-03 00:10:17,"tensorflow/lite/tools/optimize/quantize_model.cc, tensorflow/lite/tools/optimize/quantize_model.h",tensorflower-gardener,False
"Add a flag to space-to-batch

PiperOrigin-RevId: 630220239",Amit Sabne,asabne@google.com,2024-05-03 00:04:57,"third_party/xla/xla/service/space_to_batch_converter.cc, third_party/xla/xla/service/space_to_batch_converter.h",amitsabne1,False
"[xla] Remove xla runtime except cpu_event that will be moved later

PiperOrigin-RevId: 630218366",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 23:56:51,"third_party/xla/xla/runtime/BUILD, third_party/xla/xla/runtime/README.md, third_party/xla/xla/runtime/aot_ffi.cc, third_party/xla/xla/runtime/aot_ffi.h, third_party/xla/xla/runtime/aot_ffi_c_symbols.cc, third_party/xla/xla/runtime/aot_ffi_c_symbols.h, third_party/xla/xla/runtime/aot_ffi_execution_context.h, third_party/xla/xla/runtime/arguments.cc, third_party/xla/xla/runtime/arguments.h, third_party/xla/xla/runtime/arguments_test.cc, third_party/xla/xla/runtime/async_runtime.cc, third_party/xla/xla/runtime/async_runtime.h, third_party/xla/xla/runtime/async_runtime_test.cc, third_party/xla/xla/runtime/async_values_cache.h, third_party/xla/xla/runtime/compiler.h, third_party/xla/xla/runtime/constraints.cc, third_party/xla/xla/runtime/constraints.h, third_party/xla/xla/runtime/custom_call.cc, third_party/xla/xla/runtime/custom_call.h, third_party/xla/xla/runtime/custom_call_registry.cc, third_party/xla/xla/runtime/custom_call_registry.h, third_party/xla/xla/runtime/default/BUILD, third_party/xla/xla/runtime/default/async_values_cache.h, third_party/xla/xla/runtime/default/memory_mapper.h, third_party/xla/xla/runtime/diagnostics.cc, third_party/xla/xla/runtime/diagnostics.h, third_party/xla/xla/runtime/diagnostics_test.cc, third_party/xla/xla/runtime/errors.h, third_party/xla/xla/runtime/executable.cc, third_party/xla/xla/runtime/executable.h, third_party/xla/xla/runtime/execution_engine.cc, third_party/xla/xla/runtime/execution_engine.h, third_party/xla/xla/runtime/ffi/BUILD, third_party/xla/xla/runtime/ffi/ffi_abi.h, third_party/xla/xla/runtime/ffi/ffi_api.h, third_party/xla/xla/runtime/ffi/ffi_c_api.h, third_party/xla/xla/runtime/jit_executable.cc, third_party/xla/xla/runtime/jit_executable.h, third_party/xla/xla/runtime/logical_result.h, third_party/xla/xla/runtime/map_by_type.h, third_party/xla/xla/runtime/map_by_type_test.cc, third_party/xla/xla/runtime/memory_mapper.cc, third_party/xla/xla/runtime/memory_mapper.h, third_party/xla/xla/runtime/memref_view.h, third_party/xla/xla/runtime/module.h, third_party/xla/xla/runtime/module_registry.cc, third_party/xla/xla/runtime/module_registry.h, third_party/xla/xla/runtime/module_test.cc, third_party/xla/xla/runtime/results.h, third_party/xla/xla/runtime/results_test.cc, third_party/xla/xla/runtime/runtime.h, third_party/xla/xla/runtime/state.h, third_party/xla/xla/runtime/state_test.cc, third_party/xla/xla/runtime/symbolic_shape.cc, third_party/xla/xla/runtime/symbolic_shape.h, third_party/xla/xla/runtime/symbolic_shape_test.cc, third_party/xla/xla/runtime/tracing.h, third_party/xla/xla/runtime/type_id.cc, third_party/xla/xla/runtime/type_id.h, third_party/xla/xla/runtime/type_id_test.cc, third_party/xla/xla/runtime/types.cc, third_party/xla/xla/runtime/types.h",ezhulenev,False
"Register custom partitioning callbacks once instead of once per invocation
of partitioning. This causes tsan problems.

PiperOrigin-RevId: 630213072",Parker Schuh,parkers@google.com,2024-05-02 23:32:29,"third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/spmd/BUILD, third_party/xla/xla/service/spmd/shard_barrier_partitioner.cc",pschuh,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/7bdf48f1aac0b48ff85a4e0fb5ff7f98a703f8d6.

PiperOrigin-RevId: 630212142",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 23:28:33,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"[pjrt] NFC: Clean tracked_device_buffer dependencies

PiperOrigin-RevId: 630212137",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 23:28:32,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/tracked_device_buffer.cc, third_party/xla/xla/pjrt/tracked_device_buffer.h",ezhulenev,False
"Adds memory term reduction logic outside the call to Solve().

PiperOrigin-RevId: 630200445",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 22:41:38,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_impl.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_wrapper.h",tensorflower-gardener,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #9

PiperOrigin-RevId: 630200031",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 22:40:17,"third_party/xla/xla/mlir/runtime/BUILD, third_party/xla/xla/mlir/runtime/ir/BUILD, third_party/xla/xla/mlir/runtime/ir/rt_dialect.cc, third_party/xla/xla/mlir/runtime/ir/rt_dialect.h, third_party/xla/xla/mlir/runtime/ir/rt_dialect.td, third_party/xla/xla/mlir/runtime/ir/rt_interfaces.cc, third_party/xla/xla/mlir/runtime/ir/rt_interfaces.h, third_party/xla/xla/mlir/runtime/ir/rt_interfaces.td, third_party/xla/xla/mlir/runtime/ir/rt_ops.cc, third_party/xla/xla/mlir/runtime/ir/rt_ops.h, third_party/xla/xla/mlir/runtime/ir/rt_ops.td",ezhulenev,False
"[SparseCore Embedding] Add SparseCoreEmbeddingConfig to TPUEmbeddingV2.

PiperOrigin-RevId: 630199815",Ziyin Huang,ziyinh@google.com,2024-05-02 22:39:23,"tensorflow/python/tpu/tpu_embedding_v3.py, tensorflow/python/tpu/tpu_embedding_v3_test.py, tensorflow/tools/api/golden/v1/tensorflow.tpu.experimental.embedding.-sparse-core-embedding-config.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.tpu.experimental.embedding.-t-p-u-embedding-v2.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.tpu.experimental.embedding.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.tpu.experimental.embedding.-sparse-core-embedding-config.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.tpu.experimental.embedding.-t-p-u-embedding-v2.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.tpu.experimental.embedding.pbtxt",pineapplejuice233,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630198242",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 22:33:18,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[xla:ffi] NFC: Remove unused runtime::MemrefView conversion

PiperOrigin-RevId: 630194895",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 22:22:03,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/ffi.h",ezhulenev,False
"Update Eigen to commit:c1d637433e3b3f9012b226c2c9125c494b470ae6

CHANGELOG
=========
c1d637433 - Judge unitary-ness relative to scaling.
9000b3767 - Fix new generic nearest integer ops on GPU.
0ee5c90aa - Eigen transpose product
fb95e90f7 - Add truncation op
d5524fc57 - Remove unnecessary semicolons.
ae5280aa8 - Fix more hard-coded magic bounds.
a5e147305 - Fix undefined behavior for generating inputs to the predux_mul test.
dcceb9afe - Unbork avx512 preduce_mul on MSVC.

PiperOrigin-RevId: 630192447",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 22:13:03,"tensorflow/core/kernels/cwise_ops.h, tensorflow/core/kernels/stochastic_cast_op.h, tensorflow/core/kernels/stochastic_cast_op_test.cc, tensorflow/lite/tools/cmake/modules/eigen.cmake, third_party/eigen3/workspace.bzl, third_party/xla/third_party/tsl/third_party/eigen3/workspace.bzl",tensorflower-gardener,False
"Remove ScopedDeviceMemory constructor that takes a StreamExecutor pointer.

This removes a circular dependency between StreamExecutor and DeviceMemoryAllocator.

PiperOrigin-RevId: 630189601",Kyle Lucke,klucke@google.com,2024-05-02 22:02:25,"third_party/xla/xla/service/gpu/runtime/nccl_api.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/device_memory_allocator.cc, third_party/xla/xla/stream_executor/device_memory_allocator.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h",klucke,False
"[mhlo] Rip out lmhlo from the bufferization pipeline

The bufferization is still used by kernelgen, but the custom call lowering was
only used by XLA:CPU Next and is no longer needed. Unblocks lmhlo removal.

PiperOrigin-RevId: 630186841",Benjamin Kramer,kramerb@google.com,2024-05-02 21:53:08,"third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_memref/hlo_legalize_to_memref.cc, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-memref.mlir, third_party/xla/xla/mlir_hlo/transforms/bufferize_pass.cc",d0k,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #8

PiperOrigin-RevId: 630183488",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 21:40:33,"third_party/xla/xla/mlir/runtime/utils/BUILD, third_party/xla/xla/mlir/runtime/utils/async_runtime_api.cc, third_party/xla/xla/mlir/runtime/utils/async_runtime_api.h, third_party/xla/xla/mlir/runtime/utils/c_runner_utils.h, third_party/xla/xla/mlir/runtime/utils/constraints.cc, third_party/xla/xla/mlir/runtime/utils/constraints.h, third_party/xla/xla/mlir/runtime/utils/custom_calls.cc, third_party/xla/xla/mlir/runtime/utils/custom_calls.h, third_party/xla/xla/mlir/runtime/utils/float_16bits.h",ezhulenev,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #7

PiperOrigin-RevId: 630179873",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 21:28:11,"third_party/xla/xla/mlir/runtime/transforms/BUILD, third_party/xla/xla/mlir/runtime/transforms/add_initializations.cc, third_party/xla/xla/mlir/runtime/transforms/calling_convention.cc, third_party/xla/xla/mlir/runtime/transforms/calling_convention.h, third_party/xla/xla/mlir/runtime/transforms/calling_convention_test.cc, third_party/xla/xla/mlir/runtime/transforms/compilation_pipeline_cpu.cc, third_party/xla/xla/mlir/runtime/transforms/compilation_pipeline_cpu.h, third_party/xla/xla/mlir/runtime/transforms/compilation_pipeline_options.h, third_party/xla/xla/mlir/runtime/transforms/compiler.h, third_party/xla/xla/mlir/runtime/transforms/convert_asserts.cc, third_party/xla/xla/mlir/runtime/transforms/convert_custom_calls.cc, third_party/xla/xla/mlir/runtime/transforms/custom_call_encoding.cc, third_party/xla/xla/mlir/runtime/transforms/custom_call_encoding.h, third_party/xla/xla/mlir/runtime/transforms/export_functions.cc, third_party/xla/xla/mlir/runtime/transforms/jit_compiler.cc, third_party/xla/xla/mlir/runtime/transforms/jit_compiler.h, third_party/xla/xla/mlir/runtime/transforms/move_allocas_to_entry_block.cc, third_party/xla/xla/mlir/runtime/transforms/ordinal_assignment.cc, third_party/xla/xla/mlir/runtime/transforms/passes.h, third_party/xla/xla/mlir/runtime/transforms/passes.td, third_party/xla/xla/mlir/runtime/transforms/rt_to_llvm.cc, third_party/xla/xla/mlir/runtime/transforms/specialization.cc, third_party/xla/xla/mlir/runtime/transforms/specialization.h, third_party/xla/xla/mlir/runtime/transforms/type_converter.cc, third_party/xla/xla/mlir/runtime/transforms/type_converter.h, third_party/xla/xla/mlir/runtime/transforms/type_converter_test.cc, third_party/xla/xla/runtime/BUILD",ezhulenev,False
"Reverts changelist 443785169

PiperOrigin-RevId: 630177844",Jian Cai,jiancai@google.com,2024-05-02 21:21:13,"tensorflow/compiler/mlir/tensorflow/tests/convert_to_legacy_compile_and_replicate_attributes.mlir, tensorflow/compiler/mlir/tensorflow/tests/tpu_cluster_formation.mlir, tensorflow/compiler/mlir/tensorflow/tests/tpu_rewrite.mlir, tensorflow/compiler/mlir/tensorflow/utils/attribute_utils.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_cluster_formation.cc",jcai19,False
"Merge pull request #61632 from buptzyb:multistream-streammerge

PiperOrigin-RevId: 630175692",TensorFlower Gardener,gardener@tensorflow.org,2024-05-02 21:55:39,"tensorflow/core/common_runtime/gpu/gpu_device.cc, tensorflow/core/common_runtime/gpu/gpu_device.h, tensorflow/core/common_runtime/gpu/gpu_util.cc, tensorflow/core/framework/device.h, tensorflow/core/protobuf/config.proto, tensorflow/tools/api/golden/v1/tensorflow.-g-p-u-options.pbtxt",tensorflower-gardener,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #6

PiperOrigin-RevId: 630169826",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 20:55:00,third_party/xla/xla/runtime/BUILD,ezhulenev,False
"hlo_runner_pjrt: support parameter and output streaming

PiperOrigin-RevId: 630165970",Emilio Cota,ecg@google.com,2024-05-02 20:42:07,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_runner_pjrt.cc, third_party/xla/xla/service/hlo_runner_pjrt.h",cota,False
"Reverts changelist 525613555

PiperOrigin-RevId: 630159219",Jian Cai,jiancai@google.com,2024-05-02 20:20:48,"tensorflow/compiler/mlir/tensorflow/tests/tpu_cluster_formation.mlir, tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_cluster_formation.cc",jcai19,False
"[XLA:GPU] Use the correct `EXPECT_OK` version in the numerics verifier test.

PiperOrigin-RevId: 630159004",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-02 20:19:58,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/triton_fusion_numerics_verifier_test.cc",dimitar-asenov,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630158509",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 20:18:21,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[tsl:concurrency] Split Map and TryMap functors into two separate functions

Allow users to map AsyncValue into AsyncValue<StatusOr<T>> if they really want it and instead introduce a separate TryMap API that automatically folds returned StatusOr into async value error.

PiperOrigin-RevId: 630158185",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 20:17:20,"third_party/xla/xla/tsl/concurrency/async_value_ptr_test.cc, third_party/xla/xla/tsl/concurrency/async_value_ref.h, third_party/xla/xla/tsl/concurrency/async_value_ref_test.cc",ezhulenev,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #5

PiperOrigin-RevId: 630156915",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 20:13:19,"third_party/xla/xla/mlir/memref/BUILD, third_party/xla/xla/mlir/memref/transforms/BUILD, third_party/xla/xla/mlir/memref/transforms/aligned_allocations.cc, third_party/xla/xla/mlir/memref/transforms/passes.h, third_party/xla/xla/mlir/memref/transforms/passes.td, third_party/xla/xla/mlir/runtime/transforms/BUILD",ezhulenev,False
"Internal change only.

PiperOrigin-RevId: 630154742",Thomas Köppe,tkoeppe@google.com,2024-05-02 20:06:05,tensorflow/python/lib/core/BUILD,tkoeppe,False
"Generate mhlo.dynamic_reshape instead of chlo.dynamic_reshape for squeeze

The extra logic that chlo.dynamic_reshape implements is not needed for squeeze.

PiperOrigin-RevId: 630150307",Michael Levesque-Dion,mlevesquedion@google.com,2024-05-02 19:50:38,"tensorflow/compiler/mlir/tf2xla/tests/legalize-tf.mlir, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf.cc",mlevesquedion,False
"Separate backend specific code in `:gpu_timer`

1. Moves the `GpuSemaphore` type out of `GpuTimer` into its own file and target
2. Moves backend specific code from `:gpu_timer` into its own files.
3. Splits `:gpu_timer_kernel` into the backend specific targets `:gpu_timer_kernel_{cuda|rocm}`.
4. Removes the `:gpu_timer_header` target

PiperOrigin-RevId: 630141376",Henning Becker,hebecker@google.com,2024-05-02 19:17:07,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/stream_executor/cuda/BUILD, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_semaphore.cc, third_party/xla/xla/stream_executor/gpu/gpu_semaphore.h, third_party/xla/xla/stream_executor/gpu/gpu_timer.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer.h, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel.h, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel_cuda.cu.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel_rocm.cc, third_party/xla/xla/stream_executor/rocm/BUILD",beckerhe,False
"Merge pull request #62750 from mattbahr:implement-sampled-addmm-v2

PiperOrigin-RevId: 630140772",TensorFlower Gardener,gardener@tensorflow.org,2024-05-02 20:18:19,"tensorflow/python/ops/BUILD, tensorflow/python/ops/math_ops.py, tensorflow/python/ops/math_ops_test.py, tensorflow/tools/api/golden/v2/tensorflow.sparse.pbtxt",tensorflower-gardener,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #4

PiperOrigin-RevId: 630139768",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 19:10:51,"third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/compiler_functor.cc, third_party/xla/xla/service/cpu/compiler_functor.h, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/cpu_executable.cc, third_party/xla/xla/service/cpu/cpu_executable.h",ezhulenev,False
"[xla:gpu] ExecutionCounters for Send/Recv thunks should be per StreamExecutor
and RunId.

This fixes the problem that the runtime optimization to make Send/Recv
conditional no-op only works for the first run of a module.

PiperOrigin-RevId: 630138991",Bixia Zheng,bixia@google.com,2024-05-02 19:07:47,"third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/nccl_p2p_thunk_common.cc, third_party/xla/xla/service/gpu/runtime/nccl_p2p_thunk_common.h, third_party/xla/xla/service/gpu/runtime/nccl_recv_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_send_thunk.cc",bixia1,False
"Disable BES uploads and set BEP uploads to minimal for Mac RBE cross-compile builds

PiperOrigin-RevId: 630135925",Nitin Srinivasan,srnitin@google.com,2024-05-02 18:58:41,".bazelrc, third_party/xla/.bazelrc, third_party/xla/third_party/tsl/.bazelrc",nitins17,False
"Moves all the interval creation logic upstream before the call to Solve().

PiperOrigin-RevId: 630128797",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 18:33:55,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_impl.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_wrapper.h",tensorflower-gardener,False
"Replace one last use of ScopedDeviceMemory in buffer_comparator_test with DeviceHandle.

PiperOrigin-RevId: 630128405",Kyle Lucke,klucke@google.com,2024-05-02 18:32:57,third_party/xla/xla/service/gpu/buffer_comparator_test.cc,klucke,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #3

PiperOrigin-RevId: 630125494",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 18:25:18,"tensorflow/compiler/aot/tfcompile.bzl, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/runtime/BUILD, third_party/xla/xla/service/cpu/runtime/collectives.cc, third_party/xla/xla/service/cpu/runtime/collectives.h, third_party/xla/xla/service/cpu/runtime/convolution.cc, third_party/xla/xla/service/cpu/runtime/convolution.h, third_party/xla/xla/service/cpu/runtime/convolution_call.cc, third_party/xla/xla/service/cpu/runtime/convolution_call.h, third_party/xla/xla/service/cpu/runtime/convolution_ffi.cc, third_party/xla/xla/service/cpu/runtime/convolution_ffi.h, third_party/xla/xla/service/cpu/runtime/custom_call.cc, third_party/xla/xla/service/cpu/runtime/custom_call.h, third_party/xla/xla/service/cpu/runtime/fft_call.cc, third_party/xla/xla/service/cpu/runtime/fft_call.h, third_party/xla/xla/service/cpu/runtime/retain.cc, third_party/xla/xla/service/cpu/runtime/rng.cc, third_party/xla/xla/service/cpu/runtime/rng.h, third_party/xla/xla/service/cpu/runtime/rng_call.cc, third_party/xla/xla/service/cpu/runtime/rng_call.h, third_party/xla/xla/service/cpu/runtime/rng_ffi.cc, third_party/xla/xla/service/cpu/runtime/rng_ffi.h, third_party/xla/xla/service/cpu/runtime/xfeed.cc, third_party/xla/xla/service/cpu/runtime/xfeed.h",ezhulenev,False
Update unit test for data format check,Yimei Sun,yimei.sun@intel.com,2024-05-02 18:45:57,"tensorflow/python/tools/BUILD, tensorflow/python/tools/optimize_for_inference_test.py",yimeisun123,True
"Add constants for decode and prefill cost.

PiperOrigin-RevId: 630121959",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 18:14:17,tensorflow/core/common_runtime/cost_constants.h,tensorflower-gardener,False
"[xla][gpu] Implement pipelined-p2p-rewriter.

This pass rewrite pipelined point-to-point communication by rotating the
SendDone and RecvDone operations in a while-body to the beginning of the next iteration.
The SendDone and RecvDone operations for the last iteration are moved to the
while-op calling computation, after the while-op.

Add the pass to the GPU post-scheduler pipeline.

This is another approach to achieve the code pattern to pipeline two Send-Recv
chains decomposed from a collective-permute with a source-target pair cycle for
performance. The pipelined Send-Recv pattern puts SendDone and RecvDone before
Send and Recv in the while-body, and if we generate such code pattern too early
in the GPU compilation pipeline, copy-insertion may generate copies of Send
causing Send and SendDone with different buffers and thus correctness problem.

PiperOrigin-RevId: 630121252",Bixia Zheng,bixia@google.com,2024-05-02 18:12:05,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_compiler_test.cc, third_party/xla/xla/service/gpu/pipelined_p2p_rewriter.cc, third_party/xla/xla/service/gpu/pipelined_p2p_rewriter.h, third_party/xla/xla/service/gpu/pipelined_p2p_rewriter_test.cc",bixia1,False
"Update visibility rules for tf2xla targets

PiperOrigin-RevId: 630118947",Chi Zeng,chizeng@google.com,2024-05-02 18:05:27,tensorflow/compiler/tf2xla/BUILD,chihuahua,False
"[XLA:MSA] Avoid sorting colocations.

Maintaining a map from AliasedOffset* to an index in a vector lets us avoid having to sort by just constructing a colocation_vector which is stable in iteration order.

PiperOrigin-RevId: 630118439",David Majnemer,majnemer@google.com,2024-05-02 18:04:05,third_party/xla/xla/service/memory_space_assignment/algorithm.cc,majnemer,False
"[XLA:GPU] Enable strength-reduction for dots that are not supported by GemmFusion

If dot is not supported by Triton, we should do strength-reduction on it, so that it can be handled by fusion pipeline later.

This is NFC because GpuAlgebraicSimplifer is not used yet.

PiperOrigin-RevId: 630097135",Anlun Xu,anlunx@google.com,2024-05-02 17:01:50,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier.cc, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier.h, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier_test.cc",anlunx,False
"Add virtual StreamExecutorInterface::GetPlatform method.

This will eventually replace StreamExecutor::platform which collides with TpuExecutorInterface::platform method if StreamExecutor::platform was made virtual.

PiperOrigin-RevId: 630094133",Kyle Lucke,klucke@google.com,2024-05-02 16:51:35,"tensorflow/compiler/jit/xla_launch_util.cc, tensorflow/compiler/jit/xla_platform_info.cc, third_party/xla/xla/backends/interpreter/executable_base.cc, third_party/xla/xla/client/local_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/service/compiler.cc, third_party/xla/xla/service/gpu/autotuner_compile_util.cc, third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/gpu_transfer_manager.cc, third_party/xla/xla/service/gpu/stream_executor_util.cc, third_party/xla/xla/service/platform_util.cc, third_party/xla/xla/stream_executor/integrations/tf_allocator_adapter.cc, third_party/xla/xla/stream_executor/mock_stream_executor.h, third_party/xla/xla/stream_executor/stream_executor_interface.h, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h, third_party/xla/xla/stream_executor/tpu/tpu_executable_interface.cc",klucke,False
"Separate backend specific code in redzone_allocator

- Moves `LoadKernelOrGetPtr` from `asm_compiler.h` into `redzone_allocator_kernel_cuda.cc` since it's the only user of this function.
- Separate CUDA / ROCm code into separate files: `redzone_allocator_kernel_{cuda|rocm}.cc`.
- Removes all preprocessor branches from `redzone_allocator.cc`.
- Removes unnecessary build macros from `redzone_allocator_test` target definition.
- Reenables ASAN for the `redzone_allocator_test`.

PiperOrigin-RevId: 630093741",Henning Becker,hebecker@google.com,2024-05-02 16:50:20,"third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/asm_compiler.h, third_party/xla/xla/stream_executor/gpu/redzone_allocator.cc, third_party/xla/xla/stream_executor/gpu/redzone_allocator.h, third_party/xla/xla/stream_executor/gpu/redzone_allocator_kernel.h, third_party/xla/xla/stream_executor/gpu/redzone_allocator_kernel_cuda.cc, third_party/xla/xla/stream_executor/gpu/redzone_allocator_kernel_rocm.cu.cc",beckerhe,False
"Prevent generating ReadVariableOp which has a corresponding read op top of tf_device.replate op

PiperOrigin-RevId: 630092944",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 16:47:34,"tensorflow/compiler/mlir/tensorflow/tests/tpu-resource-read-for-write.mlir, tensorflow/compiler/mlir/tensorflow/transforms/tpu_resource_read_for_write.cc",tensorflower-gardener,False
"Add support for the PartialReduce custom call op in auto-sharding.

Reverts 5445d4bf8ea2e8566741926de63a891972ede491

PiperOrigin-RevId: 630085015",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 16:21:00,"third_party/xla/workspace2.bzl, third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_strategy.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.h",tensorflower-gardener,False
"Updates the solver & evaluator to handle requests that contain pre-populated reduced groups.

PiperOrigin-RevId: 630076404",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 15:49:01,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.proto, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver_test.cc",tensorflower-gardener,False
"[XLA] Enlarge size of integers in xla::DeviceAssignment to 64-bits.

In PJRT I want to use structured device IDs that pack both a node ID and a local device ID into a single device ID. A 32-bit space is uncomfortably small to be doing this.

PiperOrigin-RevId: 630059845",Peter Hawkins,phawkins@google.com,2024-05-02 14:40:11,"third_party/xla/xla/service/computation_placer.cc, third_party/xla/xla/service/computation_placer.h, third_party/xla/xla/service/tpu_computation_placer.cc, third_party/xla/xla/xla_data.proto",hawkinsp,False
"[XLA:GPU] When running run_hlo_module in isolation mode, do not stop on errors.

PiperOrigin-RevId: 630055471",Alexander Lyashuk,crem@google.com,2024-05-02 14:21:31,third_party/xla/xla/tools/run_hlo_module.cc,mooskagh,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630054647",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 14:17:41,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU][MLIR-based emitters] Add a pattern to fold constant operands for apply_indexing op.

PiperOrigin-RevId: 630046578",Alexander Belyaev,pifon@google.com,2024-05-02 13:38:20,"third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/canonicalize.mlir",pifon2a,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630030175",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 12:17:53,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[StablehloShapeRefinement] Skip constant folding of convert operations with dynamic shapes.

PiperOrigin-RevId: 630030154",George Necula,necula@google.com,2024-05-02 12:17:45,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch",gnecula,False
"Automated Code Change

PiperOrigin-RevId: 630028488",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 12:09:22,"tensorflow/core/util/strided_slice_op_test.cc, tensorflow/core/util/tensor_format.h",tensorflower-gardener,False
"[XLA:GPU] Add an optional compiler pass that verifies Triton fusions.

The pass uses existing autotuning logic to compile and run two versions of all `FusionInstructions` with a Triton backend:
- The original instruction with the Triton Backend
- A modified instruction without a backend. This one will be compiled by the regular emitters.
The outs of the two versions are compared and the pass fails if there is a mismatch.

PiperOrigin-RevId: 630024376",Dimitar (Mitko) Asenov,dasenov@google.com,2024-05-02 11:48:47,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/triton_fusion_numerics_verifier.cc, third_party/xla/xla/service/gpu/triton_fusion_numerics_verifier.h, third_party/xla/xla/service/gpu/triton_fusion_numerics_verifier_test.cc, third_party/xla/xla/xla.proto",dimitar-asenov,False
"[XLA:GPU][MLIR-based emitters] Remove unused results from apply_indexing op.

PiperOrigin-RevId: 630021836",Alexander Belyaev,pifon@google.com,2024-05-02 11:32:43,"third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/canonicalize.mlir, third_party/xla/xla/service/gpu/model/indexing_map.h",pifon2a,False
"Do not deduplicate roots in FindRoots() method.

We should not filter out duplicate roots here, as then it becomes harder to map
from the returned roots to the tuple elements. This is mostly a theoretical
concern, as it is unlikely that we will have duplicate roots.

PiperOrigin-RevId: 630018947",Adrian Kuegel,akuegel@google.com,2024-05-02 11:16:40,"third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/hlo_traversal.h, third_party/xla/xla/service/gpu/hlo_traversal_test.cc",akuegel,False
"Fix reductions with side outputs.

- The current epilogue logic doesn't work for all fusions
- The output indices have to be computed based on a reduction root
- Side outputs have to be written at the end of the loop body

Verified with JAX test suite.

PiperOrigin-RevId: 630018571",Johannes Reifferscheid,jreiffers@google.com,2024-05-02 11:14:42,"third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.h, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.h, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.h, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc",jreiffers,False
"Lower index to 64 bits if 64 bit indices are used in HLO.

Currently, we only look at shapes to determine the bit width
of `index`. We have to also look at index operands.

PiperOrigin-RevId: 630016357",Johannes Reifferscheid,jreiffers@google.com,2024-05-02 11:05:04,"third_party/xla/xla/service/gpu/fusions/loop_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc",jreiffers,False
"Add a test case to document how HloCSE works for multi-output fusions.

Currently it would create a duplicate tuple element. We might want to change
this in the future.

PiperOrigin-RevId: 630011369",Adrian Kuegel,akuegel@google.com,2024-05-02 10:41:00,third_party/xla/xla/service/hlo_cse_test.cc,akuegel,False
"[xla:gpu] Allow address computation fusion where slice has several uses.

As address fusion has zero cost, we should always perform it if possible, allowing the possibility to avoid materializing a slice with multiple uses.

PiperOrigin-RevId: 630009086",Chris Jones,cjfj@google.com,2024-05-02 10:30:08,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc",chr1sj0nes,False
"[XLA:GPU][MLIR-based emitters] Remove unused dimensions in xla_gpu.indexing_op.

PiperOrigin-RevId: 630006852",Alexander Belyaev,pifon@google.com,2024-05-02 10:19:26,"third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/canonicalize.mlir",pifon2a,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 630006561",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 10:17:48,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Add a utility for finding HLO use chains

This is needed for proper epilogue indexing computations, e.g.
in fusions like this:

```
          reduce
         /      \
   broadcast    log
        |        |
       neg    bitcast
         \      /
           ROOT
```

The current assumption in `ComputeEpilogueInputToOutputIndexing`
that we can just take the first user is incorrect here - the
reduce is both part of the side output's computation and the hero
of the fusion. Fusions like this make absolutely no sense, but they
exist.

PiperOrigin-RevId: 629994503",Johannes Reifferscheid,jreiffers@google.com,2024-05-02 09:17:07,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/hlo_traversal.h, third_party/xla/xla/service/gpu/hlo_traversal_test.cc",jreiffers,False
"Switch tfl dialect to use properties.

PiperOrigin-RevId: 629991649",Christian Sigg,csigg@google.com,2024-05-02 09:03:42,"tensorflow/compiler/mlir/lite/experimental/tac/tests/device-transform-gpu.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/device-transform-nnapi.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/e2e/device-transform-nnapi.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/e2e/simple-graph.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/fold-constants-to-subgraph.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/get-alternative-subgraph.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/pick-subgraphs.mlir, tensorflow/compiler/mlir/lite/experimental/tac/tests/raise-target-subgraphs.mlir, tensorflow/compiler/mlir/lite/ir/tfl_op_interfaces.td, tensorflow/compiler/mlir/lite/ir/tfl_ops.cc, tensorflow/compiler/mlir/lite/quantization/tensorflow/tests/fallback_to_flex_ops_default.mlir, tensorflow/compiler/mlir/lite/quantization/tensorflow/tests/fallback_to_flex_ops_legacy.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/composite-lowering.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/legalize-stablehlo-tfl-composite.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/tfl_legalize_hlo.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/tfl_legalize_hlo_custom_call.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/lite/tests/canonicalize.mlir, tensorflow/compiler/mlir/lite/tests/const-fold.mlir, tensorflow/compiler/mlir/lite/tests/decompose-hybrid-quantization.mlir, tensorflow/compiler/mlir/lite/tests/default_quant_params.mlir, tensorflow/compiler/mlir/lite/tests/end2end/fake_quant_per_channel.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/fake_quant_per_channel_4bit.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/fake_quant_without_identity.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/fake_quant_without_identity_4bit.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/quant_stats.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/unroll_batch_matmul.pbtxt, tensorflow/compiler/mlir/lite/tests/end2end/unroll_batch_matmul_disabled.pbtxt, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/basic_lstm.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/bucketize.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/constants.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/constants_offset.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/custom_op.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/custom_op_offset.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/external_constant.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/import_json.json, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/importer_test_min_max.cc, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/importer_test_min_max.cc.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/legacy_reshape.json, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/lstm.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/many_attribute_op.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/math.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/matmul.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/optional.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/optional_input.json, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/quantization.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/reshape.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/simple.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/variable.mlir, tensorflow/compiler/mlir/lite/tests/fuse-tftext.mlir, tensorflow/compiler/mlir/lite/tests/insert_call_once_op.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tensorlist.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf-hashtables.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf-no-runtime-verification.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf-variables.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf-while.mlir, tensorflow/compiler/mlir/lite/tests/legalize-tf.mlir, tensorflow/compiler/mlir/lite/tests/legalize_jax_random.mlir, tensorflow/compiler/mlir/lite/tests/mlir2flatbuffer/fake_quant.mlir, tensorflow/compiler/mlir/lite/tests/modify_io_nodes.mlir, tensorflow/compiler/mlir/lite/tests/ops.mlir, tensorflow/compiler/mlir/lite/tests/optimize.mlir, tensorflow/compiler/mlir/lite/tests/optimize_batch_matmul.mlir, tensorflow/compiler/mlir/lite/tests/optimize_no_verify.mlir, tensorflow/compiler/mlir/lite/tests/post-quantize-dynamic-range.mlir, tensorflow/compiler/mlir/lite/tests/post-quantize.mlir, tensorflow/compiler/mlir/lite/tests/prepare-composite-functions-tf.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize-dynamic-range.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize-post-training-16bits.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize-post-training.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize-signed.mlir, tensorflow/compiler/mlir/lite/tests/prepare-quantize.mlir, tensorflow/compiler/mlir/lite/tests/prepare-tf-fake-quant-4bit.mlir, tensorflow/compiler/mlir/lite/tests/prepare-tf-fake-quant.mlir, tensorflow/compiler/mlir/lite/tests/prepare-tf.mlir, tensorflow/compiler/mlir/lite/tests/push-tpose-through-ewise.mlir, tensorflow/compiler/mlir/lite/tests/quantize-dynamic-range-float16.mlir, tensorflow/compiler/mlir/lite/tests/quantize-dynamic-range.mlir, tensorflow/compiler/mlir/lite/tests/quantize-numeric-verify.mlir, tensorflow/compiler/mlir/lite/tests/quantize-variables.mlir, tensorflow/compiler/mlir/lite/tests/quantize.mlir, tensorflow/compiler/mlir/lite/tests/shape-inference.mlir, tensorflow/compiler/mlir/lite/tests/split-merged-operands.mlir, tensorflow/compiler/mlir/lite/tests/tfl_while_outline.mlir, tensorflow/compiler/mlir/tosa/tests/retain_call_once_funcs.mlir, tensorflow/compiler/mlir/tosa/tests/tfl-to-tosa-pipeline-filtered.mlir, tensorflow/compiler/mlir/tosa/tests/tfl-to-tosa-stateful.mlir, tensorflow/lite/python/analyzer_test.py",chsigg,False
"compat: Update forward compatibility horizon to 2024-05-02

PiperOrigin-RevId: 629991602",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 09:03:31,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1850.

PiperOrigin-RevId: 629991173",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 09:02:07,tensorflow/core/public/version.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629989461",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 08:53:48,"tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config_test.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf.cc, tensorflow/compiler/mlir/tf2xla/transforms/test_utils.cc, tensorflow/compiler/mlir/tf2xla/transforms/test_utils.h, tensorflow/compiler/mlir/tf2xla/transforms/tf2xla_rewriter.cc, tensorflow/compiler/mlir/tf2xla/transforms/tf2xla_rewriter.h, tensorflow/compiler/mlir/tf2xla/transforms/tf2xla_rewriter_test.cc, tensorflow/compiler/mlir/tf2xla/transforms/xla_legalize_tf_test.cc",tensorflower-gardener,False
"Integrate Triton up to [8e0c7b42](https://github.com/openai/triton/commits/8e0c7b425ac149c43183de966ffa423fd46e4762)

PiperOrigin-RevId: 629987238",Mohammed Anany,manany@google.com,2024-05-02 08:41:56,"third_party/triton/llvm_integration/cl623185214.patch, third_party/triton/llvm_integration/series.bzl, third_party/triton/temporary/cl609333259.patch, third_party/triton/temporary/series.bzl, third_party/triton/workspace.bzl, third_party/triton/xla_extensions/series.bzl, third_party/triton/xla_extensions/sparse_dot_fixes_y24w17.patch, third_party/triton/xla_extensions/sparse_dot_passes.patch, third_party/xla/third_party/triton/llvm_integration/cl623185214.patch, third_party/xla/third_party/triton/llvm_integration/series.bzl, third_party/xla/third_party/triton/temporary/cl609333259.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/third_party/triton/xla_extensions/series.bzl, third_party/xla/third_party/triton/xla_extensions/sparse_dot_fixes_y24w17.patch, third_party/xla/third_party/triton/xla_extensions/sparse_dot_passes.patch, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_cuda.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/tests/gpu_triton_custom_call_test.cc, third_party/xla/xla/service/gpu/tests/sparse_ttg_loop_pipeline.mlir",Moerafaat,False
"Merge pull request #61773 from Intel-tensorflow:kanvi/remove_stopgradient

PiperOrigin-RevId: 629985089",TensorFlower Gardener,gardener@tensorflow.org,2024-05-02 08:55:16,tensorflow/python/framework/graph_util_impl.py,tensorflower-gardener,False
"PR #11348: [XLA:GPU] Enable Async nccl collective operators in command buffer

Imported from GitHub PR https://github.com/openxla/xla/pull/11348

This PR enables async collective operators (AllReduceCmd, ReduceScatterCmd, AllGatherCmd, CollectiveBroadcastCmd) in command buffers.

The idea is to translate collective-start thunk to command buffer nccl operator with different execution scope id, and insert a barrier from the original execution scope to the nccl execution scope. on collective-done thunk, it translate into command buffer Barrier command that does synchronization from nccl execution scope to main execution scope.
Copybara import of the project:

--
7678c2306b2f4b477e5a120a61e933d49ba5d14e by Shawn Wang <shawnw@nvidia.com>:

add command buffer scope support for async instructions

use type safe NcclStreamId

fix format

fix unittest failure

fix unittest error

fix test failures

--
0d30d92343b3383c6d97c308199493b331023140 by Shawn Wang <shawnw@nvidia.com>:

fix parameter name

--
0170d4b2b9d9db3302187b0d7d1dd1fa27c089b5 by Shawn Wang <shawnw@nvidia.com>:

add header file

--
0cb9fdb1e5f24a84a6a6d1ed72a0f1270d91e977 by Shawn Wang <shawnw@nvidia.com>:

fix build file

--
321c31204a119ecb92e2bb8489aa6661c8b1cf15 by Shawn Wang <shawnw@nvidia.com>:

fix stream id assignment

--
15bd4871f5dfd23bd8564a5e710b4dce7cf8100b by Shawn Wang <shawnw@nvidia.com>:

fix c-style error

--
dfe36017756e07362fed49a2430d72d394aadb4e by Shawn Wang <shawnw@nvidia.com>:

add dep

Merging this change closes #11348

PiperOrigin-RevId: 629983411",Shawn Wang,shawnw@nvidia.com,2024-05-02 08:25:13,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_emitter.cc, third_party/xla/xla/service/gpu/runtime/nccl_clique_key.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.h, third_party/xla/xla/service/gpu/runtime/thunk.cc",shawnwang18,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629982238",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 08:19:57,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[xla:ffi] Extend typed DeviceMemory API

Add methods returning native data pointers to se::DeviceMemory<T> class. These methods aim to reduce code duplication (for example in typed FFI custom calls).

PiperOrigin-RevId: 629980509",Adam Banaś,adambanas@google.com,2024-05-02 08:11:29,"third_party/xla/xla/stream_executor/device_memory.h, third_party/xla/xla/tests/custom_call_test.cc",Adam-Banas,False
"[XLA:GPU][IndexAnalysis] Add a method to remove unused dims and symbols.

Both RemoveUnusedSymbols and RemoveUnusedDims find unused dims and symbols. Therefore, it would not be efficient to run this part twice when we want to remove both symbols and dimensions.

PiperOrigin-RevId: 629977850",Alexander Belyaev,pifon@google.com,2024-05-02 08:01:47,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",pifon2a,False
"[XLA:GPU][MLIR-Based emitters] Make lower_func pass a FunctionPass.

PiperOrigin-RevId: 629962173",Alexander Belyaev,pifon@google.com,2024-05-02 06:47:10,"third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/convert_xla_gpu_pure_call_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/passes.h, third_party/xla/xla/service/gpu/fusions/mlir/passes.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/convert_xla_gpu_pure_calls.mlir, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_func.mlir",pifon2a,False
"Allow HloDCE to remove unused tuple elements of MOF

Multi-Output fusions (MOF) should not have tuple outputs that are unused. This
change adds logic to clean up such fusions.

PiperOrigin-RevId: 629962002",Adrian Kuegel,akuegel@google.com,2024-05-02 06:46:01,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_dce.cc, third_party/xla/xla/service/hlo_dce_test.cc, third_party/xla/xla/service/hlo_rematerialization_test.cc",akuegel,False
"[XLA:GPU][MLIR-Based emitters] Lower xla_gpu.indexing_op -> arith.

PiperOrigin-RevId: 629961367",Alexander Belyaev,pifon@google.com,2024-05-02 06:42:26,"third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/simplify_affine.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/simplify_affine.mlir, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h",pifon2a,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629956384",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 06:17:54,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629954972",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 06:10:06,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/while_loop_expensive_invariant_code_motion.h, third_party/xla/xla/service/while_loop_expensive_invariant_code_motion_test.cc, third_party/xla/xla/service/while_loop_fusible_sinking.cc, third_party/xla/xla/service/while_loop_fusible_sinking.h, third_party/xla/xla/service/while_loop_invariant_code_motion.h, third_party/xla/xla/service/while_loop_simplifier.cc, third_party/xla/xla/service/while_loop_simplifier.h, third_party/xla/xla/service/while_loop_trip_count_annotator.cc, third_party/xla/xla/service/while_loop_trip_count_annotator.h, third_party/xla/xla/service/while_loop_unroller.cc, third_party/xla/xla/service/while_util.cc, third_party/xla/xla/service/while_util.h, third_party/xla/xla/service/while_util_test.cc, third_party/xla/xla/service/zero_sized_hlo_elimination.cc, third_party/xla/xla/service/zero_sized_hlo_elimination.h",tensorflower-gardener,False
"Remove unused function GetContextHandle from stream_executor

PiperOrigin-RevId: 629950436",Henning Becker,hebecker@google.com,2024-05-02 05:47:18,"third_party/xla/xla/stream_executor/cuda/cuda_driver.cc, third_party/xla/xla/stream_executor/gpu/gpu_driver.h, third_party/xla/xla/stream_executor/gpu/gpu_types.h, third_party/xla/xla/stream_executor/rocm/rocm_driver.cc",beckerhe,False
"PR #12005: [XLA:GPU] Fix cuDNN flash attention unit test failure with cuDNN 9.0

Imported from GitHub PR https://github.com/openxla/xla/pull/12005

* Use `build_plans` instead of `build_plan_at_index` for flash attention as cuDNN 9.0 could have more than 1 plan and some plans cant be built.
Copybara import of the project:

--
5379425cce6606435c84219eee3d4ca4f98fc5ab by cjkkkk <ske@nvidia.com>:

use build_plans as cudnn 9 has more than 1 plan

Merging this change closes #12005

PiperOrigin-RevId: 629945294",Shanbin Ke,ske@nvidia.com,2024-05-02 05:20:18,"third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc, third_party/xla/xla/stream_executor/cuda/cuda_dnn.h, third_party/xla/xla/stream_executor/dnn.h",Cjkkkk,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629933222",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 04:17:58,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[pjrt] NFC: Make absl::StatusOr<T> implicit part of PjRtFuture<T>

PiperOrigin-RevId: 629911344",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 02:30:06,"tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.h, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils.cc, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils_test.cc, tensorflow/core/tfrt/ifrt/ifrt_restore_tensor_registry.cc, tensorflow/core/tfrt/ifrt/ifrt_restore_tensor_registry.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc, tensorflow/dtensor/cc/parallel_executor.h, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc, third_party/xla/xla/pjrt/host_callback.h, third_party/xla/xla/pjrt/pjrt_c_api_client.h, third_party/xla/xla/pjrt/pjrt_client.cc, third_party/xla/xla/pjrt/pjrt_client.h, third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/pjrt/pjrt_future_test.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h, third_party/xla/xla/pjrt/tf_pjrt_client.h, third_party/xla/xla/python/ifrt_proxy/client/BUILD, third_party/xla/xla/python/ifrt_proxy/client/client_session.h, third_party/xla/xla/python/ifrt_proxy/client/executable.cc, third_party/xla/xla/python/ifrt_proxy/client/executable.h, third_party/xla/xla/python/ifrt_proxy/client/grpc_client.cc, third_party/xla/xla/python/ifrt_proxy/client/grpc_client_session.cc, third_party/xla/xla/python/ifrt_proxy/client/grpc_client_session.h, third_party/xla/xla/python/ifrt_proxy/client/grpc_client_session_test.cc, third_party/xla/xla/python/ifrt_proxy/client/grpc_host_buffer.cc, third_party/xla/xla/python/ifrt_proxy/client/grpc_host_buffer.h, third_party/xla/xla/python/ifrt_proxy/client/host_buffer.h, third_party/xla/xla/python/ifrt_proxy/client/mock_host_buffer.h, third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.cc, third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.h, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.h, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.cc, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.h",ezhulenev,False
"[XLA:GPU] Update FindNonTrivialHero to work with HloInstructionAdaptor.

PiperOrigin-RevId: 629910977",Oleg Shyshkov,shyshkov@google.com,2024-05-02 02:28:07,"third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/hlo_traversal.h, third_party/xla/xla/service/gpu/ir_emission_utils.cc, third_party/xla/xla/service/gpu/ir_emission_utils.h, third_party/xla/xla/service/gpu/ir_emission_utils_test.cc, third_party/xla/xla/service/gpu/rename_fusions.cc",olegshyshkov,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629909312",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 02:17:45,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Remove XLA:CPU runtime support from tf2xla

PiperOrigin-RevId: 629895538",Eugene Zhulenev,ezhulenev@google.com,2024-05-02 01:07:01,"tensorflow/compiler/aot/codegen.cc, tensorflow/compiler/aot/codegen_test_h.golden, tensorflow/compiler/tf2xla/BUILD, tensorflow/compiler/tf2xla/xla_compiled_cpu_function.cc, tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h, tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.cc",ezhulenev,False
"Adds the skeleton for `BasicStringArray` - a simple `ifrt::Array` implementation that wraps a local (or host) string buffer.

PiperOrigin-RevId: 629888345",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 00:33:45,"third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.cc, third_party/xla/xla/python/pjrt_ifrt/basic_string_array.h",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629884735",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-02 00:18:59,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA] Add an option to dump large constants.

PiperOrigin-RevId: 629880338",Tongfei Guo,tongfei@google.com,2024-05-02 00:00:03,"third_party/xla/xla/service/dump.cc, third_party/xla/xla/xla.proto",Tongfei-Guo,False
"Return error early if barrier is requested after coord service has shut down.

PiperOrigin-RevId: 629875540",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 23:39:50,"third_party/xla/xla/tsl/distributed_runtime/coordination/BUILD, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.h, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_test.cc",tensorflower-gardener,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #2

PiperOrigin-RevId: 629867362",Eugene Zhulenev,ezhulenev@google.com,2024-05-01 23:07:35,"third_party/xla/xla/mlir/backends/cpu/transforms/BUILD, third_party/xla/xla/mlir/backends/cpu/transforms/legalize_i1_vector_transfers.cc, third_party/xla/xla/mlir/backends/cpu/transforms/legalize_library_ops.cc, third_party/xla/xla/mlir/backends/cpu/transforms/passes.h, third_party/xla/xla/mlir/backends/cpu/transforms/passes.td, third_party/xla/xla/mlir/backends/cpu/transforms/remove_copies_to_out_params.cc, third_party/xla/xla/mlir/backends/cpu/transforms/xla_abi_legalization.cc, third_party/xla/xla/mlir/backends/cpu/transforms/xla_cpu_memref_element_cast_to_llvm.cc, third_party/xla/xla/mlir/backends/cpu/transforms/xla_cpu_to_cpu_runtime.cc, third_party/xla/xla/mlir/backends/cpu/transforms/xla_rewrite_realloc_to_alloc.cc, third_party/xla/xla/mlir/xla_cpu/ir/BUILD, third_party/xla/xla/mlir/xla_cpu/ir/xla_cpu.cc, third_party/xla/xla/mlir/xla_cpu/ir/xla_cpu.h, third_party/xla/xla/mlir/xla_cpu/ir/xla_cpu_dialect.td, third_party/xla/xla/mlir/xla_cpu/ir/xla_cpu_enums.td, third_party/xla/xla/mlir/xla_cpu/ir/xla_cpu_ops.td",ezhulenev,False
"Automated Code Change

PiperOrigin-RevId: 629864946",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 22:59:17,tensorflow/core/kernels/data/parallel_batch_dataset_op.cc,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@a7b968a57834

Updates LLVM usage to match
[a7b968a57834](https://github.com/llvm/llvm-project/commit/a7b968a57834)

PiperOrigin-RevId: 629861245",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 22:44:42,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"[XLA:SPMD] Support shard-as propagation with unspecified_dims.

PiperOrigin-RevId: 629857357",Tongfei Guo,tongfei@google.com,2024-05-01 22:31:28,"third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation_test.cc",Tongfei-Guo,False
"Nitpick: fix bullet point formatting in docs for `Tout` arg  of `tf.py_function`

PiperOrigin-RevId: 629854702",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 22:21:58,tensorflow/python/ops/script_ops.py,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629853989",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 22:19:23,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix TFLite converter regression for softmax due to Jax upstream change in https://github.com/google/jax/pull/15677.

PiperOrigin-RevId: 629853083",Jae H. Yoo,jaeyoo@google.com,2024-05-01 22:15:54,tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td,jaeyoo,False
"[xla:cpu] NFC: Remove deprecated XLA:CPU mlir based codegen part #1

PiperOrigin-RevId: 629853006",Eugene Zhulenev,ezhulenev@google.com,2024-05-01 22:15:37,"tensorflow/compiler/mlir/BUILD, tensorflow/compiler/mlir/register_common_dialects.cc, tensorflow/compiler/mlir/tf2xla/tests/hlo_xla_runtime_pipeline.mlir, tensorflow/compiler/mlir/tf_mlir_opt_main.cc, third_party/xla/xla/mlir/runtime/transforms/BUILD, third_party/xla/xla/mlir/runtime/transforms/compilation_pipeline_cpu.cc, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/hlo_xla_runtime_pipeline.cc, third_party/xla/xla/service/cpu/hlo_xla_runtime_pipeline.h, third_party/xla/xla/translate/BUILD",ezhulenev,False
"Make MSA more deterministic.

PiperOrigin-RevId: 629852083",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 22:12:05,third_party/xla/xla/service/memory_space_assignment/algorithm.cc,tensorflower-gardener,False
"Add folding for shlo div op and start a pass that canonicalizes and folds shlo within the odml converter.

PiperOrigin-RevId: 629851095",Luke Boyer,lukeboyer@google.com,2024-05-01 22:08:44,"tensorflow/compiler/mlir/lite/stablehlo/odml_converter/BUILD, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/folders.cc, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/folders.h, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/passes.h, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/passes.td, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/tests/BUILD, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/tests/shlo_simplify.mlir, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/transforms/shlo_simplify.cc",LukeBoyer,False
"Adds tool path to visibility list.

PiperOrigin-RevId: 629848922",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 22:01:24,tensorflow/compiler/mlir/lite/BUILD,tensorflower-gardener,False
"Integrate StableHLO at openxla/stablehlo@b6406a43

PiperOrigin-RevId: 629847908",Sandeep Dasgupta,sdasgup@google.com,2024-05-01 21:58:00,"third_party/stablehlo/temporary.patch, third_party/stablehlo/workspace.bzl, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/workspace.bzl, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/verifier_conv_op.mlir",sdasgup3,False
"Add odml_converter to runlit.cfg and runlite.site.cfg

PiperOrigin-RevId: 629836058",Luke Boyer,lukeboyer@google.com,2024-05-01 21:18:51,"tensorflow/compiler/mlir/runlit.cfg.py, tensorflow/compiler/mlir/runlit.site.cfg.py",LukeBoyer,False
"[XLA:SPMD] support sharding barrier (1/N).

1. Add a two custom-call to allow barrier sharding propagation forward/backward unidirectionally.
2. Make shard_as/shard_like shard_barrier aware.

PiperOrigin-RevId: 629829963",Tongfei Guo,tongfei@google.com,2024-05-01 20:59:48,"third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util.h, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation_test.cc, third_party/xla/xla/service/spmd/BUILD, third_party/xla/xla/service/spmd/shard_barrier_partitioner.h",Tongfei-Guo,False
"Fix the number of cores to be based on topolgoy.

PiperOrigin-RevId: 629826090",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 20:46:36,"tensorflow/core/tpu/kernels/sparse_core_xla_ops.cc, third_party/xla/xla/stream_executor/tpu/tpu_library_init_fns.inc, third_party/xla/xla/stream_executor/tpu/tpu_ops_c_api.h",tensorflower-gardener,False
"Do not include CUDA deps for LIBTPU build.

PiperOrigin-RevId: 629825294",Feng Wang,wffw@google.com,2024-05-01 20:44:10,third_party/xla/third_party/tsl/tsl/profiler/lib/BUILD,lionelfeng,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629816496",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 20:17:40,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
Update build file,Yimei Sun,yimei.sun@intel.com,2024-05-01 20:23:19,tensorflow/python/tools/BUILD,yimeisun123,True
"Update version of nsync used by TensorFlow.

TensorFlow previously imported nsync 1.25.0.
The changes to nsync since then are:
- a fix for a bug that can affect systems with weak memory
  ordering, such as Arm (the bug does not impact x86);
- a fix to a build problem when using both cmake on
  Windows with a compiler other than MSVC
  (previously, CMakeLists.txt would erroneously pass MSVC-specific
  warning-suppression flags to a non-MSVC  compiler);
- changes to help nsync work with thread sanitizer; and
- native atomic operation support for loongarch.

PiperOrigin-RevId: 629810286",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 19:58:17,"tensorflow/workspace2.bzl, third_party/nsync.patch, third_party/xla/third_party/tsl/third_party/nsync.patch, third_party/xla/third_party/tsl/workspace2.bzl",tensorflower-gardener,False
"[pjrt] NFC: Merge implementation of stateful and stateless futures

Move shared code into the PjRtFutureBase and keep only meaningfully different functions in PjRtFuture<T> and PjRtFuture<>.

PiperOrigin-RevId: 629807049",Eugene Zhulenev,ezhulenev@google.com,2024-05-01 19:47:28,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"#tf-data Fix prefetching to FlatMap global shuffling.

PiperOrigin-RevId: 629797413",Yang Chen,yangchen@google.com,2024-05-01 19:14:24,"tensorflow/core/kernels/data/flat_map_dataset_op.cc, tensorflow/core/kernels/data/repeat_dataset_op.cc, tensorflow/python/data/kernel_tests/flat_map_test.py",yangustc07,False
"Refactoring. Breaking MsaAlgorithm::AllocateAllocationValues() into smaller functions

PiperOrigin-RevId: 629795164",Mehrdad Khani,mehrdadk@google.com,2024-05-01 19:06:47,"third_party/xla/xla/service/memory_space_assignment/algorithm.cc, third_party/xla/xla/service/memory_space_assignment/algorithm.h",mehrdadkhani,False
"Add macros to disable tests on GRM

PiperOrigin-RevId: 629787240",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 18:43:33,third_party/xla/xla/tests/test_macros.h,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629778693",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 18:17:57,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Reverts changelist 444604608

PiperOrigin-RevId: 629774966",Jian Cai,jiancai@google.com,2024-05-01 18:06:33,tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_cluster_formation.cc,jcai19,False
"Fix typo in shape formatter.

PiperOrigin-RevId: 629772965",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 18:00:49,third_party/xla/xla/python/py_array.cc,tensorflower-gardener,False
"PR #11651: fix GpuPerformanceWithCollectiveModel: communication_time should be M…

Imported from GitHub PR https://github.com/openxla/xla/pull/11651

fix GpuPerformanceWithCollectiveModel: communication_time should be Milliseconds
#11650
Copybara import of the project:

--
cbdde983ab780971f384c821837b2ebda5de3ff1 by zjjott <zjjott@gmail.com>:

fix GpuPerformanceWithCollectiveModel: communication_time should be Milliseconds

Merging this change closes #11651

PiperOrigin-RevId: 629770723",zhu jianjiang,zjjott@126.com,2024-05-01 17:54:10,third_party/xla/xla/service/gpu/model/gpu_collective_performance_model.cc,zjjott,False
"Optimize KVCache memory.

PiperOrigin-RevId: 629769732",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 17:51:08,tensorflow/lite/experimental/genai/kvcache.cc,tensorflower-gardener,False
Fix python format,Yimei Sun,yimei.sun@intel.com,2024-05-01 17:45:52,"tensorflow/python/tools/optimize_for_inference_lib.py, tensorflow/python/tools/optimize_for_inference_test.py",yimeisun123,True
"functional_hlo_runner: force untuple_result if any output leaf buffer is in host memory space

PiperOrigin-RevId: 629752635",Emilio Cota,ecg@google.com,2024-05-01 16:56:00,"third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc",cota,False
"functional_hlo_runner: read entry_computation_layout from HloModule

Instead of reading it from CompilationOptions; the compiled HloModule
already contains this information.

While at it, simplify the argument_memory_space lambda -- it is
reasonable to expect parameter tuples to be flattened.

PiperOrigin-RevId: 629747967",Emilio Cota,ecg@google.com,2024-05-01 16:35:58,third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc,cota,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629745116",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 16:25:07,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
Update on comments and unit test cases,Yimei Sun,yimei.sun@intel.com,2024-05-01 16:15:45,"tensorflow/python/tools/optimize_for_inference_lib.py, tensorflow/python/tools/optimize_for_inference_test.py",yimeisun123,True
"This CL adds support for handling the SPMDFullToShardShape and SPMDShardToFullShape custom calls in auto-sharding.

PiperOrigin-RevId: 629731839",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 15:33:05,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_strategy.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_test.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.h",tensorflower-gardener,False
"[xla:gpu] Extend the collective pipeliner to support pipelining collective
operations with control dependencies.

Add should_allow_control_dependencies to the collective pipeliner configuration
to allow pipelining collective operations with control dependencies. The
control dependencies will be dropped when the operation is pipelined. This is
currently only used in kBackward pipelining.

In the GPU compiler, we make Send as a control predecessor of its corresponding
RecvDone, to prevent certain optimizations, in particular, the fusion of the
computation that calculates the Send data and the computation that uses the
Recv result. This extension to the collective pipeliner allows the GPU compiler
to pipeline RecvDone operations with a Send as their control predecessor.

Modify an existing test to test the situation.

PiperOrigin-RevId: 629725289",Bixia Zheng,bixia@google.com,2024-05-01 15:03:50,"third_party/xla/xla/service/collective_pipeliner.cc, third_party/xla/xla/service/collective_pipeliner.h, third_party/xla/xla/service/collective_pipeliner_test.cc, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.cc, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner_test.cc",bixia1,False
"Increasing minimum tiling for contracting dimension in Gemms with an 8-bit operand to 32 instead of 16. This is a workaround to avoid potential crashes that occur in Triton.

PiperOrigin-RevId: 629708698",Mohammed Anany,manany@google.com,2024-05-01 13:39:00,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.h, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc",Moerafaat,False
"Merge pull request #66082 from Intel-tensorflow:amin/fp32-quantizev2

PiperOrigin-RevId: 629699504",TensorFlower Gardener,gardener@tensorflow.org,2024-05-01 12:52:27,"tensorflow/core/kernels/mkl/mkl_quantize_op.cc, tensorflow/core/kernels/mkl/mkl_quantize_op_test.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629696046",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 12:20:54,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629682872",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 11:01:10,"tensorflow/compiler/mlir/tensorflow/translate/export_graphdef.cc, tensorflow/compiler/mlir/tensorflow/translate/export_graphdef.h, tensorflow/compiler/mlir/tensorflow/translate/export_tf_dialect_op.cc, tensorflow/compiler/mlir/tensorflow/translate/export_tf_dialect_op.h, tensorflow/compiler/mlir/tensorflow/translate/import_model.cc, tensorflow/compiler/mlir/tensorflow/translate/import_model.h, tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_flags.cc, tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_pass.cc, tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate.cc, tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate.h, tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate_registration.cc",tensorflower-gardener,False
"[xla:ffi] Revised the list of supported attribute types and added tests

Turns out the previous commit did not update the runtime, this the FFI failed
with an error when constructing a frame with e.g. bool attributes.

Here I decided to

* Only support signed integer attributes, i.e. leave out unsigned integer
  types until we have a use-case which needs them.
* Drop support for boolean arrays as attributes. The reasons are purely
  techincal: MLIR stores them as std::vector<bool> which has
  implementation-defined storage. Thus, we have to copy the vector to be able
  to expose it as XLA_FFI_Array.

PiperOrigin-RevId: 629681930",Sergei Lebedev,slebedev@google.com,2024-05-01 10:53:55,"third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/call_frame.h, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_test.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc",superbobry,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629676100",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 10:17:36,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629664099",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 09:03:41,tensorflow/python/eager/pywrap_tfe_src.cc,tensorflower-gardener,False
"Update GraphDef version to 1849.

PiperOrigin-RevId: 629664057",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 09:03:29,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-05-01

PiperOrigin-RevId: 629664043",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 09:03:24,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629660644",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 08:41:21,tensorflow/compiler/mlir/tf2xla/internal/passes/input_lowering_metrics_pass.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629656755",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 08:19:51,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629655287",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 08:10:36,tensorflow/core/profiler/internal/tfprof_utils.cc,tensorflower-gardener,False
"Sharding custom calls cannot be hoisted individually in `WhileLoopInvariantCodeMotion`.

A sharding custom call annotates sharding to its operand. If we move a single sharding custom call out of the while body, the sharding annotation may not take effect as expected.

Taking the follow while body as an example,
```
body {
  p_body = (f32[2], f32[2], s32[]) parameter(0)
  gte.0 = f32[2] get-tuple-element(p_body), index=0
  gte.1 = f32[2] get-tuple-element(p_body), index=1
  sharding.0 = f32[2] custom-call(gte.0), custom_call_target=""Sharding"", sharding={devices=[2]<=[2]}
  sharding.1 = f32[2] custom-call(gte.1), custom_call_target=""Sharding"", sharding={replicated}
  add.0 = f32[2] add(sharding.0, sharding.1)
  gte.2 = s32[] get-tuple-element(p_body), index=2
  const = s32[] constant(1)
  add.1 = s32[] add(gte.2, const)
  ROOT root = (f32[2], f32[2], s32[]) tuple(gte.0, add.0, add.1)
}
```

Before this cl, `WhileLoopInvariantCodeMotion` moves `sharding.0` out of the body and keeps `sharding.1` in the body. With this cl, `WhileLoopInvariantCodeMotion` does not modify this body.

PiperOrigin-RevId: 629637435",Zixuan Jiang,zixuanjiang@google.com,2024-05-01 06:27:49,"third_party/xla/xla/service/while_loop_invariant_code_motion.cc, third_party/xla/xla/service/while_loop_invariant_code_motion_test.cc",ZixuanJiang,False
"Automated Code Change

PiperOrigin-RevId: 629636195",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 06:19:50,"tensorflow/core/util/ctc/ctc_beam_search.h, tensorflow/core/util/ctc/ctc_decoder.h, tensorflow/core/util/ctc/ctc_loss_calculator.h",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629635864",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 06:17:39,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Switch quantization dialect to use properties.

PiperOrigin-RevId: 629634333",Christian Sigg,csigg@google.com,2024-05-01 06:07:48,"tensorflow/compiler/mlir/lite/quantization/ir/QuantOpsBase.td, tensorflow/compiler/mlir/lite/quantization/tests/import_quant_stats.mlir, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/importer_test_min_max.cc, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/lstm.json, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/quant_stats.mlir, tensorflow/compiler/mlir/quantization/common/ir/QuantOpsBase.td, tensorflow/compiler/mlir/quantization/tensorflow/tests/convert_custom_aggregation_op_to_quant_stats.mlir",chsigg,False
"[pjrt] Disable non-absl::StatusOr<T> PjRtFutures

Before switching all PjRtFutures to implicit absl::StatusOr make sure that all users use explicit StatusOr payloads.

PiperOrigin-RevId: 629633772",Eugene Zhulenev,ezhulenev@google.com,2024-05-01 06:04:29,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"[ifrt] NFC: Use PjRtFuture<absl::StatusOr<T>> in ifrt

In preparation for making PjRtFuture holding absl::StatusOr<T> payload add StatusOr to all existing PjRtFuture<T>. It will be removed later when all users will use absl::StatusOr wrappers.

PiperOrigin-RevId: 629620040",Eugene Zhulenev,ezhulenev@google.com,2024-05-01 04:38:31,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/host_callback.cc, third_party/xla/xla/pjrt/host_callback.h, third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/pjrt/pjrt_future_test.cc",ezhulenev,False
"[tsl:concurrency] Correctly handle typed indirect async values that become errors

PiperOrigin-RevId: 629616935",Eugene Zhulenev,ezhulenev@google.com,2024-05-01 04:19:33,"third_party/xla/xla/tsl/concurrency/async_value.cc, third_party/xla/xla/tsl/concurrency/async_value_ptr_test.cc, third_party/xla/xla/tsl/concurrency/async_value_ref_test.cc",ezhulenev,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629616676",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 04:17:37,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[XLA:GPU] Use parent fusion adaptor to correctly find operands and users.

After this change, HloInstruction adaptor wouldn't look inside kFusion instruction that not part of the relevant fusion adaptor.

PiperOrigin-RevId: 629615147",Oleg Shyshkov,shyshkov@google.com,2024-05-01 04:08:40,"third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/hlo_traversal.h, third_party/xla/xla/service/gpu/hlo_traversal_test.cc, third_party/xla/xla/service/gpu/ir_emission_utils.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc",olegshyshkov,False
"[xla:gpu] Add a GemmDegenerateDimRemover pass

This pass removes the degenerate dimension introduced by GemvRewriter. We should remove degenerate dimensions after we run GemmFusion.

PiperOrigin-RevId: 629606212",Anlun Xu,anlunx@google.com,2024-05-01 03:19:56,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_degenerate_dim_remover.cc, third_party/xla/xla/service/gpu/gemm_degenerate_dim_remover.h, third_party/xla/xla/service/gpu/gemm_degenerate_dim_remover_test.cc",anlunx,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629595589",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 02:18:04,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[xla:gpu] NFC: Delete unused external allocations and allocate/free command buffer commands

Run time memory allocation inside command buffers does not compose well with XLA static memory planning and was never fully implemented. Instead we should build it around memory spaces and introduce a special memory space for virtual allocations (via direct use of virtual memory allocation APIs or CUDA graphs).

PiperOrigin-RevId: 629594465",Eugene Zhulenev,ezhulenev@google.com,2024-05-01 02:09:54,"third_party/xla/xla/service/gpu/buffer_allocations.cc, third_party/xla/xla/service/gpu/buffer_allocations.h, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_allocations.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_allocations.h, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk.h, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk_test.cc, third_party/xla/xla/stream_executor/command_buffer.h, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer.cc, third_party/xla/xla/stream_executor/gpu/gpu_command_buffer.h",ezhulenev,False
"[XLA:GPU] Add HloAnyOf to hlo_traversal.h

This is a variant of HloFindIf that doesn't require instruction and fusion adaptors.

PiperOrigin-RevId: 629583927",Mohammed Anany,manany@google.com,2024-05-01 01:08:26,"third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/hlo_traversal.h",Moerafaat,False
"Fix HloAyncStartInstruction::ClassOf
Ignore verifying computation parameter/result shapes for custom-call async ops

PiperOrigin-RevId: 629581360",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 00:56:25,"third_party/xla/xla/hlo/ir/hlo_instructions.h, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/hlo_verifier_test.cc",tensorflower-gardener,False
"Fix a bug in flatbuffer_operator.cc when importing vhlo.float_v1 attribute.

FloatV1Attr expects an vhlo type instead of a regelar mlir type.

PiperOrigin-RevId: 629578682",Weiyi Wang,weiyiw@google.com,2024-05-01 00:41:35,tensorflow/compiler/mlir/lite/flatbuffer_operator.cc,sirakiin,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629577542",A. Unique TensorFlower,gardener@tensorflow.org,2024-05-01 00:36:06,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Implement a Freeze() api to release host memory for device tensors.
Whether a restored tensor can be released is based on whether it is
ever used by the CPU/Host ops and this information comes
from compiler.

PiperOrigin-RevId: 629575720",Deqiang Chen,deqiangc@google.com,2024-05-01 00:27:53,"tensorflow/compiler/mlir/tensorflow/ir/host_runtime/tfrt_ops.td, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_mlrt_ops.td, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_ops.td, tensorflow/compiler/mlir/tfrt/tests/ifrt/sink_variable_as_named_array.mlir, tensorflow/compiler/mlir/tfrt/tests/mlrt/rewrite_ifrt_load_variable.mlir, tensorflow/compiler/mlir/tfrt/tests/mlrt/tf_to_mlrt.mlir, tensorflow/compiler/mlir/tfrt/transforms/ifrt/sink_variable_as_named_array.cc, tensorflow/compiler/mlir/tfrt/transforms/mlrt/tf_to_mlrt.cc, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils_test.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_restore_tensor_registry.cc, tensorflow/core/tfrt/ifrt/ifrt_restore_tensor_registry.h, tensorflow/core/tfrt/mlrt/kernel/BUILD, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc",deqiangc,False
"[XLA:SPMD] support sharding barrier (0/N).

Fold shard group sharding instruction attribute into operand instead of replacing with an explicit copy.

PiperOrigin-RevId: 629575145",Tongfei Guo,tongfei@google.com,2024-05-01 00:25:54,"third_party/xla/xla/hlo/ir/hlo_computation.cc, third_party/xla/xla/hlo/ir/hlo_computation.h, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation_test.cc",Tongfei-Guo,False
"[xla:gpu] NFC: Move async comm streams to CollectiveExecuteParams

PiperOrigin-RevId: 629573198",Eugene Zhulenev,ezhulenev@google.com,2024-05-01 00:16:16,"third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.h",ezhulenev,False
"Add instructions to report issues to GitHub for unsupported features in PJRT C API.

PiperOrigin-RevId: 629572930",Jieying Luo,jieying@google.com,2024-05-01 00:14:49,third_party/xla/xla/pjrt/pjrt_c_api_client.h,jyingl3,False
"Mark dots to be unpropogatable on space-to-batch conversion. Delaying the conversion from dots to convs to occur post layout assignment caused this.

PiperOrigin-RevId: 629565394",Amit Sabne,asabne@google.com,2024-04-30 23:41:39,"third_party/xla/xla/service/space_to_batch_converter.cc, third_party/xla/xla/service/space_to_batch_converter_test.cc",amitsabne1,False
"#tf-data Add prefetching to WeightedFlatMap tests.

PiperOrigin-RevId: 629563974",Yang Chen,yangchen@google.com,2024-04-30 23:36:03,"tensorflow/core/kernels/data/experimental/weighted_flat_map_dataset_op.cc, tensorflow/python/data/experimental/kernel_tests/BUILD, tensorflow/python/data/experimental/kernel_tests/weighted_flat_map_test.py",yangustc07,False
"Ensure that all instructions which are inserted by HloRematerialization have .remat in their name.

Cloned computations are excluded from this check.

PiperOrigin-RevId: 629553524",Victor Stone,victorstone@google.com,2024-04-30 22:54:19,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_rematerialization.cc, third_party/xla/xla/service/hlo_rematerialization_test.cc",SandSnip3r,False
"Rollback

Reverts 838b2f22e36d483be7fd6cccbedd30d46497c7f3

PiperOrigin-RevId: 629553241",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 22:52:53,tensorflow/core/framework/op_requires.h,tensorflower-gardener,False
"Update py_client_gpu config so that it is built when if_google is true.

PiperOrigin-RevId: 629552616",Jieying Luo,jieying@google.com,2024-04-30 22:50:25,third_party/xla/xla/python/BUILD,jyingl3,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629545583",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 22:23:18,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Fix a bug in which an absl hashtable is used with inconsistent hash/eq functors.

`eq(k1, k2) -> hash(k1) == hash(k2)` must be true for hashtable usage to be valid.

The bug here is that when the hash is layout insensitive, we can't hash the data bytes in their physical order - we must hash them in their logical order.

PiperOrigin-RevId: 629543094",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 22:14:23,"third_party/xla/xla/BUILD, third_party/xla/xla/literal.h, third_party/xla/xla/literal_test.cc",tensorflower-gardener,False
"[XLA:CPU] Enable constant host offloading

PiperOrigin-RevId: 629536482",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 21:50:17,third_party/xla/xla/service/host_offloader.cc,tensorflower-gardener,False
"[XLA:GPU][IndexAnalysis] Add a method to remove unused dims.

PiperOrigin-RevId: 629535846",Alexander Belyaev,pifon@google.com,2024-04-30 21:47:48,"third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",pifon2a,False
"Create DeviceMemoryHandle which fulfills a similar function to ScopedDeviceMemory, with no ties to DeviceMemoryAllocator.

This is a step in breaking circular dependencies between DeviceMemoryAllocator and StreamExecutor.

PiperOrigin-RevId: 629529802",Kyle Lucke,klucke@google.com,2024-04-30 21:27:14,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/buffer_comparator.cc, third_party/xla/xla/service/gpu/buffer_comparator_test.cc, third_party/xla/xla/service/gpu/infeed_manager.cc, third_party/xla/xla/service/gpu/infeed_manager.h, third_party/xla/xla/service/gpu/kernels/BUILD, third_party/xla/xla/service/gpu/kernels/topk_kernel_test.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/infeed_thunk.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/device_memory_handle.cc, third_party/xla/xla/stream_executor/device_memory_handle.h, third_party/xla/xla/stream_executor/device_memory_handle_test.cc, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/redzone_allocator.cc",klucke,False
"[IFRT] Don't populate the pjrt_device() field of PJRT-IFRT devices for non-addressable devices.

Change in preparation for removing knowledge of non-addressable devices from PJRT in many cases. In the future, only IFRT should know about devices outside the current process. This change removes any access to those PJRT devices via IFRT.

PiperOrigin-RevId: 629524945",Peter Hawkins,phawkins@google.com,2024-04-30 21:11:02,"third_party/xla/xla/python/dlpack.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_array.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_device.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_device.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_device.cc",hawkinsp,False
"Internal change only.

PiperOrigin-RevId: 629524511",Thomas Köppe,tkoeppe@google.com,2024-04-30 21:09:34,tensorflow/python/lib/core/BUILD,tkoeppe,False
"Reverts changelist 473051719

PiperOrigin-RevId: 629523123",Jian Cai,jiancai@google.com,2024-04-30 21:04:57,"tensorflow/compiler/mlir/tensorflow/tests/cluster_outlining.mlir, tensorflow/compiler/mlir/tensorflow/tests/tpu_cluster_formation.mlir, tensorflow/compiler/mlir/tensorflow/tests/tpu_rewrite.mlir, tensorflow/compiler/mlir/tensorflow/transforms/cluster_outlining.cc, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/tpu_rewrite_pass.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/extract_outside_compilation.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_cluster_formation.cc",jcai19,False
"Add `--remote_download_minimal` to RBE cross-compile Mac config

Fixes https://github.com/bazelbuild/bazel/issues/21568

PiperOrigin-RevId: 629519684",Nitin Srinivasan,srnitin@google.com,2024-04-30 20:54:06,".bazelrc, third_party/xla/.bazelrc, third_party/xla/third_party/tsl/.bazelrc",nitins17,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629516583",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 20:44:06,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Move `gpu_plugin_deps` inside the `if_google` condition of `xla_extension`.

PiperOrigin-RevId: 629511119",Benjamin Chetioui,bchetioui@google.com,2024-04-30 20:27:18,third_party/xla/xla/python/BUILD,bchetioui,False
"Add get_device_ordinal to cuda plugin so that CUDA dependency can be removed from py_array (jaxlib).

py_array still has CUDA dependency as a fallback to keep jaxlib[cuda] working before the migration to CUDA plugin.

PiperOrigin-RevId: 629499893",Jieying Luo,jieying@google.com,2024-04-30 19:49:57,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/xla.cc, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_extension/__init__.pyi",jyingl3,False
"[XLA:GPU] Add hero and root accessors by index to HloFusionAnalysis.

`fusion_root(i)` and `fusion_hero(i)` return `HloInstructionAdaptor` as a preparation to store heros and fusions as adaptors.

PiperOrigin-RevId: 629483875",Oleg Shyshkov,shyshkov@google.com,2024-04-30 18:52:22,"third_party/xla/xla/service/gpu/fusions/concatenate.cc, third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/input_slices.cc, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.cc, third_party/xla/xla/service/gpu/fusions/loop.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/scatter.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.h",olegshyshkov,False
"Add memory allocation timeline in TensorBoard

PiperOrigin-RevId: 629482607",Surbhi Jain,sjsurbhi@google.com,2024-04-30 18:47:50,"tensorflow/core/profiler/convert/BUILD, tensorflow/core/profiler/convert/hlo_to_tools_data.cc",SurbhiJainUSC,False
Fix round mode.,mdfaijul,md.faijul.amin@intel.com,2024-04-30 18:52:11,tensorflow/core/kernels/mkl/mkl_kernel_util.cc,mdfaijul,True
"Reverts changelist 629123951

PiperOrigin-RevId: 629473698",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 18:21:40,tensorflow/lite/BUILD,tensorflower-gardener,False
"PR #11597: Compile F32, BF16 and S32 constants in cuDNN graph.

Imported from GitHub PR https://github.com/openxla/xla/pull/11597

Support compiling F32, BF16 and S32 constants in cuDNN graph.
This PR is blocked until cuDNN frontend dependency is upgraded to v1.3.
Copybara import of the project:

--
e8c6a3f4186242d812a00e8849350febd204f867 by Elfie Guo <elfieg@nvidia.com>:

Compile F32, BF16 and S32 constants in cuDNN graph.

Merging this change closes #11597

PiperOrigin-RevId: 629469616",Elfie Guo,elfieg@nvidia.com,2024-04-30 18:08:49,"third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc",elfiegg,False
"Integrate LLVM at llvm/llvm-project@f4843acd839f

Updates LLVM usage to match
[f4843acd839f](https://github.com/llvm/llvm-project/commit/f4843acd839f)

PiperOrigin-RevId: 629464549",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 17:54:19,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"[xla:ffi] Added attribute decoders for most FFI data types

The only exception is bfloat16, because I wans't sure what is the right native
type to use for it.

PiperOrigin-RevId: 629441149",Sergei Lebedev,slebedev@google.com,2024-04-30 16:39:32,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/ffi.h",superbobry,False
"Make OP_REQUIRES_OK* macros work correctly regardless of lifetime of the status argument.

This corrects earlier changes to OP_REQUIES_OK and OP_REQUIES_OK_ASYNC (e.g. CL/330823151), which took a reference but did not extend the lifetime of potential intermediate temporaries. This would cause problems in situations where a short-lived status was passed in as something other than a prvalue, for example:

  struct T {
    const absl::Status& f() const { return s; }
    absl::Status s;
  };

  OP_REQUIRES_OK(T().f());

This becomes

  const absl::Status& _s(T().f());

which is instantly a dangling reference.

To fix this, we move operations on user-provided arguments into a helper function, and ensure that the user-provided arguments are only used inside a single function call expression. All temporaries remain alive for the duration of the function call.

PiperOrigin-RevId: 629440932",Thomas Köppe,tkoeppe@google.com,2024-04-30 16:38:46,tensorflow/core/framework/op_requires.h,tkoeppe,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629435296",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 16:19:44,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Remove LINT check for IFTTT since we're keeping replicated and non replicated out of sync

PiperOrigin-RevId: 629429812",Mason Chang,masonchang@google.com,2024-04-30 16:00:46,tensorflow/compiler/mlir/tf2xla/internal/clustering_bridge_passes.cc,changm,False
"[tsl:concurrency] Workaround for MSVC compiler bug for std::enable_if_t specialization

https://godbolt.org/z/oj9o6eraa - fixed in msvc 19.32

PiperOrigin-RevId: 629414959",Eugene Zhulenev,ezhulenev@google.com,2024-04-30 15:04:39,third_party/xla/xla/tsl/concurrency/async_value_ref.h,ezhulenev,False
"Remove unnecessary tags on gpu tests

PiperOrigin-RevId: 629412914",David Dunleavy,ddunleavy@google.com,2024-04-30 14:58:14,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/tests/BUILD",ddunl,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629403638",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 14:17:43,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629391590",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 13:17:38,tensorflow/core/lib/hash/BUILD,tensorflower-gardener,False
"Fix CompileMemoryStats::output_size_in_bytes field deserialization from proto.

PiperOrigin-RevId: 629391051",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 13:15:05,"third_party/xla/xla/pjrt/pjrt_executable.h, third_party/xla/xla/pjrt/pjrt_executable_test.cc",tensorflower-gardener,False
"Handle fusion parameters correctly when removing instructions.

When a fusion parameter is removed, we need to renumber all fusion parameters
with a higher number, and also remove the corresponding operand from the fusion
instruction.

PiperOrigin-RevId: 629382748",Adrian Kuegel,akuegel@google.com,2024-04-30 12:39:13,"third_party/xla/xla/hlo/ir/hlo_computation.cc, third_party/xla/xla/service/hlo_computation_test.cc",akuegel,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629378832",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 12:18:47,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629374559",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 11:58:13,"tensorflow/core/ir/importexport/convert_attributes.cc, tensorflow/core/ir/importexport/convert_attributes.h, tensorflow/core/ir/importexport/convert_tensor.cc, tensorflow/core/ir/importexport/convert_tensor.h, tensorflow/core/ir/importexport/convert_types.cc, tensorflow/core/ir/importexport/convert_types.h, tensorflow/core/ir/importexport/functiondef_export.cc, tensorflow/core/ir/importexport/functiondef_export.h, tensorflow/core/ir/importexport/functiondef_import.cc, tensorflow/core/ir/importexport/graphdef_export.cc, tensorflow/core/ir/importexport/graphdef_export.h, tensorflow/core/ir/importexport/graphdef_import.cc, tensorflow/core/ir/importexport/graphdef_import.h, tensorflow/core/ir/importexport/savedmodel_import.cc, tensorflow/core/ir/importexport/savedmodel_import.h",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@8ba880b58707

Updates LLVM usage to match
[8ba880b58707](https://github.com/llvm/llvm-project/commit/8ba880b58707)

PiperOrigin-RevId: 629370627",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 11:36:36,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629370444",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 11:35:26,tensorflow/core/framework/tensor_slice.h,tensorflower-gardener,False
"[PJRT] Fork the GPU client out of `xla.cc` and adjust some test imports.

PiperOrigin-RevId: 629363030",Benjamin Chetioui,bchetioui@google.com,2024-04-30 10:59:50,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/gpu_support.cc, third_party/xla/xla/python/gpu_support.h, third_party/xla/xla/python/xla.cc, third_party/xla/xla/python/xla_client_test.py, third_party/xla/xla/python/xla_gpu_support.cc",bchetioui,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629354728",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 10:17:29,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Use tsl::Env instead of tensorflow::Env to fix the build.

PiperOrigin-RevId: 629349697",Alexander Belyaev,pifon@google.com,2024-04-30 09:53:45,tensorflow/core/runtime_fallback/test/test_kernels.cc,pifon2a,False
"Add missing dependency to cuda_headers.

stream_executor_util_kernel needs to depend on cuda_headers.

PiperOrigin-RevId: 629340695",Adrian Kuegel,akuegel@google.com,2024-04-30 09:09:18,third_party/xla/xla/service/gpu/BUILD,akuegel,False
"compat: Update forward compatibility horizon to 2024-04-30

PiperOrigin-RevId: 629339374",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 09:03:38,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1848.

PiperOrigin-RevId: 629339372",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 09:03:38,tensorflow/core/public/version.h,tensorflower-gardener,False
"Fix input/output indexing for broadcast side outputs.

The current logic is only correct for elementwise ops, but it
is possible to have broadcasts in reduction epilogues.

PiperOrigin-RevId: 629337763",Johannes Reifferscheid,jreiffers@google.com,2024-04-30 08:56:34,"third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.h, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc",jreiffers,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629329777",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 08:18:56,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #11880: InitializeBuffer: use maximum 2 h2d copies

Imported from GitHub PR https://github.com/openxla/xla/pull/11880

This provides a significant speedup when autotuning, where buffers are repeatedly initialized.
Instead of repeatedly copying the same data to different locations on the device, it is copied once (using up to two host to device copies) and then replicated on the device using a custom kernel.

Using the paxml container from JAX-Toolbox and the 5B configuration on H100, the total runtime of the `gemm-algorithm-picker` pass for the main JITed function decreased from around 4.8s to 0.16s. With the same model and `--xla_gpu_triton_gemm_any=true` to make sure the Triton autotuner does a lot of work, that pass speeds up from 17.2s to 14.2s with this change.
Copybara import of the project:

--
bc9de3720516b4450d3a9791eae8a6979a3a08a9 by Olli Lupton <olupton@nvidia.com>:

InitializeBuffer: use maximum 2 h2d copies

This provides a significant speedup when autotuning, where buffers are
repeatedly re-initialized. Instead of repeatedly copying the same data
to different locations on the device, it is copied once (using up to two
host to device copies) and then replicated on the device using a custom
kernel.

--
ee92fc52d06604ab615bca9eb278faa40e22caf0 by Olli Lupton <olupton@nvidia.com>:

Do not refer to repeat_buffer_kernel::kernel() in CPU builds.

Merging this change closes #11880

PiperOrigin-RevId: 629327952",Olli Lupton,olupton@nvidia.com,2024-04-30 08:10:09,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/stream_executor_util.cc, third_party/xla/xla/service/gpu/stream_executor_util_kernel.cu.cc",olupton,False
"[xla:ffi] Fix a bug in the FFI buffer conversion.

The size of the buffer was not set correctly.

PiperOrigin-RevId: 629323482",Adam Banaś,adambanas@google.com,2024-04-30 07:51:32,"third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_test.cc",Adam-Banas,False
"Automated Code Change

PiperOrigin-RevId: 629322137",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 07:44:12,tensorflow/python/framework/experimental/tape.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629315124",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 07:09:14,tensorflow/examples/custom_ops_doc/multiplex_4/multiplex_4_op.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629309249",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 06:44:01,tensorflow/compiler/mlir/tfrt/BUILD,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629307571",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 06:34:32,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629300347",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 05:59:24,"tensorflow/core/kernels/data/experimental/random_dataset_op.cc, tensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc, tensorflow/core/kernels/data/experimental/unbatch_dataset_op.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629298624",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 05:50:06,"third_party/xla/xla/service/cpu/cpu_executable.cc, third_party/xla/xla/service/cpu/cpu_executable.h",tensorflower-gardener,False
"Reduce the frequency of connection termination log

This can become really verbose when the server shuts down and the client doesn't terminate immediately.

PiperOrigin-RevId: 629294989",Junwhan Ahn,junwhan@google.com,2024-04-30 05:30:03,third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.cc,junwhanahn,False
"Automated Code Change

PiperOrigin-RevId: 629291661",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 05:13:10,tensorflow/cc/saved_model/BUILD,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629291372",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 05:11:50,"third_party/xla/xla/python/profiler/internal/BUILD, third_party/xla/xla/python/profiler/internal/python_hooks.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629290908",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 05:09:38,"tensorflow/core/runtime_fallback/test/BUILD, tensorflow/core/runtime_fallback/test/test_kernels.cc, tensorflow/core/runtime_fallback/test/test_opkernels.cc, tensorflow/core/runtime_fallback/test/tfrt_forwarding_kernels.cc",tensorflower-gardener,False
"Explicitly close the host callback queues inside `IfrtBackend` destruction

If there are host callback executions that are blocked inside `RemoteLoadedHostCallbackQueue::Pop()`, they will not be cancelled automatically unless `RemoteLoadedHostCallbackQueue::Close()` is called. This causes a deadlock since `IfrtBackend` also waits for all in-flight operations to finish.

PiperOrigin-RevId: 629285927",Junwhan Ahn,junwhan@google.com,2024-04-30 04:46:02,"third_party/xla/xla/python/ifrt_proxy/server/grpc_service_impl.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc",junwhanahn,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629280676",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 04:18:53,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"PR #11908: [GPU][NFC] Annotate cuDNN graphs with operation names from HLO.

Imported from GitHub PR https://github.com/openxla/xla/pull/11908

Copybara import of the project:

--
2722433efae66dfce1444ecfbe5d8bb2915a1000 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU][NFC] Annotate cuDNN graphs with operation names from HLO.

Merging this change closes #11908

PiperOrigin-RevId: 629265878",Ilia Sergachev,isergachev@nvidia.com,2024-04-30 03:03:42,third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc,sergachev,False
"PR #11881: Improve NVTX ranges emitted during auto-tuning

Imported from GitHub PR https://github.com/openxla/xla/pull/11881

New ranges:
 - XlaAutotunerCompilation
 - XlaAutotunerMeasurement

Allow easier analysis of which parts of autotuning are related to compilation.
Copybara import of the project:

--
921c3c39c3cc919f360ef8c6bb9828d96fb0cf49 by Olli Lupton <olupton@nvidia.com>:

Improve NVTX ranges emitted during auto-tuning

New ranges:
 - XlaAutotunerCompilation
 - XlaAutotunerMeasurement

Merging this change closes #11881

PiperOrigin-RevId: 629264012",Olli Lupton,olupton@nvidia.com,2024-04-30 02:56:47,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc",olupton,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629258012",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 02:17:39,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Remove `IfrtSessionHandler`

We never end up creating more than one backend and we don't have chunked requests/responses anymore, so `IfrtSessionHandler` adds more complexity with no value. This CL changes the server implementation to directly instantiate a backend without having to go through `IfrtSessionHandler`.

PiperOrigin-RevId: 629255985",Junwhan Ahn,junwhan@google.com,2024-04-30 02:06:20,"third_party/xla/xla/python/ifrt_proxy/server/BUILD, third_party/xla/xla/python/ifrt_proxy/server/grpc_service_impl.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_session_handler.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_session_handler.h, third_party/xla/xla/python/ifrt_proxy/server/ifrt_session_handler_test.cc",junwhanahn,False
"Remove unused StreamExecutor::implementation method.

PiperOrigin-RevId: 629250632",Kyle Lucke,klucke@google.com,2024-04-30 01:36:48,"third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.h",klucke,False
"Move TPU Sharding Identification Pass to internal tf2xla directory

PiperOrigin-RevId: 629250388",Mason Chang,masonchang@google.com,2024-04-30 01:35:31,"tensorflow/compiler/mlir/tensorflow/transforms/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/passes.h, tensorflow/compiler/mlir/tensorflow/transforms/tf_passes.td, tensorflow/compiler/mlir/tf2xla/internal/clustering_bridge_passes.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/BUILD, tensorflow/compiler/mlir/tf2xla/internal/passes/clustering_passes.h, tensorflow/compiler/mlir/tf2xla/internal/passes/clustering_passes.td, tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_sharding_identification_pass.cc",changm,False
"Fixes some corner cases when a non-participating task makes the barrier call

PiperOrigin-RevId: 629250068",Anshuman Goswami,anshumang@google.com,2024-04-30 01:33:55,"third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_test.cc",anshumang,False
"Use `:gtest` instead of `:gtest_main` in PJRT API test libraries
- This is to allow actual test definitions which depend on the test library to override the heap checker behavior.

PiperOrigin-RevId: 629247110",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 01:18:59,third_party/xla/xla/pjrt/c/BUILD,tensorflower-gardener,False
"A simpler and significantly more effective algorithm for memory term reduction.

PiperOrigin-RevId: 629241334",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 00:54:33,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory_test.cc",tensorflower-gardener,False
"#tf-data Use multi-threading to run flat map func.

PiperOrigin-RevId: 629235239",Yang Chen,yangchen@google.com,2024-04-30 00:24:41,"tensorflow/core/data/BUILD, tensorflow/core/data/flat_map_utils.cc, tensorflow/core/data/flat_map_utils.h",yangustc07,False
"CL to-
1. Fold double transpose in TF dialect to enable an existing prepare_tf pattern that moves a single transpose across a q-dq pair.

2. Fold a trivial reshape into proceeding transpose op to enable existing prepare_tf pattern that moves a single transpose across a q-dq pair.

PiperOrigin-RevId: 629234077",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 00:19:50,"tensorflow/compiler/mlir/lite/tests/optimize.mlir, tensorflow/compiler/mlir/lite/tests/prepare-tf.mlir, tensorflow/compiler/mlir/lite/transforms/optimize.cc, tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td, tensorflow/compiler/mlir/lite/transforms/prepare_patterns.td, tensorflow/compiler/mlir/lite/transforms/prepare_tf.cc, tensorflow/compiler/mlir/lite/utils/utils.h, tensorflow/compiler/mlir/lite/utils/utils.td",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629233840",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-30 00:19:00,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"[xla:gpu] Added the missing C* switch cases to xla::ffi::ToDataType

PiperOrigin-RevId: 629205369",Sergei Lebedev,slebedev@google.com,2024-04-29 22:32:13,"third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/ffi_test.cc",superbobry,False
"Define GetDefaultLayoutForDevice for CompileOnlyIfRtClient.

PiperOrigin-RevId: 629202089",Parker Schuh,parkers@google.com,2024-04-29 22:20:52,third_party/xla/xla/python/py_compile_only_client.cc,pschuh,False
"#tf-data Support save/load for flat_map dataset global shuffling.

PiperOrigin-RevId: 629201820",Yang Chen,yangchen@google.com,2024-04-29 22:19:50,"tensorflow/core/kernels/data/flat_map_dataset_op.cc, tensorflow/python/data/kernel_tests/BUILD, tensorflow/python/data/kernel_tests/flat_map_test.py",yangustc07,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629201555",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 22:19:00,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Allows real_output_multipliers to be > 1 for quantized sub operations

PiperOrigin-RevId: 629196063",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 21:59:20,tensorflow/lite/kernels/sub.cc,tensorflower-gardener,False
"[xla:gpu] FFI handlers can now return a variable number of results

The API mirrors that of .RemainingArgs(), so a handler with variadic inputs/inputs
now looks like this

    Ffi::Bind().RemainingArgs().RemainingRets().To(...)

PiperOrigin-RevId: 629194070",Sergei Lebedev,slebedev@google.com,2024-04-29 21:52:05,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/ffi_test.cc",superbobry,False
"PR #11551: Dimensional Ordering of Layer Norm Operands

Imported from GitHub PR https://github.com/openxla/xla/pull/11551

Orders the dimensions of the operands of layer norm Custom Calls as required by cuDNN 9.1 and newer.
Copybara import of the project:

--
d9369e905968697139b6c3d7ecf12698abcc1e04 by Philipp Hack <phack@nvidia.com>:

Aligns the ordering of the dimensions of layer norm operands.

Merging this change closes #11551

PiperOrigin-RevId: 629182211",Philipp Hack,phack@nvidia.com,2024-04-29 21:10:31,"third_party/xla/xla/service/gpu/cudnn_norm_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_norm_rewriter_test.cc",philipphack,False
"xla_compile_lib: Fix reads of uninitialized memory.

C++ still doesn't zero-initialize primitives, so we need to do it ourselves.

Discovered with MSAN.

PiperOrigin-RevId: 629170291",pizzud,pizzud@google.com,2024-04-29 20:31:37,third_party/xla/xla/tools/xla_compile_lib.h,pizzud,False
"[xla:gpu] Added support for complex types to the FFI

PiperOrigin-RevId: 629169624",Sergei Lebedev,slebedev@google.com,2024-04-29 20:29:36,"third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc",superbobry,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 629165773",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 20:18:11,tensorflow/core/ops/ops.pbtxt,tensorflower-gardener,False
"Reverts f9e60c776338536f2b31049399b5bfced6337977

PiperOrigin-RevId: 629155099",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 19:42:10,"third_party/xla/xla/backends/profiler/gpu/cupti_error_manager.cc, third_party/xla/xla/backends/profiler/gpu/cupti_error_manager.h, third_party/xla/xla/backends/profiler/gpu/cupti_error_manager_test.cc, third_party/xla/xla/backends/profiler/gpu/cupti_interface.h, third_party/xla/xla/backends/profiler/gpu/cupti_tracer.cc, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper.cc, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper.h, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper_stub.cc, third_party/xla/xla/backends/profiler/gpu/mock_cupti.h",tensorflower-gardener,False
"change the embedding API to enable the new sparse core preprocessing ops

PiperOrigin-RevId: 629143053",Ziyin Huang,ziyinh@google.com,2024-04-29 19:04:04,"RELEASE.md, tensorflow/python/tpu/BUILD, tensorflow/python/tpu/tpu_embedding_v3.py, tensorflow/python/tpu/tpu_embedding_v3_test.py, tensorflow/tools/api/golden/v1/tensorflow.tpu.experimental.embedding.-t-p-u-embedding-v2.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.tpu.experimental.embedding.-t-p-u-embedding-v2.pbtxt",pineapplejuice233,False
"Enable scatter_test on all targets

PiperOrigin-RevId: 629140997",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 18:58:05,third_party/xla/xla/tests/BUILD,tensorflower-gardener,False
"Fix linker error in `autotuner_compile_util_test_gpu` by always linking against `main` even when gpu is not configured

PiperOrigin-RevId: 629127864",David Dunleavy,ddunleavy@google.com,2024-04-29 18:18:15,third_party/xla/xla/service/gpu/BUILD,ddunl,False
"PR #11859: [XLA:GPU] Add cuDNN Flash Attention Padding Mask Generation & Skipping computation on padded tokens in XLA

Imported from GitHub PR https://github.com/openxla/xla/pull/11859

* Follow up PR on https://github.com/openxla/xla/pull/11449 and https://github.com/openxla/xla/pull/10232.
* Add cuDNN flash attention padding mask generation in XLA. cuDNN also supports skip computation at padded tokens.
* Add an e2e test to compare padding mask generation with pass padding mask as bias in cuDNN.
Copybara import of the project:

--
aab103097be5ab7b23573e605bb8e877e004f323 by cjkkkk <ske@nvidia.com>:

add var_seq

--
ba755d7c145a7c54a0cf939ea911d791f6d7f755 by cjkkkk <ske@nvidia.com>:

add uid

--
5da56ba30542d75c4e80847788b48df500934579 by cjkkkk <ske@nvidia.com>:

add var seq e2e test

--
3a109b8d26c3958557d70c5e0802b0b5e19cb2dc by cjkkkk <ske@nvidia.com>:

fix rebase error

Merging this change closes #11859

PiperOrigin-RevId: 629117542",Shanbin Ke,ske@nvidia.com,2024-04-29 17:48:24,"third_party/xla/xla/service/gpu/cudnn_workspace_rewriter.cc, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc, third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc",Cjkkkk,False
"Enabling autotuner logs for the benchmark runner to allow for faster root-cause analysis during benchmark crashes inside Triton.

PiperOrigin-RevId: 629109257",Mohammed Anany,manany@google.com,2024-04-29 17:23:42,third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc,Moerafaat,False
"Adding PRED x BF16 test to provide better coverage.

PiperOrigin-RevId: 629108835",Mohammed Anany,manany@google.com,2024-04-29 17:22:27,third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc,Moerafaat,False
"PR #11760: [gpu] Change the implementation of GetFusionRoots to a simpler one

Imported from GitHub PR https://github.com/openxla/xla/pull/11760

Following the tuple -> get-tuple-element sequence for getting roots and remove allowing a duplicate root in case it is encountered twice in a row in the recursive search.
Copybara import of the project:

--
56c10695a2ff6937b67259b7d5037187e043bbcb by Shraiysh Vaishay <svaishay@nvidia.com>:

[gpu] Change the implementation of GetFusionRoots to a simpler one

There is no apparent requirement for this check. If the CI tests fail,
then I will revert this and work on a sophisticated implementation of
the function.

Merging this change closes #11760

PiperOrigin-RevId: 629093800",Shraiysh,svaishay@nvidia.com,2024-04-29 16:35:58,"third_party/xla/xla/service/gpu/gpu_fusible.cc, third_party/xla/xla/service/gpu/gpu_fusible.h, third_party/xla/xla/service/gpu/gpu_fusible_test.cc, third_party/xla/xla/service/gpu/multi_output_fusion_test.cc",shraiysh,False
"[XLA:Array] Allow array indexing to be optionally out of bounds.

PiperOrigin-RevId: 629088793",Blake Hechtman,blakehechtman@google.com,2024-04-29 16:17:43,third_party/xla/xla/array.h,blakehechtman,False
"Fix flakiness in TFLite DRQ TransposeConv op test

PiperOrigin-RevId: 629085541",Artsiom Ablavatski,artsiom@google.com,2024-04-29 16:05:13,tensorflow/lite/delegates/xnnpack/dynamically_quantized_transpose_conv_tester.cc,ablavatski,False
"Fix transpose fusions with side outputs.

- Evaluate all transposes in one loop.
- Remove side outputs from epilogues.
- Produce side output values in first loop (otherwise, there's no chance of sharing data, making the whole side output thing pointless).

PiperOrigin-RevId: 629078835",Johannes Reifferscheid,jreiffers@google.com,2024-04-29 15:38:56,"third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.h",jreiffers,False
"Check op count and quantization_method in QuantizeSingularOpPattern

Currently, it only checks whether the function body contains the given op, therefore the matching becomes inaccurate. For example, convolution with bias addition can be matched to pattern to quantize add op.

PiperOrigin-RevId: 629058060",Doyeon Kim,doyeonkim@google.com,2024-04-29 14:11:33,"tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions.mlir",doyeonkim0,False
"Integrate LLVM at llvm/llvm-project@2914a11e3fad

Updates LLVM usage to match
[2914a11e3fad](https://github.com/llvm/llvm-project/commit/2914a11e3fad)

PiperOrigin-RevId: 629052548",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 13:45:05,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"Fix compile error in collective_ops_test_e2e.

PiperOrigin-RevId: 629039370",Adrian Kuegel,akuegel@google.com,2024-04-29 12:39:04,"third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/collective_ops_test_e2e.cc",akuegel,False
"Remove restriction on tuple shapes in hlo_to_elemental_mlir.

- fix input slices fusion (now it actually does what the legacy
  version did). I'm not sure this fusion type is particularly
  useful though (unless the input is the same for all slices).
- fix loop fusion (support root tuples with bitcasts)
- disable side outputs for reduction and transpose fusions: it
  turns out they were not tested because of the aforementioned
  restriction, so they don't actually work. Fixing them is a bit
  more involved, so I'll do that in followups.

PiperOrigin-RevId: 629030625",Johannes Reifferscheid,jreiffers@google.com,2024-04-29 11:53:56,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.cc, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.h, third_party/xla/xla/service/gpu/fusions/input_slices_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.h, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc",jreiffers,False
"[XLA:GPU] Fix the output shape in the autotune unified redzone buffers.

After this CL, the output shape will not be a tuple if it contains only a single element. I broke this by accident in cl/626122610.

I also added tests that ensure the correct behavior.

PiperOrigin-RevId: 629022555",Dimitar (Mitko) Asenov,dasenov@google.com,2024-04-29 11:07:17,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/autotuner_compile_util.cc, third_party/xla/xla/service/gpu/autotuner_compile_util_test.cc",dimitar-asenov,False
"Automated Code Change

PiperOrigin-RevId: 629016898",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 10:37:55,tensorflow/core/ops/array_ops.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629014255",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 10:26:50,"tensorflow/lite/tools/delegates/compatibility/common/BUILD, tensorflow/lite/tools/delegates/compatibility/common/delegate_compatibility_checker_base.cc, tensorflow/lite/tools/delegates/compatibility/common/delegate_compatibility_checker_base.h, tensorflow/lite/tools/delegates/compatibility/common/online_helper_delegate.cc",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@41942c852e2b

Updates LLVM usage to match
[41942c852e2b](https://github.com/llvm/llvm-project/commit/41942c852e2b)

PiperOrigin-RevId: 629011997",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 10:13:46,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 629010018",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 10:04:23,"tensorflow/core/transforms/BUILD, tensorflow/core/transforms/utils/pdll/utils.cc",tensorflower-gardener,False
"Add kernel support for StableHLO Composite op.

PiperOrigin-RevId: 629009236",Quentin Khan,qkhan@google.com,2024-04-29 10:01:22,"tensorflow/lite/core/api/BUILD, tensorflow/lite/core/api/flatbuffer_conversions.cc, tensorflow/lite/core/api/flatbuffer_conversions.h, tensorflow/lite/core/c/builtin_op_data.h, tensorflow/lite/kernels/BUILD, tensorflow/lite/kernels/control_flow_common.cc, tensorflow/lite/kernels/control_flow_common.h, tensorflow/lite/kernels/if.cc, tensorflow/lite/kernels/stablehlo_composite.cc, tensorflow/lite/kernels/stablehlo_composite_test.cc, tensorflow/lite/kernels/subgraph_test_util.cc, tensorflow/lite/kernels/subgraph_test_util.h",qukhan,False
"PR #11422: [NVIDIA GPU] Remove control knobs for each individual async collective and use the global xla_gpu_disable_async_collectives

Imported from GitHub PR https://github.com/openxla/xla/pull/11422

Currently we have 1 global flag(xla_gpu_enable_async_collectives) to control whether we want to asynchronize collectives or not. This flag overrides all other control knobs for each collective. The usage of it is confusing, instead we introduce a new flag xla_gpu_disable_async_collectives which will consolidate all the async flags we have now. We remove xla_gpu_enable_async_collectives and all other individual control knobs.
Sample usage:
xla_gpu_disable_async_collectives=allreduce,reducescatter
disables async allreduce and reducescatter
By default it's empty which indicates enabling async for all collectives.

Copybara import of the project:

--
afff139cb742662801c49052b70a8f234bb280e4 by TJ Xu <tjx@nvidia.com>:

Remove control knobs for each individual async collective and use the
global xla_gpu_enable_async_collectives

--
e1385c5b1f82aee1d3ea98e5d453c3e60fc5fa8a by TJ Xu <tjx@nvidia.com>:

Consolidate all flags into one

--
72020bef1368f514760cbfd6630c22d2348121c9 by TJ Xu <tjx@nvidia.com>:

Change description of xla_gpu_disable_async_collectives

Merging this change closes #11422

PiperOrigin-RevId: 629003173",TJ Xu,tjx@nvidia.com,2024-04-29 09:27:21,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/python/xla_compiler.cc, third_party/xla/xla/python/xla_extension/__init__.pyi, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/tests/collective_ops_test_e2e.cc, third_party/xla/xla/xla.proto",Tixxx,False
"Enable flatbuffer verifier for TFLite files bigger than 2GiB.

PiperOrigin-RevId: 629000156",Quentin Khan,qkhan@google.com,2024-04-29 09:12:20,tensorflow/lite/core/model_builder.cc,qukhan,False
"Update GraphDef version to 1847.

PiperOrigin-RevId: 628998162",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 09:03:25,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-29

PiperOrigin-RevId: 628998126",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 09:03:15,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"[xla:ffi] Fix nested tuples CPU custom call tests

Nested tuples tests use FfiTupleRotate custom call, which works correctly only for scalar F32 buffers. Changed FfiTupleRotate signature to express that (use ranked 0 typed buffers instead of generic BufferBase).

PiperOrigin-RevId: 628988769",Adam Banaś,adambanas@google.com,2024-04-29 08:13:19,third_party/xla/xla/tests/custom_call_test.cc,Adam-Banas,False
"Automated Code Change

PiperOrigin-RevId: 628981103",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 07:34:44,tensorflow/lite/toco/toco.cc,tensorflower-gardener,False
"PR #10495: Enforce same input/output layout for offloading ops

Imported from GitHub PR https://github.com/openxla/xla/pull/10495

This patch makes sure that the host offloader will not introduce layout mismatches
after removing the offloading custom calls by constraining the layout assignment
to assign the same layout for the custom call's input and output.
Copybara import of the project:

--
ce6aeac3ac5445ab014d36c92a181dbe7afc35e7 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Enforce same input/output layout for offloading ops

Merging this change closes #10495

PiperOrigin-RevId: 628970016",Jaroslav Sevcik,jsevcik@nvidia.com,2024-04-29 06:38:50,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_layout_assignment.cc, third_party/xla/xla/service/gpu/gpu_layout_assignment.h, third_party/xla/xla/service/gpu/gpu_layout_assignment_test.cc",jaro-sevcik,False
"Automated Code Change

PiperOrigin-RevId: 628927272",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 02:09:58,tensorflow/compiler/mlir/tfr/integration/tfr_decompose_ctx.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628926805",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 02:06:10,"tensorflow/lite/toco/graph_transformations/convert_expanddims_to_reshape.cc, tensorflow/lite/toco/graph_transformations/convert_matrix_diag_v2_or_v3_to_v1.cc, tensorflow/lite/toco/graph_transformations/convert_matrix_set_diag_v2_or_v3_to_v1.cc, tensorflow/lite/toco/graph_transformations/convert_pure_conv_to_depthwise.cc, tensorflow/lite/toco/graph_transformations/convert_reorder_axes.cc, tensorflow/lite/toco/graph_transformations/convert_squeeze_to_reshape.cc, tensorflow/lite/toco/graph_transformations/convert_trivial_addn_to_add.cc, tensorflow/lite/toco/graph_transformations/convert_trivial_pack_to_reshape.cc, tensorflow/lite/toco/graph_transformations/convert_trivial_tile_to_concat.cc, tensorflow/lite/toco/graph_transformations/convert_trivial_transpose_to_reshape.cc, tensorflow/lite/toco/graph_transformations/create_im2col_arrays.cc, tensorflow/lite/toco/graph_transformations/dequantize.cc, tensorflow/lite/toco/graph_transformations/drop_fake_quant.cc, tensorflow/lite/toco/graph_transformations/drop_im2col_arrays.cc, tensorflow/lite/toco/graph_transformations/ensure_bias_vectors.cc, tensorflow/lite/toco/graph_transformations/ensure_uint8_weights_safe_for_fast_int8_kernels.cc, tensorflow/lite/toco/graph_transformations/fuse_activation_functions.cc, tensorflow/lite/toco/graph_transformations/fuse_binary_into_following_affine.cc, tensorflow/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc, tensorflow/lite/toco/graph_transformations/fuse_broadcast_into_following_binary.cc, tensorflow/lite/toco/graph_transformations/group_bidirectional_sequence_ops.cc, tensorflow/lite/toco/graph_transformations/hardcode_min_max.cc, tensorflow/lite/toco/graph_transformations/identify_dilated_conv.cc, tensorflow/lite/toco/graph_transformations/identify_hardswish.cc, tensorflow/lite/toco/graph_transformations/identify_l2_normalization.cc, tensorflow/lite/toco/graph_transformations/identify_l2_pool.cc, tensorflow/lite/toco/graph_transformations/identify_lstm.cc, tensorflow/lite/toco/graph_transformations/identify_lstm_merge_inputs.cc, tensorflow/lite/toco/graph_transformations/identify_lstm_split_inputs.cc, tensorflow/lite/toco/graph_transformations/identify_nearest_upsample.cc, tensorflow/lite/toco/graph_transformations/identify_prelu.cc, tensorflow/lite/toco/graph_transformations/identify_relu1.cc, tensorflow/lite/toco/graph_transformations/make_initial_dequantize_operator.cc, tensorflow/lite/toco/graph_transformations/merge_reshape_into_preceding_transpose.cc, tensorflow/lite/toco/graph_transformations/move_binary_operator_before_reshape.cc, tensorflow/lite/toco/graph_transformations/propagate_activation_function_into_constants.cc, tensorflow/lite/toco/graph_transformations/propagate_array_data_types.cc, tensorflow/lite/toco/graph_transformations/propagate_default_min_max.cc, tensorflow/lite/toco/graph_transformations/propagate_fake_quant_num_bits.cc, tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc, tensorflow/lite/toco/graph_transformations/quantize.cc, tensorflow/lite/toco/graph_transformations/read_array_minmax_and_narrow_range_from_fake_quant.cc, tensorflow/lite/toco/graph_transformations/remove_final_dequantize_op.cc, tensorflow/lite/toco/graph_transformations/remove_successive_transpose.cc, tensorflow/lite/toco/graph_transformations/remove_tensorflow_assert.cc, tensorflow/lite/toco/graph_transformations/remove_tensorflow_identity.cc, tensorflow/lite/toco/graph_transformations/remove_trivial_binary.cc, tensorflow/lite/toco/graph_transformations/remove_trivial_concatenation.cc, tensorflow/lite/toco/graph_transformations/remove_trivial_concatenation_input.cc, tensorflow/lite/toco/graph_transformations/remove_trivial_fake_quant.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628926788",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 02:06:00,tensorflow/compiler/mlir/lite/utils/tftext_utils_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628919837",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 01:06:04,tensorflow/python/ops/linalg/sparse/BUILD,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628914097",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-29 00:18:50,"tensorflow/lite/core/tools/BUILD, tensorflow/lite/core/tools/verifier.cc, tensorflow/lite/core/tools/verifier.h, tensorflow/lite/core/tools/verifier_internal.cc, tensorflow/lite/core/tools/verifier_internal_test.cc, tensorflow/lite/core/tools/verifier_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628872077",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-28 18:10:04,"tensorflow/core/transforms/consolidate_attrs/BUILD, tensorflow/core/transforms/consolidate_attrs/pass.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628847023",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-28 14:44:13,"tensorflow/compiler/mlir/quantization/common/BUILD, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.h",tensorflower-gardener,False
"Update GraphDef version to 1846.

PiperOrigin-RevId: 628805552",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-28 09:02:21,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-28

PiperOrigin-RevId: 628805444",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-28 09:01:59,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628790702",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-28 07:10:43,tensorflow/compiler/mlir/quantization/stablehlo/cc/pass_pipeline.cc,tensorflower-gardener,False
"Skip graph export for newly added TF MLIR functions if backend_compiler is not specified.

All the needed function defs are already in the function library if no special backend_compiler is used. This reduces the memory usage.

PiperOrigin-RevId: 628740418",Kuangyuan Chen,chky@google.com,2024-04-28 00:44:02,tensorflow/compiler/mlir/tfrt/transforms/mlrt/import_model.cc,cky9301,False
"Automated Code Change

PiperOrigin-RevId: 628713979",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-27 20:35:01,tensorflow/compiler/mlir/tfrt/ir/BUILD,tensorflower-gardener,False
package changes to golden file,Matt Bahr,mattbahr1992@gmail.com,2024-04-27 13:08:20,tensorflow/tools/api/golden/v2/tensorflow.sparse.pbtxt,mattbahr,True
"Automated Code Change

PiperOrigin-RevId: 628634650",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-27 09:28:12,tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_cluster_formation.cc,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-27

PiperOrigin-RevId: 628631100",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-27 09:02:14,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1845.

PiperOrigin-RevId: 628631083",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-27 09:02:09,tensorflow/core/public/version.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628629105",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-27 08:46:44,tensorflow/core/platform/tensor_coding.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628616788",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-27 07:19:33,third_party/xla/third_party/tsl/tsl/platform/protobuf.h,tensorflower-gardener,False
"Clean up HloInputOutputAliasConfig

PiperOrigin-RevId: 628601105",Eugene Zhulenev,ezhulenev@google.com,2024-04-27 05:24:58,"third_party/xla/xla/hlo/ir/BUILD, third_party/xla/xla/hlo/ir/hlo_input_output_alias_config.h",ezhulenev,False
"[pjrt] NFC: Always use concrete async value in PjRtFuture<T>

We plan to make absl::StatusOr<T> an implicit payload of PjRtFuture<T> and for consistency always use AsyncValueRef with concrete payload instead of relying on AsyncValue error semantics.

PjRtFuture can't be constructed from async values passed from a user (only from a promise) so we can safely ignore the error bit as we never use it.

This is a first CL in preparation for making absl::StatusOr implicit in PjRtFuture<T>.

PiperOrigin-RevId: 628598778",Eugene Zhulenev,ezhulenev@google.com,2024-04-27 05:06:38,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
Merge branch 'tensorflow:master' into implement-sampled-addmm-v2,Matt Bahr,mattbahr1992@gmail.com,2024-04-27 04:55:52,".bazelrc, .bazelversion, .github/workflows/arm-cd.yml, .github/workflows/arm-ci-extended-cpp.yml, .github/workflows/arm-ci-extended.yml, .github/workflows/arm-ci.yml, .github/workflows/osv-scanner-scheduled.yml, .github/workflows/update-rbe.yml, .gitignore, CONTRIBUTING.md, ISSUE_TEMPLATE.md, RELEASE.md, WORKSPACE, ci/official/README.md, ci/official/any.sh, ci/official/bisect.sh, ci/official/code_check_full.sh, ci/official/containers/linux_arm64/Dockerfile, ci/official/containers/linux_arm64/cuda.packages.txt, ci/official/containers/linux_arm64/devel.packages.txt, ci/official/containers/linux_arm64/devel.usertools/wheel_verification.bats, ci/official/containers/linux_arm64/jax.requirements.txt, ci/official/envs/ci_default, ci/official/envs/ci_nightly_uploads, ci/official/envs/continuous_linux_arm64_cpu_py310, ci/official/envs/continuous_linux_arm64_cpu_py311, ci/official/envs/continuous_linux_arm64_cpu_py311_cross_compile, ci/official/envs/continuous_linux_arm64_cpu_py39, ci/official/envs/continuous_linux_x86_cpu_py310, ci/official/envs/continuous_linux_x86_cpu_py311, ci/official/envs/continuous_linux_x86_cpu_py39, ci/official/envs/continuous_linux_x86_cuda_py310, ci/official/envs/continuous_linux_x86_cuda_py311, ci/official/envs/continuous_linux_x86_cuda_py39, ci/official/envs/continuous_macos_arm64_py310, ci/official/envs/continuous_macos_arm64_py311, ci/official/envs/continuous_macos_arm64_py39, ci/official/envs/disable_all_uploads, ci/official/envs/disk_cache, ci/official/envs/enable_pycpp_build, ci/official/envs/linux_arm64, ci/official/envs/linux_arm64_cross_compile, ci/official/envs/linux_arm64_onednn, ci/official/envs/linux_x86, ci/official/envs/linux_x86_cuda, ci/official/envs/linux_x86_tpu, ci/official/envs/macos_arm64, ci/official/envs/macos_x86, ci/official/envs/macos_x86_cross_compile, ci/official/envs/nightly_libtensorflow_linux_x86_cpu, ci/official/envs/nightly_libtensorflow_linux_x86_cuda, ci/official/envs/nightly_libtensorflow_macos_arm64, ci/official/envs/nightly_linux_arm64_cpu_py310, ci/official/envs/nightly_linux_arm64_cpu_py311, ci/official/envs/nightly_linux_arm64_cpu_py312, ci/official/envs/nightly_linux_arm64_cpu_py39, ci/official/envs/nightly_linux_x86_cpu_py310, ci/official/envs/nightly_linux_x86_cpu_py311, ci/official/envs/nightly_linux_x86_cpu_py312, ci/official/envs/nightly_linux_x86_cpu_py39, ci/official/envs/nightly_linux_x86_cuda_py310, ci/official/envs/nightly_linux_x86_cuda_py311, ci/official/envs/nightly_linux_x86_cuda_py312, ci/official/envs/nightly_linux_x86_cuda_py39, ci/official/envs/nightly_linux_x86_tpu_py310, ci/official/envs/nightly_linux_x86_tpu_py311, ci/official/envs/nightly_linux_x86_tpu_py312, ci/official/envs/nightly_linux_x86_tpu_py39, ci/official/envs/nightly_macos_arm64_py310, ci/official/envs/nightly_macos_arm64_py311, ci/official/envs/nightly_macos_arm64_py312, ci/official/envs/nightly_macos_arm64_py39, ci/official/envs/nightly_upload, ci/official/envs/no_docker, ci/official/envs/no_upload, ci/official/envs/public_cache, ci/official/envs/public_cache_push, ci/official/envs/py310, ci/official/envs/py311, ci/official/envs/py312, ci/official/envs/py39, ci/official/envs/rbe, ci/official/envs/sample, ci/official/envs/versions_upload, ci/official/libtensorflow.sh, ci/official/pycpp.sh, ci/official/requirements_updater/.bazelversion, ci/official/requirements_updater/BUILD.bazel, ci/official/requirements_updater/README.md, ci/official/requirements_updater/WORKSPACE, ci/official/requirements_updater/release_updater.sh, ci/official/requirements_updater/requirements.in, ci/official/requirements_updater/updater.sh, ci/official/upload.sh, ci/official/utilities/code_check_changed_files.bats, ci/official/utilities/code_check_full.bats, ci/official/utilities/docker.sh, ci/official/utilities/get_versions.sh, ci/official/utilities/rename_and_verify_wheels.sh, ci/official/utilities/setup.sh, ci/official/utilities/setup_docker.sh, ci/official/utilities/setup_macos.sh, ci/official/wheel.sh, ci/official/wheel_test/WORKSPACE, configure.py, requirements_lock_3_10.txt, requirements_lock_3_11.txt, requirements_lock_3_12.txt, requirements_lock_3_9.txt, tensorflow/BUILD, tensorflow/api_template.__init__.py, tensorflow/api_template_v1.__init__.py, tensorflow/build_cleaner_spec.textproto, tensorflow/c/BUILD, tensorflow/c/c_api.cc, tensorflow/c/c_api_experimental.cc, tensorflow/c/c_api_function.cc, tensorflow/c/c_api_test.cc, tensorflow/c/c_test.c, tensorflow/c/eager/BUILD, tensorflow/c/eager/abstract_function.h, tensorflow/c/eager/abstract_tensor_handle.cc, tensorflow/c/eager/c_api.cc, tensorflow/c/eager/c_api_distributed_test.cc, tensorflow/c/eager/c_api_experimental.cc, tensorflow/c/eager/c_api_experimental.h, tensorflow/c/eager/c_api_test_util.cc, tensorflow/c/eager/c_api_unified_experimental.cc, tensorflow/c/eager/c_api_unified_experimental_graph.cc, tensorflow/c/eager/dlpack.cc, tensorflow/c/eager/gradient_checker.cc, tensorflow/c/eager/gradients.cc, tensorflow/c/eager/gradients_test.cc, tensorflow/c/eager/graph_function.cc, tensorflow/c/eager/graph_function.h, tensorflow/c/eager/immediate_execution_distributed_manager.h, tensorflow/c/eager/immediate_execution_tensor_handle.cc, tensorflow/c/eager/parallel_device/BUILD, tensorflow/c/eager/parallel_device/parallel_device_lib.cc, tensorflow/c/eager/tape.h, tensorflow/c/eager/tracing_utils.cc, tensorflow/c/eager/unified_api_test.cc, tensorflow/c/eager/unified_api_testutil.cc, tensorflow/c/eager/unified_api_testutil.h, tensorflow/c/experimental/filesystem/BUILD, tensorflow/c/experimental/filesystem/plugins/gcs/BUILD, tensorflow/c/experimental/filesystem/plugins/posix/BUILD, tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem.cc, tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem_static.cc, tensorflow/c/experimental/filesystem/plugins/windows/BUILD, tensorflow/c/experimental/filesystem/plugins/windows/windows_filesystem.cc, tensorflow/c/experimental/gradients/BUILD, tensorflow/c/experimental/gradients/array_grad.cc, tensorflow/c/experimental/gradients/array_grad_test.cc, tensorflow/c/experimental/gradients/custom_gradient_test.cc, tensorflow/c/experimental/gradients/grad_test_helper.cc, tensorflow/c/experimental/gradients/math_grad.cc, tensorflow/c/experimental/gradients/nn_grad.cc, tensorflow/c/experimental/gradients/nn_grad_test.cc, tensorflow/c/experimental/gradients/not_differentiable.cc, tensorflow/c/experimental/gradients/tape/tape_operation.cc, tensorflow/c/experimental/grappler/BUILD, tensorflow/c/experimental/next_pluggable_device/BUILD, tensorflow/c/experimental/next_pluggable_device/c_api.cc, tensorflow/c/experimental/next_pluggable_device/c_api.h, tensorflow/c/experimental/next_pluggable_device/tensor_pjrt_buffer_util.cc, tensorflow/c/experimental/next_pluggable_device/tensor_pjrt_buffer_util.h, tensorflow/c/experimental/next_pluggable_device/tensor_pjrt_buffer_util_test.cc, tensorflow/c/experimental/ops/gen/cpp/golden/testing_ops.cc.golden, tensorflow/c/experimental/ops/gen/cpp/golden/testing_ops.h.golden, tensorflow/c/experimental/ops/gen/cpp/renderers/BUILD, tensorflow/c/experimental/ops/gen/cpp/renderers/cpp_config.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/cpp_file_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/guard_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/guard_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/include_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/include_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/namespace_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/namespace_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_comment_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_comment_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_implementation_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_implementation_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer_test.cc, tensorflow/c/experimental/pluggable_profiler/BUILD, tensorflow/c/experimental/saved_model/core/BUILD, tensorflow/c/experimental/saved_model/core/ops/BUILD, tensorflow/c/experimental/saved_model/core/ops/variable_ops.cc, tensorflow/c/experimental/saved_model/core/saved_variable_loading_test.cc, tensorflow/c/experimental/saved_model/core/tf_saved_model_api.cc, tensorflow/c/experimental/saved_model/internal/BUILD, tensorflow/c/experimental/saved_model/internal/saved_model_api_test.cc, tensorflow/c/experimental/saved_model/internal/testdata/BUILD, tensorflow/c/experimental/stream_executor/BUILD, tensorflow/c/experimental/stream_executor/stream_executor.cc, tensorflow/c/experimental/stream_executor/stream_executor_internal.h, tensorflow/c/experimental/stream_executor/stream_executor_test.cc, tensorflow/c/kernels.cc, tensorflow/c/kernels.h, tensorflow/c/kernels/BUILD, tensorflow/c/kernels/ops/bitcast.cc, tensorflow/c/kernels_experimental.cc, tensorflow/c/tf_buffer.cc, tensorflow/c/tf_status.h, tensorflow/c/tf_status_helper.cc, tensorflow/c/tf_status_helper.h, tensorflow/c/tf_status_helper_test.cc, tensorflow/c/tf_status_internal.h, tensorflow/c/tf_tensor.cc, tensorflow/c/tf_tensor.h, tensorflow/c/while_loop_test.cc, tensorflow/cc/BUILD, tensorflow/cc/client/client_session.cc, tensorflow/cc/experimental/base/tests/BUILD, tensorflow/cc/experimental/base/tests/tensor_test.cc, tensorflow/cc/experimental/base/tests/tensorhandle_test.cc, tensorflow/cc/experimental/libexport/BUILD, tensorflow/cc/experimental/libexport/save.cc, tensorflow/cc/experimental/libtf/BUILD, tensorflow/cc/experimental/libtf/function.cc, tensorflow/cc/experimental/libtf/impl/BUILD, tensorflow/cc/experimental/libtf/impl/iostream_test.cc, tensorflow/cc/experimental/libtf/impl/tensor_spec_test.cc, tensorflow/cc/experimental/libtf/value.h, tensorflow/cc/framework/cc_op_gen_main.cc, tensorflow/cc/framework/cc_op_gen_util.cc, tensorflow/cc/framework/cc_op_gen_util.h, tensorflow/cc/framework/fuzzing/BUILD, tensorflow/cc/framework/fuzzing/cc_op_fuzz_gen.cc, tensorflow/cc/framework/fuzzing/cc_op_fuzz_gen_main.cc, tensorflow/cc/framework/grad_op_registry.cc, tensorflow/cc/framework/gradient_checker.cc, tensorflow/cc/framework/gradients.cc, tensorflow/cc/framework/ops.h, tensorflow/cc/framework/scope.cc, tensorflow/cc/framework/scope.h, tensorflow/cc/framework/while_gradients.cc, tensorflow/cc/gradients/grad_testutil.cc, tensorflow/cc/ops/while_loop.cc, tensorflow/cc/saved_model/BUILD, tensorflow/cc/saved_model/bundle_v2.cc, tensorflow/cc/saved_model/fingerprinting.cc, tensorflow/cc/saved_model/fingerprinting_utils.cc, tensorflow/cc/saved_model/fingerprinting_utils.h, tensorflow/cc/saved_model/fingerprinting_utils_test.cc, tensorflow/cc/saved_model/image_format/BUILD, tensorflow/cc/saved_model/image_format/internal_api.cc, tensorflow/cc/saved_model/image_format/internal_api.h, tensorflow/cc/saved_model/loader.cc, tensorflow/cc/saved_model/loader.h, tensorflow/cc/saved_model/loader_util.cc, tensorflow/cc/saved_model/metrics.cc, tensorflow/cc/saved_model/metrics.h, tensorflow/cc/saved_model/metrics_test.cc, tensorflow/cc/saved_model/reader.cc, tensorflow/cc/saved_model/reader.h, tensorflow/cc/saved_model/util.cc, tensorflow/cc/tools/BUILD, tensorflow/cc/training/coordinator.cc, tensorflow/cc/training/queue_runner.cc, tensorflow/compat_template.__init__.py, tensorflow/compat_template_v1.__init__.py, tensorflow/compiler/aot/BUILD, tensorflow/compiler/aot/aot_only_var_handle_op.cc, tensorflow/compiler/aot/codegen.cc, tensorflow/compiler/aot/codegen_test.cc, tensorflow/compiler/aot/codegen_test_h.golden, tensorflow/compiler/aot/codegen_test_o.golden, tensorflow/compiler/aot/compile.cc, tensorflow/compiler/aot/embedded_protocol_buffers.cc, tensorflow/compiler/aot/embedded_protocol_buffers.h, tensorflow/compiler/aot/tests/BUILD, tensorflow/compiler/jit/BUILD, tensorflow/compiler/jit/build_xla_ops_pass.cc, tensorflow/compiler/jit/build_xla_ops_pass_test.cc, tensorflow/compiler/jit/clone_constants_for_better_clustering.cc, tensorflow/compiler/jit/clone_constants_for_better_clustering_test.cc, tensorflow/compiler/jit/cluster_scoping_pass.cc, tensorflow/compiler/jit/compilability_check_util.cc, tensorflow/compiler/jit/deadness_analysis.cc, tensorflow/compiler/jit/deadness_analysis.h, tensorflow/compiler/jit/deadness_analysis_test.cc, tensorflow/compiler/jit/device_compilation_cache_test.cc, tensorflow/compiler/jit/device_compilation_cluster_signature.cc, tensorflow/compiler/jit/device_compilation_cluster_signature.h, tensorflow/compiler/jit/device_compilation_profiler.cc, tensorflow/compiler/jit/device_compilation_profiler.h, tensorflow/compiler/jit/device_compiler.h, tensorflow/compiler/jit/device_compiler_client.h, tensorflow/compiler/jit/device_compiler_test.cc, tensorflow/compiler/jit/device_executable_persistor.h, tensorflow/compiler/jit/device_executable_persistor_test.cc, tensorflow/compiler/jit/device_util.cc, tensorflow/compiler/jit/device_util.h, tensorflow/compiler/jit/device_util_test.cc, tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc",mattbahr,True
"Internal BUILD rule change.

PiperOrigin-RevId: 628590011",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-27 04:03:58,third_party/xla/xla/tests/BUILD,tensorflower-gardener,False
Merge branch 'master' into yimei/fuse_old_bn,Yimei Sun,yimei.sun@intel.com,2024-04-27 04:03:45,".bazelrc, .bazelversion, .github/workflows/arm-cd.yml, .github/workflows/arm-ci-extended-cpp.yml, .github/workflows/arm-ci-extended.yml, .github/workflows/arm-ci.yml, .github/workflows/osv-scanner-scheduled.yml, .github/workflows/update-rbe.yml, .gitignore, CONTRIBUTING.md, ISSUE_TEMPLATE.md, RELEASE.md, WORKSPACE, ci/official/README.md, ci/official/any.sh, ci/official/bisect.sh, ci/official/code_check_full.sh, ci/official/containers/linux_arm64/Dockerfile, ci/official/containers/linux_arm64/cuda.packages.txt, ci/official/containers/linux_arm64/devel.packages.txt, ci/official/containers/linux_arm64/devel.usertools/wheel_verification.bats, ci/official/containers/linux_arm64/jax.requirements.txt, ci/official/envs/ci_default, ci/official/envs/ci_nightly_uploads, ci/official/envs/continuous_linux_arm64_cpu_py310, ci/official/envs/continuous_linux_arm64_cpu_py311, ci/official/envs/continuous_linux_arm64_cpu_py311_cross_compile, ci/official/envs/continuous_linux_arm64_cpu_py39, ci/official/envs/continuous_linux_arm64_cpu_py39_cross_compile, ci/official/envs/continuous_linux_x86_cpu_py310, ci/official/envs/continuous_linux_x86_cpu_py311, ci/official/envs/continuous_linux_x86_cpu_py39, ci/official/envs/continuous_linux_x86_cuda_py310, ci/official/envs/continuous_linux_x86_cuda_py311, ci/official/envs/continuous_linux_x86_cuda_py39, ci/official/envs/continuous_macos_arm64_py310, ci/official/envs/continuous_macos_arm64_py311, ci/official/envs/continuous_macos_arm64_py39, ci/official/envs/disable_all_uploads, ci/official/envs/disk_cache, ci/official/envs/enable_pycpp_build, ci/official/envs/linux_arm64, ci/official/envs/linux_arm64_cross_compile, ci/official/envs/linux_arm64_onednn, ci/official/envs/linux_x86, ci/official/envs/linux_x86_cuda, ci/official/envs/linux_x86_tpu, ci/official/envs/macos_arm64, ci/official/envs/macos_x86, ci/official/envs/macos_x86_cross_compile, ci/official/envs/nightly_libtensorflow_linux_x86_cpu, ci/official/envs/nightly_libtensorflow_linux_x86_cuda, ci/official/envs/nightly_libtensorflow_macos_arm64, ci/official/envs/nightly_libtensorflow_macos_x86, ci/official/envs/nightly_linux_arm64_cpu_py310, ci/official/envs/nightly_linux_arm64_cpu_py311, ci/official/envs/nightly_linux_arm64_cpu_py312, ci/official/envs/nightly_linux_arm64_cpu_py39, ci/official/envs/nightly_linux_x86_cpu_py310, ci/official/envs/nightly_linux_x86_cpu_py311, ci/official/envs/nightly_linux_x86_cpu_py312, ci/official/envs/nightly_linux_x86_cpu_py39, ci/official/envs/nightly_linux_x86_cuda_py310, ci/official/envs/nightly_linux_x86_cuda_py311, ci/official/envs/nightly_linux_x86_cuda_py312, ci/official/envs/nightly_linux_x86_cuda_py39, ci/official/envs/nightly_linux_x86_tpu_py310, ci/official/envs/nightly_linux_x86_tpu_py311, ci/official/envs/nightly_linux_x86_tpu_py312, ci/official/envs/nightly_linux_x86_tpu_py39, ci/official/envs/nightly_macos_arm64_py310, ci/official/envs/nightly_macos_arm64_py311, ci/official/envs/nightly_macos_arm64_py312, ci/official/envs/nightly_macos_arm64_py39, ci/official/envs/nightly_macos_x86_py310, ci/official/envs/nightly_macos_x86_py311, ci/official/envs/nightly_macos_x86_py312, ci/official/envs/nightly_macos_x86_py39, ci/official/envs/nightly_upload, ci/official/envs/no_docker, ci/official/envs/no_upload, ci/official/envs/public_cache, ci/official/envs/public_cache_push, ci/official/envs/py310, ci/official/envs/py311, ci/official/envs/py312, ci/official/envs/py39, ci/official/envs/rbe, ci/official/envs/sample, ci/official/envs/versions_upload, ci/official/libtensorflow.sh, ci/official/pycpp.sh, ci/official/requirements_updater/.bazelversion, ci/official/requirements_updater/BUILD.bazel, ci/official/requirements_updater/README.md, ci/official/requirements_updater/WORKSPACE, ci/official/requirements_updater/release_updater.sh, ci/official/requirements_updater/requirements.in, ci/official/requirements_updater/updater.sh, ci/official/upload.sh, ci/official/utilities/code_check_changed_files.bats, ci/official/utilities/code_check_full.bats, ci/official/utilities/docker.sh, ci/official/utilities/get_versions.sh, ci/official/utilities/rename_and_verify_wheels.sh, ci/official/utilities/setup.sh, ci/official/utilities/setup_docker.sh, ci/official/utilities/setup_macos.sh, ci/official/wheel.sh, ci/official/wheel_test/WORKSPACE, configure.py, requirements_lock_3_10.txt, requirements_lock_3_11.txt, requirements_lock_3_12.txt, requirements_lock_3_9.txt, tensorflow/BUILD, tensorflow/api_template.__init__.py, tensorflow/api_template_v1.__init__.py, tensorflow/c/BUILD, tensorflow/c/c_api.cc, tensorflow/c/c_api_experimental.cc, tensorflow/c/c_api_function.cc, tensorflow/c/c_api_test.cc, tensorflow/c/c_test.c, tensorflow/c/eager/BUILD, tensorflow/c/eager/abstract_function.h, tensorflow/c/eager/abstract_tensor_handle.cc, tensorflow/c/eager/c_api.cc, tensorflow/c/eager/c_api_distributed_test.cc, tensorflow/c/eager/c_api_experimental.cc, tensorflow/c/eager/c_api_experimental.h, tensorflow/c/eager/c_api_test_util.cc, tensorflow/c/eager/c_api_unified_experimental.cc, tensorflow/c/eager/c_api_unified_experimental_graph.cc, tensorflow/c/eager/dlpack.cc, tensorflow/c/eager/gradient_checker.cc, tensorflow/c/eager/gradients.cc, tensorflow/c/eager/gradients_test.cc, tensorflow/c/eager/graph_function.cc, tensorflow/c/eager/graph_function.h, tensorflow/c/eager/immediate_execution_distributed_manager.h, tensorflow/c/eager/immediate_execution_tensor_handle.cc, tensorflow/c/eager/parallel_device/BUILD, tensorflow/c/eager/parallel_device/parallel_device_lib.cc, tensorflow/c/eager/tape.h, tensorflow/c/eager/tracing_utils.cc, tensorflow/c/eager/unified_api_test.cc, tensorflow/c/eager/unified_api_testutil.cc, tensorflow/c/eager/unified_api_testutil.h, tensorflow/c/experimental/filesystem/BUILD, tensorflow/c/experimental/filesystem/plugins/gcs/BUILD, tensorflow/c/experimental/filesystem/plugins/posix/BUILD, tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem.cc, tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem_static.cc, tensorflow/c/experimental/filesystem/plugins/windows/BUILD, tensorflow/c/experimental/filesystem/plugins/windows/windows_filesystem.cc, tensorflow/c/experimental/gradients/BUILD, tensorflow/c/experimental/gradients/array_grad.cc, tensorflow/c/experimental/gradients/array_grad_test.cc, tensorflow/c/experimental/gradients/custom_gradient_test.cc, tensorflow/c/experimental/gradients/grad_test_helper.cc, tensorflow/c/experimental/gradients/math_grad.cc, tensorflow/c/experimental/gradients/nn_grad.cc, tensorflow/c/experimental/gradients/nn_grad_test.cc, tensorflow/c/experimental/gradients/not_differentiable.cc, tensorflow/c/experimental/gradients/tape/tape_operation.cc, tensorflow/c/experimental/grappler/BUILD, tensorflow/c/experimental/next_pluggable_device/BUILD, tensorflow/c/experimental/next_pluggable_device/c_api.cc, tensorflow/c/experimental/next_pluggable_device/c_api.h, tensorflow/c/experimental/next_pluggable_device/tensor_pjrt_buffer_util.cc, tensorflow/c/experimental/next_pluggable_device/tensor_pjrt_buffer_util.h, tensorflow/c/experimental/next_pluggable_device/tensor_pjrt_buffer_util_test.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/BUILD, tensorflow/c/experimental/ops/gen/cpp/renderers/cpp_config.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/cpp_file_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/guard_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/guard_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/include_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/include_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/namespace_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/namespace_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_comment_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_comment_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_implementation_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_implementation_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer_test.cc, tensorflow/c/experimental/pluggable_profiler/BUILD, tensorflow/c/experimental/saved_model/core/BUILD, tensorflow/c/experimental/saved_model/core/ops/BUILD, tensorflow/c/experimental/saved_model/core/ops/variable_ops.cc, tensorflow/c/experimental/saved_model/core/saved_variable_loading_test.cc, tensorflow/c/experimental/saved_model/core/tf_saved_model_api.cc, tensorflow/c/experimental/saved_model/internal/BUILD, tensorflow/c/experimental/saved_model/internal/saved_model_api_test.cc, tensorflow/c/experimental/saved_model/internal/testdata/BUILD, tensorflow/c/experimental/stream_executor/BUILD, tensorflow/c/experimental/stream_executor/stream_executor.cc, tensorflow/c/experimental/stream_executor/stream_executor_internal.h, tensorflow/c/experimental/stream_executor/stream_executor_test.cc, tensorflow/c/kernels.cc, tensorflow/c/kernels.h, tensorflow/c/kernels/BUILD, tensorflow/c/kernels/ops/bitcast.cc, tensorflow/c/kernels_experimental.cc, tensorflow/c/tf_buffer.cc, tensorflow/c/tf_status.h, tensorflow/c/tf_status_helper.cc, tensorflow/c/tf_status_helper.h, tensorflow/c/tf_status_helper_test.cc, tensorflow/c/tf_status_internal.h, tensorflow/c/tf_tensor.cc, tensorflow/c/tf_tensor.h, tensorflow/c/while_loop_test.cc, tensorflow/cc/BUILD, tensorflow/cc/client/client_session.cc, tensorflow/cc/experimental/base/tests/BUILD, tensorflow/cc/experimental/base/tests/tensor_test.cc, tensorflow/cc/experimental/base/tests/tensorhandle_test.cc, tensorflow/cc/experimental/libexport/BUILD, tensorflow/cc/experimental/libexport/save.cc, tensorflow/cc/experimental/libtf/BUILD, tensorflow/cc/experimental/libtf/function.cc, tensorflow/cc/experimental/libtf/impl/BUILD, tensorflow/cc/experimental/libtf/impl/iostream_test.cc, tensorflow/cc/experimental/libtf/impl/tensor_spec_test.cc, tensorflow/cc/experimental/libtf/value.h, tensorflow/cc/framework/cc_op_gen_main.cc, tensorflow/cc/framework/cc_op_gen_util.cc, tensorflow/cc/framework/cc_op_gen_util.h, tensorflow/cc/framework/fuzzing/BUILD, tensorflow/cc/framework/fuzzing/cc_op_fuzz_gen.cc, tensorflow/cc/framework/fuzzing/cc_op_fuzz_gen_main.cc, tensorflow/cc/framework/grad_op_registry.cc, tensorflow/cc/framework/gradient_checker.cc, tensorflow/cc/framework/gradients.cc, tensorflow/cc/framework/ops.h, tensorflow/cc/framework/scope.cc, tensorflow/cc/framework/scope.h, tensorflow/cc/framework/while_gradients.cc, tensorflow/cc/gradients/grad_testutil.cc, tensorflow/cc/ops/while_loop.cc, tensorflow/cc/saved_model/BUILD, tensorflow/cc/saved_model/fingerprinting.cc, tensorflow/cc/saved_model/fingerprinting_utils.cc, tensorflow/cc/saved_model/fingerprinting_utils.h, tensorflow/cc/saved_model/fingerprinting_utils_test.cc, tensorflow/cc/saved_model/image_format/BUILD, tensorflow/cc/saved_model/loader.cc, tensorflow/cc/saved_model/loader_util.cc, tensorflow/cc/saved_model/metrics.cc, tensorflow/cc/saved_model/metrics.h, tensorflow/cc/saved_model/metrics_test.cc, tensorflow/cc/saved_model/reader.cc, tensorflow/cc/saved_model/reader.h, tensorflow/cc/saved_model/util.cc, tensorflow/cc/tools/BUILD, tensorflow/cc/training/coordinator.cc, tensorflow/cc/training/queue_runner.cc, tensorflow/compat_template.__init__.py, tensorflow/compat_template_v1.__init__.py, tensorflow/compiler/aot/BUILD, tensorflow/compiler/aot/aot_only_var_handle_op.cc, tensorflow/compiler/aot/codegen.cc, tensorflow/compiler/aot/codegen_test.cc, tensorflow/compiler/aot/codegen_test_h.golden, tensorflow/compiler/aot/codegen_test_o.golden, tensorflow/compiler/aot/compile.cc, tensorflow/compiler/aot/embedded_protocol_buffers.cc, tensorflow/compiler/aot/embedded_protocol_buffers.h, tensorflow/compiler/aot/tests/BUILD, tensorflow/compiler/jit/BUILD, tensorflow/compiler/jit/build_xla_ops_pass.cc, tensorflow/compiler/jit/build_xla_ops_pass_test.cc, tensorflow/compiler/jit/clone_constants_for_better_clustering.cc, tensorflow/compiler/jit/clone_constants_for_better_clustering_test.cc, tensorflow/compiler/jit/cluster_scoping_pass.cc, tensorflow/compiler/jit/compilability_check_util.cc, tensorflow/compiler/jit/deadness_analysis.cc, tensorflow/compiler/jit/deadness_analysis.h, tensorflow/compiler/jit/deadness_analysis_test.cc, tensorflow/compiler/jit/device_compilation_cache_test.cc, tensorflow/compiler/jit/device_compilation_cluster_signature.cc, tensorflow/compiler/jit/device_compilation_cluster_signature.h, tensorflow/compiler/jit/device_compilation_profiler.cc, tensorflow/compiler/jit/device_compilation_profiler.h, tensorflow/compiler/jit/device_compiler.h, tensorflow/compiler/jit/device_compiler_client.h, tensorflow/compiler/jit/device_compiler_test.cc, tensorflow/compiler/jit/device_executable_persistor.h, tensorflow/compiler/jit/device_executable_persistor_test.cc, tensorflow/compiler/jit/device_util.cc, tensorflow/compiler/jit/device_util.h, tensorflow/compiler/jit/device_util_test.cc, tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc, tensorflow/compiler/jit/encapsulate_subgraphs_pass_test.cc",yimeisun123,True
"Integrate LLVM at llvm/llvm-project@fefac5d5458a

Updates LLVM usage to match
[fefac5d5458a](https://github.com/llvm/llvm-project/commit/fefac5d5458a)

PiperOrigin-RevId: 628561850",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-27 01:13:34,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"Register and load all applicable dialects for parallel compilation

PiperOrigin-RevId: 628528700",Deqiang Chen,deqiangc@google.com,2024-04-26 22:38:04,"tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler.h, tensorflow/core/tfrt/graph_executor/graph_executor.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h",deqiangc,False
"Integrate LLVM at llvm/llvm-project@c49b74a4e6ff

Updates LLVM usage to match
[c49b74a4e6ff](https://github.com/llvm/llvm-project/commit/c49b74a4e6ff)

PiperOrigin-RevId: 628520992",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 22:07:40,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"#tf-data Support global shuffle for the `flat_map`  dataset.

PiperOrigin-RevId: 628517842",Yang Chen,yangchen@google.com,2024-04-26 21:55:46,"tensorflow/core/data/BUILD, tensorflow/core/data/flat_map_utils.cc, tensorflow/core/data/flat_map_utils.h, tensorflow/core/kernels/data/BUILD, tensorflow/core/kernels/data/experimental/BUILD, tensorflow/core/kernels/data/experimental/global_shuffle_dataset_op.cc, tensorflow/core/kernels/data/flat_map_dataset_op.cc, tensorflow/python/data/kernel_tests/BUILD, tensorflow/python/data/kernel_tests/flat_map_test.py",yangustc07,False
"    Set frontend attributes for copied instructions in layout assignment.

PiperOrigin-RevId: 628517259",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 21:53:36,third_party/xla/xla/service/layout_assignment.cc,tensorflower-gardener,False
"Integrate tsl::ServingDeviceSelector in IfrtServingExecutable.

PiperOrigin-RevId: 628514002",Siqiao Wu,siqiaowu@google.com,2024-04-26 21:40:11,"tensorflow/compiler/mlir/tfrt/transforms/ifrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler_test.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.h, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo_test.cc, tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_executable_registry_test.cc, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.cc, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.h, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils.cc, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils.h, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils_test.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test.cc, tensorflow/core/tfrt/mlrt/kernel/BUILD, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc, tensorflow/core/tfrt/saved_model/tests/BUILD, tensorflow/core/tfrt/saved_model/tests/saved_model_ifrt_test.cc",SiqiaoWu1993,False
"    Set metadata for new while instructions created in while_loop_simplifier.

PiperOrigin-RevId: 628508010",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 21:17:31,"third_party/xla/xla/service/while_loop_simplifier.cc, third_party/xla/xla/service/while_loop_simplifier_test.cc",tensorflower-gardener,False
"internal code change

PiperOrigin-RevId: 628506844",Taehee Jeong,taeheej@google.com,2024-04-26 21:13:12,tensorflow/core/framework/BUILD,teijeong,False
"Enable some previously disabled tests

PiperOrigin-RevId: 628500283",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 20:48:53,third_party/xla/xla/tests/BUILD,tensorflower-gardener,False
"Unify token lowering in JAX to always use `stablehlo.token`.

Right now, in JAX native execution, tokens are lowered to dummy `bool[0]`, but when exporting, we use `stablehlo.token`.

To make it work, we need to make changes across XLA/PjRt/IFRT, the main change is to allow `token` parameters in compiler and runtime.

PiperOrigin-RevId: 628491703",Yue Sheng,yueshengys@google.com,2024-04-26 20:17:00,"third_party/xla/xla/pjrt/c/CHANGELOG.md, third_party/xla/xla/pjrt/c/pjrt_c_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/types.cc, third_party/xla/xla/python/types.h, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/service/host_offloader.cc",yueshengys,False
"[xla:gpu] Fix a bug in GpuAlgebraicSimplifier

I don't know what I was thinking

PiperOrigin-RevId: 628490277",Anlun Xu,anlunx@google.com,2024-04-26 20:11:50,"third_party/xla/xla/service/gpu/gpu_algebraic_simplifier.cc, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier_test.cc",anlunx,False
"Replace `absl::make_unique_for_overwrite` with `std::make_unique`

PiperOrigin-RevId: 628480822",Ziyin Huang,ziyinh@google.com,2024-04-26 19:34:06,"tensorflow/core/tpu/kernels/BUILD, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.cc",pineapplejuice233,False
"Minor changes to improve readability and reduce code size.

PiperOrigin-RevId: 628475159",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 19:12:25,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.cc,tensorflower-gardener,False
"#tf-data Do not log auto-scaler error messages by default.

Otherwise this may clutter output logs.

PiperOrigin-RevId: 628474343",Yang Chen,yangchen@google.com,2024-04-26 19:09:32,tensorflow/core/data/service/dispatcher_impl.cc,yangustc07,False
"[XLA:Runtime] Moved the nccl_clique_key target to runtime folder.

This is part of an effort to move runtime targets to the runtime folder. #5758

PiperOrigin-RevId: 628473816",Sara Smoot,sarasmoot@google.com,2024-04-26 19:07:40,"tensorflow/compiler/tf2xla/BUILD, tensorflow/compiler/tf2xla/xla_helpers.cc, third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/nccl_id_store.cc, third_party/xla/xla/pjrt/gpu/nccl_id_store.h, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/gpu_executable_run_options.cc, third_party/xla/xla/service/gpu/gpu_executable_run_options.h, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/nccl_api.cc, third_party/xla/xla/service/gpu/runtime/nccl_api.h, third_party/xla/xla/service/gpu/runtime/nccl_api_stub.cc, third_party/xla/xla/service/gpu/runtime/nccl_clique.cc, third_party/xla/xla/service/gpu/runtime/nccl_clique.h, third_party/xla/xla/service/gpu/runtime/nccl_clique_key.cc, third_party/xla/xla/service/gpu/runtime/nccl_clique_key.h, third_party/xla/xla/service/gpu/runtime/nccl_clique_key_test.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_p2p_thunk_common.cc, third_party/xla/xla/service/gpu/runtime/nccl_p2p_thunk_common.h, third_party/xla/xla/service/gpu/runtime/nccl_recv_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_send_thunk.h, third_party/xla/xla/service/gpu/runtime/thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.h",sgerrard,False
"Define MLIR helper `StatusScopedDiagnosticHandler`.

PiperOrigin-RevId: 628473788",Bart Chrzaszcz,bartchr@google.com,2024-04-26 19:07:32,"third_party/xla/third_party/tsl/tsl/framework/mlir/BUILD, third_party/xla/third_party/tsl/tsl/framework/mlir/status_scoped_diagnostic_handler.cc, third_party/xla/third_party/tsl/tsl/framework/mlir/status_scoped_diagnostic_handler.h",bartchr808,False
"tf.Tensor supports Garbage collection.

Unit tests added. Specificly cycles from EagerTensor._handle_data and EagerTensor.shape were not tracked in the old behavior.

PiperOrigin-RevId: 628472173",Yu Feng,feyu@google.com,2024-04-26 19:02:13,"tensorflow/python/eager/ops_test.py, tensorflow/python/eager/pywrap_tensor.cc, tensorflow/python/eager/pywrap_tensor_test.py",rainwoodman,False
"[XLA:GPU][Mlir-based emitters] Add a pattern to fold constants/symbols/dims.

PiperOrigin-RevId: 628471575",Alexander Belyaev,pifon@google.com,2024-04-26 19:00:23,"third_party/xla/xla/service/gpu/fusions/mlir/ir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/tests/canonicalize.mlir",pifon2a,False
"    Set metadata and frontend attributes for new get-tuple-element instructions in multi-output-fusion pass.

PiperOrigin-RevId: 628468467",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 18:49:36,third_party/xla/xla/hlo/ir/hlo_instructions.cc,tensorflower-gardener,False
"Support shape transpose in `hlo_sharding_util::ReshapeSharding`.

Before this cl, `hlo_sharding_util::ReshapeSharding` can handle the cases where source and target shapes can be transformed to each other by merging and splitting dimension sizes. It returns `std::nullopt` if transpose is needed between source and target shapes.

This cl extracts the `gcd(source_sharding_tile_size, target_shape)` when `source_shape % source_sharding_tile_size == 0` in the major dimensions. We also skip the source_dim if `source_sharding_tile_size` is 1. An example is shown below.
```
input_shape: [6, 2, 5]
output_shape: [4, 3, 5]
input_sharding: {devices=[2, 1, 5]<=[10]}
output_sharding: {devices=[2, 1, 5]<=[10]}
```

Reverts e30abe681fdcced8ba3d19685293a3e6fc18e7b7

PiperOrigin-RevId: 628466633",Zixuan Jiang,zixuanjiang@google.com,2024-04-26 18:42:48,"third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util_test.cc, third_party/xla/xla/service/sharding_propagation_test.cc",ZixuanJiang,False
"[XLA:GPU] NFC: Create GpuAlgebraicSimplifier
This class implements ShouldStrengthReduceDotToReduce so that we can control the which dot to strength-reduce for GPU. Currently we only strength-reduce vector-vector dots, but we should implement a heuristic by analyzing performance data.

PiperOrigin-RevId: 628461702",Anlun Xu,anlunx@google.com,2024-04-26 18:26:56,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier.cc, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier.h, third_party/xla/xla/service/gpu/gpu_algebraic_simplifier_test.cc",anlunx,False
"Integrate LLVM at llvm/llvm-project@1728a56d0e66

Updates LLVM usage to match
[1728a56d0e66](https://github.com/llvm/llvm-project/commit/1728a56d0e66)

PiperOrigin-RevId: 628451659",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 17:54:01,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Update CompileFunction to use XlaBuilder only.

PiperOrigin-RevId: 628451304",Arturo Schmidt,arturoschmidt@google.com,2024-04-26 17:52:50,"tensorflow/compiler/tf2xla/xla_compiler.cc, tensorflow/python/eager/polymorphic_function/polymorphic_function_xla_jit_test.py",rocketas,False
"[xla_compile][NFC] Allow loading autotune results from a SymbolRepository.

Doing so allows recompilation of uploaded modules with autotune results to
mimic more cases...and allows full recompilation without GPU hardware.

We now have enough arguments in XlaCompileMain that it's time to extract some
options structs, which significantly improved usability at the cost of verbose
code in places.

PiperOrigin-RevId: 628449949",pizzud,pizzud@google.com,2024-04-26 17:48:25,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_symbol_repository.h, third_party/xla/xla/service/xla_compile_main.cc, third_party/xla/xla/tools/BUILD, third_party/xla/xla/tools/xla_compile_lib.cc, third_party/xla/xla/tools/xla_compile_lib.h, third_party/xla/xla/tools/xla_compile_lib_test.cc",pizzud,False
"Do not keep the bytecode that is only used for loading if lazy loading is enabled.

PiperOrigin-RevId: 628449723",Kuangyuan Chen,chky@google.com,2024-04-26 17:47:39,tensorflow/core/tfrt/saved_model/saved_model.cc,cky9301,False
"Update target visibility rules

PiperOrigin-RevId: 628445192",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 17:31:38,third_party/xla/third_party/tsl/tsl/profiler/rpc/client/BUILD,tensorflower-gardener,False
"[xla] Test output to operands aliasing by updating the input in the custom call.

PiperOrigin-RevId: 628443321",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 17:25:15,third_party/xla/xla/tests/custom_call_test.cc,tensorflower-gardener,False
"Remove invalid quantized tests

Quantized tensors have a constraint that `sizeof(storage_type) < sizeof(expressed_type)`. This CL removes quantized tensor tests that were quantizing from BF16/F16 to SI16 and BF16/F16/F32 to SI32.

PiperOrigin-RevId: 628443237",RJ Ascani,rjascani@google.com,2024-04-26 17:24:57,tensorflow/lite/experimental/shlo/legacy/test/elementwise_unary_test.cc,rascani,False
"#tf-data Implement `Cardinality` for flat_map_dataset.

PiperOrigin-RevId: 628442757",Yang Chen,yangchen@google.com,2024-04-26 17:23:26,"tensorflow/core/data/BUILD, tensorflow/core/data/flat_map_utils.cc, tensorflow/core/data/flat_map_utils.h, tensorflow/core/kernels/data/BUILD, tensorflow/core/kernels/data/flat_map_dataset_op.cc, tensorflow/python/data/kernel_tests/BUILD, tensorflow/python/data/kernel_tests/flat_map_test.py",yangustc07,False
"Reverts 92304fecd216e522deef31adefa1a17b441b507d

PiperOrigin-RevId: 628440873",Jim Lin,jimlintw@google.com,2024-04-26 17:16:44,tensorflow/core/framework/model.cc,jimlinntu,False
"Remove tsl/concurrency now that it has mmoved to xla/tsl/concurrency

PiperOrigin-RevId: 628440187",David Dunleavy,ddunleavy@google.com,2024-04-26 17:14:26,"third_party/xla/third_party/tsl/tsl/concurrency/BUILD, third_party/xla/third_party/tsl/tsl/concurrency/async_value.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h, third_party/xla/third_party/tsl/tsl/concurrency/chain.h, third_party/xla/third_party/tsl/tsl/concurrency/concurrent_vector.h, third_party/xla/third_party/tsl/tsl/concurrency/ref_count.h",ddunl,False
"Update OpenXLA contributing docs

PiperOrigin-RevId: 628435989",Elliot English,elliotenglish@google.com,2024-04-26 17:01:10,"third_party/xla/CONTRIBUTING.md, third_party/xla/docs/_toc.yaml, third_party/xla/docs/code_reviews.md, third_party/xla/docs/contributing.md",,False
"Adds an option to limit the number of iterations performed by the Memory Term Reducer.

PiperOrigin-RevId: 628428349",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 16:32:19,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory_test.cc",tensorflower-gardener,False
"Add dynamically quantized Transpose Convolution to XNNPACK delegate

PiperOrigin-RevId: 628423888",Artsiom Ablavatski,artsiom@google.com,2024-04-26 16:14:06,"tensorflow/lite/delegates/xnnpack/BUILD, tensorflow/lite/delegates/xnnpack/dynamically_quantized_transpose_conv_test.cc, tensorflow/lite/delegates/xnnpack/dynamically_quantized_transpose_conv_tester.cc, tensorflow/lite/delegates/xnnpack/dynamically_quantized_transpose_conv_tester.h, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc",ablavatski,False
"Fix LHS input masking for sparse dots

PiperOrigin-RevId: 628419193",Sergey Kozub,sergeykozub@google.com,2024-04-26 15:55:22,"third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",sergeykozub,False
"Fixes the Memory Term Reducer to properly handle the case of invalid intervals in the input.

PiperOrigin-RevId: 628413845",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 15:32:32,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory_test.cc",tensorflower-gardener,False
"Clean-up kernels build file.

PiperOrigin-RevId: 628408707",Quentin Khan,qkhan@google.com,2024-04-26 15:09:10,tensorflow/lite/core/BUILD,qukhan,False
"Disable already failing tests on TPU

PiperOrigin-RevId: 628407871",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 15:05:49,"third_party/xla/xla/client/lib/math_test.cc, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/convolution_test.cc, third_party/xla/xla/tests/dot_operation_test.cc, third_party/xla/xla/tests/reduce_hlo_test.cc, third_party/xla/xla/tests/reduce_precision_test.cc, third_party/xla/xla/tests/select_and_scatter_test.cc, third_party/xla/xla/tests/transfer_manager_test.cc",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@0c6e1ca1c704

Updates LLVM usage to match
[0c6e1ca1c704](https://github.com/llvm/llvm-project/commit/0c6e1ca1c704)

PiperOrigin-RevId: 628403915",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 14:49:15,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Allow fusions for sparse dot metadata input

Note: metadata has the same shape as LHS, except for the contracting dimension size.
PiperOrigin-RevId: 628403370",Sergey Kozub,sergeykozub@google.com,2024-04-26 14:46:44,"third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",sergeykozub,False
"Add a check that HloComputationFusion is only created for fusion computations.

The comment is outdated. But fix other wrong callers of FindNonTrivialHero.

PiperOrigin-RevId: 628385581",Adrian Kuegel,akuegel@google.com,2024-04-26 13:18:02,"third_party/xla/xla/service/gpu/gpu_fusible.cc, third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/ir_emission_utils_test.cc",akuegel,False
"[XLA] Add the option to flatten function tuple arguments and result when converting HLO to MHLO.

Given that the added option is set to false by default, this change is a no-op for existing uses.

PiperOrigin-RevId: 628383155",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 13:05:08,"third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.cc, third_party/xla/xla/translate/hlo_to_mhlo/BUILD, third_party/xla/xla/translate/hlo_to_mhlo/hlo_function_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_function_importer.h, third_party/xla/xla/translate/hlo_to_mhlo/hlo_module_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_module_importer.h, third_party/xla/xla/translate/hlo_to_mhlo/hlo_to_mlir_hlo.cc, third_party/xla/xla/translate/hlo_to_mhlo/hlo_to_mlir_hlo.h, third_party/xla/xla/translate/hlo_to_mhlo/tests/case_conditional.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/frontend_attributes.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/if_conditional.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/import.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/module_attributes.hlo, third_party/xla/xla/translate/hlo_to_mhlo/tests/spmd_module_sharding.hlo, third_party/xla/xla/translate/hlo_to_mhlo/tests/while.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/translate.cc, third_party/xla/xla/translate/hlo_to_mhlo/translate.h, third_party/xla/xla/translate/hlo_to_mhlo/translate_registration.cc",tensorflower-gardener,False
"Add HloFindIf to search through non-fusion computations (NFC).

Use this in AddressComputationFusionRewriter. It (mis-)uses the HloFindIf for
fusions.

PiperOrigin-RevId: 628371156",Adrian Kuegel,akuegel@google.com,2024-04-26 12:04:03,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/hlo_traversal.h",akuegel,False
"Use correct kWidth in sparse dots with int8 input (on Ampere)

PiperOrigin-RevId: 628368832",Sergey Kozub,sergeykozub@google.com,2024-04-26 11:52:47,"third_party/triton/temporary/sparse_dot_fixes_y24w17.patch, third_party/xla/third_party/triton/temporary/sparse_dot_fixes_y24w17.patch",sergeykozub,False
"Reverts 49a561f7aa52aae84039000d91d46ed18df8855d

PiperOrigin-RevId: 628367605",Adrian Kuegel,akuegel@google.com,2024-04-26 11:45:02,"third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/gpu/multi_output_fusion_test.cc, third_party/xla/xla/service/hlo_instruction_test.cc",akuegel,False
"Fix deprecated `mlir::Type::dyn_cast` call.

PiperOrigin-RevId: 628366850",Christian Sigg,csigg@google.com,2024-04-26 11:40:32,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch",chsigg,False
"Fix sparse dot metadata loader

PiperOrigin-RevId: 628362299",Sergey Kozub,sergeykozub@google.com,2024-04-26 11:13:45,"third_party/triton/temporary/series.bzl, third_party/triton/temporary/sparse_dot_fixes_y24w17.patch, third_party/xla/third_party/triton/temporary/series.bzl, third_party/xla/third_party/triton/temporary/sparse_dot_fixes_y24w17.patch, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/tests/gpu_sparse_dot_test.cc",sergeykozub,False
"PR #10782: Offloading 2/3: generate multi-stream async copies using events on GPUs

Imported from GitHub PR https://github.com/openxla/xla/pull/10782

Emit asynchronous memory copies between hosts and devices using additional streams while the main stream does the computation. The async copies are guarded by RecordEvent() and WaitForEvent() created by the copy-start/copy-done thunks respectively. A hash table is utilized to map copy-start instructions to events. The corresponding events will be waited at copy-done and extracted from the hash table.
Copybara import of the project:

--
a9271ee9b99eb43a0a0806c8dbdfc7753aef4644 by Jane Liu <janeliu@nvidia.com>:

Add the multi-stream implementation for copy-start and copy-done.

Merging this change closes #10782

PiperOrigin-RevId: 628351161",Jane Liu,janeliu@nvidia.com,2024-04-26 10:19:09,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_offloading_test.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.h, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/copy_thunk.cc, third_party/xla/xla/service/gpu/runtime/copy_thunk.h, third_party/xla/xla/service/gpu/runtime/thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.h",zhenying-liu,False
"Automated Code Change

PiperOrigin-RevId: 628350037",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 10:13:00,"tensorflow/core/kernels/risc/experimental/BUILD, tensorflow/core/kernels/risc/experimental/risc_abs_op.cc, tensorflow/core/kernels/risc/experimental/risc_add_op.cc, tensorflow/core/kernels/risc/experimental/risc_binary_arithmetic_op.cc, tensorflow/core/kernels/risc/experimental/risc_binary_comparison_op.cc, tensorflow/core/kernels/risc/experimental/risc_bitcast_op.cc, tensorflow/core/kernels/risc/experimental/risc_broadcast_op.cc, tensorflow/core/kernels/risc/experimental/risc_cast_op.cc, tensorflow/core/kernels/risc/experimental/risc_ceil_op.cc, tensorflow/core/kernels/risc/experimental/risc_cholesky_op.cc, tensorflow/core/kernels/risc/experimental/risc_concat_op.cc, tensorflow/core/kernels/risc/experimental/risc_condition_op.cc, tensorflow/core/kernels/risc/experimental/risc_conv_op.cc, tensorflow/core/kernels/risc/experimental/risc_cos_op.cc, tensorflow/core/kernels/risc/experimental/risc_div_op.cc, tensorflow/core/kernels/risc/experimental/risc_dot_op.cc, tensorflow/core/kernels/risc/experimental/risc_exp_op.cc, tensorflow/core/kernels/risc/experimental/risc_fft_op.cc, tensorflow/core/kernels/risc/experimental/risc_floor_op.cc, tensorflow/core/kernels/risc/experimental/risc_gather_op.cc, tensorflow/core/kernels/risc/experimental/risc_imag_op.cc, tensorflow/core/kernels/risc/experimental/risc_is_finite_op.cc, tensorflow/core/kernels/risc/experimental/risc_log_op.cc, tensorflow/core/kernels/risc/experimental/risc_logical_and_op.cc, tensorflow/core/kernels/risc/experimental/risc_logical_not_op.cc, tensorflow/core/kernels/risc/experimental/risc_logical_or_op.cc, tensorflow/core/kernels/risc/experimental/risc_max_op.cc, tensorflow/core/kernels/risc/experimental/risc_min_op.cc, tensorflow/core/kernels/risc/experimental/risc_mul_op.cc, tensorflow/core/kernels/risc/experimental/risc_neg_op.cc, tensorflow/core/kernels/risc/experimental/risc_pad_op.cc, tensorflow/core/kernels/risc/experimental/risc_pool_op.cc, tensorflow/core/kernels/risc/experimental/risc_pow_op.cc, tensorflow/core/kernels/risc/experimental/risc_random_uniform_op.cc, tensorflow/core/kernels/risc/experimental/risc_real_op.cc, tensorflow/core/kernels/risc/experimental/risc_reduce_op.cc, tensorflow/core/kernels/risc/experimental/risc_rem_op.cc, tensorflow/core/kernels/risc/experimental/risc_reshape_op.cc, tensorflow/core/kernels/risc/experimental/risc_reverse_op.cc, tensorflow/core/kernels/risc/experimental/risc_scatter_op.cc, tensorflow/core/kernels/risc/experimental/risc_shape_op.cc, tensorflow/core/kernels/risc/experimental/risc_sign_op.cc, tensorflow/core/kernels/risc/experimental/risc_slice_op.cc, tensorflow/core/kernels/risc/experimental/risc_sort_op.cc, tensorflow/core/kernels/risc/experimental/risc_squeeze_op.cc, tensorflow/core/kernels/risc/experimental/risc_sub_op.cc, tensorflow/core/kernels/risc/experimental/risc_transpose_op.cc, tensorflow/core/kernels/risc/experimental/risc_triangular_solve_op.cc, tensorflow/core/kernels/risc/experimental/risc_unary_op.cc, tensorflow/core/kernels/risc/experimental/risc_while_op.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628339857",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 09:25:07,"tensorflow/compiler/mlir/tensorflow/utils/cluster_util_test.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_attr.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_attr.h, tensorflow/compiler/mlir/tensorflow/utils/convert_tensor.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_tensor.h, tensorflow/compiler/mlir/tensorflow/utils/convert_type.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_type.h, tensorflow/compiler/mlir/tensorflow/utils/export_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/export_utils.h, tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util.cc, tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util.h, tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util_test.cc, tensorflow/compiler/mlir/tensorflow/utils/translate_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/translate_utils.h, tensorflow/compiler/mlir/tensorflow/utils/xla_rewrite_util_test.cc",tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-26

PiperOrigin-RevId: 628335538",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 09:03:23,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1844.

PiperOrigin-RevId: 628335202",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 09:02:15,tensorflow/core/public/version.h,tensorflower-gardener,False
"[XLA:GPU] Remove unnecessary preprocessor directive.

PiperOrigin-RevId: 628326070",Thomas Joerg,tjoerg@google.com,2024-04-26 08:15:48,third_party/xla/xla/service/gpu/matmul_utils.cc,thomasjoerg,False
"[XLA:GPU] Use raw HloInstruction pointers instead of HloInstructionAdaptor in caches.

HloInstructionAdaptor should be an ""iterator"" to HloFusionAdaptor. Creating an instruction adaptor without fusion adaptor doesn't make sense.

Using raw pointer inside one pass is fine, because instruction are only deleted after the pass. If this becomes a problem at some point, we should used a separate abstraction to compare unique_ids.

PiperOrigin-RevId: 628319223",Oleg Shyshkov,shyshkov@google.com,2024-04-26 07:41:49,"third_party/xla/xla/service/gpu/model/gpu_performance_model_base.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.h, third_party/xla/xla/service/gpu/priority_fusion.cc",olegshyshkov,False
"Automated Code Change

PiperOrigin-RevId: 628307724",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 06:40:58,tensorflow/lite/tools/evaluation/tasks/task_executor.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628299749",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 05:53:32,"tensorflow/python/lib/core/ndarray_tensor.cc, tensorflow/python/lib/core/py_seq_tensor.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 628299451",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 05:51:21,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/utils/math_utils_test.cc",tensorflower-gardener,False
"[xla] Add a test for custom call with output to operand aliasing

PiperOrigin-RevId: 628280351",Eugene Zhulenev,ezhulenev@google.com,2024-04-26 03:55:04,"third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h, third_party/xla/xla/tests/custom_call_test.cc",ezhulenev,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/bdefdf4f5655ff8f19fd401ac16804d8d0db4a4b.

PiperOrigin-RevId: 628275115",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 03:23:16,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Use get_compatible_with_portable rather than non_prod directly.

PiperOrigin-RevId: 628264836",Luke Boyer,lukeboyer@google.com,2024-04-26 02:30:14,tensorflow/compiler/mlir/lite/stablehlo/BUILD,LukeBoyer,False
"Reverts dd491d46f1737d41774e6efeabf694ef59845126

PiperOrigin-RevId: 628242337",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-26 00:39:56,"tensorflow/lite/acceleration/configuration/configuration_generated.h, tensorflow/lite/delegates/gpu/cl/compiled_program_cache_generated.h, tensorflow/lite/delegates/gpu/cl/serialization_generated.h, tensorflow/lite/delegates/gpu/common/gpu_model_generated.h, tensorflow/lite/delegates/gpu/common/task/serialization_base_generated.h, tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h, tensorflow/lite/schema/conversion_metadata_generated.h, tensorflow/lite/schema/schema_generated.h, tensorflow/lite/tools/cmake/modules/flatbuffers.cmake, tensorflow/tools/ci_build/release/requirements_common.txt, tensorflow/tools/pip_package/setup.py, tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt, third_party/flatbuffers/workspace.bzl",tensorflower-gardener,False
"Use the input's shapes directly instead of getting them from the op

PiperOrigin-RevId: 628192496",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 21:32:39,"tensorflow/core/tpu/kernels/BUILD, tensorflow/core/tpu/kernels/tpu_embedding_ops.cc",tensorflower-gardener,False
"Move tranpose ops through pad and reduce_window.

PiperOrigin-RevId: 628184072",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 21:04:19,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/tests/optimize_layout.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/optimize_layout.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/passes.h, tensorflow/compiler/mlir/lite/stablehlo/transforms/passes.td, tensorflow/compiler/mlir/lite/tf_tfl_passes.cc",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@76a3be7c766b

Updates LLVM usage to match
[76a3be7c766b](https://github.com/llvm/llvm-project/commit/76a3be7c766b)

PiperOrigin-RevId: 628182652",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 20:59:47,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"[XLA:GPU][MLIR-based emitters] Add a pattern to simplify apply_indexing op.

Right now it also removes unused symbols, but later unused dims will be added
as well.

PiperOrigin-RevId: 628181321",Alexander Belyaev,pifon@google.com,2024-04-25 20:54:41,"third_party/xla/xla/service/gpu/fusions/mlir/ir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/canonicalize.mlir, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h",pifon2a,False
"[IFRT] Support portable PjRtLoadedExecutable

This change fixes support for portable `PjRtLoadedExecutable` (an executable
that can be compiled once and dynamically loaded onto any device at execution
time). The previous code had device assignment handling that is not compatible
with `TfrtCpuClient`: `xla::ifrt::PjRtLoadedExecutable` expects some device to
be present in the device assignment, while `xla::PjRtLoadedExecutable` expects
no device to be present. This is resolved by making
`xla::ifrt::PjRtLoadedExecutable` allow empty device assignment.

PiperOrigin-RevId: 628168913",Hyeontaek Lim,hyeontaek@google.com,2024-04-25 20:13:12,"third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.h, third_party/xla/xla/python/pjrt_ifrt/xla_executable_impl_test_lib.cc",hyeontaek,False
"[pjrt] Clean up PjRtFuture documentation and internal APIs

PiperOrigin-RevId: 628161783",Eugene Zhulenev,ezhulenev@google.com,2024-04-25 19:47:27,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"Populates Auto Sharding solver requests with intervals instead of liveness matrices.

PiperOrigin-RevId: 628152039",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 19:11:50,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_impl.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_wrapper.h",tensorflower-gardener,False
"PR #11717: [XLA:GPU] Default to flash attention and remove mask input in cuDNN

Imported from GitHub PR https://github.com/openxla/xla/pull/11717

* Default to flash attention as it is high performant and maintained actively by cuDNN, remove old fused attn.
  * Remove lowering to fused attn in rewriter
  * Remove cudnn graph generation
* Remove mask input as it is only doing multiply instead of masking with -inf, give incorrect results. Also cuDNN does not support this anymore, mask should be combined with bias. This is follow up on https://github.com/openxla/xla/pull/11444.
  * Remove mask logic in rewriter
  * Remove mask buffer/descriptor in thunk
* Remove bmm1-bmm2 pattern as it is not support by flash attention. Modified related rewriter test to use bmm1-softmax - bmm2.

Current pattern:
bmm1 - (scale) - (bias) - softmax - (dropout) - bmm2.
Copybara import of the project:

--
552b4a3387c6d5b2b5adcf31b6f44cc858387b23 by cjkkkk <ske@nvidia.com>:

remove fused attn

--
13b683bf923e6fe344f879f913ae6ce41334eeb2 by cjkkkk <ske@nvidia.com>:

remove mask and bmm1-bmm2 pattern

--
9e843dd66c8f7d51d239b433e1b9bc329afee90d by cjkkkk <ske@nvidia.com>:

rm unused vari

--
1104df540e9196b34d9e61e679d88260151728d5 by cjkkkk <ske@nvidia.com>:

remove fused attn cudnnv version check and update flash attn cudnn version check

--
b020cb8e91d8f7b834645ff815c38c4798174857 by cjkkkk <ske@nvidia.com>:

remove mask related cudnnfmhakind&descriptor&buffer

--
ff1952faa460eecfca62660a5c34ea6fa3c2dfd4 by cjkkkk <ske@nvidia.com>:

rename hlo_string to shorter name

Merging this change closes #11717

PiperOrigin-RevId: 628146618",Shanbin Ke,ske@nvidia.com,2024-04-25 18:55:34,"third_party/xla/xla/service/gpu/cublas_cudnn.cc, third_party/xla/xla/service/gpu/cublas_cudnn.h, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter_test.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_transpose_fusion.cc, third_party/xla/xla/service/gpu/cudnn_workspace_rewriter.cc, third_party/xla/xla/service/gpu/gpu_fused_mha_runner.cc, third_party/xla/xla/service/gpu/gpu_fused_mha_runner.h, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/runtime/fused_mha_thunk.cc, third_party/xla/xla/service/gpu/runtime/fused_mha_thunk.h, third_party/xla/xla/service/gpu/stream_executor_util.cc, third_party/xla/xla/service/gpu/stream_executor_util.h, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc, third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc, third_party/xla/xla/stream_executor/cuda/cuda_dnn.h, third_party/xla/xla/stream_executor/dnn.cc, third_party/xla/xla/stream_executor/dnn.h, third_party/xla/xla/stream_executor/lazy_op_runner.h",Cjkkkk,False
"[pjrt] Add const& qualified Await() to fix broken tests

PiperOrigin-RevId: 628146042",Eugene Zhulenev,ezhulenev@google.com,2024-04-25 18:53:44,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/8b26d736c7e05a4a4a2fdb099c882c7c0010c8ae.

PiperOrigin-RevId: 628145220",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 18:51:02,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Fuse redundant RHS TFL_TransposeOp into TFL_BatchMatMulOp if rhs is constant quantized tensor of rank-2.

PiperOrigin-RevId: 628138462",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 18:29:32,"tensorflow/compiler/mlir/lite/tests/optimize.mlir, tensorflow/compiler/mlir/lite/transforms/legalize_patterns.td, tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td, tensorflow/compiler/mlir/lite/utils/utils.td",tensorflower-gardener,False
"[pjrt] Add OnReady overload for unique (move-only) futures

PiperOrigin-RevId: 628134226",Eugene Zhulenev,ezhulenev@google.com,2024-04-25 18:16:41,"third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/pjrt/pjrt_future_test.cc",ezhulenev,False
"PR #10638: Handle no-op custom call in the emitter

Imported from GitHub PR https://github.com/openxla/xla/pull/10638

The AllocateBuffer custom call (a.k.a. `kNopCustomCallTarget`) is no-op because the runtime allocates the buffer. Let us handle AllocateBuffer by emitting nothing and returning.
Copybara import of the project:

--
6ad7c399e05182a543e50ed14f34b99a281155ce by Jaroslav Sevcik <jsevcik@nvidia.com>:

Emit no-op (AllocateBuffer custom-call)

--
0f78007475921031549c8555ad56ed8903efe6cb by Jaroslav Sevcik <jsevcik@nvidia.com>:

Renamed allocate-buffer to nop in the test

Merging this change closes #10638

PiperOrigin-RevId: 628129950",Jaroslav Sevcik,jsevcik@nvidia.com,2024-04-25 18:04:07,"third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/nop_custom_call_test.cc",jaro-sevcik,False
"Update stableHLO temporary.patch

PiperOrigin-RevId: 628129609",Jeremy Kun,jkun@google.com,2024-04-25 18:03:16,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch",j2kun,False
"PR #11757: [GPU] Enable workspace support in cuDNN GEMM fusions.

Imported from GitHub PR https://github.com/openxla/xla/pull/11757

Copybara import of the project:

--
a2b4e3ec5f508e64301307b7eb39d7c4c7009023 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Enable workspace support in cuDNN GEMM fusions.

Merging this change closes #11757

PiperOrigin-RevId: 628128298",Ilia Sergachev,isergachev@nvidia.com,2024-04-25 17:59:37,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/cudnn_support_utils.cc, third_party/xla/xla/service/gpu/cudnn_support_utils.h, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis.cc, third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc",sergachev,False
"PR #11345: [XLA:GPU] Relax row reduction vectorization restriction

Imported from GitHub PR https://github.com/openxla/xla/pull/11345

Row reduction did not enable vectorization if num_threads_x <= WarpSize() previously due to half or more of the threads don't do anything. But for current tiling implementation, it is not right. Assume row reduction operand shape is [1024, 256] and num_threads_x is 32 (because of 32 * 16 > 256),  each thread can handle 8 scalar or 4 vec<T, 2>.
It is better to judge whether (num_threads_x * vector_size) is larger than the reduced minor dimension.
Copybara import of the project:

--
4fe28d16b52728773a82b6cd31dd3314857ebd21 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

Relax row reduction vectorization restriction. Below hlo can improve
from 0.030ms to 0.026ms on A100 40GB:
HloModule reduce_sum

region_0.5 {
  Arg_1.7.0 = f32[] parameter(1)
  Arg_0.6.0 = f32[] parameter(0)
  ROOT add.4.0 = f32[] add(Arg_0.6.0, Arg_1.7.0)
}

ENTRY main.14 {
  Arg_0.1.0 = bf16[65536,256]{1,0} parameter(0)
  convert.8.1 = f32[65536,256]{1,0} convert(Arg_0.1.0)
  constant_3_1 = f32[] constant(0)
  ROOT reduce.9.1 = f32[65536]{0} reduce(convert.8.1, constant_3_1), dimensions={1}, to_apply=region_0.5
}

--
90e14e2cd2966ac093677536ce2452e4c073541c by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

analysis memory coalescing correctly for vectorization load

--
aa0a3fb62f8877b919ca906291a19440da9ff631 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

match symbol with range

Merging this change closes #11345

PiperOrigin-RevId: 628126104",lingzhi98,103185827+lingzhi98@users.noreply.github.com,2024-04-25 17:53:27,"third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc",lingzhi98,False
"Fixed proto2 to google::protobuf conversion.

PiperOrigin-RevId: 628125475",Dero Gharibian,dero@google.com,2024-04-25 17:51:43,"tensorflow/core/tfrt/saved_model/saved_model_util.cc, tensorflow/core/tfrt/saved_model/saved_model_util.h",gharibian,False
"Make CachedExecutableBundle movable only to avoid repeated copy and
allows us to clarify ownership of IfrtExecutable and TfHostCallbacks
using std::unique_ptr instead of using std::shared_ptr

PiperOrigin-RevId: 628124595",Deqiang Chen,deqiangc@google.com,2024-04-25 17:49:10,"tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h",deqiangc,False
"[XLA:GPU] Only upload the autotuning results for the module being compiled.

If multiple uploads occur from the same process, there's no need to upload all
modules every time. At best it's wasteful.

PiperOrigin-RevId: 628123380",pizzud,pizzud@google.com,2024-04-25 17:45:01,"third_party/xla/xla/service/gpu/autotuner_util.cc, third_party/xla/xla/service/gpu/autotuner_util.h, third_party/xla/xla/service/gpu/gpu_compiler.cc",pizzud,False
"Add `Subgraph::ResizeInputTensor` overloads that don't require allocating a vector before.

PiperOrigin-RevId: 628123323",Quentin Khan,qkhan@google.com,2024-04-25 17:44:47,"tensorflow/lite/BUILD, tensorflow/lite/core/BUILD, tensorflow/lite/core/subgraph.cc, tensorflow/lite/core/subgraph.h, tensorflow/lite/kernels/BUILD, tensorflow/lite/kernels/control_flow_common.h, tensorflow/lite/kernels/if.cc",qukhan,False
"[pjrt] Remove error-prone PjRtFuture constructor taking AynsValueRef directly

For move-only types it's impossible to guarantee correct PjRtFuture::Await and OnReady semantics if we allow constructing futures from async values directly

PiperOrigin-RevId: 628119556",Eugene Zhulenev,ezhulenev@google.com,2024-04-25 17:33:29,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"[pjrt] Add a run time check to guarantee that only one unique future created from a promise for move-only types

PiperOrigin-RevId: 628114989",Eugene Zhulenev,ezhulenev@google.com,2024-04-25 17:20:11,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"[pjrt] Add support for awaiting on move-only (unique) PjRtFutures

PiperOrigin-RevId: 628109419",Eugene Zhulenev,ezhulenev@google.com,2024-04-25 17:03:33,"third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/pjrt/pjrt_future_test.cc",ezhulenev,False
"Correct usage of Protobuf DebugString APIs

PiperOrigin-RevId: 628107250",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 16:56:34,"tensorflow/core/ops/compat/BUILD, tensorflow/core/ops/compat/update_ops_main.cc, tensorflow/core/tfrt/gpu/kernel/BUILD, tensorflow/core/tfrt/gpu/kernel/gpu_runner.cc, third_party/xla/xla/service/gpu/model/hlo_op_profiler_run.cc",tensorflower-gardener,False
"[xla:gpu] Fix the dimension order propagation for kPad

Previously trivial fragments are not handled because we didn't support matrices with trivial dimensions.

PiperOrigin-RevId: 628105574",Anlun Xu,anlunx@google.com,2024-04-25 16:50:10,"third_party/xla/xla/service/gpu/split_k_gemm_rewriter_test.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis_test.cc, third_party/xla/xla/service/gpu/triton_tiling_propagation.cc",anlunx,False
"Reverts f1bac5e7917a4542707c2e175abc5929d4beed3e

PiperOrigin-RevId: 628097889",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 16:21:13,"third_party/xla/workspace2.bzl, third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_strategy.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.h",tensorflower-gardener,False
"NFC: Use the free function variants for `dyn_cast/cast/isa/...`.

The member functions in `Type/Attribute/Value/Location/AffineExpr` are deprecated and will go away.

PiperOrigin-RevId: 628090109",Christian Sigg,csigg@google.com,2024-04-25 15:51:58,"tensorflow/compiler/mlir/BUILD, tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/experimental/common/outline_operations.cc, tensorflow/compiler/mlir/lite/experimental/tac/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/common/utils.h, tensorflow/compiler/mlir/lite/experimental/tac/execution_metadata_exporter.cc, tensorflow/compiler/mlir/lite/experimental/tac/transforms/cost_model.cc, tensorflow/compiler/mlir/lite/experimental/tac/transforms/device_transform.cc, tensorflow/compiler/mlir/lite/experimental/tac/transforms/device_transform_patterns.cc, tensorflow/compiler/mlir/lite/experimental/tac/transforms/fold_constants_to_subgraph.cc, tensorflow/compiler/mlir/lite/experimental/tac/transforms/raise_target_subgraphs.cc, tensorflow/compiler/mlir/lite/experimental/tac/transforms/tac_filter.cc, tensorflow/compiler/mlir/lite/flatbuffer_export.cc, tensorflow/compiler/mlir/lite/flatbuffer_operator.cc, tensorflow/compiler/mlir/lite/flatbuffer_operator.h, tensorflow/compiler/mlir/lite/metrics/BUILD, tensorflow/compiler/mlir/lite/metrics/types_util.cc, tensorflow/compiler/mlir/lite/python/saved_model_to_tfl_flatbuffer.cc, tensorflow/compiler/mlir/lite/quantization/ir/ConvertConst.cc, tensorflow/compiler/mlir/lite/quantization/ir/ConvertSimQuant.cc, tensorflow/compiler/mlir/lite/quantization/ir/QuantOps.cc, tensorflow/compiler/mlir/lite/quantization/ir/QuantizeUtils.cc, tensorflow/compiler/mlir/lite/quantization/tensorflow/fallback_to_flex_ops.cc, tensorflow/compiler/mlir/lite/quantization/tensorflow/tf_to_quant.cc, tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/transforms/compose_uniform_quantized_type_pass.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_avg_pool.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_utils.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_utils.h, tensorflow/compiler/mlir/lite/stablehlo/transforms/fold_broadcast_pass.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/hlo_matchers.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/custom_call.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/dot_general.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/reduce.h, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/scatter.h, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_hlo_conversions/util.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_composite_to_tfl_custom.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_custom_call_to_composite.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_to_vhlo.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/optimize.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/rename_entrypoint_to_main.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/tflite_legalize_hlo.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/unfold_splat_constant_pass.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/unfuse_batch_norm_pass.cc, tensorflow/compiler/mlir/lite/transforms/analyze_variables.cc, tensorflow/compiler/mlir/lite/transforms/decompose_hybrid_quantization.cc, tensorflow/compiler/mlir/lite/transforms/default_quant_params.cc, tensorflow/compiler/mlir/lite/transforms/dense_to_sparse.cc, tensorflow/compiler/mlir/lite/transforms/dilated_conv.h, tensorflow/compiler/mlir/lite/transforms/legalize_hashtables.cc, tensorflow/compiler/mlir/lite/transforms/legalize_jax_random.cc, tensorflow/compiler/mlir/lite/transforms/legalize_tf.cc, tensorflow/compiler/mlir/lite/transforms/legalize_variables.cc, tensorflow/compiler/mlir/lite/transforms/lift_tflite_flex_ops.cc, tensorflow/compiler/mlir/lite/transforms/modify_io_nodes.cc, tensorflow/compiler/mlir/lite/transforms/optimize.cc, tensorflow/compiler/mlir/lite/transforms/optimize_batch_matmul.cc, tensorflow/compiler/mlir/lite/transforms/optimize_functional_ops.cc, tensorflow/compiler/mlir/lite/transforms/optimize_op_order.cc, tensorflow/compiler/mlir/lite/transforms/pin_ops_with_side_effects.cc, tensorflow/compiler/mlir/lite/transforms/post_quantize.cc, tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.cc, tensorflow/compiler/mlir/lite/transforms/prepare_quantize.cc, tensorflow/compiler/mlir/lite/transforms/prepare_quantize_dynamic_range.cc, tensorflow/compiler/mlir/lite/transforms/prepare_quantize_helper.h, tensorflow/compiler/mlir/lite/transforms/prepare_tf.cc, tensorflow/compiler/mlir/lite/transforms/push_transpose_through_ewise.cc, tensorflow/compiler/mlir/lite/transforms/quantize_variables.cc, tensorflow/compiler/mlir/lite/transforms/reduce_type_precision.cc, tensorflow/compiler/mlir/lite/transforms/reduce_while_operands.cc, tensorflow/compiler/mlir/lite/transforms/unfold_large_splat_constant.cc, tensorflow/compiler/mlir/lite/transforms/while_loop_outline.cc, tensorflow/compiler/mlir/lite/utils/arithmetic_count_util.h, tensorflow/compiler/mlir/lite/utils/attribute_utils.cc, tensorflow/compiler/mlir/lite/utils/const_tensor_utils.cc, tensorflow/compiler/mlir/lite/utils/constant_utils.cc, tensorflow/compiler/mlir/lite/utils/convert_type.cc, tensorflow/compiler/mlir/lite/utils/fake_quant_utils.h, tensorflow/compiler/mlir/lite/utils/lstm_utils.cc, tensorflow/compiler/mlir/lite/utils/lstm_utils_test.cc, tensorflow/compiler/mlir/lite/utils/nms_utils.cc, tensorflow/compiler/mlir/lite/utils/perception_ops_utils.cc, tensorflow/compiler/mlir/lite/utils/tftext_utils.cc, tensorflow/compiler/mlir/lite/utils/utils.h, tensorflow/compiler/mlir/lite/utils/validators.cc, tensorflow/compiler/mlir/lite/utils/validators.h, tensorflow/compiler/mlir/op_or_arg_name_mapper.cc, tensorflow/compiler/mlir/quantization/common/attrs_and_constraints.cc, tensorflow/compiler/mlir/quantization/common/attrs_and_constraints.h, tensorflow/compiler/mlir/quantization/common/ir/QuantOps.cc, tensorflow/compiler/mlir/quantization/common/ir/UniformSupport.cc, tensorflow/compiler/mlir/quantization/common/ir/UniformSupport.h, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.cc, tensorflow/compiler/mlir/quantization/common/lift_as_function_call_test.cc, tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_driver.cc, tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_driver_test.cc, tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.cc, tensorflow/compiler/mlir/quantization/common/uniform_quantized_types.cc, tensorflow/compiler/mlir/quantization/common/uniform_quantized_types.h, tensorflow/compiler/mlir/quantization/common/uniform_quantized_types_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/report.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/bridge/convert_tf_quant_ops_to_mhlo.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/bridge/convert_tf_quant_types.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/bridge/verify_quant_legalization.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/convert_func_to_bfloat16.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/defer_activation_transpose.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/fold_constant_transpose.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/insert_weight_param.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/lift_quantizable_spots_as_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/merge_fusion_with_dequantize.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/nchw_convolution_to_nhwc.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize_weight.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/replace_stablehlo_ops_in_main_function_with_xla_call_module_ops.cc, tensorflow/compiler/mlir/quantization/stablehlo/utils/bfloat16_type.cc, tensorflow/compiler/mlir/quantization/stablehlo/utils/tf_type_utils.cc, tensorflow/compiler/mlir/quantization/stablehlo/utils/tf_type_utils_test.cc, tensorflow/compiler/mlir/quantization/tensorflow/cc/convert_asset_args.cc, tensorflow/compiler/mlir/quantization/tensorflow/cc/convert_asset_args_test.cc, tensorflow/compiler/mlir/quantization/tensorflow/cc/quantization_unit_loc.cc, tensorflow/compiler/mlir/quantization/tensorflow/ops/tf_op_quant_spec.cc, tensorflow/compiler/mlir/quantization/tensorflow/ops/tf_quantize_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/add_quantization_unit_loc.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/convert_custom_aggregation_op_to_quant_stats.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/convert_tf_xla_op_to_tf_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/convert_tpu_model_to_cpu.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_custom_aggregation_ops.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_main_function.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/lift_quantizable_spots_as_functions.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/lift_quantizable_spots_as_functions_drq.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/merge_initializer_function_ops_to_main.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/merge_save_function_ops_to_main.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/prepare_lifting.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/prepare_quantize.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/prepare_quantize_drq.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/preprocess_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/propagate_quantize_type.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/quantize_composite_functions.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/replace_cast_hacks_with_tf_xla_ops.cc, tensorflow/compiler/mlir/quantization/tensorflow/utils/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/utils/fake_quant_utils.h, tensorflow/compiler/mlir/quantization/tensorflow/utils/tf_quantize_op_utils.cc, tensorflow/compiler/mlir/quantization/tensorflow/utils/tf_to_uniform_attribute_utils.cc, tensorflow/compiler/mlir/quantization/tensorflow/utils/tf_to_xla_attribute_utils.cc, tensorflow/compiler/mlir/quantization/tensorflow/utils/tf_to_xla_attribute_utils_test.cc, tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/analysis/resource_alias_analysis.cc, tensorflow/compiler/mlir/tensorflow/analysis/resource_dataflow.cc, tensorflow/compiler/mlir/tensorflow/analysis/resource_value_typed_analyzer.cc, tensorflow/compiler/mlir/tensorflow/analysis/side_effect_analysis.cc, tensorflow/compiler/mlir/tensorflow/c/c_api_unified_experimental_mlir.cc, tensorflow/compiler/mlir/tensorflow/ir/host_runtime/tfrt_ops.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_arith_ops_folder.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_arith_ops_folder.h, tensorflow/compiler/mlir/tensorflow/ir/tf_device.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_executor.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_ops_a_m.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_ops_layout_helper.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_ops_tensor_helper.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_ops_tensor_helper.h, tensorflow/compiler/mlir/tensorflow/ir/tf_saved_model.cc, tensorflow/compiler/mlir/tensorflow/ir/tf_traits.h, tensorflow/compiler/mlir/tensorflow/transforms/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/annotate_parameter_replication.cc, tensorflow/compiler/mlir/tensorflow/transforms/batchmatmul_to_einsum.cc, tensorflow/compiler/mlir/tensorflow/transforms/cluster_ops_by_policy.cc, tensorflow/compiler/mlir/tensorflow/transforms/cluster_tf_ops_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/collection_ops_util.cc, tensorflow/compiler/mlir/tensorflow/transforms/constant_fold.cc, tensorflow/compiler/mlir/tensorflow/transforms/constant_fold_utils.cc, tensorflow/compiler/mlir/tensorflow/transforms/convert_control_to_data_outputs.cc, tensorflow/compiler/mlir/tensorflow/transforms/decompose_reduce_dataset.cc, tensorflow/compiler/mlir/tensorflow/transforms/einsum.cc, tensorflow/compiler/mlir/tensorflow/transforms/executor_island_coarsening.cc, tensorflow/compiler/mlir/tensorflow/transforms/executor_tpuv1_island_coarsening.cc, tensorflow/compiler/mlir/tensorflow/transforms/executor_tpuv1_outline_tpu_island.cc, tensorflow/compiler/mlir/tensorflow/transforms/extract_tpu_copy_with_dynamic_shape_op.cc, tensorflow/compiler/mlir/tensorflow/transforms/fold_broadcast.cc, tensorflow/compiler/mlir/tensorflow/transforms/freeze_global_tensors.cc, tensorflow/compiler/mlir/tensorflow/transforms/functional_control_flow_to_regions.cc, tensorflow/compiler/mlir/tensorflow/transforms/fused_kernel_matcher.cc, tensorflow/compiler/mlir/tensorflow/transforms/hoist_loop_invariant.cc, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/tpu_metadata_utils.cc, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/tpu_rewrite_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/tpu_variable_runtime_reformatting.cc, tensorflow/compiler/mlir/tensorflow/transforms/initialize_variables_in_session_init.cc, tensorflow/compiler/mlir/tensorflow/transforms/launch_to_device_attribute.cc, tensorflow/compiler/mlir/tensorflow/transforms/layout_optimization.cc, tensorflow/compiler/mlir/tensorflow/transforms/lift_variables.cc, tensorflow/compiler/mlir/tensorflow/transforms/lower_globals_to_ml_program.cc, tensorflow/compiler/mlir/tensorflow/transforms/lower_tf.cc, tensorflow/compiler/mlir/tensorflow/transforms/optimize.cc, tensorflow/compiler/mlir/tensorflow/transforms/optimize_global_tensors.cc, tensorflow/compiler/mlir/tensorflow/transforms/prepare_tpu_computation_for_tf_export.cc, tensorflow/compiler/mlir/tensorflow/transforms/promote_resources_to_args.cc, tensorflow/compiler/mlir/tensorflow/transforms/readonly_references_to_resources.cc, tensorflow/compiler/mlir/tensorflow/transforms/region_control_flow_to_functional.cc, tensorflow/compiler/mlir/tensorflow/transforms/remove_unused_arguments.cc, tensorflow/compiler/mlir/tensorflow/transforms/remove_vars_in_session_initializer.cc, tensorflow/compiler/mlir/tensorflow/transforms/replicate_invariant_op_hoisting.cc, tensorflow/compiler/mlir/tensorflow/transforms/resource_op_lifting.cc, tensorflow/compiler/mlir/tensorflow/transforms/resource_op_lifting_cleanup.cc, tensorflow/compiler/mlir/tensorflow/transforms/rewrite_util.h, tensorflow/compiler/mlir/tensorflow/transforms/set_tpu_infeed_layout.cc, tensorflow/compiler/mlir/tensorflow/transforms/shape_inference.cc, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/embedding_pipelining.cc, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/embedding_program_key.cc, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/embedding_sequencing.cc, tensorflow/compiler/mlir/tensorflow/transforms/stack_ops_decomposition.cc, tensorflow/compiler/mlir/tensorflow/transforms/tensor_device_copy_conversion.cc, tensorflow/compiler/mlir/tensorflow/transforms/tensor_list_ops_decomposition.cc, tensorflow/compiler/mlir/tensorflow/transforms/tf_saved_model_asset_sinking_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/tfg-to-tfe.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_annotate_dynamic_shape_inputs.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_device_propagation.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_dynamic_layout_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_host_computation_expansion.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_partitioned_op_conversion.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_sharding_identification_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_space_to_depth_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/tpu_validate_inputs.cc, tensorflow/compiler/mlir/tensorflow/transforms/unroll_batch_matmul.cc, tensorflow/compiler/mlir/tensorflow/transforms/xla_call_module_deserialization.cc, tensorflow/compiler/mlir/tensorflow/transforms/xla_call_module_serialization.cc, tensorflow/compiler/mlir/tensorflow/transforms/xla_rewrite.cc, tensorflow/compiler/mlir/tensorflow/translate/BUILD, tensorflow/compiler/mlir/tensorflow/translate/export_graphdef.cc, tensorflow/compiler/mlir/tensorflow/translate/export_tf_dialect_op.cc, tensorflow/compiler/mlir/tensorflow/translate/import_model.cc, tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate.cc, tensorflow/compiler/mlir/tensorflow/utils/attribute_utils.h, tensorflow/compiler/mlir/tensorflow/utils/call_graph_util.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_tensor.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_tensor_test.cc, tensorflow/compiler/mlir/tensorflow/utils/convert_type.cc, tensorflow/compiler/mlir/tensorflow/utils/device_util.cc, tensorflow/compiler/mlir/tensorflow/utils/device_util_test.cc, tensorflow/compiler/mlir/tensorflow/utils/error_util.cc, tensorflow/compiler/mlir/tensorflow/utils/export_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/location_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/session_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/stablehlo_custom_call.cc, tensorflow/compiler/mlir/tensorflow/utils/tf_xla_mlir_translate.cc, tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util.cc, tensorflow/compiler/mlir/tensorflow/utils/translate_utils.cc, tensorflow/compiler/mlir/tensorflow/utils/xla_sharding_util.cc, tensorflow/compiler/mlir/tf2xla/api/v1/compile_mlir_util.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/extract_head_tail_outside_compilation.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/extract_outside_compilation.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/hoist_broadcast_read.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/mark_ops_for_outside_compilation.cc, tensorflow/compiler/mlir/tf2xla/internal/passes/tpu_cluster_formation.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf_collective.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf_communication.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalize_tf_with_tf2xla.cc, tensorflow/compiler/mlir/tf2xla/transforms/tf2xla_rewriter.cc, tensorflow/compiler/mlir/tf2xla/transforms/verify_tfxla_legalization.cc, tensorflow/compiler/mlir/tfr/passes/decompose.cc, tensorflow/compiler/mlir/tfr/passes/raise_to_tf.cc, tensorflow/compiler/mlir/tfrt/BUILD, tensorflow/compiler/mlir/tfrt/analysis/cost_analysis.cc, tensorflow/compiler/mlir/tfrt/ir/BUILD, tensorflow/compiler/mlir/tfrt/ir/mlrt/BUILD, tensorflow/compiler/mlir/tfrt/ir/mlrt/mlrt_dialect.cc, tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_mlrt_ops.cc, tensorflow/compiler/mlir/tfrt/ir/tfrt_fallback.cc, tensorflow/compiler/mlir/tfrt/ir/tfrt_fallback_common.cc, tensorflow/compiler/mlir/tfrt/ir/tfrt_fallback_common.h, tensorflow/compiler/mlir/tfrt/saved_model/saved_model.cc, tensorflow/compiler/mlir/tfrt/transforms/attr_lowering_utils.cc, tensorflow/compiler/mlir/tfrt/transforms/corert_converter.cc, tensorflow/compiler/mlir/tfrt/transforms/cross_device_transfer.cc, tensorflow/compiler/mlir/tfrt/transforms/fallback_converter.cc, tensorflow/compiler/mlir/tfrt/transforms/insert_tensor_copy.cc, tensorflow/compiler/mlir/tfrt/transforms/lower_saved_model.cc, tensorflow/compiler/mlir/tfrt/transforms/mlrt/tf_to_mlrt.cc, tensorflow/compiler/mlir/tfrt/transforms/optimize.cc, tensorflow/compiler/mlir/tfrt/transforms/sink_in_invariant_ops.cc, tensorflow/compiler/mlir/tfrt/transforms/tf_to_tfrt.cc, tensorflow/compiler/mlir/tfrt/transforms/utils.cc, tensorflow/compiler/mlir/tfrt/translate/import_model.cc, tensorflow/compiler/mlir/tfrt/translate/mlrt/BUILD, tensorflow/compiler/mlir/tfrt/translate/mlrt/mlir_to_bytecode.cc, tensorflow/compiler/mlir/tfrt/translate/mlrt/mlir_to_bytecode_test.cc, tensorflow/compiler/mlir/tools/kernel_gen/ir/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/ir/tf_framework_ops.cc, tensorflow/compiler/mlir/tools/kernel_gen/kernel_creator.cc, tensorflow/compiler/mlir/tools/kernel_gen/transforms/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/transforms/buffer_reuse_pass.cc, tensorflow/compiler/mlir/tools/kernel_gen/transforms/copy_cleanup_pass.cc, tensorflow/compiler/mlir/tools/kernel_gen/transforms/embed_tf_framework.cc, tensorflow/compiler/mlir/tools/kernel_gen/transforms/embed_tf_framework_pass.cc, tensorflow/compiler/mlir/tools/kernel_gen/transforms/same_shape_propagation.cc, tensorflow/compiler/mlir/tools/kernel_gen/transforms/tensorflow_abi_knowledge_propagation.cc",chsigg,False
"Updates the solver to support interval-based memory representations.

PiperOrigin-RevId: 628079964",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 15:10:02,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.proto, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver_test.cc",tensorflower-gardener,False
"Reverts 35a836fd2066b76ec900689416999455c99524ec

PiperOrigin-RevId: 628071862",Johannes Reifferscheid,jreiffers@google.com,2024-04-25 14:38:21,"third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",jreiffers,False
"Integrate LLVM at llvm/llvm-project@fe47e8ff3ae7

Updates LLVM usage to match
[fe47e8ff3ae7](https://github.com/llvm/llvm-project/commit/fe47e8ff3ae7)

PiperOrigin-RevId: 628032566",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 11:34:18,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"Add a MultiOutputFusion test case for CommonElementwiseUtilization().

This is to document that the function also works as expected if called by
FusionUsesParameterElementwiseFromRoot() with a MultiOutputFusion.

PiperOrigin-RevId: 628028929",Adrian Kuegel,akuegel@google.com,2024-04-25 11:14:57,third_party/xla/xla/service/gpu/model/gpu_hlo_cost_analysis_test.cc,akuegel,False
"Automated Code Change

PiperOrigin-RevId: 628022534",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 10:46:16,third_party/xla/third_party/tsl/tsl/framework/tracking_allocator.h,tensorflower-gardener,False
"PR #11592: Add a TritonFusionAnalysis util to query an op's scope.

Imported from GitHub PR https://github.com/openxla/xla/pull/11592

Add a TritonFusionAnalysis util to query an op's scope.
This will be used in cuDNN compiler for deciding an op's dimensions in the followup PR.
Copybara import of the project:

--
33d4a59ebf970689a4c05c1847152c9a6aab632f by Elfie Guo <elfieg@nvidia.com>:

Add a TritonFusionAnalysis util to query an op's scope.

Merging this change closes #11592

PiperOrigin-RevId: 628015848",Elfie Guo,elfieg@nvidia.com,2024-04-25 10:14:17,"third_party/xla/xla/service/gpu/triton_fusion_analysis.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis.h, third_party/xla/xla/service/gpu/triton_fusion_analysis_test.cc",elfiegg,False
"Enable saving quantization report to file from `QuantizationReport`.

PiperOrigin-RevId: 628012969",Dan Suh,dansuh@google.com,2024-04-25 10:00:45,"tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/report.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/report.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/report_test.cc",dansuh17,False
"Automated Code Change

PiperOrigin-RevId: 628011201",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 09:51:17,"tensorflow/compiler/mlir/tensorflow/transforms/constant_fold_utils.cc, tensorflow/compiler/mlir/tensorflow/transforms/graph_optimization_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/tf_saved_model_freeze_variables.cc",tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-25

PiperOrigin-RevId: 628001218",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 09:03:15,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1843.

PiperOrigin-RevId: 628001045",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 09:02:33,tensorflow/core/public/version.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627981036",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 07:24:02,"tensorflow/core/framework/function.h, tensorflow/core/framework/op_kernel.h, tensorflow/core/framework/tensor.h, tensorflow/core/framework/types.h",tensorflower-gardener,False
"PR #11643: Fix unexpected resursive call in ksl for loop

Imported from GitHub PR https://github.com/openxla/xla/pull/11643

ksl does not have this func: ForWithStatus(string_view, llvm::Value*, llvm::Value*, llvm::Value, bool, const std::function<Status(llvm::Value*, bool)>&), only has ForWithStatus(string_view, llvm::Value*, llvm::Value*, llvm::Value, const std::function<Status(llvm::Value*, bool)>&) which is the expected func call. So if use peel first iteration, will call ForWithStatus(string_view, llvm::Value*, llvm::Value*, llvm::Value, bool, const std::function<Status(llvm::Value*, llvm::Value*)>&) recursively (std::function<Status(llvm::Value*, bool)> will cast to std::function<Status(llvm::Value*, llvm::Value*)> implicitly on my running enviroment), which leads stack smash.
Copybara import of the project:

--
daa71e5687726f30cc8d0da6419e576d4ddedff8 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix unexpected resursive call

--
d67a61ea83d8204c034f6eadb98bebc7fecbcd27 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

remove deadcode

--
7e1c236da49cf4012cac372db5c7760876563461 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix build error

--
e5ac16d665d88b8b8d1258b1e0e4ebfd94813547 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix filecheck error

Merging this change closes #11643

PiperOrigin-RevId: 627980814",lingzhi98,103185827+lingzhi98@users.noreply.github.com,2024-04-25 07:22:40,"third_party/xla/xla/service/cpu/tiled_dot_emitter.cc, third_party/xla/xla/service/gpu/tests/reduce_atomic_min.hlo, third_party/xla/xla/service/gpu/tests/reduce_column_layout_change.hlo, third_party/xla/xla/service/gpu/tests/reduce_f64_column.hlo, third_party/xla/xla/service/gpu/tests/reduce_large_row_to_scalar.hlo, third_party/xla/xla/service/gpu/tests/reduce_row_vectorized.hlo, third_party/xla/xla/service/gpu/tests/reduce_variadic_column.hlo, third_party/xla/xla/service/gpu/tests/transpose_021.hlo, third_party/xla/xla/service/gpu/tests/transpose_021_extra_output.hlo, third_party/xla/xla/service/gpu/tests/transpose_210.hlo, third_party/xla/xla/service/gpu/tests/transpose_210_extra_output.hlo, third_party/xla/xla/service/llvm_ir/kernel_support_library.cc, third_party/xla/xla/service/llvm_ir/kernel_support_library.h",lingzhi98,False
"`libnum` has build errors on MacOS on both Arm and x86 CPUs, hence removed from TensorFlow build.

PiperOrigin-RevId: 627974466",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 06:53:10,"tensorflow/tensorflow.bzl, tensorflow/tensorflow.default.bzl, third_party/xla/xla/tsl/tsl.bzl, third_party/xla/xla/tsl/tsl.default.bzl",tensorflower-gardener,False
"Support per-channel weight-only quantization and enable by default

PiperOrigin-RevId: 627974133",Doyeon Kim,doyeonkim@google.com,2024-04-25 06:51:17,"tensorflow/compiler/mlir/quantization/stablehlo/cc/config.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/config_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/insert_weight_param.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/insert_weight_param.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions_weight_only.mlir",doyeonkim0,False
"Automated Code Change

PiperOrigin-RevId: 627964992",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 06:01:35,"tensorflow/python/framework/BUILD, tensorflow/python/framework/errors_test_helper.cc",tensorflower-gardener,False
"Allow to fuse multi-output fusion producers into consumers.

It was already possible to sibling-fuse two multi-output fusions. This worked
as treating tuples that are fused into a computation in a special way, and uses
the assumption that there is no (direct or indirect) user of the tuple inside
the ""target"" fusion. Now we add logic to detect which of the fusion outputs
is still needed as fusion output of the merged fusion, and fuse the tuple
elements one by one.

PiperOrigin-RevId: 627964452",Adrian Kuegel,akuegel@google.com,2024-04-25 05:58:29,"third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/gpu/multi_output_fusion_test.cc, third_party/xla/xla/service/hlo_instruction_test.cc",akuegel,False
"Add back TPU device check in MlirBridgePass::GetPassState()

This unblocks some graphs that target TPU yet without replication.

PiperOrigin-RevId: 627954635",Jian Cai,jiancai@google.com,2024-04-25 05:01:57,tensorflow/compiler/tf2xla/mlir_bridge_pass.cc,jcai19,False
"Automated Code Change

PiperOrigin-RevId: 627949308",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 04:28:51,tensorflow/compiler/mlir/lite/stablehlo/transforms/transforms.cc,tensorflower-gardener,False
"[xla] memory_placement: drop number of users' restriction on to_host custom calls

There is no good reason to place this restriction.

PiperOrigin-RevId: 627946606",Emilio Cota,ecg@google.com,2024-04-25 04:10:42,"third_party/xla/xla/service/convert_memory_placement_to_internal_annotations.cc, third_party/xla/xla/service/convert_memory_placement_to_internal_annotations_test.cc",cota,False
"Pass in GraphDef + CallableOptions instead of MetaGraphDef to TFRT's ModelContext.

PiperOrigin-RevId: 627942063",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 03:41:59,"tensorflow/core/tfrt/runtime/runtime.h, tensorflow/core/tfrt/saved_model/BUILD, tensorflow/core/tfrt/saved_model/saved_model.cc, tensorflow/core/tfrt/saved_model/saved_model_aot_compile.cc, tensorflow/core/tfrt/saved_model/saved_model_util.cc, tensorflow/core/tfrt/saved_model/saved_model_util.h, tensorflow/core/tfrt/saved_model/tests/saved_model_test.cc, tensorflow/core/tfrt/tfrt_session/tfrt_session.cc",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@69bde04230d4

Updates LLVM usage to match
[69bde04230d4](https://github.com/llvm/llvm-project/commit/69bde04230d4)

PiperOrigin-RevId: 627918052",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-25 01:43:05,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"Add num_bins and calibration_data_dir to CalibrationOptions

The initial_num_bins is no-longer used, thus, being removed.

PiperOrigin-RevId: 627907775",Thai Nguyen,thaink@google.com,2024-04-25 01:02:01,"tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/calibration_parameters.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/component.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/config.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/config_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/post_calibration_component.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/pre_calibration_component.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/insert_calibration_statistics_saver.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/replace_stablehlo_ops_in_main_function_with_xla_call_module_ops.mlir, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/custom_aggregator_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/integration_test/custom_aggregator_op_test.py, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_custom_aggregation_ops.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/tf_quant_ops.td, tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.py, tensorflow/compiler/mlir/quantization/tensorflow/python/save_model.py, tensorflow/compiler/mlir/quantization/tensorflow/tests/convert_custom_aggregation_op_to_quant_stats.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/insert_custom_aggregation_ops.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/issue_ids_of_custom_aggregation_ops.mlir",thaink,False
"Python bindings for tensorflow to stablehlo tooling

PiperOrigin-RevId: 627899113",Sandeep Dasgupta,sdasgup@google.com,2024-04-25 00:22:44,"tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/README.md, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/python/BUILD, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/python/integration_test/tensorflow_to_stablehlo_test.py, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo.cc, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo.pyi",sdasgup3,False
"Refactoring: Separate the model exporting of calibration and debugging models

Currently, we create the whole-model debugging model by modifying the calibration model. This is no longer suitable as it will be affected by coming changes to prepare the calibration model.

PiperOrigin-RevId: 627894939",Thai Nguyen,thaink@google.com,2024-04-25 00:05:13,"tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/component.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/debugger.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/debugger.h, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc",thaink,False
"Stabilize flaky test & tolerances

PiperOrigin-RevId: 627890806",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 23:47:20,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc, third_party/xla/xla/tests/hlo_test_base.cc, third_party/xla/xla/tests/hlo_test_base.h",tensorflower-gardener,False
"Allow multiple epilogues.

Each reduction group requires its own epilogue.

PiperOrigin-RevId: 627888840",Johannes Reifferscheid,jreiffers@google.com,2024-04-24 23:39:53,"third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/concatenate_mlir.h, third_party/xla/xla/service/gpu/fusions/concatenate_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.h, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.h, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.h, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir.h, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.h",jreiffers,False
"Add support for the PartialReduce custom call op in auto-sharding.

PiperOrigin-RevId: 627883051",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 23:16:28,"third_party/xla/workspace2.bzl, third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_strategy.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.h",tensorflower-gardener,False
"Add platform_version to GpuTopology.

PiperOrigin-RevId: 627881472",Changhui Lin,changhuilin@google.com,2024-04-24 23:10:45,"third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/gpu_topology.cc, third_party/xla/xla/pjrt/gpu/gpu_topology.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",changhuilin,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/17c8497777411bc497ebdde64f02b002d7da4889.

PiperOrigin-RevId: 627881294",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 23:10:06,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Support MOF DUS fusions.

PiperOrigin-RevId: 627862360",Johannes Reifferscheid,jreiffers@google.com,2024-04-24 22:01:39,"third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir_test.cc",jreiffers,False
"Update users of `tsl/concurrency` to use `xla/tsl/concurrency`

PiperOrigin-RevId: 627856035",David Dunleavy,ddunleavy@google.com,2024-04-24 21:39:19,"tensorflow/core/tfrt/graph_executor/BUILD, tensorflow/core/tfrt/graph_executor/graph_executor.cc, tensorflow/core/tfrt/graph_executor/graph_executor.h, tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.h, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils.cc, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils_test.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.cc, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test.cc, tensorflow/core/tfrt/ifrt/sharding_utils.cc, tensorflow/core/tfrt/ifrt/sharding_utils.h, tensorflow/core/tfrt/ifrt/sharding_utils_test.cc, tensorflow/core/tfrt/mlrt/interpreter/BUILD, tensorflow/core/tfrt/mlrt/interpreter/async_handle.cc, tensorflow/core/tfrt/mlrt/interpreter/future_test.cc, third_party/xla/xla/mlir/runtime/transforms/BUILD, third_party/xla/xla/mlir/runtime/transforms/custom_call_encoding.cc, third_party/xla/xla/mlir/runtime/utils/BUILD, third_party/xla/xla/mlir/runtime/utils/async_runtime_api.cc, third_party/xla/xla/mlir/runtime/utils/async_runtime_api.h, third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.cc, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.h, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer.cc, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer.h, third_party/xla/xla/pjrt/cpu/tracked_tfrt_cpu_device_buffer_test.cc, third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client_test.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/array.h, third_party/xla/xla/python/ifrt/executable.h, third_party/xla/xla/python/ifrt/host_callback.h, third_party/xla/xla/python/ifrt/ir/tests/BUILD, third_party/xla/xla/python/ifrt/ir/tests/executable_impl_test_base.h, third_party/xla/xla/python/ifrt/ir/tests/executable_impl_test_lib.cc, third_party/xla/xla/python/ifrt/mock.cc, third_party/xla/xla/python/ifrt/mock.h, third_party/xla/xla/python/ifrt/test_util.h, third_party/xla/xla/python/ifrt/tuple.h, third_party/xla/xla/python/ifrt/tuple_impl_test_lib.cc, third_party/xla/xla/python/ifrt/value.h, third_party/xla/xla/python/ifrt_proxy/client/BUILD, third_party/xla/xla/python/ifrt_proxy/client/array.cc, third_party/xla/xla/python/ifrt_proxy/client/array.h, third_party/xla/xla/python/ifrt_proxy/client/array_test.cc, third_party/xla/xla/python/ifrt_proxy/client/client.cc, third_party/xla/xla/python/ifrt_proxy/client/client.h, third_party/xla/xla/python/ifrt_proxy/client/compiler.cc, third_party/xla/xla/python/ifrt_proxy/client/executable.cc, third_party/xla/xla/python/ifrt_proxy/client/executable.h, third_party/xla/xla/python/ifrt_proxy/client/executable_test.cc, third_party/xla/xla/python/ifrt_proxy/integration_tests/BUILD, third_party/xla/xla/python/ifrt_proxy/integration_tests/mock_array_test.cc, third_party/xla/xla/python/ifrt_proxy/server/BUILD, third_party/xla/xla/python/ifrt_proxy/server/host_callback.cc, third_party/xla/xla/python/ifrt_proxy/server/host_callback.h, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.h, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend_test.cc, third_party/xla/xla/python/pjit.cc, third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/pjrt_array.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_array.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_tuple.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_tuple.h, third_party/xla/xla/python/pmap_lib.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/py_client.cc, third_party/xla/xla/python/py_compile_only_client.cc, third_party/xla/xla/python/py_executable.cc, third_party/xla/xla/python/py_executable.h, third_party/xla/xla/python/py_host_callback.cc, third_party/xla/xla/python/py_host_callback.h, third_party/xla/xla/python/py_program.cc, third_party/xla/xla/python/py_values.cc, third_party/xla/xla/python/py_values.h, third_party/xla/xla/runtime/BUILD, third_party/xla/xla/runtime/async_runtime.cc, third_party/xla/xla/runtime/async_runtime.h, third_party/xla/xla/runtime/async_runtime_test.cc, third_party/xla/xla/runtime/custom_call.h, third_party/xla/xla/runtime/default/BUILD, third_party/xla/xla/runtime/default/async_values_cache.h, third_party/xla/xla/runtime/jit_executable.h, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/nccl_api.cc, third_party/xla/xla/service/gpu/runtime/nccl_api.h, third_party/xla/xla/service/gpu/runtime/nccl_api_stub.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.h, third_party/xla/xla/service/gpu/runtime/send_recv_thunk.cc, third_party/xla/xla/service/gpu/runtime/send_recv_thunk.h",ddunl,False
"Support reductions that require atomics.

PiperOrigin-RevId: 627850074",Johannes Reifferscheid,jreiffers@google.com,2024-04-24 21:20:03,"third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc",jreiffers,False
"Remove redundant load of QuantizationDialect

PiperOrigin-RevId: 627849896",Deqiang Chen,deqiangc@google.com,2024-04-24 21:19:31,third_party/xla/xla/translate/hlo_to_mhlo/hlo_module_importer.cc,deqiangc,False
"Update //tensorflow/lite/swift:Tests size to medium.

PiperOrigin-RevId: 627847238",Yishuang Pang,ypang@google.com,2024-04-24 21:11:59,tensorflow/lite/swift/BUILD.apple,yishuangP,False
"Integrate LLVM at llvm/llvm-project@21ef187654c8

Updates LLVM usage to match
[21ef187654c8](https://github.com/llvm/llvm-project/commit/21ef187654c8)

PiperOrigin-RevId: 627846332",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 21:09:12,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"Add RBE toolchains for Clang on Windows.

PiperOrigin-RevId: 627830607",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 20:22:37,".bazelrc, tensorflow/c/c_test.c, tensorflow/opensource_only.files, tensorflow/tools/toolchains/win/20240424/BUILD, tensorflow/tools/toolchains/win/20240424/armeabi_cc_toolchain_config.bzl, tensorflow/tools/toolchains/win/20240424/builtin_include_directory_paths_clangcl, tensorflow/tools/toolchains/win/20240424/builtin_include_directory_paths_msvc, tensorflow/tools/toolchains/win/20240424/toolchain_image_info, tensorflow/tools/toolchains/win/20240424/windows_cc_toolchain_config.bzl, tensorflow/tools/toolchains/win/BUILD, third_party/xla/.bazelrc, third_party/xla/opensource_only.files, third_party/xla/third_party/tsl/.bazelrc, third_party/xla/third_party/tsl/opensource_only.files, third_party/xla/third_party/tsl/tools/toolchains/win/20240424/BUILD, third_party/xla/third_party/tsl/tools/toolchains/win/20240424/armeabi_cc_toolchain_config.bzl, third_party/xla/third_party/tsl/tools/toolchains/win/20240424/builtin_include_directory_paths_clangcl, third_party/xla/third_party/tsl/tools/toolchains/win/20240424/builtin_include_directory_paths_msvc, third_party/xla/third_party/tsl/tools/toolchains/win/20240424/toolchain_image_info, third_party/xla/third_party/tsl/tools/toolchains/win/20240424/windows_cc_toolchain_config.bzl, third_party/xla/third_party/tsl/tools/toolchains/win/BUILD, third_party/xla/tools/toolchains/win/20240424/BUILD, third_party/xla/tools/toolchains/win/20240424/armeabi_cc_toolchain_config.bzl, third_party/xla/tools/toolchains/win/20240424/builtin_include_directory_paths_clangcl, third_party/xla/tools/toolchains/win/20240424/builtin_include_directory_paths_msvc, third_party/xla/tools/toolchains/win/20240424/toolchain_image_info, third_party/xla/tools/toolchains/win/20240424/windows_cc_toolchain_config.bzl, third_party/xla/tools/toolchains/win/BUILD",tensorflower-gardener,False
"Fix float16 quantization for LSTM ops

This CL fixes 2 issues:
1. in Quantize pass, for float16 quant, the pass replaces the original op with an identical one. This causes infinite loop for lstm ops. This CL adds checks to avoid such situations.
2. in SplitMergedOperands pass, const stateful operands are duplicated. But for float16 quantization, stateful operands have const->dequantize pattern. This CL add duplication for such pattern.

PiperOrigin-RevId: 627826212",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 20:07:08,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/tests/quantize-dynamic-range-float16.mlir, tensorflow/compiler/mlir/lite/tests/split-merged-operands.mlir, tensorflow/compiler/mlir/lite/transforms/passes.td, tensorflow/compiler/mlir/lite/transforms/quantize.cc, tensorflow/compiler/mlir/lite/transforms/split_merged_operands.cc, tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.h, tensorflow/lite/python/lite_v2_test.py",tensorflower-gardener,False
"Uses intervals instead of a liveness matrix to construct all memory constraints.

PiperOrigin-RevId: 627825584",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 20:05:07,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc,tensorflower-gardener,False
"Add `IsPredeterminedError` to annotate an error buffer which doesn't have any events on the device.

PiperOrigin-RevId: 627822828",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 19:56:26,"third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/tracked_device_buffer.h",tensorflower-gardener,False
"[tsl:concurrency] Disable ambiguous AndThen callback for AsyncValueRef<absl::Status>

PiperOrigin-RevId: 627814960",Eugene Zhulenev,ezhulenev@google.com,2024-04-24 19:28:29,third_party/xla/xla/tsl/concurrency/async_value_ref.h,ezhulenev,False
"[XLA:GPU][MLIR-based emitters] Add verifier for apply_indexing op.

PiperOrigin-RevId: 627807819",Alexander Belyaev,pifon@google.com,2024-04-24 19:05:51,"third_party/xla/xla/service/gpu/fusions/mlir/ir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.h, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/invalid.mlir",pifon2a,False
"Reverts 21f6e08a3f39591c1915410f4c256c9456e36d80

PiperOrigin-RevId: 627800352",Roman Dzhabarov,rdzhabarov@google.com,2024-04-24 18:44:01,"third_party/xla/xla/backends/profiler/gpu/cupti_error_manager.cc, third_party/xla/xla/backends/profiler/gpu/cupti_error_manager.h, third_party/xla/xla/backends/profiler/gpu/cupti_error_manager_test.cc, third_party/xla/xla/backends/profiler/gpu/cupti_interface.h, third_party/xla/xla/backends/profiler/gpu/cupti_tracer.cc, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper.cc, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper.h, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper_stub.cc, third_party/xla/xla/backends/profiler/gpu/mock_cupti.h",rdzhabarov,False
"Reverts d9417b25e86151823b3be5aa3f57b3b35f303fd5

PiperOrigin-RevId: 627795237",Anastasia Petrushkina,dicentra@google.com,2024-04-24 18:29:34,"third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util_test.cc, third_party/xla/xla/service/sharding_propagation_test.cc",dicentra13,False
"Defines an alternate interface for the Memory Term Reducer that uses primitive intervals instead of liveness matrices.

PiperOrigin-RevId: 627790657",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 18:16:40,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory_test.cc",tensorflower-gardener,False
"Move tsl/concurrency to xla/tsl/concurrency

PiperOrigin-RevId: 627785092",David Dunleavy,ddunleavy@google.com,2024-04-24 18:02:09,"third_party/xla/third_party/tsl/tsl/concurrency/BUILD, third_party/xla/third_party/tsl/tsl/concurrency/async_value.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h, third_party/xla/third_party/tsl/tsl/concurrency/chain.h, third_party/xla/third_party/tsl/tsl/concurrency/concurrent_vector.h, third_party/xla/third_party/tsl/tsl/concurrency/ref_count.h, third_party/xla/xla/tsl/concurrency/BUILD, third_party/xla/xla/tsl/concurrency/async_value.cc, third_party/xla/xla/tsl/concurrency/async_value.h, third_party/xla/xla/tsl/concurrency/async_value_ptr_test.cc, third_party/xla/xla/tsl/concurrency/async_value_ref.cc, third_party/xla/xla/tsl/concurrency/async_value_ref.h, third_party/xla/xla/tsl/concurrency/async_value_ref_test.cc, third_party/xla/xla/tsl/concurrency/async_value_test.cc, third_party/xla/xla/tsl/concurrency/chain.h, third_party/xla/xla/tsl/concurrency/concurrent_vector.h, third_party/xla/xla/tsl/concurrency/concurrent_vector_test.cc, third_party/xla/xla/tsl/concurrency/ref_count.h",ddunl,False
"Fix execution engine after https://github.com/llvm/llvm-project/commit/7da63426ac5d9719038842c30ca2a644620be071.

PiperOrigin-RevId: 627782515",Christian Sigg,csigg@google.com,2024-04-24 17:55:26,third_party/xla/xla/runtime/execution_engine.cc,chsigg,False
"Update GpuTopologyProto to include multi-host information.

PiperOrigin-RevId: 627775502",Changhui Lin,changhuilin@google.com,2024-04-24 17:35:13,third_party/xla/xla/pjrt/gpu/gpu_topology.proto,changhuilin,False
"Remove unused `requires-gpu` tag from `tf_gpu_test_tags`

PiperOrigin-RevId: 627774282",David Dunleavy,ddunleavy@google.com,2024-04-24 17:31:23,third_party/xla/third_party/tsl/tsl/platform/default/build_config_root.bzl,ddunl,False
"PR #11784: [ROCm] Add Dropout support based on MIOpen API

Imported from GitHub PR https://github.com/openxla/xla/pull/11784

Copybara import of the project:

--
fc334e480802d2686907ff720a97697e51177690 by mmakevic <Milica.Makevic@amd.com>:

Add dropout descriptor for rocm

--
52cf3ad49e70b3ecf632d8bf83283a068fbb58d0 by mmakevic <Milica.Makevic@amd.com>:

Use SetRNNDescriptor version 2

Merging this change closes #11784

PiperOrigin-RevId: 627770243",mmakevic-amd,Milica.Makevic@amd.com,2024-04-24 17:19:11,third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc,mmakevic-amd,False
"Remove unnecessary epilogue restrictions and corner cases.

- Allow injected values to be roots of epilogues
- Allow n-ary values to be injected
- Always generate an epilogue function if it's requested.
- Simplify EmitEpilogue interface to hide indexes and calling convention
  details from the caller.

This simplifies the logic in the reduction emitter somewhat.

PiperOrigin-RevId: 627770230",Johannes Reifferscheid,jreiffers@google.com,2024-04-24 17:19:08,"third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.h, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.h, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc",jreiffers,False
"Allow XlaHostComputeOp to the allowed list in mark_ops_for_outside_compilation.cc

PiperOrigin-RevId: 627746297",Deqiang Chen,deqiangc@google.com,2024-04-24 16:00:27,"tensorflow/compiler/mlir/tensorflow/tests/mark_ops_for_outside_compilation.mlir, tensorflow/compiler/mlir/tf2xla/internal/passes/mark_ops_for_outside_compilation.cc",deqiangc,False
"Allow for short-circuiting optimization in ShapeUtil::EqualStructure.

Note that operator& doesn't do short-circuiting, unlike operator&&.

PiperOrigin-RevId: 627745915",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 15:59:22,third_party/xla/xla/shape_util.cc,tensorflower-gardener,False
"Don't try to patch pywrap_calibrator.so, as it was removed.

Follow-up to
https://github.com/tensorflow/tensorflow/commit/c8ee77626915c7a5ed3be88bce0f12b1a9ef2c6f

PiperOrigin-RevId: 627732799",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 15:09:26,tensorflow/tools/pip_package/build_pip_package.py,tensorflower-gardener,False
"BUILD visibility change only

PiperOrigin-RevId: 627726838",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 14:47:29,third_party/xla/xla/BUILD,tensorflower-gardener,False
"FC bias is per channel quantized when per channel quantization is used

PiperOrigin-RevId: 627725365",Alan Kelly,alankelly@google.com,2024-04-24 14:41:15,tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc,alankelly,False
"#shlo_ref Fix OSS.

- Use the correct absl::BitGen.
- Fix the definition of `std::common_type` for `shlo_ref::F16`
- Fix building `shlo_ref::F16` from values that can be converted to `float`.

PiperOrigin-RevId: 627723091",Quentin Khan,qkhan@google.com,2024-04-24 14:32:10,"tensorflow/lite/experimental/shlo/f16.h, tensorflow/lite/experimental/shlo/ops/compare_test.cc",qukhan,False
"Integrate LLVM at llvm/llvm-project@b3ca9c30dedf

Updates LLVM usage to match
[b3ca9c30dedf](https://github.com/llvm/llvm-project/commit/b3ca9c30dedf)

PiperOrigin-RevId: 627709586",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 13:31:29,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Small code simplifications in hlo_instructions.cc (NFC)

PiperOrigin-RevId: 627700209",Adrian Kuegel,akuegel@google.com,2024-04-24 12:49:13,third_party/xla/xla/hlo/ir/hlo_instructions.cc,akuegel,False
"Tool to convert TF SavedModel to StableHLO

Here is the signature of the provide API:

```c++
// Converts a TensorFlow model (either from a SavedModel or an MLIR module) to a
// StableHLO MLIR module.
//
// Args:
//  input_path: The path to the input TensorFlow SavedModel or MLIR module.
//  context: The MLIR context to use for parsing or creating the MLIR module.
//  exported_model_signatures: A comma-separated list of exported model
//    signatures (functions) to convert.
//  tag_names: A comma-separated list of tag names used for loading SavedModel.
//  input_arg_shapes_str: A string representation of input argument shapes.
//    Shapes for different tensors are separated by ':', and dimension sizes for
//    the same tensor are separated by ','. For example,
//    'input-arg-shapes=1,2::1,?' expresses input arguments with shapes [1,2],
//    [] and [1,?].
//  is_input_mlir_module: If true, `input_path` is treated as an MLIR
//    module instead of a SavedModel.
//
// Returns:
//   An absl::StatusOr containing the converted StableHLO MLIR module on
//   success, or an absl::Status with an error message on failure.
absl::StatusOr<OwningOpRef<ModuleOp>> TfToStablehlo(
    absl::string_view input_path, MLIRContext* context,
    absl::string_view exported_model_signatures, absl::string_view tag_names,
    absl::string_view input_arg_shapes_str, bool is_input_mlir_module = false);
```
PiperOrigin-RevId: 627698652",Sandeep Dasgupta,sdasgup@google.com,2024-04-24 12:41:48,"tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/transforms/rename_entrypoint_to_main.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/saved_model_import.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/saved_model_import.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/static_range_ptq.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/weight_only_ptq.cc, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/quantize_preprocess.cc, tensorflow/compiler/mlir/quantization/tensorflow/quantize_preprocess.h, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/BUILD, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/README.md, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/tests/test_tf_to_stablehlo.mlir, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/tf_to_stablehlo.cc, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/tf_to_stablehlo.h, tensorflow/compiler/mlir/quantization/tensorflow_to_stablehlo/tf_to_stablehlo_translate.cc, tensorflow/compiler/mlir/tensorflow/tests/shape_inference_with_shape_specialization.mlir, tensorflow/compiler/mlir/tensorflow/transforms/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/passes.h, tensorflow/compiler/mlir/tensorflow/transforms/shape_inference.cc, tensorflow/compiler/mlir/tensorflow/transforms/shape_inference.h, tensorflow/compiler/mlir/tensorflow/transforms/shape_inference_pass.cc, tensorflow/compiler/mlir/tensorflow/transforms/tf_passes.td",sdasgup3,False
"Automated Code Change

PiperOrigin-RevId: 627677804",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 11:01:22,tensorflow/compiler/mlir/lite/stablehlo/odml_to_stablehlo.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627674518",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 10:44:18,"tensorflow/core/util/ragged_to_dense_util.cc, tensorflow/core/util/reffed_status_callback_test.cc, tensorflow/core/util/saved_tensor_slice_util.cc",tensorflower-gardener,False
"PR #11306: [XLA:GPU] Fix not unique name issue in sanitize constant pass

Imported from GitHub PR https://github.com/openxla/xla/pull/11306

Fix `Instruction name is not unique` error reported by JAX UT [`ShardMapTest.test_matmul_reduce_scatter`](https://github.com/google/jax/blob/jaxlib-v0.4.24/tests/shard_map_test.py#L149-L162) in XLA:GPU.

### Background
Error message:
```
!ContainsKey(instruction_names, instruction->name()) Instruction name is not unique: param_1
```
This error is reported after `PrepareHloModuleForIrEmitting()`. The non-unique name `param_1` is generated from 2 different passes `GpuSanitizeConstantNames` and `FusionWrapper`. The related HLO changes are as follows:

1. Original HLO, there's no `param_1` and only got `param_0` in `async_computation`:
```ll
%main.19_spmd (param: s32[4,4], param.1: s32[4,8]) -> s32[2,8] {
  %param = s32[4,4]{1,0} parameter(0), sharding={devices=[2,2]<=[4]}, metadata={op_name=""jit(fwd)/jit(main)/shard_map[mesh=Mesh(\'x\': 2, \'y\': 2) in_names=({0: (\'x\',), 1: (\'y\',)}, {0: (\'x\',)}) out_names=({0: (\'x\', \'y\')},) check_rep=True rewrite=True auto=frozenset()]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=161}
  %param.1 = s32[4,8]{1,0} parameter(1), sharding={devices=[2,1,2]<=[4] last_tile_dim_replicate}, metadata={op_name=""jit(fwd)/jit(main)/shard_map[mesh=Mesh(\'x\': 2, \'y\': 2) in_names=({0: (\'x\',), 1: (\'y\',)}, {0: (\'x\',)}) out_names=({0: (\'x\', \'y\')},) check_rep=True rewrite=True auto=frozenset()]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=161}
  %dot.1 = s32[4,8]{1,0} dot(s32[4,4]{1,0} %param, s32[4,8]{1,0} %param.1), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=int32]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=158}
  %reduce-scatter-start = ((s32[4,8]{1,0}), s32[2,8]{1,0}) reduce-scatter-start(s32[4,8]{1,0} %dot.1), channel_id=1, replica_groups={{0,1},{2,3}}, use_global_device_ids=true, dimensions={0}, to_apply=%region_0.7, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}, backend_config={""operation_queue_id"":""0"",""wait_on_operation_queues"":[],""collective_backend_config"":{""is_sync"":false,""no_parallel_custom_call"":false}}
  ROOT %reduce-scatter-done = s32[2,8]{1,0} reduce-scatter-done(((s32[4,8]{1,0}), s32[2,8]{1,0}) %reduce-scatter-start), metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}
}
%async_computation (param_0: s32[4,8]) -> s32[2,8] {
  %param_0 = s32[4,8]{1,0} parameter(0)
  ROOT %reduce-scatter.2 = s32[2,8]{1,0} reduce-scatter(s32[4,8]{1,0} %param_0), channel_id=1, replica_groups={{0,1},{2,3}}, use_global_device_ids=true, dimensions={0}, to_apply=%region_0.7, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}
}
```

2. `param_0` was changed to `param_1` after `GpuSanitizeConstantNames` pass:
```ll
%main.19_spmd (param: s32[4,4], param.1: s32[4,8]) -> s32[2,8] {
  %param = s32[4,4]{1,0} parameter(0), sharding={devices=[2,2]<=[4]}, metadata={op_name=""jit(fwd)/jit(main)/shard_map[mesh=Mesh(\'x\': 2, \'y\': 2) in_names=({0: (\'x\',), 1: (\'y\',)}, {0: (\'x\',)}) out_names=({0: (\'x\', \'y\')},) check_rep=True rewrite=True auto=frozenset()]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=161}
  %param.1 = s32[4,8]{1,0} parameter(1), sharding={devices=[2,1,2]<=[4] last_tile_dim_replicate}, metadata={op_name=""jit(fwd)/jit(main)/shard_map[mesh=Mesh(\'x\': 2, \'y\': 2) in_names=({0: (\'x\',), 1: (\'y\',)}, {0: (\'x\',)}) out_names=({0: (\'x\', \'y\')},) check_rep=True rewrite=True auto=frozenset()]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=161}
  %dot.1 = s32[4,8]{1,0} dot(s32[4,4]{1,0} %param, s32[4,8]{1,0} %param.1), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=int32]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=158}
  %reduce-scatter-start = ((s32[4,8]{1,0}), s32[2,8]{1,0}) reduce-scatter-start(s32[4,8]{1,0} %dot.1), channel_id=1, replica_groups={{0,1},{2,3}}, use_global_device_ids=true, dimensions={0}, to_apply=%region_0.7, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}, backend_config={""operation_queue_id"":""0"",""wait_on_operation_queues"":[],""collective_backend_config"":{""is_sync"":false,""no_parallel_custom_call"":false}}
  ROOT %reduce-scatter-done = s32[2,8]{1,0} reduce-scatter-done(((s32[4,8]{1,0}), s32[2,8]{1,0}) %reduce-scatter-start), metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}
}
%async_computation (param_1: s32[4,8]) -> s32[2,8] {
  %param_1 = s32[4,8]{1,0} parameter(0)
  ROOT %reduce-scatter.2 = s32[2,8]{1,0} reduce-scatter(s32[4,8]{1,0} %param_1), channel_id=1, replica_groups={{0,1},{2,3}}, use_global_device_ids=true, dimensions={0}, to_apply=%region_0.7, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}
}
```

3. Another `param_1` was generated after `FusionWrapper` pass:
```ll
%async_computation (param_1: s32[4,8]) -> s32[2,8] {
  %param_1 = s32[4,8]{1,0} parameter(0)
  ROOT %reduce-scatter.2 = s32[2,8]{1,0} reduce-scatter(s32[4,8]{1,0} %param_1), channel_id=1, replica_groups={{0,2},{1,3},{4,6},{5,7}}, use_global_device_ids=true, dimensions={0}, to_apply=%region_0.7, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}
}
%wrapped_dot_computation (param_0.1: s32[4,4], param_1: s32[4,8]) -> s32[4,8] {
  %param_0.1 = s32[4,4]{1,0} parameter(0)
  %param_1 = s32[4,8]{1,0} parameter(1)
  ROOT %dot.2 = s32[4,8]{1,0} dot(s32[4,4]{1,0} %param_0.1, s32[4,8]{1,0} %param_1), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=int32]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=158}
}

%main.19_spmd (param: s32[4,4], param.1: s32[4,8]) -> s32[2,8] {
  %param = s32[4,4]{1,0} parameter(0), sharding={devices=[2,2]<=[4]}, metadata={op_name=""jit(fwd)/jit(main)/shard_map[mesh=Mesh(\'x\': 2, \'y\': 2) in_names=({0: (\'x\',), 1: (\'y\',)}, {0: (\'x\',)}) out_names=({0: (\'x\', \'y\')},) check_rep=True rewrite=True auto=frozenset()]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=161}
  %param.1 = s32[4,8]{1,0} parameter(1), sharding={devices=[2,1,2]<=[4] last_tile_dim_replicate}, metadata={op_name=""jit(fwd)/jit(main)/shard_map[mesh=Mesh(\'x\': 2, \'y\': 2) in_names=({0: (\'x\',), 1: (\'y\',)}, {0: (\'x\',)}) out_names=({0: (\'x\', \'y\')},) check_rep=True rewrite=True auto=frozenset()]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=161}
  %dot.1 = s32[4,8]{1,0} dot(s32[4,4]{1,0} %param, s32[4,8]{1,0} %param.1), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=int32]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=158}
  %reduce-scatter-start = ((s32[4,8]{1,0}), s32[2,8]{1,0}) reduce-scatter-start(s32[4,8]{1,0} %dot.1), channel_id=1, replica_groups={{0,1},{2,3}}, use_global_device_ids=true, dimensions={0}, to_apply=%region_0.7, metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}, backend_config={""operation_queue_id"":""0"",""wait_on_operation_queues"":[],""collective_backend_config"":{""is_sync"":false,""no_parallel_custom_call"":false}}
  ROOT %reduce-scatter-done = s32[2,8]{1,0} reduce-scatter-done(((s32[4,8]{1,0}), s32[2,8]{1,0}) %reduce-scatter-start), metadata={op_name=""jit(fwd)/jit(main)/jit(shmap_body)/reduce_scatter[axis_name=y scatter_dimension=0 axis_index_groups=None axis_size=2 tiled=True]"" source_file=""/home/sdp/tenglu/intel-jax/tests/shard_map_test.py"" source_line=159}
}
```

### Root cause
`GpuSanitizeConstantNames` runs before `FusionWrapper` and may change HLO instruction name by a [local name uniquer](https://github.com/openxla/xla/blob/main/xla/service/gpu/gpu_sanitize_constant_names.cc#L37). There're 2 issues here:

* The original HLO instruction name may be changed unexpectedly even though [the pass does not intend to do so](https://github.com/openxla/xla/blob/main/xla/service/gpu/gpu_sanitize_constant_names.cc#L50-L51).
* The global name uniquer of HLO module isn't aware of this change and may wrongly assign the same name to another HLO instruction in other passes, e.g. `FusionWrapper`.

`param_0` is changed to `param_1` by `GpuSanitizeConstantNames` unexpectedly.

### Solution
Only record HLO instruction names in the local name uniquer of `GpuSanitizeConstantNames` and do not change the original names. It exactly follows the pass design.
Copybara import of the project:

--
c39bc256957db681cfe1706fb716986da89edf3a by Lu Teng <teng.lu@intel.com>:

Fix not unique name issue in sanitize constant pass.

Merging this change closes #11306

PiperOrigin-RevId: 627661920",Lu Teng,teng.lu@intel.com,2024-04-24 09:41:13,third_party/xla/xla/service/gpu/gpu_sanitize_constant_names.cc,Zantares,False
"Update GraphDef version to 1842.

PiperOrigin-RevId: 627652913",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 09:02:39,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-24

PiperOrigin-RevId: 627652860",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 09:02:29,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627644782",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 08:24:26,"tensorflow/core/ops/math_grad.cc, tensorflow/core/ops/math_grad_test.cc",tensorflower-gardener,False
"PR #11313: Use CHECK-DAG to validate low and high padding mlir

Imported from GitHub PR https://github.com/openxla/xla/pull/11313

Copybara import of the project:

--
98ee3b456f62a9404bfaf976ab9a2d25415293cc by Harsha HS <harsha.havanurshamsundara@amd.com>:

Distinguish order of padding operation between CUDA and ROCm

--
6f318827a4f2f31938349e24d292966fc6b95b97 by Harsha HS <harsha.havanurshamsundara@amd.com>:

Use CHECK-DAG to check for low and high padding mlir

--
8a3da357c20a865dc91f090d6e600ade492c3e7f by Harsha HS <harsha.havanurshamsundara@amd.com>:

Add -no_gpu tag to the test, so that it is picked by CI

--
f13a4003aedb5a005c3b0668c474da30b46fe5e2 by Harsha HS <harsha.havanurshamsundara@amd.com>:

Revert ""Add -no_gpu tag to the test, so that it is picked by CI""

This reverts commit 8a3da357c20a865dc91f090d6e600ade492c3e7f.

--
9fca062f688dca198e232b1cfcd04eba3a8d99d2 by Harsha HS <harsha.havanurshamsundara@amd.com>:

Remove tags as it is covered by CPU CI

Merging this change closes #11313

PiperOrigin-RevId: 627638965",Harsha H S,hsharsha@users.noreply.github.com,2024-04-24 07:59:06,third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc,hsharsha,False
"Automated Code Change

PiperOrigin-RevId: 627637071",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 07:49:00,tensorflow/compiler/mlir/lite/tf_to_tfl_flatbuffer.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627636880",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 07:47:50,"tensorflow/python/client/tf_session_helper.cc, tensorflow/python/client/tf_session_helper.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627627484",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 07:02:20,tensorflow/compiler/mlir/tfrt/transforms/mlrt/tf_to_mlrt.cc,tensorflower-gardener,False
"PR #11761: [GPU] Support nccl comm splitting in multiprocess mode

Imported from GitHub PR https://github.com/openxla/xla/pull/11761

Currently `--xla_gpu_enable_nccl_comm_splitting` is a no-op unless using single process mode. This PR allows it to work in multiprocess mode by removing the IsLocal check and fixing the key in the rank -> comm map which was causing the following error:
```
7:  Communicator for rank 1 not found in a NCCL clique devices=[3,7]; stream=0
5: E0403 15:37:24.104311 3871038 pjrt_stream_executor_client.cc:2809] Execution of replica 0 failed: INTERNAL: Communicator for rank 1 not found in a NCCL clique devices=[1,5]; stream=0
6: E0403 15:37:24.104477 3870182 pjrt_stream_executor_client.cc:2809] Execution of replica 0 failed: INTERNAL: Communicator for rank 1 not found in a NCCL clique devices=[2,6]; stream=0
4: E0403 15:37:24.105872 3871021 pjrt_stream_executor_client.cc:2809] Execution of replica 0 failed: INTERNAL: Communicator for rank 1 not found in a NCCL clique devices=[0,4]; stream=0
```
Copybara import of the project:

--
c77ed08f77e252a5068a23d02555ffa765913d42 by Trevor Morris <tmorris@nvidia.com>:

Enable nccl comm split for multiprocess mode

Merging this change closes #11761

PiperOrigin-RevId: 627626547",Trevor Morris,tmorris@nvidia.com,2024-04-24 06:58:03,third_party/xla/xla/service/gpu/runtime/nccl_clique.cc,trevor-m,False
"Automated Code Change

PiperOrigin-RevId: 627625947",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 06:55:04,"tensorflow/lite/testing/tf_driver.cc, tensorflow/lite/testing/tf_driver_test.cc",tensorflower-gardener,False
"multihost_hlo_runner: support host parameter buffers

PiperOrigin-RevId: 627625806",Emilio Cota,ecg@google.com,2024-04-24 06:54:20,"third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc, third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.h",cota,False
"PR #11603: [ROCm] Configure pjrt gpu plugin for rocm

Imported from GitHub PR https://github.com/openxla/xla/pull/11603

Configure PJRT GPU plugin so it can be built for ROCm as well.
Copybara import of the project:

--
a1c8bcb4be41dc56899118d44bf604a2723a3c56 by mmakevic <Milica.Makevic@amd.com>:

Configure pjrt gpu plugin for rocm

--
9ca24357f52c53febb474c798c67d0b8dda586ee by mmakevic <Milica.Makevic@amd.com>:

Change platform name defining

Merging this change closes #11603

PiperOrigin-RevId: 627625764",mmakevic-amd,Milica.Makevic@amd.com,2024-04-24 06:54:10,"third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_internal.cc",mmakevic-amd,False
"Automated Code Change

PiperOrigin-RevId: 627625513",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 06:52:52,"tensorflow/python/framework/offset_counter_helper.cc, tensorflow/python/framework/offset_counter_helper.h, tensorflow/python/framework/python_api_info.cc, tensorflow/python/framework/python_op_gen_main.cc, tensorflow/python/framework/test_file_system.cc, tensorflow/python/framework/test_ops.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627608517",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 05:22:17,tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627608157",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 05:19:49,"tensorflow/lite/python/analyzer_wrapper/BUILD, tensorflow/lite/python/analyzer_wrapper/model_analyzer.cc",tensorflower-gardener,False
"Merge pull request #64520 from Intel-tensorflow:amin/xla-disable-remapper

PiperOrigin-RevId: 627598905",TensorFlower Gardener,gardener@tensorflow.org,2024-04-24 04:52:53,"tensorflow/core/grappler/optimizers/remapper.cc, tensorflow/core/grappler/optimizers/remapper_test.cc",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 627597893",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 04:17:56,"tensorflow/core/ops/compat/ops_history_v2/XlaSparseDenseMatmulGradWithAdagradAndStaticBufferSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/XlaSparseDenseMatmulGradWithAdagradMomentumAndStaticBufferSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/XlaSparseDenseMatmulGradWithAdamAndStaticBufferSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/XlaSparseDenseMatmulGradWithFtrlAndStaticBufferSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/XlaSparseDenseMatmulGradWithSgdAndStaticBufferSize.pbtxt, tensorflow/core/ops/compat/ops_history_v2/XlaSparseDenseMatmulWithStaticBufferSize.pbtxt, tensorflow/core/ops/ops.pbtxt",tensorflower-gardener,False
"[XLA] Avoid crash in LatencyHidingScheduler when it fails to schedule a node and improve error message.

PiperOrigin-RevId: 627596827",Ce Zheng,zce@google.com,2024-04-24 04:11:26,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/latency_hiding_scheduler.cc, third_party/xla/xla/service/latency_hiding_scheduler.h",cezheng,False
"Add new sets of XlaSparseDenseMatmulWithStaticBufferSizeOps that takes a static buffer size as an attribute.

PiperOrigin-RevId: 627594700",Ziyin Huang,ziyinh@google.com,2024-04-24 03:59:36,"tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td, tensorflow/compiler/mlir/tf2xla/transforms/BUILD, tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config.cc, tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config_test.cc, tensorflow/core/api_def/base_api/api_def_XlaSparseDenseMatmulGradWithAdagradAndStaticBufferSize.pbtxt, tensorflow/core/api_def/base_api/api_def_XlaSparseDenseMatmulGradWithAdagradMomentumAndStaticBufferSize.pbtxt, tensorflow/core/api_def/base_api/api_def_XlaSparseDenseMatmulGradWithAdamAndStaticBufferSize.pbtxt, tensorflow/core/api_def/base_api/api_def_XlaSparseDenseMatmulGradWithFtrlAndStaticBufferSize.pbtxt, tensorflow/core/api_def/base_api/api_def_XlaSparseDenseMatmulGradWithSgdAndStaticBufferSize.pbtxt, tensorflow/core/api_def/base_api/api_def_XlaSparseDenseMatmulWithStaticBufferSize.pbtxt, tensorflow/core/api_def/python_api/api_def_XlaSparseDenseMatmulGradWithAdagradAndStaticBufferSize.pbtxt, tensorflow/core/api_def/python_api/api_def_XlaSparseDenseMatmulGradWithAdagradMomentumAndStaticBufferSize.pbtxt, tensorflow/core/api_def/python_api/api_def_XlaSparseDenseMatmulGradWithAdamAndStaticBufferSize.pbtxt, tensorflow/core/api_def/python_api/api_def_XlaSparseDenseMatmulGradWithFtrlAndStaticBufferSize.pbtxt, tensorflow/core/api_def/python_api/api_def_XlaSparseDenseMatmulGradWithSgdAndStaticBufferSize.pbtxt, tensorflow/core/api_def/python_api/api_def_XlaSparseDenseMatmulWithStaticBufferSize.pbtxt, tensorflow/core/tpu/kernels/sparse_core_xla_ops.cc, tensorflow/core/tpu/ops/BUILD, tensorflow/core/tpu/ops/sparse_core_ops.cc, tensorflow/python/tpu/ops/BUILD, tensorflow/tools/api/golden/v1/tensorflow.raw_ops.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.raw_ops.pbtxt",pineapplejuice233,False
"Support shape transpose in `hlo_sharding_util::ReshapeSharding`.

Before this cl, `hlo_sharding_util::ReshapeSharding` can handle the cases where source and target shapes can be transformed to each other by merging and splitting dimension sizes. It returns `std::nullopt` if transpose is needed between source and target shapes.

This cl extracts the `gcd(source_sharding_tile_size, target_shape)` when `source_shape % source_sharding_tile_size == 0` in the major dimensions. We also skip the source_dim if `source_sharding_tile_size` is 1. An example is shown below.
```
input_shape: [6, 2, 5]
output_shape: [4, 3, 5]
input_sharding: {devices=[2, 1, 5]<=[10]}
output_sharding: {devices=[2, 1, 5]<=[10]}
```
PiperOrigin-RevId: 627592738",Zixuan Jiang,zixuanjiang@google.com,2024-04-24 03:46:42,"third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util_test.cc, third_party/xla/xla/service/sharding_propagation_test.cc",ZixuanJiang,False
"adding support for Composite ops in TFLite flatbuffer schema

PiperOrigin-RevId: 627588497",Steven Toribio,toribiosteven@google.com,2024-04-24 03:21:46,"tensorflow/compiler/mlir/lite/flatbuffer_export.cc, tensorflow/compiler/mlir/lite/flatbuffer_import.cc, tensorflow/compiler/mlir/lite/flatbuffer_operator.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_to_vhlo.cc, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/BUILD, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/composite_op_round_trip.mlir, tensorflow/lite/builtin_ops.h, tensorflow/lite/core/api/flatbuffer_conversions.cc, tensorflow/lite/core/kernels/builtin_op_kernels.h, tensorflow/lite/core/macros.h, tensorflow/lite/kernels/builtin_ops_list.inc, tensorflow/lite/schema/schema.fbs, tensorflow/lite/schema/schema_generated.h",turbotoribio,False
"Remove the CalibrationSingleton

The Singleton is a legacy design that only works on CPU.

PiperOrigin-RevId: 627586362",Thai Nguyen,thaink@google.com,2024-04-24 03:08:41,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/component.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/component.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/statistics.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/statistics.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/io.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/io.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/io_test.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibrator_singleton.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibrator_singleton.h, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibrator_singleton_test.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/custom_aggregator_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/integration_test/custom_aggregator_op_test.py, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/pywrap_calibration.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.py, tensorflow/tools/pip_package/BUILD",thaink,False
"Integrate LLVM at llvm/llvm-project@688c10d23630

Updates LLVM usage to match
[688c10d23630](https://github.com/llvm/llvm-project/commit/688c10d23630)

PiperOrigin-RevId: 627579261",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 02:36:09,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 627575911",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 02:17:29,"tensorflow/core/ops/compat/ops_history_v2/ConvertToSparseCoreCsrWrappedCooTensor.pbtxt, tensorflow/core/ops/compat/ops_history_v2/GetStatsFromListOfSparseCoreCooTensors.pbtxt, tensorflow/core/ops/ops.pbtxt",tensorflower-gardener,False
"Add a new op to get the max_ids and max_unique_ids from a list of SparseCoreCooTensors.

PiperOrigin-RevId: 627575205",Ziyin Huang,ziyinh@google.com,2024-04-24 02:12:45,"tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td, tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config_test.cc, tensorflow/core/api_def/base_api/api_def_GetStatsFromListOfSparseCoreCooTensors.pbtxt, tensorflow/core/api_def/python_api/api_def_GetStatsFromListOfSparseCoreCooTensors.pbtxt, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.cc, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.h, tensorflow/core/tpu/ops/sparse_core_preprocess_ops.cc, tensorflow/python/tpu/ops/BUILD, tensorflow/python/tpu/tpu_embedding_v3_cpu_ops_test.py, tensorflow/tools/api/golden/v1/tensorflow.raw_ops.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.raw_ops.pbtxt",pineapplejuice233,False
"[XLA:GPU] Refactor HloFusionAdaptor to a flat structure.

There is a need for HloInstructionAdaptor to know it's parent HloFusionAdaptor to be able to distinguish fusion instruction for operands and users. Current nested structure of HloFusionAdaptor prevents us from having a convenient single parent pointer.

This CL add `parent` field to HloInstructionAdaptor, but doesn't set or use it consistently yet.

PiperOrigin-RevId: 627556942",Oleg Shyshkov,shyshkov@google.com,2024-04-24 00:41:07,"third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/hlo_traversal.cc, third_party/xla/xla/service/gpu/hlo_traversal.h, third_party/xla/xla/service/gpu/hlo_traversal_test.cc, third_party/xla/xla/service/gpu/ir_emission_utils_test.cc, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc",olegshyshkov,False
"Add a new op to convert the sorted coo tensor into sparse core CSR wrapped COO format.

PiperOrigin-RevId: 627555672",Ziyin Huang,ziyinh@google.com,2024-04-24 00:35:18,"tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td, tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config_test.cc, tensorflow/core/api_def/base_api/api_def_ConvertToSparseCoreCsrWrappedCooTensor.pbtxt, tensorflow/core/api_def/python_api/api_def_ConvertToSparseCoreCsrWrappedCooTensor.pbtxt, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.cc, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.h, tensorflow/core/tpu/ops/sparse_core_preprocess_ops.cc, tensorflow/python/tpu/BUILD, tensorflow/python/tpu/ops/BUILD, tensorflow/python/tpu/tpu_embedding_v3_cpu_ops_test.py, tensorflow/tools/api/golden/v1/tensorflow.raw_ops.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.raw_ops.pbtxt",pineapplejuice233,False
"Support reduction side outputs.

PiperOrigin-RevId: 627549534",Johannes Reifferscheid,jreiffers@google.com,2024-04-24 00:10:50,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.cc, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner.h, third_party/xla/xla/service/gpu/fusions/mlir/computation_partitioner_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.h, third_party/xla/xla/service/gpu/fusions/reduction_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc",jreiffers,False
"Integrate LLVM at llvm/llvm-project@f426be195a08

Updates LLVM usage to match
[f426be195a08](https://github.com/llvm/llvm-project/commit/f426be195a08)

PiperOrigin-RevId: 627549113",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-24 00:09:07,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"PR #11721: [XLA:CPU] Add  MpiCollectives to the the .pyi stubs

Imported from GitHub PR https://github.com/openxla/xla/pull/11721

we forgot this in https://github.com/openxla/xla/pull/7849.
Copybara import of the project:

--
3924cc0fbbb63e9503f38a59aede3b8e817b17fa by Clemens Giuliani <clemens@inailuig.it>:

[XLA:CPU] add missing type annotations for the mpi collectives

Merging this change closes #11721

PiperOrigin-RevId: 627544891",Clemens Giuliani,clemens@inailuig.it,2024-04-23 23:51:55,third_party/xla/xla/python/xla_extension/__init__.pyi,inailuig,False
"Reverts 2ba594da18e8d016494ec91a9d2e973991a4ce72

PiperOrigin-RevId: 627538841",RJ Ascani,rjascani@google.com,2024-04-23 23:27:28,"tensorflow/lite/acceleration/configuration/configuration_generated.h, tensorflow/lite/delegates/gpu/cl/compiled_program_cache_generated.h, tensorflow/lite/delegates/gpu/cl/serialization_generated.h, tensorflow/lite/delegates/gpu/common/gpu_model_generated.h, tensorflow/lite/delegates/gpu/common/task/serialization_base_generated.h, tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h, tensorflow/lite/schema/conversion_metadata_generated.h, tensorflow/lite/schema/schema_generated.h, tensorflow/lite/tools/cmake/modules/flatbuffers.cmake, tensorflow/tools/ci_build/release/requirements_common.txt, tensorflow/tools/pip_package/setup.py, tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt, third_party/flatbuffers/workspace.bzl",rascani,False
"#tf-data Support save/load for cache dataset random access iterators.

Moved `IteratorRandomAccessCache` from the iterator to the dataset so
the cache is preserved after iterator restoration.

PiperOrigin-RevId: 627531286",Yang Chen,yangchen@google.com,2024-04-23 22:59:06,"tensorflow/core/kernels/data/BUILD, tensorflow/core/kernels/data/cache_dataset_ops.cc, tensorflow/python/data/kernel_tests/cache_test.py",yangustc07,False
"Update the comment and error message.
The selector doesn't have to be round-robin to reach the comment or error.

PiperOrigin-RevId: 627530817",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 22:57:22,tensorflow/core/tpu/kernels/tpu_functional_ops.cc,tensorflower-gardener,False
"[pjrt] Make PjRtFuture<T> for move-only T also move-only type

More CLs will follow to use rvalue qualified methods for OnReady and Await.

PiperOrigin-RevId: 627527040",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 22:41:31,"third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/pjrt/pjrt_future_test.cc",ezhulenev,False
"XProf GPU: Enable CUPTI per-thread activity buffer for better overhead.

PiperOrigin-RevId: 627525954",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 22:37:04,"third_party/xla/xla/backends/profiler/gpu/cupti_error_manager.cc, third_party/xla/xla/backends/profiler/gpu/cupti_error_manager.h, third_party/xla/xla/backends/profiler/gpu/cupti_error_manager_test.cc, third_party/xla/xla/backends/profiler/gpu/cupti_interface.h, third_party/xla/xla/backends/profiler/gpu/cupti_tracer.cc, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper.cc, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper.h, third_party/xla/xla/backends/profiler/gpu/cupti_wrapper_stub.cc, third_party/xla/xla/backends/profiler/gpu/mock_cupti.h",tensorflower-gardener,False
"[pjrt] NFC: Remove a workaround for unsafe PjRtFuture<>::Await() call as it's no longer needed

PiperOrigin-RevId: 627524280",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 22:30:58,"third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.h",ezhulenev,False
"[XLA:GPU][MLIR-based emitters] Add xla_gpu.apply_indexing op.

This first CL just adds printer/parser.

PiperOrigin-RevId: 627523697",Alexander Belyaev,pifon@google.com,2024-04-23 22:29:12,"third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.cc, third_party/xla/xla/service/gpu/fusions/mlir/ir/xla_gpu_ops.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/ops.mlir",pifon2a,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 627520682",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 22:17:48,"tensorflow/core/ops/compat/ops_history_v2/ConvertToListOfSparseCoreCooTensors.pbtxt, tensorflow/core/ops/compat/ops_history_v2/SortListOfSparseCoreCooTensors.pbtxt, tensorflow/core/ops/ops.pbtxt",tensorflower-gardener,False
"Add a SortListOfSparseCoreCooTensors op.

PiperOrigin-RevId: 627519922",Ziyin Huang,ziyinh@google.com,2024-04-23 22:14:55,"tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td, tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config_test.cc, tensorflow/core/api_def/base_api/api_def_SortListOfSparseCoreCooTensors.pbtxt, tensorflow/core/api_def/python_api/api_def_SortListOfSparseCoreCooTensors.pbtxt, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.cc, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.h, tensorflow/core/tpu/ops/BUILD, tensorflow/core/tpu/ops/sparse_core_preprocess_ops.cc, tensorflow/python/tpu/ops/BUILD, tensorflow/python/tpu/tpu_embedding_v3_cpu_ops_test.py, tensorflow/tools/api/golden/v1/tensorflow.raw_ops.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.raw_ops.pbtxt",pineapplejuice233,False
"[tsl:concurrency] Add AsyncValueRef::FlatMap to be able to use functors returning async values

PiperOrigin-RevId: 627517355",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 22:05:27,"third_party/xla/third_party/tsl/tsl/concurrency/async_value_ptr_test.cc, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref_test.cc",ezhulenev,False
"[tsl:concurrency] Fix a potential data race when emplacig into all_allocated_elements_ vector

PiperOrigin-RevId: 627516783",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 22:03:19,"third_party/xla/third_party/tsl/tsl/concurrency/BUILD, third_party/xla/third_party/tsl/tsl/concurrency/concurrent_vector.h",ezhulenev,False
"[XLA] Fix an infinite loop in MSA.

The bug was due to use time definitions being different in AddRequiredAssignment
vs AllocateAllocationAssignment.

PiperOrigin-RevId: 627509558",Berkin Ilbeyi,berkin@google.com,2024-04-23 21:38:11,"third_party/xla/xla/service/memory_space_assignment/algorithm.cc, third_party/xla/xla/service/memory_space_assignment/algorithm.h, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",berkinilbeyi,False
"[pjrt] Remove PjRtFuture<>::Promise::SetError() in favor of Set()

PiperOrigin-RevId: 627504142",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 21:20:32,"third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/python/ifrt_proxy/client/array.cc",ezhulenev,False
"[tsl:concurrency] Correctly form a strong reference to async values when running on executor

PiperOrigin-RevId: 627502952",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 21:16:37,third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h,ezhulenev,False
"Add builtin cc dataclass pytree node for performance.

PiperOrigin-RevId: 627502102",Enrique Piqueras,enriqueps@google.com,2024-04-23 21:14:02,"third_party/xla/xla/python/pytree.cc, third_party/xla/xla/python/pytree.h, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_extension/pytree.pyi",,False
"Reverts 04aa434c0e5a011e980c9b42f4da489834b054de

PiperOrigin-RevId: 627500637",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 21:09:30,"third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc, third_party/xla/xla/translate/mhlo_to_hlo/tests/sharding.mlir",tensorflower-gardener,False
"[tsl:concurrency] NFC: Add a benchmark for AsyncValuePtr<T>::Map(executor, ...)

---------------------------------------------------------------------
Benchmark                           Time             CPU   Iterations
---------------------------------------------------------------------
BM_MapIntToFloat                 38.3 ns         38.3 ns     18232592
BM_MapIntToFloatOnExecutor       53.1 ns         53.1 ns     13204614

PiperOrigin-RevId: 627498984",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 21:04:59,third_party/xla/third_party/tsl/tsl/concurrency/async_value_ptr_test.cc,ezhulenev,False
"[Cleanup] Remove unused CreateCollectiveBroadcast function.

PiperOrigin-RevId: 627498188",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 21:02:51,third_party/xla/xla/hlo/ir/hlo_instruction.h,tensorflower-gardener,False
"[tsl:concurrency] Add special handling of Map functors returning StatusOr<U> results

AsyncValueRef<absl::StatusOr<T>> is discouraged and should be replaced with AsyncValueRef<T> because async value is already an container with a absl::Status or a value and Status of Status makes APIs ambiguous.

Add specializations to AsyncValueRef::Map to handle functors returning StatusOr objects.

PiperOrigin-RevId: 627495246",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 20:53:08,"third_party/xla/third_party/tsl/tsl/concurrency/async_value_ptr_test.cc, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref_test.cc",ezhulenev,False
"[tsl:concurrency] Add TypedIndirectAsyncValue to be able to create indirect async values that expected to be forwarded to an async value with a concrete type

+ added documentation for how AsyncValueRef<T> type checks work for type hierarchies

PiperOrigin-RevId: 627491213",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 20:39:28,"third_party/xla/third_party/tsl/tsl/concurrency/async_value.cc, third_party/xla/third_party/tsl/tsl/concurrency/async_value.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ptr_test.cc, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref_test.cc",ezhulenev,False
Fix typos.,mdfaijul,md.faijul.amin@intel.com,2024-04-23 21:06:50,"tensorflow/core/grappler/optimizers/remapper.cc, tensorflow/core/grappler/optimizers/remapper_test.cc",mdfaijul,True
"Add a new op ConvertToListOfSparseCoreCooTensors for OSS sparse core embedding API.

PiperOrigin-RevId: 627484669",Ziyin Huang,ziyinh@google.com,2024-04-23 20:18:51,"tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td, tensorflow/compiler/mlir/tf2xla/transforms/legalization_op_config_test.cc, tensorflow/core/api_def/base_api/api_def_ConvertToListOfSparseCoreCooTensors.pbtxt, tensorflow/core/api_def/python_api/api_def_ConvertToListOfSparseCoreCooTensors.pbtxt, tensorflow/core/tpu/kernels/BUILD, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.cc, tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.h, tensorflow/core/tpu/ops/BUILD, tensorflow/core/tpu/ops/sparse_core_preprocess_ops.cc, tensorflow/python/tpu/BUILD, tensorflow/python/tpu/ops/BUILD, tensorflow/python/tpu/tpu_embedding_v3_cpu_ops_test.py, tensorflow/tools/api/golden/v1/tensorflow.raw_ops.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.raw_ops.pbtxt",pineapplejuice233,False
"[tsl:concurrency] NFC: Add a benchmark for AsyncValuePtr<T>::Map

-----------------------------------------------------------
Benchmark                 Time             CPU   Iterations
-----------------------------------------------------------
BM_MapIntToFloat       38.4 ns         38.4 ns     18157872

All of the overheads are in AsyncValueRef<float> reference counting.

PiperOrigin-RevId: 627481575",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 20:08:03,"third_party/xla/third_party/tsl/tsl/concurrency/BUILD, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ptr_test.cc",ezhulenev,False
"Notebooks should run end-to-end without stopping for configmation.

PiperOrigin-RevId: 627481283",Mark Daoust,markdaoust@google.com,2024-04-23 20:07:07,tensorflow/lite/g3doc/models/modify/model_maker/text_classification.ipynb,MarkDaoust,False
"[tsl:concurrency] Add AsyncValue::Executor to be able to customize where the waiter will execute

PiperOrigin-RevId: 627476421",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 19:52:16,"third_party/xla/third_party/tsl/tsl/concurrency/BUILD, third_party/xla/third_party/tsl/tsl/concurrency/async_value.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ptr_test.cc, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref_test.cc",ezhulenev,False
Add more signed quantized types.,mdfaijul,md.faijul.amin@intel.com,2024-04-23 20:32:32,tensorflow/core/kernels/mkl/mkl_quantize_op.cc,mdfaijul,True
"Add donation attr to ReshardOp and pass that verifies donations are set correctly.

The pass verifies that:
1) No array is donated more than once.
2) If an array that is an input to the IR program is donated, then it must have the ifrt.donated attribute set.

PiperOrigin-RevId: 627475531",Ionel Gog,icgog@google.com,2024-04-23 19:49:01,"third_party/xla/xla/python/ifrt/ir/ifrt_ops.td, third_party/xla/xla/python/ifrt/ir/tests/BUILD, third_party/xla/xla/python/ifrt/ir/tests/ifrt_verify_donation.mlir, third_party/xla/xla/python/ifrt/ir/transforms/BUILD, third_party/xla/xla/python/ifrt/ir/transforms/ifrt_verify_donation_pass.cc, third_party/xla/xla/python/ifrt/ir/transforms/passes.h, third_party/xla/xla/python/ifrt/ir/transforms/passes.td",ICGog,False
"[pjrt] Make sure that PjRtFuture<> is copyable and moveable

Explicitly add copy and move constructors/assignment to make sure that stateless
future stays copyable and moveable.

PiperOrigin-RevId: 627474702",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 19:46:03,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"Adds default move constructors to `tensorflow::XlaCompiledFunction`.

This class already deletes the copy constructors, but does not enable the move constructors. As written today, users of `tensorflow::XlaCompiledFunction` must wrap their instances in a `std::unique_ptr` (or similar) in order to move this instance. That solution would add indirection and proliferate null checks that is not needed after this chance.

PiperOrigin-RevId: 627474665",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 19:45:55,tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h,tensorflower-gardener,False
"Merge pull request #65538 from Intel-tensorflow:remove_blockformat_tests

PiperOrigin-RevId: 627473738",TensorFlower Gardener,gardener@tensorflow.org,2024-04-23 19:52:58,"tensorflow/core/grappler/costs/graph_properties_test.cc, tensorflow/core/util/mkl_util_test.cc",tensorflower-gardener,False
"[pjrt] Add static_assert to disable PjRtFuture<absl::Status>

PiperOrigin-RevId: 627466573",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 19:14:54,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"[XLA:GPU] Avoid segfault in serializing autotune results.

In some cases, the debug options reference may become invalid in
GpuCompiler::RunHloPasses, at which point serializing segfaults upon access to
the debug options.

The reason for the invalid reference is not clear, as all methods operate on
unique_ptr::get(), not on raw pointers that would invalidate it, but taking a
copy of a modest-sized variable is not the end of the world from a performance
perspective even if it's not ideal.

A never-used call to GetAutotuneConfig is also removed from RunHloPasses.

PiperOrigin-RevId: 627461704",pizzud,pizzud@google.com,2024-04-23 19:00:03,third_party/xla/xla/service/gpu/gpu_compiler.cc,pizzud,False
"Remove call to StreamExecutor::implementation in rocm_executor.cc now that all StreamExecutors inherit from StreamExecutorInterface.

PiperOrigin-RevId: 627458028",Kyle Lucke,klucke@google.com,2024-04-23 18:47:28,third_party/xla/xla/stream_executor/rocm/rocm_executor.cc,klucke,False
"Align tensorflow-tpu and libtpu versions for release consistency

PiperOrigin-RevId: 627452179",Kanglan Tang,kanglan@google.com,2024-04-23 18:29:03,tensorflow/tools/pip_package/setup.py,kanglant,False
"Add Adreno 750 to GPU info

PiperOrigin-RevId: 627451701",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 18:27:35,"tensorflow/lite/delegates/gpu/common/gpu_info.cc, tensorflow/lite/delegates/gpu/common/gpu_info.h",tensorflower-gardener,False
"#tf-data Add a test for deeply nested `map_func`.

PiperOrigin-RevId: 627441971",Yang Chen,yangchen@google.com,2024-04-23 17:58:48,tensorflow/python/data/experimental/kernel_tests/index_flat_map_test.py,yangustc07,False
"Flatbuffer export memory optimization for large models.

PiperOrigin-RevId: 627417753",Weiyi Wang,weiyiw@google.com,2024-04-23 16:46:26,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/flatbuffer_export.cc",sirakiin,False
"#shlo_ref Inline the definitions of arithmetic operators for the F16 shim.

This would fail to compile because:

> On a friend function template declaration, default template arguments are allowed only if the declaration is a definition, and no other declarations of this function appear in this translation unit.

PiperOrigin-RevId: 627399749",Quentin Khan,qkhan@google.com,2024-04-23 15:40:54,tensorflow/lite/experimental/shlo/f16.h,qukhan,False
"Replaces the lazy constraint instantiation logic with memory term reduction.

PiperOrigin-RevId: 627368773",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 13:32:13,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc,tensorflower-gardener,False
"[xla:ffi] Add test cases for nested tuple to CPU custom call tests

Add test cases for handling nested tuples (given both as inputs and outputs) to CPU custom call typed FFI API tests.
Implements #10056.

PiperOrigin-RevId: 627368299",Adam Banaś,adambanas@google.com,2024-04-23 13:30:06,third_party/xla/xla/tests/custom_call_test.cc,Adam-Banas,False
"Automated Code Change

PiperOrigin-RevId: 627355076",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 12:33:31,"tensorflow/core/util/strided_slice_op.cc, tensorflow/core/util/strided_slice_op.h, tensorflow/core/util/util.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627346724",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 11:56:36,"tensorflow/lite/delegates/flex/delegate.cc, tensorflow/lite/delegates/flex/util.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627340605",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 11:24:08,tensorflow/python/profiler/internal/profiler_wrapper.cc,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@9ba6961ce05b

Updates LLVM usage to match
[9ba6961ce05b](https://github.com/llvm/llvm-project/commit/9ba6961ce05b)

PiperOrigin-RevId: 627338682",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 11:14:38,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Use actual PTX target version for CUDA compilation

Provides two code paths: either use the configured CUDA version, or the runtime version of ptxas (this might be different in some configurations).

PiperOrigin-RevId: 627336876",Sergey Kozub,sergeykozub@google.com,2024-04-23 11:06:14,"third_party/xla/xla/service/gpu/llvm_gpu_backend/BUILD, third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc, third_party/xla/xla/service/gpu/tests/BUILD",sergeykozub,False
"Automated Code Change

PiperOrigin-RevId: 627335226",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 11:00:47,tensorflow/c/experimental/saved_model/core/ops/variable_ops.cc,tensorflower-gardener,False
"Reverts de0257fda50b973b143f4dbc576cebb58aa3da5f

PiperOrigin-RevId: 627331414",Adrian Kuegel,akuegel@google.com,2024-04-23 10:40:34,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc",akuegel,False
"Automated Code Change

PiperOrigin-RevId: 627330392",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 10:35:01,tensorflow/tools/optimization/optimization_pass_runner.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627330299",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 10:34:34,tensorflow/python/eager/pywrap_tfe.h,tensorflower-gardener,False
"Reverts 7edfea8c24f42045c75d329ff3d498c7dd6e34b9

PiperOrigin-RevId: 627323093",Jaroslav Sevcik,jsevcik@nvidia.com,2024-04-23 10:01:49,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation_test.cc",jaro-sevcik,False
"Automated Code Change

PiperOrigin-RevId: 627313743",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 09:18:05,tensorflow/compiler/tf2tensorrt/plugin/trt_plugin.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627311608",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 09:09:26,"third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_collection.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_collection.h, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_controller.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_controller.h, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_factory_test.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_interface.h, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_lock.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_lock.h, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_lock_test.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_session.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_session.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627311340",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 09:08:13,"third_party/xla/third_party/tsl/tsl/lib/monitoring/cell_reader-inl.cc, third_party/xla/third_party/tsl/tsl/lib/monitoring/cell_reader-inl.h, third_party/xla/third_party/tsl/tsl/lib/monitoring/counter.h, third_party/xla/third_party/tsl/tsl/lib/monitoring/gauge.h, third_party/xla/third_party/tsl/tsl/lib/monitoring/percentile_sampler.h, third_party/xla/third_party/tsl/tsl/lib/monitoring/sampler.h, third_party/xla/third_party/tsl/tsl/lib/monitoring/test_utils.cc, third_party/xla/third_party/tsl/tsl/lib/monitoring/test_utils.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627311048",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 09:07:10,tensorflow/compiler/mlir/tfrt/saved_model/saved_model.cc,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-23

PiperOrigin-RevId: 627309655",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 09:02:57,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1841.

PiperOrigin-RevId: 627309620",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 09:02:51,tensorflow/core/public/version.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627302960",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 08:30:05,tensorflow/core/profiler/lib/profiler_disabled_test.cc,tensorflower-gardener,False
"PR #11435: Spmd partitioning for host memory offloading ops

Imported from GitHub PR https://github.com/openxla/xla/pull/11435

This partitions MoveToHost and MoveToDevice custom calls in a way that
tries to avoid resharding on the host. That is, MoveToHost reshards input,
MoveToDevice reshards output.
Copybara import of the project:

--
a6d01010f3b468de02ebee8a0c59f9e28ea4297d by Jaroslav Sevcik <jsevcik@nvidia.com>:

Partition host offloading ops

Merging this change closes #11435

PiperOrigin-RevId: 627298170",Jaroslav Sevcik,jsevcik@nvidia.com,2024-04-23 08:08:05,"third_party/xla/xla/service/spmd/BUILD, third_party/xla/xla/service/spmd/custom_call_handler.cc, third_party/xla/xla/service/spmd/spmd_partitioner_test.cc",jaro-sevcik,False
"PR #11649: [GPU] Rename and better describe flags related to GEMM fusions.

Imported from GitHub PR https://github.com/openxla/xla/pull/11649

Rename one flag for consistency because fusions can use different backends.

Also clarify descriptions of other 2 related flags.
Copybara import of the project:

--
e82637723b3252b9218ded171b026ff4f860e835 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Rename and better describe flags related to GEMM fusions.

Rename one flag for consistency because fusions can use different backends.

Also clarify descriptions of other 2 related flags.

Merging this change closes #11649

PiperOrigin-RevId: 627297075",Ilia Sergachev,isergachev@nvidia.com,2024-04-23 08:03:56,"third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/xla.proto",sergachev,False
"Automated Code Change

PiperOrigin-RevId: 627293366",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 07:47:06,tensorflow/core/runtime_fallback/kernel/kernel_fallback_execute_compat.cc,tensorflower-gardener,False
"PR #11405: [gpu] Add address computation fusion for RS->DUS pattern

Imported from GitHub PR https://github.com/openxla/xla/pull/11405

This patch recognizes a reduce-scatter operation that is used by a dynamic-update-slice operation. It then fuses this operation to an address-computation fusion.
For example, the following pattern is extracted to a fusion:
```
reduce-scatter = f16[64,128] reduce-scatter(%p0), channel_id=64, replica_groups={{0,1}}, use_global_device_ids=true, dimensions={0}, to_apply=add
dynamic-update-slice = f16[128,128] dynamic-update-slice(%p1, reduce-scatter, %p3, constant.718)
```
Copybara import of the project:

--
2c26d292ac1cbe8742b773228caf4a21d8bb6d36 by Shraiysh Vaishay <svaishay@nvidia.com>:

[gpu] Add address computation fusion for RS->DUS pattern

Merging this change closes #11405

PiperOrigin-RevId: 627291508",Shraiysh,svaishay@nvidia.com,2024-04-23 07:38:17,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc",shraiysh,False
"Automated Code Change

PiperOrigin-RevId: 627289653",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 07:29:03,tensorflow/lite/delegates/flex/kernel.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627288973",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 07:25:28,tensorflow/c/experimental/saved_model/internal/saved_model_api_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627288489",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 07:22:56,tensorflow/core/util/sparse/sparse_tensor_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627288322",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 07:21:59,tensorflow/compiler/mlir/tfrt/transforms/tf_to_tfrt.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627288050",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 07:20:30,"third_party/xla/xla/hlo/transforms/BUILD, third_party/xla/xla/hlo/transforms/hlo_constant_splitter.cc, third_party/xla/xla/hlo/transforms/hlo_constant_splitter.h, third_party/xla/xla/hlo/transforms/hlo_constant_splitter_test.cc",tensorflower-gardener,False
"[pjrt] Switch TfrtTpuBuffer to PjRtFuture<>::Promise to track definition event

In preparation for disabling absl::Status payloads for AsyncValue convert PjRtClient to PjRtFuture

PiperOrigin-RevId: 627279053",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 06:38:10,third_party/xla/xla/pjrt/pjrt_future.h,ezhulenev,False
"PR #11631: Cleanup passes names

Imported from GitHub PR https://github.com/openxla/xla/pull/11631

I found couple passes with simple `absl::string_view name()` implementation which were defined in cc files.
All other passes define `name()` in header file. (Unless name() impl requires if/switch block)

This PR makes simple `absl::string_view name()` implementation consistent across all passes.
Copybara import of the project:

--
d53f3da013b68002f1cca9370a5618051f819cf5 by Alexander Pivovarov <pivovaa@amazon.com>:

Cleanup passes names

Merging this change closes #11631

PiperOrigin-RevId: 627276075",Alexander Pivovarov,pivovaa@amazon.com,2024-04-23 06:23:49,"third_party/xla/xla/service/batch_dot_simplification.cc, third_party/xla/xla/service/batch_dot_simplification.h, third_party/xla/xla/service/collective_transformation_reorderer.h, third_party/xla/xla/service/indexed_array_analysis.cc, third_party/xla/xla/service/indexed_array_analysis.h, third_party/xla/xla/service/while_loop_concat_code_motion.h",apivovarov,False
"[pjrt] Migrate the rest of PjRt to PjRtFuture<> for stateless events

PiperOrigin-RevId: 627273030",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 06:07:00,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/future.cc, third_party/xla/xla/python/ifrt/future.h, third_party/xla/xla/python/ifrt/future_test.cc, third_party/xla/xla/python/ifrt_proxy/server/host_callback.cc, third_party/xla/xla/python/ifrt_proxy/server/host_callback.h, third_party/xla/xla/python/py_executable.cc",ezhulenev,False
"Skip parallel mapfn optimization if the tensorlist cannot be found in the current function block.

PiperOrigin-RevId: 627270701",Kuangyuan Chen,chky@google.com,2024-04-23 05:55:39,"tensorflow/compiler/mlir/tfrt/tests/mlrt/while_to_map_fn.mlir, tensorflow/compiler/mlir/tfrt/transforms/mlrt/while_to_map_fn.cc",cky9301,False
"Automated Code Change

PiperOrigin-RevId: 627269986",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 05:51:36,"tensorflow/core/util/sparse/dim_comparator.h, tensorflow/core/util/sparse/group_iterator.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 627269790",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 05:50:25,"tensorflow/c/kernels_experimental.cc, tensorflow/c/tf_status_helper.cc",tensorflower-gardener,False
"[tsl:concurrency] Add AsyncValueRef<T>::Map() function to transform async values

PiperOrigin-RevId: 627266586",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 05:32:11,"third_party/xla/third_party/tsl/tsl/concurrency/async_value_ptr_test.cc, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref_test.cc",ezhulenev,False
"Updates the Memory Term Reducer to try merging with a nearby primitive before starting with the earliest.

PiperOrigin-RevId: 627266189",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 05:29:52,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_memory_test.cc",tensorflower-gardener,False
"Add support for nested tuples in MutableBorrowingLiteral

PiperOrigin-RevId: 627266147",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 05:29:36,"third_party/xla/xla/literal.cc, third_party/xla/xla/literal.h, third_party/xla/xla/literal_test.cc",ezhulenev,False
"Automated Code Change

PiperOrigin-RevId: 627265004",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 05:22:33,"tensorflow/lite/delegates/hexagon/builders/tests/BUILD, tensorflow/lite/delegates/hexagon/builders/tests/activations_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/arg_min_max_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/arithmetic_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/batch_seq_config_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/concat_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/conv_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/l2_norm_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/matmul_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/min_max_builder_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/mirror_pad_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/mul_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/neg_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/pack_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/pad_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/pool_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/quantize_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/reduce_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/reshape_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/resize_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/rsqrt_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/slice_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/softmax_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/space_to_depth_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/split_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/squared_difference_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/strided_slice_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/transpose_conv_test.cc, tensorflow/lite/delegates/hexagon/builders/tests/transpose_test.cc",tensorflower-gardener,False
"[tsl:concurrency] NFC: Clean up AndThen type signature detection

Rename WaiterT to Waiter to be consistent with google style guide

PiperOrigin-RevId: 627258492",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 04:46:18,"third_party/xla/third_party/tsl/tsl/concurrency/async_value.h, third_party/xla/third_party/tsl/tsl/concurrency/async_value_ref.h",ezhulenev,False
"[pjrt] Switch more of ifrt to Future<> for stateless events

PiperOrigin-RevId: 627251984",Eugene Zhulenev,ezhulenev@google.com,2024-04-23 04:07:17,"third_party/xla/xla/pjrt/pjrt_client.h, third_party/xla/xla/pjrt/pjrt_future.h, third_party/xla/xla/pjrt/pjrt_future_test.cc, third_party/xla/xla/python/ifrt/executable.h, third_party/xla/xla/python/ifrt/mock.h, third_party/xla/xla/python/ifrt_proxy/client/array.cc, third_party/xla/xla/python/ifrt_proxy/client/compiler.cc, third_party/xla/xla/python/ifrt_proxy/client/executable.cc, third_party/xla/xla/python/ifrt_proxy/client/executable.h, third_party/xla/xla/python/ifrt_proxy/client/executable_test.cc, third_party/xla/xla/python/ifrt_proxy/client/grpc_host_buffer.cc, third_party/xla/xla/python/ifrt_proxy/client/grpc_host_buffer.h, third_party/xla/xla/python/ifrt_proxy/client/host_buffer.h, third_party/xla/xla/python/ifrt_proxy/client/mock_host_buffer.h, third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.cc, third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.h, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.h, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend_test.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.h, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/py_executable.cc",ezhulenev,False
"Integrate LLVM at llvm/llvm-project@59bf49a63261

Updates LLVM usage to match
[59bf49a63261](https://github.com/llvm/llvm-project/commit/59bf49a63261)

PiperOrigin-RevId: 627235870",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 02:46:27,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Adds GQA support for SDPA op.

PiperOrigin-RevId: 627235612",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-23 02:44:42,"tensorflow/lite/delegates/xnnpack/odml_sdpa_test.cc, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc, tensorflow/lite/experimental/genai/sdpa.cc",tensorflower-gardener,False
"Add a pass to insert CalibrationStatisticsSaver op

As the op is stateful. Operations like If, IfRegion,... that contain CustomAggregator must be marked as stateful. If not, the CalibrationStatisticsSaver op might be skipped.

PiperOrigin-RevId: 627231720",Thai Nguyen,thaink@google.com,2024-04-23 02:25:08,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/passes/insert_calibration_statistics_saver.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.td, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/insert_calibration_statistics_saver.mlir, tensorflow/compiler/mlir/quantization/tensorflow/passes/tf_quant_ops.td",thaink,False
"PR #11644: [XLA:GPU] move cublasLt creation to thunk initialization.

Imported from GitHub PR https://github.com/openxla/xla/pull/11644

To avoid cublasLt and command buffer deadlock, move cublasLt creation to thunk initialization.
Copybara import of the project:

--
1d9b36f31fa8dbfce6f628065e946b3219148757 by Shawn Wang <shawnw@nvidia.com>:

move cublasLt creation to thunk initialize

Merging this change closes #11644

PiperOrigin-RevId: 627218676",Shawn Wang,shawnw@nvidia.com,2024-04-23 01:23:41,"third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.cc, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.h",shawnwang18,False
"PR #11299: [XLA:CPU] Enable XLA on Windows

Imported from GitHub PR https://github.com/openxla/xla/pull/11299

This PR aims to enable the XLA test cases on the Windows Platform. The changes made:

1. Changed the .bazelrc file to use the correct toolchain and platform
This change will allow the user to successfully run XLA tests on the Windows platform using the Clang compiler using '--config=win_clang' in the bazel command

2. Added conditions to a few test cases to successfully run on the Windows platform
These test cases check the exit/termination status of a process
WIFEXITED is typically supported in POSIX-compliant operating systems like Unix and Linux to check if a process has terminated normally. WEXITSTATUS allows examining the termination status of child processes. However, these macros are not Windows compliant, hence the additional condition block was added to check the exit/termination status of process or child process for the Windows platform
Copybara import of the project:

--
ece9eefa224a6d051bcac089fe2a9a393af16a2b by Raunak <mayank.kumar.raunak@intel.com>:

Enable XLA Windows

--
347c0326af8f608047f06345cad4dfbb53a52150 by mraunak <83710963+mraunak@users.noreply.github.com>:

Update interactive_graphviz_bin_test.cc
--
2d4a3c2bb2ea23f12029583c53087d8739da0319 by mraunak <83710963+mraunak@users.noreply.github.com>:

Update xla/tools/interactive_graphviz_bin_test.cc

Co-authored-by: Penporn Koanantakool <38085909+penpornk@users.noreply.github.com>
--
90ad8b2730900d7f82b0fb1a83a73ffa2e452e0e by mraunak <83710963+mraunak@users.noreply.github.com>:

Update run_hlo_module_bin_test.cc
--
7f31412f6b57e53bd56ba92149b015fcba92b07c by mraunak <83710963+mraunak@users.noreply.github.com>:

Update xla/tools/run_hlo_module_bin_test.cc

Co-authored-by: Penporn Koanantakool <38085909+penpornk@users.noreply.github.com>
--
4d39e35461f6977f36404a435c68b4809fb51a44 by mraunak <83710963+mraunak@users.noreply.github.com>:

Update hlo_expand_test.cc
--
816b9ae0498831b55139c72d627d07f05e51213b by mraunak <83710963+mraunak@users.noreply.github.com>:

Update hlo_expand_test.cc
--
a728fff1aca4258602c3d7c78afcc7d38b545b7a by mraunak <83710963+mraunak@users.noreply.github.com>:

Update hlo_expand_test.cc
--
ffcb6861becf8de7a5c4e64ef0f19d977475d281 by mraunak <83710963+mraunak@users.noreply.github.com>:

Update interactive_graphviz_bin_test.cc
--
f181497793c2c48079d72b545e6efb837f490504 by mraunak <83710963+mraunak@users.noreply.github.com>:

Update interactive_graphviz_bin_test.cc
--
f9af75677e4663b3348e9e89376262eaff389ea9 by mraunak <83710963+mraunak@users.noreply.github.com>:

Update run_hlo_module_bin_test.cc

Merging this change closes #11299

PiperOrigin-RevId: 627216606",mraunak,83710963+mraunak@users.noreply.github.com,2024-04-23 01:15:05,".bazelrc, third_party/xla/.bazelrc, third_party/xla/third_party/tsl/.bazelrc, third_party/xla/xla/tools/interactive_graphviz_bin_test.cc, third_party/xla/xla/tools/run_hlo_module_bin_test.cc, third_party/xla/xla/tools/tests/hlo_expand_test.cc",mraunak,False
"Call IsCollective when looking for collectives with channel id.

This change unifies the place we check if an instruction is collective or not.

PiperOrigin-RevId: 627212550",Farzin Houshmand,farzinh@google.com,2024-04-23 00:59:34,"third_party/xla/xla/service/collective_ops_utils.cc, third_party/xla/xla/service/collective_ops_utils_test.cc",farzinhoushmand,False
"Reverts 109956f6f03a3fc97b94df29df3027564d101706

PiperOrigin-RevId: 627192322",Yash Katariya,yashkatariya@google.com,2024-04-22 23:34:46,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation_test.cc",yashk2810,False
"Bugfix for the transform api.

PiperOrigin-RevId: 627181787",Sagun Bajra,sagunb@google.com,2024-04-22 22:55:00,tensorflow/core/function/transform/transform.py,sagunb,False
"[XLA:GPU][MLIR Emitters] Lower atomic_rmw to direct atomic ops when possible.

PiperOrigin-RevId: 627180078",Alexander Belyaev,pifon@google.com,2024-04-22 22:48:10,"third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/mlir/passes.h, third_party/xla/xla/service/gpu/fusions/mlir/passes.td, third_party/xla/xla/service/gpu/fusions/mlir/tests/lower_tensors.mlir, third_party/xla/xla/stream_executor/device_description.h",pifon2a,False
"Cache begin/end iterators in min/max extraction loop

PiperOrigin-RevId: 627174757",Pauline Sho,psho@google.com,2024-04-22 22:30:15,tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.cc,paulinesho,False
"Integrate LLVM at llvm/llvm-project@89c95effe82c

Updates LLVM usage to match
[89c95effe82c](https://github.com/llvm/llvm-project/commit/89c95effe82c)

PiperOrigin-RevId: 627170988",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 22:17:15,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"#tf-data Adds random access support to the zip dataset

PiperOrigin-RevId: 627167652",Jim Lin,jimlintw@google.com,2024-04-22 22:04:55,"tensorflow/core/framework/dataset.h, tensorflow/core/kernels/data/BUILD, tensorflow/core/kernels/data/zip_dataset_op.cc, tensorflow/python/data/kernel_tests/BUILD, tensorflow/python/data/kernel_tests/zip_test.py",jimlinntu,False
"Update flatbuffers used in tflite.

PiperOrigin-RevId: 627165379",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 21:57:40,"tensorflow/lite/acceleration/configuration/configuration_generated.h, tensorflow/lite/delegates/gpu/cl/compiled_program_cache_generated.h, tensorflow/lite/delegates/gpu/cl/serialization_generated.h, tensorflow/lite/delegates/gpu/common/gpu_model_generated.h, tensorflow/lite/delegates/gpu/common/task/serialization_base_generated.h, tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h, tensorflow/lite/schema/conversion_metadata_generated.h, tensorflow/lite/schema/schema_generated.h, tensorflow/lite/tools/cmake/modules/flatbuffers.cmake, tensorflow/tools/ci_build/release/requirements_common.txt, tensorflow/tools/pip_package/setup.py, tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt, third_party/flatbuffers/workspace.bzl",tensorflower-gardener,False
"Support auto in shard_map.

- Pull mesh from NamedSharding when rewriting manual axes.
- Properly set manual axes in SPMDAxisContext in shard_map.
- Properly set dims as unspecified inside shard_map.

PiperOrigin-RevId: 627156892",Parker Schuh,parkers@google.com,2024-04-22 21:27:38,third_party/xla/xla/python/sharding.cc,pschuh,False
"[XLA:GPU] Export autotune results to uploader registries.

Doing so allows debugging the results at scale and re-using them for later
recompilation.

PiperOrigin-RevId: 627149309",pizzud,pizzud@google.com,2024-04-22 21:02:35,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/export_hlo.h, third_party/xla/xla/service/gpu/autotuner_util.cc, third_party/xla/xla/service/gpu/autotuner_util.h, third_party/xla/xla/service/gpu/gpu_compiler.cc",pizzud,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/2b13a98c79d17027f474ed545740fe2b39547dbd.

PiperOrigin-RevId: 627132075",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 20:06:33,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@6bd29d66398d

Updates LLVM usage to match
[6bd29d66398d](https://github.com/llvm/llvm-project/commit/6bd29d66398d)

PiperOrigin-RevId: 627124273",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 19:38:46,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/28da0975d11f4efd9167d63d4dcce04ec60db5d6.

PiperOrigin-RevId: 627107757",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 18:45:09,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"PR #11714: Add ToString methods that make it easier to debug DeviceDescription issues.

Imported from GitHub PR https://github.com/openxla/xla/pull/11714

Add ToString methods that make it easier to debug DeviceDescription issues.
Copybara import of the project:

--
15d36e3dcde6637f91a28e56658cdde9a81eaae3 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Add ToString methods that make it easier to debug DeviceDescription issues.

Merging this change closes #11714

PiperOrigin-RevId: 627096781",Dimitris Vardoulakis,dvardoulakis@nvidia.com,2024-04-22 18:11:55,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/compiler.h, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/gpu_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_performance_model_base.h, third_party/xla/xla/service/hlo_cost_analysis.h, third_party/xla/xla/stream_executor/device_description.cc, third_party/xla/xla/stream_executor/device_description.h",dimvar,False
"#tf-data #tf-data `index_flat_map` supports nested lists.

PiperOrigin-RevId: 627092695",Yang Chen,yangchen@google.com,2024-04-22 18:00:17,"tensorflow/core/kernels/data/experimental/index_flat_map_dataset_op.cc, tensorflow/python/data/experimental/kernel_tests/index_flat_map_test.py, tensorflow/python/data/experimental/ops/index_flat_map_op.py",yangustc07,False
"Internal tooling changes.

PiperOrigin-RevId: 627083462",Quentin Khan,qkhan@google.com,2024-04-22 17:32:52,"tensorflow/lite/testing/init_tensorflow.cc, tensorflow/lite/testing/init_tensorflow.h",qukhan,False
"[ReplicaGroupV2] Create CollectiveDeviceList.

As part of an effort the speed up compile time, there have been some explorations on different ways to represent replica groups. In order to support these new representations, we need to migrate from directly passing around lists of replica groups (list of list of device). This creates a CollectiveDeviceList class whose purpose is to abstract away the details of replica group representation from usage. We later intend to expand this class to support compact representations.

PiperOrigin-RevId: 627079763",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 17:22:07,"third_party/xla/xla/hlo/ir/BUILD, third_party/xla/xla/hlo/ir/collective_device_list.cc, third_party/xla/xla/hlo/ir/collective_device_list.h, third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h, third_party/xla/xla/hlo/ir/hlo_instructions.cc, third_party/xla/xla/hlo/ir/hlo_instructions.h, third_party/xla/xla/hlo/utils/hlo_matchers_test.cc, third_party/xla/xla/service/all_gather_combiner.cc, third_party/xla/xla/service/all_gather_decomposer.cc, third_party/xla/xla/service/all_reduce_combiner.cc, third_party/xla/xla/service/all_reduce_combiner_test.cc, third_party/xla/xla/service/all_reduce_contiguous.cc, third_party/xla/xla/service/all_reduce_folder.cc, third_party/xla/xla/service/all_to_all_decomposer.cc, third_party/xla/xla/service/async_collective_creator.cc, third_party/xla/xla/service/bfloat16_conversion_folding_test.cc, third_party/xla/xla/service/bfloat16_propagation_test.cc, third_party/xla/xla/service/collective_ops_utils_test.cc, third_party/xla/xla/service/collective_transformation_reorderer.cc, third_party/xla/xla/service/convert_async_collectives_to_sync.cc, third_party/xla/xla/service/float_normalization_test.cc, third_party/xla/xla/service/gpu/all_reduce_blueconnect.cc, third_party/xla/xla/service/gpu/gpu_all_gather_optimizer.cc, third_party/xla/xla/service/gpu/gpu_hlo_schedule_test.cc, third_party/xla/xla/service/gpu/gpu_reduce_scatter_creator.cc, third_party/xla/xla/service/hlo_instruction_test.cc, third_party/xla/xla/service/hlo_parser.cc, third_party/xla/xla/service/reduce_scatter_combiner.cc, third_party/xla/xla/service/reduce_scatter_decomposer.cc, third_party/xla/xla/service/spmd/canonicalize_all_gather_for_cse.cc, third_party/xla/xla/service/spmd/spmd_partitioner.cc, third_party/xla/xla/service/while_loop_all_reduce_code_motion.cc",tensorflower-gardener,False
"[IFRT] Introduce PjRtCompatibleDevice and PjRtCompatibleMemory classes.

PiperOrigin-RevId: 627066678",Peter Hawkins,phawkins@google.com,2024-04-22 16:42:25,"third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_device.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_device.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_memory.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_memory.h",hawkinsp,False
"Remove test use of StreamExecutor::GetAllocator.

PiperOrigin-RevId: 627053448",Kyle Lucke,klucke@google.com,2024-04-22 15:58:22,"third_party/xla/xla/service/generic_transfer_manager_test.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk_test.cc, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc, third_party/xla/xla/service/gpu/tests/gpu_too_many_blocks_test.cc",klucke,False
"[TSL] Move away from deprecated typedef

PiperOrigin-RevId: 627050864",David Majnemer,majnemer@google.com,2024-04-22 15:48:20,"third_party/xla/third_party/tsl/tsl/framework/type_traits.h, third_party/xla/third_party/tsl/tsl/platform/ml_dtypes.h, third_party/xla/xla/hlo/evaluator/hlo_evaluator_typed_visitor.h, third_party/xla/xla/hlo/evaluator/hlo_evaluator_typed_visitor_float8.cc, third_party/xla/xla/literal.cc, third_party/xla/xla/literal_test.cc, third_party/xla/xla/primitive_util.h, third_party/xla/xla/python/py_values.cc, third_party/xla/xla/service/elemental_ir_emitter.cc, third_party/xla/xla/tests/constants_test.cc, third_party/xla/xla/tests/convert_test.cc, third_party/xla/xla/util.cc, third_party/xla/xla/util.h, third_party/xla/xla/util_test.cc",majnemer,False
"Fix support for sparse dots in algebraic simplifier, add more tests.

All the uses of `CreateDot` and `MakeDotHlo` should either support sparse dots (i.e. pass down ""sparsity"" and ""sparse_meta"" arguments), or skip sparse dots. Failure to do so would result in compilation errors when sparse dots are encountered.
Some support was introduced previously, but not all the uses were covered, and some of the tests were missing.

Detailed list of changes:
1) Skip the dots where both operands are transposed - as removing the transposes requires swapping the operands, and sparse dot implementation only supports sparsity on the LHS operand (nVidia hardware restriction).
2) Skip the optimization for sparse dot of concat, gather, and transpose/reshape - those operate only on constants, so have limited applicability.
3) Add support for sparse dots for eliminating reduction of batch dimensions.
4) Add previously missing tests for associative reordering of sparse dots.

PiperOrigin-RevId: 627032258",Sergey Kozub,sergeykozub@google.com,2024-04-22 14:38:12,"third_party/xla/xla/service/algebraic_simplifier.cc, third_party/xla/xla/service/algebraic_simplifier_test.cc",sergeykozub,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/8120c877848a8ea7fb39a7228df442a6cccaf683.

PiperOrigin-RevId: 627028182",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 14:22:24,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@5b6db43f29ac

Updates LLVM usage to match
[5b6db43f29ac](https://github.com/llvm/llvm-project/commit/5b6db43f29ac)

PiperOrigin-RevId: 627010633",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 13:01:55,third_party/llvm/workspace.bzl,tensorflower-gardener,False
"Allow per-channel quantization without specifying quantization dimension

Current QuantizedType in QuantizationConfig can only specify per-channel quantization with specified quantization dimension. But quantization dimension may vary depending on the dimension layout within a model, but at the same time, it is straight forward to decide quantization dimension for the most of the times(output feature dimension for convolution, and non-batching and non-contracting dimension for dot_general - usually it is unique for ODML cases). Therefore, allowing option to do per-channel quantization without specifying quantization dimension will make it more accessible.

PiperOrigin-RevId: 627007513",Doyeon Kim,doyeonkim@google.com,2024-04-22 12:47:47,"tensorflow/compiler/mlir/quantization/stablehlo/cc/config_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto",doyeonkim0,False
"PR #11568: Improve NVTX ranges emitted during compilation

Imported from GitHub PR https://github.com/openxla/xla/pull/11568

New ranges:
 - XlaBufferAssignment
 - XlaCompileCudnnFusion
 - XlaCompileGpuAsm
 - XlaCreateGpuExecutable
 - XlaDumpHloModule
 - XlaDumpLlvmIr
 - XlaEmitGpuAsm
 - XlaEmitLlvmIr
 - XlaMemoryScheduler
 - XlaOptimizeLlvmIr

Tweaked XlaCompile, XlaCompileBackend and XlaPass to improve consistency. To allow more explicit range names, the `llvm::Module` is now set to the corresponding HLO module name, where previously it was an empty string.

Because part of #9896 was reverted, `GOOGLE_CUDA` needs to be defined in more translation units to make the NVTX ranges appear. This is done in a separate PR, https://github.com/openxla/xla/pull/11611, on the request of @cheshire.
Copybara import of the project:

--
998bebdee84498eb5ec2df97b9ba94b84d8162cb by Olli Lupton <olupton@nvidia.com>:

Improve NVTX ranges emitted during compilation

New ranges:
 - XlaBufferAssignment
 - XlaCompileCudnnFusion
 - XlaCompileGpuAsm
 - XlaCreateGpuExecutable
 - XlaDumpHloModule
 - XlaDumpLlvmIr
 - XlaEmitGpuAsm
 - XlaEmitLlvmIr
 - XlaMemoryScheduler
 - XlaOptimizeLlvmIr

Tweaked XlaCompile, XlaCompileBackend and XlaPass to improve
consistency. To allow more explicit range names, the llvm::Module is now
set to the corresponding HLO module name, where previously it was an
empty string.

Because part of openxla#9896 was reverted, additional changes to define the
GOOGLE_CUDA macro are needed in order for the new ranges to appear.

Merging this change closes #11568

PiperOrigin-RevId: 627003648",Olli Lupton,olupton@nvidia.com,2024-04-22 12:30:00,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/dump.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/llvm_gpu_backend/BUILD, third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc, third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/service/hlo_memory_scheduler.cc, third_party/xla/xla/service/hlo_pass_pipeline.cc, third_party/xla/xla/service/llvm_compiler.cc, third_party/xla/xla/service/llvm_ir/BUILD, third_party/xla/xla/service/llvm_ir/llvm_util.cc, third_party/xla/xla/service/service.cc",olupton,False
"PR #11309: Run algebraic simplifier after layout normalization

Imported from GitHub PR https://github.com/openxla/xla/pull/11309

The newly introduced layout normalization pass (https://github.com/openxla/xla/pull/10811) leaves redundant bitcasts in the HLO graph. In particular, the bitcasts for the host buffer intializations confuse HostOffloadLegalize pass. The legalization pass tries to ensure that host-offloader’s alias analysis can treat dynamic-update-slice instructions as in-place by duplicating (for each use) the broadcast instructions that will be treated as buffer initializations. However, the layout normalization pass l introduces a single bitcast as a user of the broadcast instruction, so the broadcast does not get duplicated.

This patch runs algebraic simplifier after layout normalization to get rid of the redundant bitcasts.
Copybara import of the project:

--
aa918f1939b0c9f192034aad8f87d1d9358892e9 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Run algebraic simplifier after layout normalization

Merging this change closes #11309

PiperOrigin-RevId: 626988671",Jaroslav Sevcik,jsevcik@nvidia.com,2024-04-22 11:18:28,third_party/xla/xla/service/gpu/gpu_compiler.cc,jaro-sevcik,False
"Switch TensorFlow Composition dialect (`tfr`) to use properties.

PiperOrigin-RevId: 626978116",Christian Sigg,csigg@google.com,2024-04-22 10:30:26,tensorflow/compiler/mlir/tfr/ir/tfr_ops.td,chsigg,False
"Add nVidia-specific pass for rewriting sparse dots with RHS sparse operand

PiperOrigin-RevId: 626975956",Sergey Kozub,sergeykozub@google.com,2024-04-22 10:22:15,"third_party/xla/xla/service/algebraic_simplifier.cc, third_party/xla/xla/service/algebraic_simplifier_test.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/dot_sparsity_rewriter.cc, third_party/xla/xla/service/gpu/dot_sparsity_rewriter.h, third_party/xla/xla/service/gpu/dot_sparsity_rewriter_test.cc, third_party/xla/xla/service/gpu/nvptx_compiler.cc",sergeykozub,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/711b66495de2cb3538b7c3c95e4a98f90e2640bf.

PiperOrigin-RevId: 626970388",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-22 09:56:01,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
