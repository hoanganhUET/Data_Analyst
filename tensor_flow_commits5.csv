Commit Message,Name,Email,Updated at,Files Changed,Contributor,All Checks Passed
"KV Cache storage is now a CacheBuffer in the resource map.

PiperOrigin-RevId: 622657668",T.J. Alumbaugh,talumbau@google.com,2024-04-07 19:49:05,"tensorflow/lite/experimental/genai/BUILD, tensorflow/lite/experimental/genai/kvcache.cc, tensorflow/lite/experimental/genai/kvcache_test.cc, tensorflow/lite/experimental/resource/cache_buffer.cc, tensorflow/lite/experimental/resource/cache_buffer.h, tensorflow/lite/experimental/resource/cache_buffer_test.cc",talumbau,False
"Ignores the previous run's peak times if we're in deterministic mode.

PiperOrigin-RevId: 622650042",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-07 18:41:18,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-07

PiperOrigin-RevId: 622580800",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-07 09:03:36,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1825.

PiperOrigin-RevId: 622580458",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-07 09:02:08,tensorflow/core/public/version.h,tensorflower-gardener,False
"In the Auto Sharding solver output, populates the times where peak memory was observed & the subsequent constraints were enforced.

PiperOrigin-RevId: 622543997",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-07 04:18:08,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.proto, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_impl.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver_test.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_wrapper.h",tensorflower-gardener,False
"Remove deprecated code from JAX lowering and compilation

PiperOrigin-RevId: 622530123",Yash Katariya,yashkatariya@google.com,2024-04-07 02:42:39,"third_party/xla/xla/python/pjit.cc, third_party/xla/xla/python/pmap_lib.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/py_executable.cc, third_party/xla/xla/python/py_values.cc, third_party/xla/xla/python/xla_extension/__init__.pyi",yashk2810,False
"Use StreamExecutor to create stream rather than manually constructing.

PiperOrigin-RevId: 622493277",Kyle Lucke,klucke@google.com,2024-04-06 21:41:12,third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc,klucke,False
"Automated Code Change

PiperOrigin-RevId: 622487938",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 20:51:40,"third_party/xla/xla/mlir/runtime/transforms/BUILD, third_party/xla/xla/mlir/runtime/transforms/calling_convention.cc, third_party/xla/xla/mlir/runtime/transforms/calling_convention_test.cc, third_party/xla/xla/mlir/runtime/transforms/convert_asserts.cc, third_party/xla/xla/mlir/runtime/transforms/convert_custom_calls.cc, third_party/xla/xla/mlir/runtime/transforms/custom_call_encoding.cc, third_party/xla/xla/mlir/runtime/transforms/custom_call_encoding.h, third_party/xla/xla/mlir/runtime/transforms/export_functions.cc, third_party/xla/xla/mlir/runtime/transforms/jit_compiler.cc, third_party/xla/xla/mlir/runtime/transforms/jit_compiler.h, third_party/xla/xla/mlir/runtime/transforms/ordinal_assignment.cc, third_party/xla/xla/mlir/runtime/transforms/rt_to_llvm.cc, third_party/xla/xla/mlir/runtime/transforms/specialization.cc, third_party/xla/xla/mlir/runtime/transforms/specialization.h, third_party/xla/xla/mlir/runtime/transforms/type_converter.cc, third_party/xla/xla/mlir/runtime/transforms/type_converter.h, third_party/xla/xla/mlir/runtime/transforms/type_converter_test.cc",tensorflower-gardener,False
"Add support for recv and recv-done HLO ops in auto-sharding

PiperOrigin-RevId: 622474129",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 18:52:46,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_strategy.cc",tensorflower-gardener,False
"[NFC] Switch `mhlo` dialect to MLIR properties.

PiperOrigin-RevId: 622450101",Christian Sigg,csigg@google.com,2024-04-06 15:27:43,"tensorflow/compiler/mlir/lite/stablehlo/tests/composite-lowering.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/fold_broadcast.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/fuse_mhlo_convolution.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/legalize_hlo.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/optimize.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/tfl_legalize_hlo.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/unfold_splat_constant_pass.mlir, tensorflow/compiler/mlir/lite/stablehlo/tests/unfuse_mhlo_batch_norm.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/bridge/convert_tf_quant_ops_to_mhlo.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/unfuse_mhlo_batch_norm.mlir, tensorflow/compiler/mlir/tensorflow/tests/order_by_dialect.mlir, tensorflow/compiler/mlir/tf2xla/tests/adjust-layout.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf-BatchMatMulV2.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf-binary-elementwise.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf-collective.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf-prefer-tf2xla.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf-quant.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf-with-tf2xla-hlo-importer.mlir, tensorflow/compiler/mlir/tf2xla/tests/legalize-tf.mlir, tensorflow/compiler/mlir/tf2xla/tests/verify-tfxla-legalization.mlir, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops.cc, third_party/xla/xla/mlir_hlo/mhlo/IR/hlo_ops_common.td, third_party/xla/xla/mlir_hlo/mhlo/transforms/map_mhlo_to_scalar_op.h, third_party/xla/xla/mlir_hlo/mhlo/transforms/test_infer_shaped_type/test_infer_shaped_type_pass.cc, third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_mhlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/broadcast_propagation.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/canonicalize.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/concatenate.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/convolution.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/folder_limit.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/reduce.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/reverse.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/scatter.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/canonicalize/transpose.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/expand_ops_simplifier.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/group_reduction_dimensions.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-broadcast-to-broadcast-in-dim.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-cross-replica-sum-to-all-reduce.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-dot-general-to-dot.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-dot-to-dot-general.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-einsum-to-dot-general.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-gather-to-torch-index-select.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-rng-to-linalg.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-linalg.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-to-stablehlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/hlo-legalize-torch-index-select-to-gather.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/legalize-control-flow.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/legalize-hlo-shape-computations.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/legalize-to-std.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/lower-general-dot.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/materialize-broadcasts.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/mhlo-quant-legalize-to-int.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/mhlo_canonicalize_scatter.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/mhlo_infer_shape_type_methods.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/mhlo_ops_prettyprint.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/ops.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/optimize-hlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/prepare-for-export.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/restrict_max_rank.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/shape_cstr_legalize_to_hlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/shape_legalize_to_hlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/stablehlo-legalize-to-hlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/symbolic-shape-optimization.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/unfuse_batch_norm.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/verifier_while_op.mlir, third_party/xla/xla/mlir_hlo/tests/bufferize.mlir, third_party/xla/xla/mlir_hlo/tests/bufferize_one_shot.mlir, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/translate/hlo_to_mhlo/tests/custom_call.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/fully_connected_reference_model.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/fusion.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/import.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/import_async.hlotxt, third_party/xla/xla/translate/hlo_to_mhlo/tests/simple.hlo, third_party/xla/xla/translate/hlo_to_mhlo/tests/while.hlotxt, third_party/xla/xla/translate/mhlo_to_hlo/tests/dynamic.mlir, third_party/xla/xla/translate/mhlo_to_hlo/tests/export.mlir, third_party/xla/xla/translate/mhlo_to_hlo/tests/multiple_return_tuple.mlir, third_party/xla/xla/translate/mhlo_to_hlo/tests/sharding.mlir, third_party/xla/xla/translate/mhlo_to_hlo/tests/while.mlir",chsigg,False
"#shlo_ref Rework quantized tensor element types.

This separates the implementation of per-tensor and per-axis quantization
types. The goal is to allow value parametrized tests without having to use
templating mechanisms to create the values. This will also make the user
dispatching code much more concise.

- Information duplication is reduced in the quantized type structures (only the variants).
- The code is better decoupled.
- Per-tensor does not need to get the per axis 0th element for scales and zero points.

PiperOrigin-RevId: 622429656",Quentin Khan,qkhan@google.com,2024-04-06 12:28:54,"tensorflow/lite/experimental/shlo/BUILD, tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/abs.cc, tensorflow/lite/experimental/shlo/ops/abs_test.cc, tensorflow/lite/experimental/shlo/ops/binary_elementwise.h, tensorflow/lite/experimental/shlo/ops/binary_elementwise_test.cc, tensorflow/lite/experimental/shlo/ops/cbrt.cc, tensorflow/lite/experimental/shlo/ops/cbrt_test.cc, tensorflow/lite/experimental/shlo/ops/ceil.cc, tensorflow/lite/experimental/shlo/ops/ceil_test.cc, tensorflow/lite/experimental/shlo/ops/compare.cc, tensorflow/lite/experimental/shlo/ops/compare_test.cc, tensorflow/lite/experimental/shlo/ops/cosine.cc, tensorflow/lite/experimental/shlo/ops/cosine_test.cc, tensorflow/lite/experimental/shlo/ops/divide.cc, tensorflow/lite/experimental/shlo/ops/divide_test.cc, tensorflow/lite/experimental/shlo/ops/exponential.cc, tensorflow/lite/experimental/shlo/ops/exponential_minus_one.cc, tensorflow/lite/experimental/shlo/ops/exponential_minus_one_test.cc, tensorflow/lite/experimental/shlo/ops/exponential_test.cc, tensorflow/lite/experimental/shlo/ops/floor.cc, tensorflow/lite/experimental/shlo/ops/floor_test.cc, tensorflow/lite/experimental/shlo/ops/is_finite_bench.cc, tensorflow/lite/experimental/shlo/ops/is_finite_test.cc, tensorflow/lite/experimental/shlo/ops/log.cc, tensorflow/lite/experimental/shlo/ops/log_plus_one.cc, tensorflow/lite/experimental/shlo/ops/log_plus_one_test.cc, tensorflow/lite/experimental/shlo/ops/log_test.cc, tensorflow/lite/experimental/shlo/ops/logistic.cc, tensorflow/lite/experimental/shlo/ops/logistic_test.cc, tensorflow/lite/experimental/shlo/ops/maximum.cc, tensorflow/lite/experimental/shlo/ops/maximum_test.cc, tensorflow/lite/experimental/shlo/ops/minimum.cc, tensorflow/lite/experimental/shlo/ops/minimum_test.cc, tensorflow/lite/experimental/shlo/ops/multiply.cc, tensorflow/lite/experimental/shlo/ops/multiply_test.cc, tensorflow/lite/experimental/shlo/ops/negate.cc, tensorflow/lite/experimental/shlo/ops/negate_test.cc, tensorflow/lite/experimental/shlo/ops/sign.cc, tensorflow/lite/experimental/shlo/ops/sign_test.cc, tensorflow/lite/experimental/shlo/ops/sine.cc, tensorflow/lite/experimental/shlo/ops/sine_test.cc, tensorflow/lite/experimental/shlo/ops/sqrt.cc, tensorflow/lite/experimental/shlo/ops/sqrt_test.cc, tensorflow/lite/experimental/shlo/ops/subtract.cc, tensorflow/lite/experimental/shlo/ops/subtract_test.cc, tensorflow/lite/experimental/shlo/ops/tanh.cc, tensorflow/lite/experimental/shlo/ops/tanh_test.cc, tensorflow/lite/experimental/shlo/ops/test_util.h, tensorflow/lite/experimental/shlo/ops/unary_elementwise.h, tensorflow/lite/experimental/shlo/ops/unary_elementwise_test.cc, tensorflow/lite/experimental/shlo/overload.h, tensorflow/lite/experimental/shlo/overload_test.cc, tensorflow/lite/experimental/shlo/quantized_tensor_element_type.cc, tensorflow/lite/experimental/shlo/quantized_tensor_element_type.h, tensorflow/lite/experimental/shlo/quantized_tensor_element_type_test.cc, tensorflow/lite/experimental/shlo/tensor.cc, tensorflow/lite/experimental/shlo/tensor.h, tensorflow/lite/experimental/shlo/tensor_with_data.h",qukhan,False
"Automated Code Change

PiperOrigin-RevId: 622427154",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 12:08:30,"tensorflow/lite/core/BUILD, tensorflow/lite/core/interpreter.cc, tensorflow/lite/core/interpreter_builder.cc, tensorflow/lite/core/interpreter_experimental.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 622412129",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 10:12:58,"tensorflow/lite/tools/optimize/calibration/BUILD, tensorflow/lite/tools/optimize/calibration/calibration_logger.cc, tensorflow/lite/tools/optimize/calibration/calibration_reader.cc, tensorflow/lite/tools/optimize/calibration/calibration_reader.h, tensorflow/lite/tools/optimize/calibration/calibrator.cc, tensorflow/lite/tools/optimize/calibration/calibrator.h, tensorflow/lite/tools/optimize/calibration/calibrator_test.cc, tensorflow/lite/tools/optimize/calibration/logging_op_resolver.cc, tensorflow/lite/tools/optimize/calibration/logging_op_resolver.h, tensorflow/lite/tools/optimize/calibration/logging_op_resolver_test.cc",tensorflower-gardener,False
"Update GraphDef version to 1824.

PiperOrigin-RevId: 622402771",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 09:02:11,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-06

PiperOrigin-RevId: 622402727",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 09:01:58,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 622400767",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 08:47:29,"tensorflow/compiler/jit/ops/BUILD, tensorflow/compiler/jit/ops/xla_ops.cc",tensorflower-gardener,False
"Ensure that the module we consume has no unused computations. This can causes issues as we clone modules to support try_multiple_mesh_shapes, and cloning an HLO module removes dead computations leading to mismatches.

PiperOrigin-RevId: 622389491",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 07:25:26,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc,tensorflower-gardener,False
"Support shape transpose in `hlo_sharding_util::ReshapeSharding`.

Before this cl, `hlo_sharding_util::ReshapeSharding` can handle the cases where source and target shapes can be transformed to each other by merging and splitting dimension sizes. It returns `std::nullopt` if transpose is needed between source and target shapes.

This cl extracts the gcd(source_sharding_tile_size, target_shape) when `source_shape % source_sharding_tile_size == 0` in the major dimensions. An example is shown below.
```
input_shape: [6, 4]
output_shape: [2, 2, 3, 2]
input_sharding: {devices=[6,1]<=[6]}
```
output_sharding is `{devices=[2,1,1,1,3]<=[6] last_tile_dim_replicate}`. Before this cl, the output_sharding is `{replicated}`.
PiperOrigin-RevId: 622385031",Zixuan Jiang,zixuanjiang@google.com,2024-04-06 06:58:12,"third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util_test.cc, third_party/xla/xla/service/sharding_propagation_test.cc",ZixuanJiang,False
"Add unbounded dynamism test for ShiftRightArithmeticOp.

PiperOrigin-RevId: 622384560",Gunhyun Park,gunhyun@google.com,2024-04-06 06:55:05,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Automated Code Change

PiperOrigin-RevId: 622376129",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 05:57:10,"third_party/xla/xla/translate/BUILD, third_party/xla/xla/translate/xla_translate_main.cc, third_party/xla/xla/translate/xla_translate_opt_main.cc",tensorflower-gardener,False
"Add unbounded dynamism test for ShiftLeftOp.

PiperOrigin-RevId: 622373455",Gunhyun Park,gunhyun@google.com,2024-04-06 05:35:51,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Automated Code Change

PiperOrigin-RevId: 622368464",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 04:59:20,"tensorflow/core/framework/registration/BUILD, tensorflow/core/framework/registration/registration_test.cc",tensorflower-gardener,False
"IfrtServingExecutable support host callback execution

PiperOrigin-RevId: 622365713",Deqiang Chen,deqiangc@google.com,2024-04-06 04:36:41,"tensorflow/compiler/mlir/tfrt/transforms/ifrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/ifrt/extract_callback.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/extract_callback.h, tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_backend_compiler.cc, tensorflow/compiler/mlir/tfrt/utils/export.cc, tensorflow/compiler/mlir/tfrt/utils/export.h, tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test.cc, third_party/xla/xla/pjrt/BUILD",deqiangc,False
"[IFRT] Add fast pointer equality test for `DeviceList` internal state

Copied `DeviceList`s share their internal state with the source `DeviceList`.
We leverage it to make comparison faster between two `DeviceList` that are a
(transitive) copy of the other.

The single-device `DeviceList` does not use pointer equality test because the
internal state is not wrapped in a shared pointer, but this case will not
benefit from pointer equality test anyway.

PiperOrigin-RevId: 622347506",Hyeontaek Lim,hyeontaek@google.com,2024-04-06 02:51:43,"third_party/xla/xla/python/ifrt/device.h, third_party/xla/xla/python/ifrt/device_test.cc",hyeontaek,False
"Add unbounded dynamism test for ComplexOp.

PiperOrigin-RevId: 622343055",Gunhyun Park,gunhyun@google.com,2024-04-06 02:24:28,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Add unbounded dynamism test for XorOp.

PiperOrigin-RevId: 622341386",Gunhyun Park,gunhyun@google.com,2024-04-06 02:14:09,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Add unbounded dynamism test for MapOp.

PiperOrigin-RevId: 622339564",Gunhyun Park,gunhyun@google.com,2024-04-06 02:03:52,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Add unbounded dynamism test for ReducePrecisionOp.

PiperOrigin-RevId: 622337667",Gunhyun Park,gunhyun@google.com,2024-04-06 01:53:36,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Reverts 664bac882e57fa04900870162c04cbd3db853d1d

PiperOrigin-RevId: 622326029",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-06 00:52:44,"tensorflow/lite/delegates/gpu/cl/BUILD, tensorflow/lite/delegates/gpu/cl/opencl_wrapper.cc",tensorflower-gardener,False
"Add unbounded dynamism test for RemOp.

PiperOrigin-RevId: 622325701",Gunhyun Park,gunhyun@google.com,2024-04-06 00:51:17,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Add unbounded dynamism test for MinOp.

PiperOrigin-RevId: 622323978",Gunhyun Park,gunhyun@google.com,2024-04-06 00:41:59,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Add unbounded dynamism test for NotOp.

PiperOrigin-RevId: 622322298",Gunhyun Park,gunhyun@google.com,2024-04-06 00:32:01,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Add a method to get default layout in PyClient.

PiperOrigin-RevId: 622311375",Jieying Luo,jieying@google.com,2024-04-05 23:35:32,"third_party/xla/xla/python/py_client.cc, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_extension/__init__.pyi",jyingl3,False
"Allow both nb::tuple and nb::list for fastpath_data.

PiperOrigin-RevId: 622310671",Parker Schuh,parkers@google.com,2024-04-05 23:32:04,third_party/xla/xla/python/pjit.cc,pschuh,False
"[IFRT] Cache the hash of `DeviceList`

This change makes `xla::ifrt::DeviceList` cache its hash value once it is
computed. This makes it fast to compare two `DeviceList`s if they are created
from two different sources.

This is a part of the change that will enable the user of `DeviceList` build their
own cache to store runtime-specific attributes for the devices.

PiperOrigin-RevId: 622310612",Hyeontaek Lim,hyeontaek@google.com,2024-04-05 23:31:46,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/device.cc, third_party/xla/xla/python/ifrt/device.h, third_party/xla/xla/python/ifrt/device_test.cc",hyeontaek,False
"Add SourceLocation information to xla::InvalidArgument.

PiperOrigin-RevId: 622309810",Kyle Lucke,klucke@google.com,2024-04-05 23:27:16,"third_party/xla/xla/backends/interpreter/executable_base.cc, third_party/xla/xla/client/lib/matrix.cc, third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/layout_util.cc, third_party/xla/xla/literal.cc, third_party/xla/xla/literal.h, third_party/xla/xla/literal_comparison.cc, third_party/xla/xla/pjrt/utils.cc, third_party/xla/xla/python/ifrt/shape.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/service/buffer_assignment.cc, third_party/xla/xla/service/cpu/cpu_xfeed.cc, third_party/xla/xla/service/gpu/gpu_transfer_manager.cc, third_party/xla/xla/service/gpu/matmul_utils.cc, third_party/xla/xla/service/shape_inference.cc, third_party/xla/xla/service/transfer_manager.cc, third_party/xla/xla/shape_util.cc, third_party/xla/xla/stream_executor/tpu/tpu_executable_interface.cc, third_party/xla/xla/util.h",klucke,False
"Update comments per TODOs.

PiperOrigin-RevId: 622299908",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 22:40:45,"tensorflow/core/data/service/snapshot/snapshot_manager.cc, tensorflow/python/data/experimental/kernel_tests/service/distributed_save_load_ft_test.py",tensorflower-gardener,False
"Add GetDefaultLayoutForDevice to IFRT.

PiperOrigin-RevId: 622296342",Jieying Luo,jieying@google.com,2024-04-05 22:26:49,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/client.h, third_party/xla/xla/python/ifrt/mock.cc, third_party/xla/xla/python/ifrt/mock.h, third_party/xla/xla/python/ifrt_proxy/client/client.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.h, third_party/xla/xla/python/py_compile_only_client.cc",jyingl3,False
"Integrate LLVM at llvm/llvm-project@8487e05967aa

Updates LLVM usage to match
[8487e05967aa](https://github.com/llvm/llvm-project/commit/8487e05967aa)

PiperOrigin-RevId: 622295604",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 22:23:14,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl, third_party/xla/xla/mlir_hlo/transforms/collapse_parallel_loops_to_1d_pass.cc",tensorflower-gardener,False
"Pass MLIR bytecode across XLA Extension boundary for JAX when converting StableHLO<->MHLO

PiperOrigin-RevId: 622294316",Kevin Gleason,gleasonk@google.com,2024-04-05 22:17:45,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/mlir.cc, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_extension/mlir.pyi",GleasonK,False
"Defines a solver 'output' class, to replace the earlier (unnamed) tuple.

PiperOrigin-RevId: 622292813",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 22:11:05,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver_test.cc",tensorflower-gardener,False
"Use absl::Status rather than tsl::Status

PiperOrigin-RevId: 622291171",Kyle Lucke,klucke@google.com,2024-04-05 22:04:19,"third_party/xla/xla/backends/profiler/gpu/rocm_tracer.cc, third_party/xla/xla/backends/profiler/gpu/rocm_tracer.h, third_party/xla/xla/backends/profiler/tpu/tpu_tracer.cc, third_party/xla/xla/stream_executor/tpu/tsl_status_helper.h",klucke,False
"Internal cleanup of BUILD/.bzl files

PiperOrigin-RevId: 622283235",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 21:30:08,"WORKSPACE, ci/official/wheel_test/WORKSPACE",tensorflower-gardener,False
"Make common host memory spaces sharable across backends.

PiperOrigin-RevId: 622282662",Yunlong Liu,yunlongl@google.com,2024-04-05 21:27:48,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.cc, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.h, third_party/xla/xla/pjrt/host_memory_spaces.cc, third_party/xla/xla/pjrt/host_memory_spaces.h",yliu120,False
"Internal cleanup of BUILD/.bzl files

PiperOrigin-RevId: 622282379",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 21:26:33,ci/official/requirements_updater/WORKSPACE,tensorflower-gardener,False
"Breaks TF MacOS arm64 (min/max python) and Linux min_python Kokoro tests

Reverts cd3b38bfb0215e65d765dd766dad8e98068759db

PiperOrigin-RevId: 622281166",Carlos Guia,guia@google.com,2024-04-05 21:21:36,"tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/uniform_quantized_stablehlo_to_tfl_pass.cc",carlos-guia,False
"Revert TrivialDce pass

The need for this was due to a bug in MLIR's GreedyPatternRewriteDriver (https://github.com/llvm/llvm-project/issues/86765) which has been fixed (https://github.com/llvm/llvm-project/pull/86990), so the TrivialDce pass is no longer needed.

Reverts 04b31c7d1e349856d4bf7d7758020ce4a36dd21d

PiperOrigin-RevId: 622280033",Michael Levesque-Dion,mlevesquedion@google.com,2024-04-05 21:17:15,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/python/refine_polymorphic_shapes.cc",mlevesquedion,False
"Add a fallback when GetDefaultLayout is unimplemented for that backend.

PiperOrigin-RevId: 622278710",Jieying Luo,jieying@google.com,2024-04-05 21:12:21,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/dlpack.cc",jyingl3,False
"Fix test to load autotuning results from cache instead of actually computing it. This test wants to assume CUBLAS is always faster than Triton for this particular GEMM, and can only be so via autotuning DB.

PiperOrigin-RevId: 622277357",Mohammed Anany,manany@google.com,2024-04-05 21:06:48,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_compiler_test.cc, third_party/xla/xla/service/gpu/gpu_compiler_test_autotune_db.textproto",Moerafaat,False
"Automated Code Change

PiperOrigin-RevId: 622275280",Kyle Lucke,klucke@google.com,2024-04-05 20:59:48,"tensorflow/core/tpu/kernels/BUILD, tensorflow/core/tpu/kernels/tpu_compilation_cache_rpc_support.cc, tensorflow/core/tpu/kernels/tpu_compilation_cache_rpc_support.h, tensorflow/core/tpu/kernels/tpu_compilation_cache_service.cc, tensorflow/core/tpu/kernels/tpu_execute_op.cc, tensorflow/core/tpu/kernels/tpu_reshard_variables_op_util.cc, tensorflow/core/tpu/kernels/tpu_reshard_variables_op_util.h, tensorflow/core/tpu/kernels/tpu_util.h",klucke,False
"Slightly increase test tolerance for comparison with golden outputs in LSTM test.

PiperOrigin-RevId: 622265334",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 20:20:34,tensorflow/lite/kernels/lstm_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 622249641",Kyle Lucke,klucke@google.com,2024-04-05 19:18:58,"third_party/xla/xla/pjrt/distributed/client.cc, third_party/xla/xla/pjrt/distributed/client.h, third_party/xla/xla/pjrt/distributed/client_server_test.cc, third_party/xla/xla/pjrt/pjrt_api.cc, third_party/xla/xla/pjrt/pjrt_api.h, third_party/xla/xla/pjrt/pjrt_c_api_client.cc, third_party/xla/xla/pjrt/pjrt_c_api_client.h, third_party/xla/xla/pjrt/pjrt_stream_executor_client_test.cc, third_party/xla/xla/pjrt/status_casters.h, third_party/xla/xla/service/custom_call_sharding_helper.cc, third_party/xla/xla/service/custom_call_sharding_helper.h, third_party/xla/xla/service/tpu_computation_placer.h, third_party/xla/xla/service/xla_compile_main.cc, third_party/xla/xla/stream_executor/tpu/tpu_executor.cc, third_party/xla/xla/stream_executor/tpu/tpu_op_executable.cc, third_party/xla/xla/stream_executor/tpu/tpu_op_executable.h, third_party/xla/xla/translate/mhlo_to_hlo/layout_util.cc, third_party/xla/xla/translate/mhlo_to_hlo/layout_util.h, third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc, third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.h",klucke,False
"Lazily instantiates memory constraints.

PiperOrigin-RevId: 622248254",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 19:14:02,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 622232172",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 18:18:30,"tensorflow/core/ops/compat/ops_history_v2/BatchFunction.pbtxt, tensorflow/core/ops/ops.pbtxt",tensorflower-gardener,False
"Fix Copybara reversibility issues

PiperOrigin-RevId: 622224664",David Dunleavy,ddunleavy@google.com,2024-04-05 17:54:18,third_party/xla/xla/service/gpu/ir_emitter_triton_rocm.cc,ddunl,False
"Add flag to guard TF2/Min ICI weight optimization

PiperOrigin-RevId: 622224361",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 17:53:18,"tensorflow/core/common_runtime/BUILD, tensorflow/core/common_runtime/colocate_predecessor_trees_pass.cc, tensorflow/core/common_runtime/colocate_predecessor_trees_pass_test.cc, tensorflow/core/config/flag_defs.h, tensorflow/core/config/flags_api_wrapper.cc, tensorflow/python/flags_pybind.pyi",tensorflower-gardener,False
"Rolling back for now.

Reverts af4e1d5038bfb576d3fcc775962d764dccdc2d93

PiperOrigin-RevId: 622223304",David Majnemer,majnemer@google.com,2024-04-05 17:49:26,third_party/xla/.github/workflows/check_contents.yml,majnemer,False
"Add the priority_isolation policy to the BatchFunction op to disallow mixing the high priority and low priority tasks

PiperOrigin-RevId: 622221414",Eunjae Kim,eunjaekim@google.com,2024-04-05 17:42:30,"tensorflow/compiler/mlir/tensorflow/ir/tf_generated_ops.td, tensorflow/core/kernels/batch_kernels_test.cc, tensorflow/core/kernels/batching_util/batch_scheduler.cc, tensorflow/core/kernels/batching_util/batch_scheduler.h, tensorflow/core/kernels/batching_util/batch_scheduler_test.cc, tensorflow/core/kernels/batching_util/shared_batch_scheduler_test.cc, tensorflow/core/ops/batch_ops.cc",eunjaekim-0,False
"Fix error message about fallback call to MLIR bridge.

PiperOrigin-RevId: 622218232",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 17:32:00,tensorflow/compiler/mlir/tf2xla/api/v2/legalize_tf.cc,tensorflower-gardener,False
"Remove unused proto imports

PiperOrigin-RevId: 622215162",Hyeontaek Lim,hyeontaek@google.com,2024-04-05 17:21:55,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/sharding_serdes.proto, third_party/xla/xla/python/ifrt_proxy/common/BUILD, third_party/xla/xla/python/ifrt_proxy/common/types.proto",hyeontaek,False
"Adds utilities for extracting chosen node & edge strategies.

PiperOrigin-RevId: 622212589",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 17:13:39,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc,tensorflower-gardener,False
"PR #10649: [ROCm] Triton in XLA for ROCm - ir_emitter_triton related changes.

Imported from GitHub PR https://github.com/openxla/xla/pull/10649

Second commit of the series for enabling Triton in XLA for ROCm.

Copybara import of the project:

--
23d442f83c731cd86131bcd1d91c4e3d7cc42468 by Zoran Jovanovic <zjovanov@amd.com>:

[ROCm] Triton in XLA for ROCm - ir_emitter_triton related changes.

Merging this change closes #10649

PiperOrigin-RevId: 622202797",zoranjovanovic-ns,126815388+zoranjovanovic-ns@users.noreply.github.com,2024-04-05 16:37:28,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/triton.cc, third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/ir_emitter_triton_cuda.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_rocm.cc, third_party/xla/xla/service/gpu/llvm_gpu_backend/BUILD, third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc, third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.h",zoranjovanovic-ns,False
"[XLA:GPU] Move code to compute block id to tile offset indexing map to SymbolicTileAnalysis.

The block id to tile offset map is relevant for both Triton Emitter and Cost Model, so SymbolicTileAnalysis looks like a better place to have it ATM.

PiperOrigin-RevId: 622198142",Oleg Shyshkov,shyshkov@google.com,2024-04-05 16:19:17,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc",olegshyshkov,False
"#shlo_ref Use 4 bit integer wrapper in ops implementation.

PiperOrigin-RevId: 622184895",Quentin Khan,qkhan@google.com,2024-04-05 15:22:11,"tensorflow/lite/experimental/shlo/BUILD, tensorflow/lite/experimental/shlo/data_type.h, tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/abs.cc, tensorflow/lite/experimental/shlo/ops/abs_test.cc, tensorflow/lite/experimental/shlo/ops/binary_elementwise.h, tensorflow/lite/experimental/shlo/ops/count_leading_zeros.cc, tensorflow/lite/experimental/shlo/ops/count_leading_zeros_test.cc, tensorflow/lite/experimental/shlo/ops/not.cc, tensorflow/lite/experimental/shlo/ops/popcnt.cc, tensorflow/lite/experimental/shlo/ops/popcnt_test.cc, tensorflow/lite/experimental/shlo/ops/sign.cc, tensorflow/lite/experimental/shlo/ops/sign_test.cc, tensorflow/lite/experimental/shlo/ops/sqrt_test.cc, tensorflow/lite/experimental/shlo/ops/test_util.h, tensorflow/lite/experimental/shlo/ops/unary_elementwise_test.cc, tensorflow/lite/experimental/shlo/quantize.h, tensorflow/lite/experimental/shlo/quantize_test.cc, tensorflow/lite/experimental/shlo/quantized_tensor_element_type.h",qukhan,False
"Add `load()` statements for the builtin Bazel java rules

Loads are being added in preparation for moving the rules out of Bazel and into `rules_java`.

PiperOrigin-RevId: 622175129",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 14:36:44,"tensorflow/BUILD, tensorflow/tensorflow.bzl, third_party/flatbuffers/build_defs.bzl",tensorflower-gardener,False
"Enable latest ops and subgraph reshaping in OS Bazel builds

PiperOrigin-RevId: 622171519",Alan Kelly,alankelly@google.com,2024-04-05 14:19:54,tensorflow/lite/delegates/xnnpack/BUILD,alankelly,False
"Update triton compiler passes to support sparse dot operation.

1) TritonToTritonGPU: adds initial tensor encoding;
2) AccelerateMatmul: adds layout conversions;
3) ReduceDataDuplication: forces loading metadata into shared memory;
4) MatmulLoopPipeline: enables async loading of the metadata;
5) FenceInsertion: adds fences (Hopper only).

PiperOrigin-RevId: 622154852",Sergey Kozub,sergeykozub@google.com,2024-04-05 12:53:05,"third_party/triton/sparse_dot_passes.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/sparse_dot_passes.patch, third_party/xla/third_party/triton/workspace.bzl",sergeykozub,False
"Reverts 98493bf56e3e25a40d89797b070809c05d42d6ce

PiperOrigin-RevId: 622145041",Mohammed Anany,manany@google.com,2024-04-05 11:59:19,"third_party/triton/cl609333259.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/cl609333259.patch, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",Moerafaat,False
"Introduce a new dot operation with a sparse operand (2:4) and its lowering to Nvidia-specific PTX instructions (""mma.sp"" or ""wgmma.sp"").

PiperOrigin-RevId: 622135817",Sergey Kozub,sergeykozub@google.com,2024-04-05 11:08:00,"third_party/triton/sparse_dot_base.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/sparse_dot_base.patch, third_party/xla/third_party/triton/workspace.bzl",sergeykozub,False
"Add support for sparse dot (wgmma.sp) to NVGPU triton dialect.

PiperOrigin-RevId: 622126691",Sergey Kozub,sergeykozub@google.com,2024-04-05 10:25:10,"third_party/triton/sparse_dot_nvgpu.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/sparse_dot_nvgpu.patch, third_party/xla/third_party/triton/workspace.bzl",sergeykozub,False
"PR #11164: [XLA:GPU] bump up minimum PTX ISA to be 8.1 for CUDA >= 12.1

Imported from GitHub PR https://github.com/openxla/xla/pull/11164

NV internal workloads facing an error rn: `error   : Feature 'Kernel parameter size larger than 4352 bytes' requires PTX ISA .version 8.1 or later`. Bumping up to PTX81 solved the issue however it requires minimum CUDA 12.1 to work. So for WAR, I added a check to use PTX81 if CUDA 12.1 is available.
Copybara import of the project:

--
4a15c97bd021560c553b8f93b8c421fb8487f41e by cjkkkk <ske@nvidia.com>:

bump up minimum PTX ISA to be 8.1 for CUDA >= 12.1

--
b04703e5fced0937bdb68f177ad908bcec3d153c by cjkkkk <ske@nvidia.com>:

include cuda.h

Merging this change closes #11164

PiperOrigin-RevId: 622120255",Shanbin Ke,ske@nvidia.com,2024-04-05 09:52:28,third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc,Cjkkkk,False
"compat: Update forward compatibility horizon to 2024-04-05

PiperOrigin-RevId: 622110391",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 09:02:45,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1823.

PiperOrigin-RevId: 622110228",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 09:02:14,tensorflow/core/public/version.h,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@e0e615efac52

Updates LLVM usage to match
[e0e615efac52](https://github.com/llvm/llvm-project/commit/e0e615efac52)

PiperOrigin-RevId: 622104340",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 08:31:07,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"Make the CustomAggregator op stateless

This cl make the CustomAggregator output a fixed size histogram, thus make it stateless. Histograms are aggregated with the first bin width so the behavior is kept the same as existing implementation.

PiperOrigin-RevId: 622099935",Thai Nguyen,thaink@google.com,2024-04-05 08:08:54,"tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/calibration_parameters.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/calibration_parameters_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/pre_calibration_component.mlir, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics.proto, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_histogram.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_test.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/custom_aggregator_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/integration_test/custom_aggregator_op_test.py, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_custom_aggregation_ops.cc, tensorflow/compiler/mlir/quantization/tensorflow/tests/insert_custom_aggregation_ops.mlir",thaink,False
"Add GetDefaultLayout to PjRtTopologyDescription. This is needed to support py_compile_only_client.

PiperOrigin-RevId: 622056553",Parker Schuh,parkers@google.com,2024-04-05 03:54:45,"third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h, third_party/xla/xla/pjrt/pjrt_c_api_client.h, third_party/xla/xla/pjrt/pjrt_compiler.h, third_party/xla/xla/pjrt/pjrt_compiler_test.cc",pschuh,False
"Add `load()` statements for the builtin Bazel java rules

Loads are being added in preparation for moving the rules out of Bazel and into `rules_java`.

PiperOrigin-RevId: 622055151",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-05 03:44:26,"WORKSPACE, tensorflow/lite/core/shims/BUILD, tensorflow/lite/core/shims/cc_library_with_tflite.bzl",tensorflower-gardener,False
"Calculate min/max and histogram inside the CustomAggregator op

This cl is the first part of removing the Calibration singleton:
- Part 1 (this cl): Move the min/max and histogram calculation inside CustomAggregator op.
- Part 2 (follow-up cl): Aggregate the statistics inside StatisticsSaver op and remove the singleton.

PiperOrigin-RevId: 622053138",Thai Nguyen,thaink@google.com,2024-04-05 03:31:14,"tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/calibration_parameters.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/calibration_parameters_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/post_calibration_component.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/pre_calibration_component.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/replace_stablehlo_ops_in_main_function_with_xla_call_module_ops.mlir, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_average_min_max.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_average_min_max.h, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_base.h, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_histogram.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_histogram.h, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_min_max.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_min_max.h, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_collector_test.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibrator_singleton.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibrator_singleton.h, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibrator_singleton_test.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/custom_aggregator_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/calibrator/integration_test/custom_aggregator_op_test.py, tensorflow/compiler/mlir/quantization/tensorflow/passes/convert_custom_aggregation_op_to_quant_stats.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_custom_aggregation_ops.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/tf_quant_ops.td, tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/tensorflow/tests/convert_custom_aggregation_op_to_quant_stats.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/insert_custom_aggregation_ops.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/issue_ids_of_custom_aggregation_ops.mlir",thaink,False
"[xla:gpu] Pass custom-call results as xla:ffi results to handlers

PiperOrigin-RevId: 622044812",Eugene Zhulenev,ezhulenev@google.com,2024-04-05 02:50:19,"third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/service/gpu/custom_call_test.cc, third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc",ezhulenev,False
"Transpose weights for hybrid quantized convolution

Factored out function for matching input and kernel and function for transposing the weight values to share implementation between SRQ and weight-only convolution.

PiperOrigin-RevId: 622023834",Doyeon Kim,doyeonkim@google.com,2024-04-05 00:55:52,"tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/uniform_quantized_stablehlo_to_tfl_pass.cc",doyeonkim0,False
"Integrate StableHLO at openxla/stablehlo@1bdf7c26

PiperOrigin-RevId: 622009836",Abhinav Gunjal,agunjal@google.com,2024-04-04 23:51:56,"third_party/stablehlo/workspace.bzl, third_party/xla/third_party/stablehlo/workspace.bzl",abhigunj,False
"Crash on HLOs with nested tuples in conditionals.

PiperOrigin-RevId: 622009093",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 23:48:35,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h",tensorflower-gardener,False
"[xla:ffi] Add auto-binding for FFI results

PiperOrigin-RevId: 622006316",Eugene Zhulenev,ezhulenev@google.com,2024-04-04 23:35:59,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc",ezhulenev,False
"[xla:ffi] Add support for annotating FFI results with type tags to distingush them from regular args

PiperOrigin-RevId: 622004088",Eugene Zhulenev,ezhulenev@google.com,2024-04-04 23:26:15,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/call_frame.h",ezhulenev,False
"Implement a pass to merge requantize+dequantize for StableHLO Quantizer

This pass will convert req+dq pattern in the quantized fusion to dq+relu(6).

Also add an option in PipelineConfig to enable this pass. This option is defaulted to false for ODML pipeline. But enabled by server.

PiperOrigin-RevId: 621997250",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 22:58:57,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/pass_pipeline.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/merge_fusion_with_dequantize.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.td, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize_composite_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/merge-fusion-with-dequantize.mlir",tensorflower-gardener,False
"Update OpenCL wrapper when using ICD loader for Google Linux.

Also add TFLITE_LOG to show which loading path is used.

PiperOrigin-RevId: 621991152",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 22:36:24,"tensorflow/lite/delegates/gpu/cl/BUILD, tensorflow/lite/delegates/gpu/cl/opencl_wrapper.cc",tensorflower-gardener,False
"Import nanobind caster for std::string to avoid casting error.

PiperOrigin-RevId: 621985950",Parker Schuh,parkers@google.com,2024-04-04 22:19:47,"third_party/xla/xla/python/weakref_lru_cache.cc, third_party/xla/xla/python/weakref_lru_cache_test.py",pschuh,False
"Fix for a bug where the while loop fusible sinking crashes when all of the while loop invariant operands have been propagated.

PiperOrigin-RevId: 621985445",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 22:18:12,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/while_loop_fusible_sinking.cc",tensorflower-gardener,False
"Disabled unsupported cases

PiperOrigin-RevId: 621983418",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 22:10:55,tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py,tensorflower-gardener,False
"Setup boiler plate (entry point, test infra, pass header and td gen) for shlo converter.

PiperOrigin-RevId: 621966799",Luke Boyer,lukeboyer@google.com,2024-04-04 21:12:33,"tensorflow/compiler/mlir/lite/stablehlo/odml_converter/BUILD, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/odml_converter_main.cc, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/passes.h, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/passes.td, tensorflow/compiler/mlir/lite/stablehlo/odml_converter/tests/BUILD",LukeBoyer,False
"[xla][gpu] Change the point-to-point pipeliner to produce an intermediate form
of pipelined code.

The pipeliner now rotates all point-to-point instructions for a communication
chain, including Send, Recv, SendDone and RecvDone, in a while-body. We will
add a post-scheduling pass to further transform such a pipelined loop by
pushing the SendDone and RecvDone to the next loop iteration.

Adjust the p2p-schedule-preparation pass to reflect this change.

PiperOrigin-RevId: 621959951",Bixia Zheng,bixia@google.com,2024-04-04 20:50:17,"third_party/xla/xla/service/gpu/gpu_hlo_schedule_test.cc, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.cc, third_party/xla/xla/service/p2p_schedule_preparation.cc, third_party/xla/xla/service/p2p_schedule_preparation_test.cc",bixia1,False
"Remove obsolete TODOs.

PiperOrigin-RevId: 621958583",Jieying Luo,jieying@google.com,2024-04-04 20:45:19,tensorflow/compiler/jit/pjrt_device_context.cc,jyingl3,False
"[XLA:Runtime] Moved the nccl_clique target to runtime folder.

This is part of an effort to move runtime targets to the runtime folder. #5758

PiperOrigin-RevId: 621957117",Sara Smoot,sarasmoot@google.com,2024-04-04 20:39:57,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/mock_nccl_utils.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/nccl_clique.cc, third_party/xla/xla/service/gpu/runtime/nccl_clique.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.h",sgerrard,False
"Add missing deps.

PiperOrigin-RevId: 621956688",Changhui Lin,changhuilin@google.com,2024-04-04 20:38:34,tensorflow/c/experimental/ops/gen/cpp/renderers/BUILD,changhuilin,False
"#tf-data-service Update docstrings for `distributed_save` and `load`.

PiperOrigin-RevId: 621953294",Yang Chen,yangchen@google.com,2024-04-04 20:27:34,"tensorflow/python/data/experimental/ops/distributed_save_op.py, tensorflow/python/data/ops/dataset_ops.py",yangustc07,False
"presubmits: Add a presubmit for CHECK and related macros.

Generally it's a better idea to find a way to report the error rather than to
crash the process. When XLA is used in a server, crashes expose the server to
potential queries of death when unexpected data or API calls occur.

Removing existing crashes is a longer-term fixit-type effort, but at least we
can prevent new intentional crashes from slipping in.

PiperOrigin-RevId: 621952801",pizzud,pizzud@google.com,2024-04-04 20:25:52,third_party/xla/.github/workflows/check_contents.yml,pizzud,False
"Adding additional variables that could be of used in determining compatibility.

PiperOrigin-RevId: 621942234",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 19:46:59,tensorflow/lite/experimental/acceleration/compatibility/variables.h,tensorflower-gardener,False
"Add SourceLocation information to xla::Unimplemented errors.

PiperOrigin-RevId: 621934438",Kyle Lucke,klucke@google.com,2024-04-04 19:16:37,"third_party/xla/xla/service/computation_layout.cc, third_party/xla/xla/service/dynamic_dimension_inference.cc, third_party/xla/xla/util.h",klucke,False
"Create an executable wrapper to run host callback.

PiperOrigin-RevId: 621933538",Deqiang Chen,deqiangc@google.com,2024-04-04 19:12:59,"tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/tf_host_callback.cc, tensorflow/core/tfrt/ifrt/tf_host_callback.h, tensorflow/core/tfrt/ifrt/tf_host_callback_test.cc",deqiangc,False
"Convert unquantized XlaCallModule to func.call

Some composite ops may be unquantized due to not supported or selective quantization. We still want to convert them to func.call. This CL converts any unquantized XlaCallModule ops to func.call. This covers both srq and weight-only cases.

PiperOrigin-RevId: 621919066",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 18:25:58,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.td, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize_composite_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/xla_call_module_to_call.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test_base.py, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/post_calibration_component.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/xla_call_module_to_call.mlir",tensorflower-gardener,False
"PR #10503: Fix log1p inaccuracies on complex inputs with large absolute values.

Imported from GitHub PR https://github.com/openxla/xla/pull/10503

As in the title.

Tests and improvement reports are in https://github.com/google/jax/pull/20144.

Accuracy tests are enabled in https://github.com/google/jax/pull/20436
Copybara import of the project:

--
2b8f2539d6bf364c0a97f65e186430c5eb3ed07b by Pearu Peterson <pearu.peterson@gmail.com>:

Fix log1p inaccuracies on complex inputs with large absolute values.

--
d35cef4f5fa09482c49edfee709e86c5ca29adde by Pearu Peterson <pearu.peterson@gmail.com>:

Add tests to complex Log1p

Merging this change closes #10503

PiperOrigin-RevId: 621917683",Pearu Peterson,pearu.peterson@gmail.com,2024-04-04 18:21:18,"third_party/xla/xla/python/xla_client.py, third_party/xla/xla/service/elemental_ir_emitter.cc, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/complex_unary_op_samples.h, third_party/xla/xla/tests/complex_unary_op_test.cc, third_party/xla/xla/tests/generate_complex_unary_op_samples.py",pearu,False
"Added a virtual function (`CanPropagateShardingToOperands`) to `CustomCallShardingHelper` that can be used to specify whether a custom call can propagate sharding from/to its operands.

PiperOrigin-RevId: 621915832",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 18:15:27,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc, third_party/xla/xla/service/custom_call_sharding_helper.cc, third_party/xla/xla/service/custom_call_sharding_helper.h, third_party/xla/xla/service/sharding_propagation.cc, third_party/xla/xla/service/sharding_propagation.h, third_party/xla/xla/service/spmd/dot_handler.cc",tensorflower-gardener,False
"[xla] Add a method to express that we want to schedule a node as early as
possible.

We have kForceDelay to express that we want to schedule a node as late as
possible. This change adds kForceEarly for similar purpose.

This is used for the GPU scheduler initially, for scheduling pipelined Recv
close to RecvDone, so that copies of RecvDone can be removed.

PiperOrigin-RevId: 621905910",Bixia Zheng,bixia@google.com,2024-04-04 17:43:37,"third_party/xla/xla/service/gpu/gpu_hlo_schedule.cc, third_party/xla/xla/service/latency_hiding_scheduler.cc, third_party/xla/xla/service/latency_hiding_scheduler.h",bixia1,False
"[XLA:GPU] Add TiledHloInstruction.

A graph of TiledHloInstruction represents an HLO graph with associated concrete tiles sizes. In the following changes I'll add code to build the graph from SymbolicTiledHloInstruction and use the tiled graph for Cost Model and Triton codegen.

PiperOrigin-RevId: 621903701",Oleg Shyshkov,shyshkov@google.com,2024-04-04 17:37:31,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/tiled_hlo_instruction.cc, third_party/xla/xla/service/gpu/model/tiled_hlo_instruction.h, third_party/xla/xla/service/gpu/model/tiled_hlo_instruction_test.cc",olegshyshkov,False
"[pjrt] NFC: Rename HostBufferSemantics::kZeroCopy to kImmutableZeroCopy

PiperOrigin-RevId: 621900021",Eugene Zhulenev,ezhulenev@google.com,2024-04-04 17:25:10,"tensorflow/compiler/jit/pjrt_device_context.cc, third_party/xla/xla/pjrt/c/CHANGELOG.md, third_party/xla/xla/pjrt/c/pjrt_c_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.cc, third_party/xla/xla/pjrt/cpu/abstract_tfrt_cpu_buffer.cc, third_party/xla/xla/pjrt/pjrt_c_api_client.cc, third_party/xla/xla/pjrt/pjrt_client.h, third_party/xla/xla/pjrt/pjrt_client_test.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/python/ifrt/array_impl_test_lib.cc, third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_client.cc, third_party/xla/xla/python/py_values.cc, third_party/xla/xla/python/xla.cc",ezhulenev,False
"Fix msan error introduced in https://github.com/openxla/xla/commit/7b4b2754f96309dd76d0ecbea12c2e9b5533f74d.

The commit above makes accessing args.attributes unconditionally when creating a PJRT C API client.

PiperOrigin-RevId: 621894681",Jieying Luo,jieying@google.com,2024-04-04 17:08:36,third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc,jyingl3,False
"Reverts 4242a023fa1a1c44d7e8871eaf835ae836ee70d0

PiperOrigin-RevId: 621883586",Mohammed Anany,manany@google.com,2024-04-04 16:30:33,"third_party/triton/cl609333259.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/cl609333259.patch, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",Moerafaat,False
"Disable a test that is failing on H100

PiperOrigin-RevId: 621862882",Adrian Kuegel,akuegel@google.com,2024-04-04 15:10:32,third_party/xla/xla/service/BUILD,akuegel,False
"Better disable mechanism for tensor cores for 8-bit-or-less dot with F32.

PiperOrigin-RevId: 621860879",Mohammed Anany,manany@google.com,2024-04-04 15:02:55,"third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",Moerafaat,False
"Bump the operands+outputs threshold to allow larger fusions.

PiperOrigin-RevId: 621857328",Thomas Joerg,tjoerg@google.com,2024-04-04 14:47:48,third_party/xla/xla/service/gpu/gpu_fusible.h,thomasjoerg,False
"Reverts 9a5c06c9382417ba65bd8e79ef0de9ba093f9086

PiperOrigin-RevId: 621842461",Adrian Kuegel,akuegel@google.com,2024-04-04 13:41:32,"third_party/llvm/vs2019.patch, third_party/llvm/workspace.bzl",akuegel,False
"Integrate LLVM at llvm/llvm-project@c511c90680ee

Updates LLVM usage to match
[c511c90680ee](https://github.com/llvm/llvm-project/commit/c511c90680ee)

PiperOrigin-RevId: 621836786",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 13:15:13,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/hlo_xla_runtime_pipeline.cc",tensorflower-gardener,False
"Internal cleanup of BUILD/.bzl files

PiperOrigin-RevId: 621826959",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 12:28:50,third_party/xla/xla/mlir_hlo/WORKSPACE,tensorflower-gardener,False
"[xla:ffi] Unit tests for CPU type-safe custom call API

Port existing CPU custom call tests to the new FFI API. Add new test cases, mostly taken from GPU custom call tests.
Implements #10060.

The tests are disabled for now, they will be enabled when #10056 is finished.

PiperOrigin-RevId: 621815176",Adam Banaś,adambanas@google.com,2024-04-04 11:28:46,"third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/custom_call_test.cc",Adam-Banas,False
"PR #11139: [GPU] Enable cuDNN integer math mode only with v9.1+.

Imported from GitHub PR https://github.com/openxla/xla/pull/11139

Copybara import of the project:

--
8b346d0c6bc03b58ddca79e345e9b57b6af05cb2 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Enable cuDNN integer math mode only with v9.1+.

Merging this change closes #11139

PiperOrigin-RevId: 621803779",Ilia Sergachev,isergachev@nvidia.com,2024-04-04 10:33:28,"third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc",sergachev,False
"Automated Code Change

PiperOrigin-RevId: 621803695",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 10:33:04,"third_party/xla/xla/service/cpu/tests/BUILD, third_party/xla/xla/service/cpu/tests/cpu_bytesizeof_test.cc, third_party/xla/xla/service/cpu/tests/cpu_dyn_shape_test.cc, third_party/xla/xla/service/cpu/tests/cpu_eigen_dot_operation_test.cc, third_party/xla/xla/service/cpu/tests/cpu_external_constants_test.cc, third_party/xla/xla/service/cpu/tests/cpu_fusion_test.cc, third_party/xla/xla/service/cpu/tests/cpu_infeed_test.cc, third_party/xla/xla/service/cpu/tests/cpu_intrinsic_test.cc, third_party/xla/xla/service/cpu/tests/cpu_key_value_sort_test.cc, third_party/xla/xla/service/cpu/tests/cpu_literal_caching_test.cc, third_party/xla/xla/service/cpu/tests/cpu_noalias_test.cc, third_party/xla/xla/service/cpu/tests/cpu_outfeed_test.cc, third_party/xla/xla/service/cpu/tests/cpu_profiling_test.cc, third_party/xla/xla/service/cpu/tests/cpu_spmd_compile_test.cc, third_party/xla/xla/service/cpu/tests/cpu_topk_test.cc, third_party/xla/xla/service/cpu/tests/cpu_vectorization_test.cc, third_party/xla/xla/service/cpu/tests/cpu_while_test.cc, third_party/xla/xla/service/cpu/tests/tree_reduction_rewriter_test.cc",tensorflower-gardener,False
"PR #10763: [XLA:GPU] Fix cuDNN FMHA fwd scale not passed into cuDNN

Imported from GitHub PR https://github.com/openxla/xla/pull/10763

* FMHA fwd scale is not passed into cuDNN in pattern bmm1-scale-softmax-(dropout)-bmm2. Work correctly on other patterns (with bias/mask).
* A quick fix is that I simply copy what works in bwd scale setting.
* Weirdly e2e run does not capture this since we do have cases where fwd scale is not 1.
Copybara import of the project:

--
4a63497ba070f2b52c2942bccf8156f3a3bbd4ab by cjkkkk <ske@nvidia.com>:

fix scale is not passed into cudnn

--
b333fa3ce10712f6e9f4590478b6c053f331e00b by cjkkkk <ske@nvidia.com>:

increase scale in pattern bmm1-scale-softmax-bmm2 test

--
a6eb74b553b26d415be9d97265be0789a7bff47c by cjkkkk <ske@nvidia.com>:

use magic 37 as WAR

Merging this change closes #10763

PiperOrigin-RevId: 621801343",Shanbin Ke,ske@nvidia.com,2024-04-04 10:21:52,"third_party/xla/xla/service/gpu/gpu_fused_mha_runner.cc, third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc",Cjkkkk,False
"Automated Code Change

PiperOrigin-RevId: 621801304",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 10:21:41,"third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/lower_tensors.cc, third_party/xla/xla/service/gpu/fusions/mlir/lower_to_llvm.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/simplify_arith.cc, third_party/xla/xla/service/gpu/fusions/mlir/type_util_test.cc",tensorflower-gardener,False
"Collect quantization results from `ModuleOp`.

With this change, `QuantizationReport` will have its `quantization_results_` field populated by collecting quantization results from `ModuleOp`.

PiperOrigin-RevId: 621789311",Dan Suh,dansuh@google.com,2024-04-04 09:26:51,"tensorflow/compiler/mlir/quantization/common/lift_as_function_call.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/report.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/report.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/report_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc",dansuh17,False
"compat: Update forward compatibility horizon to 2024-04-04

PiperOrigin-RevId: 621783654",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 09:03:02,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1822.

PiperOrigin-RevId: 621783524",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 09:02:37,tensorflow/core/public/version.h,tensorflower-gardener,False
"Integrate Triton up to [e902d3b6](https://github.com/openai/triton/commits/e902d3b617b100f38caac5c4f74e462edab5f18a)

PiperOrigin-RevId: 621779585",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 08:44:42,"third_party/triton/cl617812302.patch, third_party/triton/cl619146327.patch, third_party/triton/cl619443019.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/cl617812302.patch, third_party/xla/third_party/triton/cl619146327.patch, third_party/xla/third_party/triton/cl619443019.patch, third_party/xla/third_party/triton/workspace.bzl",tensorflower-gardener,False
"Internal CI configuration to run tests on H100

Do some required BUILD file adjustments

PiperOrigin-RevId: 621777011",Adrian Kuegel,akuegel@google.com,2024-04-04 08:33:36,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/kernels/BUILD",akuegel,False
"Implement convolution via indexing maps.

Reusing the dot emitter code, which is (almost) the same as the convolution code.
Note that adding the tests uncovered an issue with convolution indexing analysis - it was using an incorrect divisor when `feature_group_count` attribute is used.

PiperOrigin-RevId: 621769303",Sergey Kozub,sergeykozub@google.com,2024-04-04 07:58:33,"third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc",sergeykozub,False
"Support lifting of same shape bias for `stablehlo.convolution`.

Although it is common to write models where 1D constant would be broadcasted, it is possible to explicitly give bias with the desired shape.
The examples in `odml_coverage_test` are such.
Handle such cases where the bias has the same shape as target accumulation.

Additionally, add `FindOperandType` for finding an operand of specific type and respective tests.

PiperOrigin-RevId: 621749920",Jiyoun (Jen) Ha,jiyounha@google.com,2024-04-04 06:41:48,"tensorflow/compiler/mlir/lite/stablehlo/transforms/uniform_quantized_stablehlo_to_tfl_pass.cc, tensorflow/compiler/mlir/quantization/common/BUILD, tensorflow/compiler/mlir/quantization/common/attrs_and_constraints.h, tensorflow/compiler/mlir/quantization/common/attrs_and_constraints_test.cc, tensorflow/compiler/mlir/quantization/common/lift_as_function_call_test.cc, tensorflow/compiler/mlir/quantization/common/test_base.h, tensorflow/compiler/mlir/quantization/stablehlo/ops/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/ops/stablehlo_op_quant_spec_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/lift_quantizable_spots_as_functions_fusion.td, tensorflow/compiler/mlir/quantization/tensorflow/cc/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/cc/constant_fold_test.cc",chococigar,False
"Automated Code Change

PiperOrigin-RevId: 621738848",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-04 05:39:37,"tensorflow/core/tfrt/saved_model/tests/BUILD, tensorflow/core/tfrt/saved_model/tests/saved_model_test.cc",tensorflower-gardener,False
"Rename WeightOnlyPreset to WeightOnlyPtqPreset

PiperOrigin-RevId: 621720590",Doyeon Kim,doyeonkim@google.com,2024-04-04 03:54:06,"tensorflow/compiler/mlir/lite/quantization/stablehlo/quantization.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/python/quantization.py, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto",doyeonkim0,False
"Relax subgraph byte constraint to `required_bytes <= bytes` rather than exact match.

This has been an error raised for some issues [github example](https://github.com/tensorflow/tensorflow/issues/14929).

If the required bytes are covered by the current model, there is no need to raise an error due to exact size mismatch on user's side.

PiperOrigin-RevId: 621699856",Jiyoun (Jen) Ha,jiyounha@google.com,2024-04-04 01:50:32,tensorflow/lite/core/subgraph.cc,chococigar,False
"Expose QuantizationConfig to TFLite converter

PiperOrigin-RevId: 621689064",Doyeon Kim,doyeonkim@google.com,2024-04-04 00:46:07,"tensorflow/compiler/mlir/lite/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/lite/quantization/stablehlo/quantization.cc, tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/lite/python/lite.py, tensorflow/lite/python/lite_v2_test.py",doyeonkim0,False
"Update SharedBatchScheduler to use the mixed priority batching policy

PiperOrigin-RevId: 621682727",Eunjae Kim,eunjaekim@google.com,2024-04-04 00:15:41,"tensorflow/core/kernels/BUILD, tensorflow/core/kernels/batch_kernels.cc, tensorflow/core/kernels/batch_kernels_test.cc, tensorflow/core/kernels/batching_util/BUILD, tensorflow/core/kernels/batching_util/batch_resource_base.cc, tensorflow/core/kernels/batching_util/batch_resource_base.h, tensorflow/core/kernels/batching_util/batch_scheduler_utils.cc, tensorflow/core/kernels/batching_util/batch_scheduler_utils.h, tensorflow/core/kernels/batching_util/batch_scheduler_utils_test.cc, tensorflow/core/kernels/batching_util/shared_batch_scheduler.h, tensorflow/core/kernels/batching_util/shared_batch_scheduler_test.cc",eunjaekim-0,False
"Minimize number of Copybara transforms that operate on `tensorflow/third_party`

PiperOrigin-RevId: 621679504",David Dunleavy,ddunleavy@google.com,2024-04-04 00:02:10,"third_party/compute_library/build_defs.bzl, third_party/gpus/cuda_configure.bzl, third_party/gpus/rocm_configure.bzl, third_party/hwloc/hwloc.BUILD, third_party/llvm_openmp/BUILD, third_party/llvm_openmp/cmake_vars.bzl, third_party/mkl_dnn/build_defs.bzl, third_party/mkl_dnn/mkldnn_acl.BUILD, third_party/mkl_dnn/mkldnn_v1.BUILD, third_party/mpitrampoline/mpitrampoline.BUILD, third_party/nanobind/nanobind.BUILD, third_party/nccl/nccl_configure.bzl, third_party/py/ml_dtypes/ml_dtypes.BUILD, third_party/py/ml_dtypes/ml_dtypes.tests.BUILD, third_party/py/non_hermetic/ml_dtypes/ml_dtypes.BUILD, third_party/py/non_hermetic/ml_dtypes/ml_dtypes.tests.BUILD, third_party/pybind11.BUILD, third_party/remote_config/remote_platform_configure.bzl, third_party/systemlibs/pybind11.BUILD, third_party/tensorrt/tensorrt_configure.bzl, third_party/xla/third_party/compute_library/build_defs.bzl, third_party/xla/third_party/llvm_openmp/BUILD, third_party/xla/third_party/llvm_openmp/cmake_vars.bzl, third_party/xla/third_party/nanobind/nanobind.BUILD, third_party/xla/third_party/py/ml_dtypes/ml_dtypes.BUILD, third_party/xla/third_party/py/ml_dtypes/ml_dtypes.tests.BUILD, third_party/xla/third_party/py/non_hermetic/ml_dtypes/ml_dtypes.BUILD, third_party/xla/third_party/py/non_hermetic/ml_dtypes/ml_dtypes.tests.BUILD, third_party/xla/third_party/tsl/third_party/git/git_configure.bzl, third_party/xla/third_party/tsl/third_party/llvm_openmp/openmp.bzl, third_party/xla/third_party/tsl/third_party/py/ml_dtypes/ml_dtypes.BUILD, third_party/xla/third_party/tsl/third_party/py/ml_dtypes/ml_dtypes.tests.BUILD, third_party/xla/third_party/tsl/third_party/py/non_hermetic/ml_dtypes/ml_dtypes.BUILD, third_party/xla/third_party/tsl/third_party/py/non_hermetic/ml_dtypes/ml_dtypes.tests.BUILD",ddunl,False
"Integrate LLVM at llvm/llvm-project@9df19ce40281

Updates LLVM usage to match
[9df19ce40281](https://github.com/llvm/llvm-project/commit/9df19ce40281)

PiperOrigin-RevId: 621676170",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 23:47:31,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",tensorflower-gardener,False
"[PJRT C API] Plumb plugin attributes from plugin to JAX python.

Also add a method for the plugin to return an xla_version plugin attribute.

Currently jaxlib pins a TPU/GPU backend, and uses `xla_extension_version` for backend version. As we want to stop pinning TPU/GPU backend and allow pip install different backend separately, we need this `xla_version` for features that are not capture by PJRT C API version. `xla_extension_version` will still be used for API changes such as xla_client.py, or any XLA changes in jaxlib that are not part of plugins.

PiperOrigin-RevId: 621672421",Jieying Luo,jieying@google.com,2024-04-03 23:30:33,"third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_internal.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_helpers.h, third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc, third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.h, third_party/xla/xla/pjrt/pjrt_c_api_client.cc, third_party/xla/xla/pjrt/pjrt_c_api_client.h, third_party/xla/xla/pjrt/pjrt_client.h, third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc",jyingl3,False
"Remove fallback call to MLIR bridge.

PiperOrigin-RevId: 621669154",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 23:16:23,"tensorflow/compiler/mlir/tf2xla/api/v2/legalize_tf.cc, tensorflow/compiler/mlir/tf2xla/api/v2/legalize_tf_test.cc",tensorflower-gardener,False
"Remove the constraint that tokens cannot be passed as entry parameters in `HloVerifier`. Also fixed some headers.

PiperOrigin-RevId: 621665981",Yue Sheng,yueshengys@google.com,2024-04-03 23:03:14,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/token_hlo_test.cc",yueshengys,False
"Add IFRT pass that verifies if all !ifrt.arrays have sharding specified.

PiperOrigin-RevId: 621664546",Ionel Gog,icgog@google.com,2024-04-03 22:57:45,"third_party/xla/xla/python/ifrt/ir/tests/BUILD, third_party/xla/xla/python/ifrt/ir/tests/ifrt-opt.cc, third_party/xla/xla/python/ifrt/ir/tests/ifrt_verify_sharding_specified.mlir, third_party/xla/xla/python/ifrt/ir/transforms/BUILD, third_party/xla/xla/python/ifrt/ir/transforms/ifrt_verify_sharding_specified_pass.cc, third_party/xla/xla/python/ifrt/ir/transforms/passes.h, third_party/xla/xla/python/ifrt/ir/transforms/passes.td",ICGog,False
"Assign `layer_index` and `num_layers` as we build KV cache from composite op.

PiperOrigin-RevId: 621661915",Haoliang Zhang,haoliang@google.com,2024-04-03 22:47:39,"tensorflow/compiler/mlir/lite/stablehlo/tests/legalize-stablehlo-tfl-composite.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_composite_to_tfl_custom.cc",haozha111,False
"[XLA] Make shape util fuzzer happy

Handle the following cases:
1. Don't call ShapeUtil::ByteSizeOf() on a shape that isn't a dense array.
2. Don't call ShapeUtil::ByteSizeOf() on a shape with unbounded dim(s).
3. Handle negative element_size_in_bits field in the Layout proto. Change Layout::element_size_in_bits_ to match the proto type to avoid narrowing conversion and sign loss. Then check if the field is negative and return an error during validation.

PiperOrigin-RevId: 621642403",Vlad Sytchenko,vsytch@google.com,2024-04-03 21:36:36,"third_party/xla/xla/layout.h, third_party/xla/xla/layout_util.cc",vsytch,False
"Remove add_default_attributes param as it is not being used by clients.

PiperOrigin-RevId: 621638720",Arturo Schmidt,arturoschmidt@google.com,2024-04-03 21:23:41,"tensorflow/compiler/mlir/tensorflow/translate/import_model.cc, tensorflow/compiler/mlir/tensorflow/translate/import_model.h",rocketas,False
"[JAX] Rebuild CUDA 12.1 image with newer ml_dtypes and numpy.

PiperOrigin-RevId: 621628036",Peter Hawkins,phawkins@google.com,2024-04-03 20:48:36,"tensorflow/tools/toolchains/remote_config/containers.bzl, third_party/xla/third_party/tsl/tools/toolchains/remote_config/containers.bzl, third_party/xla/tools/toolchains/remote_config/containers.bzl",hawkinsp,False
"[XLA:Python] Making `absl::StatusOr`-casting explicit.

This removes the need for Abseil's pybind11 status-casters, and is working towards the goal of porting everything to use nanobind.

PiperOrigin-RevId: 621613974",Wren Romano,wrengr@google.com,2024-04-03 20:01:57,"third_party/xla/xla/python/tools/BUILD, third_party/xla/xla/python/tools/_types.cc",wrengr,False
"Support `data.experimental.distribued_save` and add `wait` to `load`.

`distribued_save` uses tf.data service
(https://www.tensorflow.org/api_docs/python/tf/data/experimental/service)
to write distributed dataset snapshots. The call is non-blocking and
returns without waiting for the snapshot to finish. Setting `wait=True` to
`tf.data.Dataset.load` allows the snapshots to be read while they are
being written. The default is `False` for backward compatibility. It will
raise an error if the requested snapshot does not exist.

PiperOrigin-RevId: 621612641",Yang Chen,yangchen@google.com,2024-04-03 19:57:36,"RELEASE.md, tensorflow/python/data/experimental/BUILD, tensorflow/python/data/experimental/__init__.py, tensorflow/python/data/experimental/kernel_tests/service/distributed_save_load_ft_test.py, tensorflow/python/data/experimental/kernel_tests/service/distributed_save_load_test.py, tensorflow/python/data/experimental/ops/BUILD, tensorflow/python/data/experimental/ops/distributed_save_op.py, tensorflow/python/data/kernel_tests/io_test.py, tensorflow/python/data/ops/dataset_ops.py, tensorflow/python/data/ops/load_op.py, tensorflow/tools/api/golden/v1/tensorflow.data.-dataset.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.data.-fixed-length-record-dataset.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.data.-t-f-record-dataset.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.data.-text-line-dataset.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.data.experimental.-csv-dataset.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.data.experimental.-random-dataset.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.data.experimental.-sql-dataset.pbtxt, tensorflow/tools/api/golden/v1/tensorflow.data.experimental.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.data.-dataset.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.data.-fixed-length-record-dataset.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.data.-t-f-record-dataset.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.data.-text-line-dataset.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.data.experimental.-csv-dataset.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.data.experimental.-random-dataset.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.data.experimental.-sql-dataset.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.data.experimental.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.experimental.dtensor.-d-tensor-dataset.pbtxt",yangustc07,False
"Add SourceLocation information to xla::Internal errors.

PiperOrigin-RevId: 621612633",Kyle Lucke,klucke@google.com,2024-04-03 19:57:34,"third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/service/cpu/ir_emitter.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/layout_assignment.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc, third_party/xla/xla/util.h",klucke,False
"Rollforward with fix.

Reverts 8323e79751693db8e5dfa6c8493a945b310d5a7a

PiperOrigin-RevId: 621579629",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 18:05:39,tensorflow/core/profiler/convert/hlo_proto_to_memory_visualization_utils.cc,tensorflower-gardener,False
"Add attribute interface for IFRT IR sharding.

This change modifies the `ifrt.array` type, which previously directly used `ShardingParam` as a parameter to instead use a newly introduced `IfrtShardingAttrInterface`. By doing so, we can support multiple types of shardings in IFRT IR.

PiperOrigin-RevId: 621578052",Ionel Gog,icgog@google.com,2024-04-03 18:01:11,"third_party/xla/xla/python/ifrt/ir/BUILD, third_party/xla/xla/python/ifrt/ir/ifrt_dialect.cc, third_party/xla/xla/python/ifrt/ir/ifrt_dialect.h, third_party/xla/xla/python/ifrt/ir/ifrt_dialect.td, third_party/xla/xla/python/ifrt/ir/ifrt_interfaces.cc, third_party/xla/xla/python/ifrt/ir/ifrt_interfaces.h, third_party/xla/xla/python/ifrt/ir/ifrt_interfaces.td, third_party/xla/xla/python/ifrt/ir/ifrt_ops.cc, third_party/xla/xla/python/ifrt/ir/sharding_param.cc, third_party/xla/xla/python/ifrt/ir/sharding_param.h, third_party/xla/xla/python/ifrt/ir/tests/executable_impl_test_lib.cc, third_party/xla/xla/python/ifrt/ir/tests/ifrt_duplicated_callee_elimination.mlir, third_party/xla/xla/python/ifrt/ir/tests/spmd_expansion.mlir, third_party/xla/xla/python/ifrt/ir/tests/spmd_interface_verification.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_array.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_assemble.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_attrs.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_call.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_call_loaded_executable.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_disassemble.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_loaded_executable.mlir, third_party/xla/xla/python/ifrt/ir/tests/verify_reshard.mlir, third_party/xla/xla/python/ifrt/ir/transforms/BUILD, third_party/xla/xla/python/ifrt/ir/transforms/passes.td, third_party/xla/xla/python/ifrt/ir/transforms/spmd_expansion_pass.cc",ICGog,False
"[XLA:LatencyHidingScheduler] Schedule while and its tuple back to back.

PiperOrigin-RevId: 621567226",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 17:29:16,third_party/xla/xla/service/latency_hiding_scheduler.cc,tensorflower-gardener,False
"Only use `config-cuda-only` tag under `if_google` wrapper

This is an NFC, but an attempt to make clear that CI on GitHub does not read this tag for any reason, only internal CI needs this. This came up during https://github.com/openxla/xla/pull/11094

PiperOrigin-RevId: 621566226",David Dunleavy,ddunleavy@google.com,2024-04-03 17:26:14,"third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/python/BUILD, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/tools/BUILD",ddunl,False
"Disable colocate_predecessor_trees pass

PiperOrigin-RevId: 621565834",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 17:25:01,tensorflow/core/common_runtime/colocate_predecessor_trees_pass.cc,tensorflower-gardener,False
"Fix a breakage

Reverts f8226259068cec549df18a83329ca7e7dde4e9ab

PiperOrigin-RevId: 621560053",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 17:07:54,tensorflow/core/profiler/convert/hlo_proto_to_memory_visualization_utils.cc,tensorflower-gardener,False
"[ifrt_proxy] Added a separate thread pool for host callbacks

The default thread pool does not have sufficient stack size for reasonable
Python callbacks and in fact overflows for google/jax#49178.

PiperOrigin-RevId: 621545356",Sergei Lebedev,slebedev@google.com,2024-04-03 16:20:29,"third_party/xla/xla/python/ifrt_proxy/client/BUILD, third_party/xla/xla/python/ifrt_proxy/client/executable.cc",superbobry,False
"Expose these functions to make testing delegation easier.

PiperOrigin-RevId: 621537008",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 15:50:36,tensorflow/lite/core/subgraph.h,tensorflower-gardener,False
"Add source locations to FAILED_PRECONDITION errors.

PiperOrigin-RevId: 621535865",Kyle Lucke,klucke@google.com,2024-04-03 15:46:14,third_party/xla/xla/util.h,klucke,False
"Use absl::Status errors rather than the tsl equivalents.

PiperOrigin-RevId: 621531764",Kyle Lucke,klucke@google.com,2024-04-03 15:31:08,third_party/xla/xla/util.h,klucke,False
"#shlo_ref Add 4 bit with 8 bit storage support.

PiperOrigin-RevId: 621522973",Quentin Khan,qkhan@google.com,2024-04-03 14:58:49,"tensorflow/lite/experimental/shlo/BUILD, tensorflow/lite/experimental/shlo/i4.h, tensorflow/lite/experimental/shlo/i4_test.cc",qukhan,False
"[XLA:GPU] Extract SymbolicTiledHloInstruction into a separate file.

PiperOrigin-RevId: 621519818",Oleg Shyshkov,shyshkov@google.com,2024-04-03 14:44:48,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc, third_party/xla/xla/service/gpu/model/symbolic_tiled_hlo_instruction.cc, third_party/xla/xla/service/gpu/model/symbolic_tiled_hlo_instruction.h, third_party/xla/xla/service/gpu/model/symbolic_tiled_hlo_instruction_test.cc",olegshyshkov,False
"Add an XNNPACK delegate for the `Rsqrt` node in TFLite.

PiperOrigin-RevId: 621493958",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 12:42:40,"tensorflow/lite/delegates/xnnpack/BUILD, tensorflow/lite/delegates/xnnpack/rsqrt_test.cc, tensorflow/lite/delegates/xnnpack/unary_elementwise_tester.cc, tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc, tensorflow/lite/tools/cmake/modules/xnnpack.cmake, tensorflow/workspace2.bzl",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621488269",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 12:13:34,"third_party/xla/xla/hlo/ir/dfs_hlo_visitor_with_default.h, third_party/xla/xla/hlo/ir/hlo_computation.cc, third_party/xla/xla/hlo/ir/hlo_computation.h, third_party/xla/xla/hlo/ir/hlo_input_output_alias_config.cc, third_party/xla/xla/hlo/ir/hlo_input_output_alias_config.h, third_party/xla/xla/hlo/ir/hlo_instruction.cc, third_party/xla/xla/hlo/ir/hlo_instruction.h, third_party/xla/xla/hlo/ir/hlo_module.cc, third_party/xla/xla/hlo/ir/hlo_module.h, third_party/xla/xla/hlo/ir/hlo_module_group.cc, third_party/xla/xla/hlo/ir/hlo_module_group.h, third_party/xla/xla/hlo/ir/hlo_module_metadata.cc, third_party/xla/xla/hlo/ir/hlo_module_metadata.h, third_party/xla/xla/hlo/ir/hlo_opcode.cc, third_party/xla/xla/hlo/ir/hlo_opcode.h, third_party/xla/xla/hlo/ir/hlo_schedule.cc, third_party/xla/xla/hlo/ir/hlo_schedule.h, third_party/xla/xla/hlo/ir/hlo_sharding.cc, third_party/xla/xla/hlo/ir/hlo_sharding.h, third_party/xla/xla/hlo/ir/hlo_sharding_metadata.cc, third_party/xla/xla/hlo/ir/hlo_sharding_metadata.h",tensorflower-gardener,False
"PR #11172: GpuTimer: use delay kernel to improve accuracy

Imported from GitHub PR https://github.com/openxla/xla/pull/11172

Originally imported from GitHub PR https://github.com/openxla/xla/pull/9757.

This ensures that all the device operations to be timed are queued to
the relevant stream before any of them are executed, resulting in a more
accurate measurement. This is skipped if CUDA_LAUNCH_BLOCKING=1 or
unified addressing is not available.

Only launch the delay kernel if it has been explicitly flagged that a
warm-up run, which might have triggered lazy kernel loading, has been
executed.

Reproducing information from https://github.com/openxla/xla/pull/9757 below:

Quoting my comment in the code:
```c++
// When a timer is created it launches a delay kernel into the given stream and
// queues a start event immediately afterwards. This delay kernel blocks
// execution on the stream until GetElapsedDuration() is called, at which point
// an end event is queued and the delay kernel exits. This allows the device
// execution time of the tasks queued to the stream while the timer is active
// to be measured more accurately.
```
this should improve the accuracy of the measurements that are used to make
auto-tuning decisions, especially for small kernels.

With the example HLO:
```
  parameter_0 = bf16[128,12,128]{2,1,0} parameter(0)
  parameter_1 = bf16[12,128,128]{2,1,0} parameter(1)
  ROOT dot.26 = bf16[12,128,128]{2,1,0} dot(parameter_0, parameter_1),
    lhs_batch_dims={1}, lhs_contracting_dims={0}, rhs_batch_dims={0},
    rhs_contracting_dims={2}
```
a cuBLAS kernel was selected with a CUPTI/NSys-measured runtime of
3.9µs and before this change, GpuTimer measured a runtime of 17.5µs.
With this change, GpuTimer measures a runtime of 8.1µs.

With the example HLO:
```
  p0 = bf16[128,1536]{0,1} parameter(0)
  p1 = s8[1536,12288]{0,1} parameter(1)
  c = bf16[1536,12288]{0,1} convert(p1)
  ROOT d = bf16[128,12288]{1,0} dot(p0, c), lhs_contracting_dims={1},
    rhs_contracting_dims={0}
```
five cuDNN plans were auto-tuned, with CUPTI/Nsys-measured runtimes of
{34.9, 18.5, 30.9, 32.4, 31.5}µs. Before this change, GpuTimer measured
runtimes of {76.6, 40.0, 52.5, 55.7, 51.8}µs. With this change, GpuTimer
measures runtimes of {39.6, 23.0, 35.4, 35.1, 35.1}µs.

In summary, with this change, GpuTimer gives results that are much
closer to the CUPTI/Nsys measurements, with a ~uniform offset of ~4µs. A
constant offset doesn't matter for auto-tuning.

There are a couple of edge cases that have special treatment:
- if `CUDA_LAUNCH_BLOCKING=1` then the delay kernel will not achieve anything,
  so we don't launch it
- if any code in the timed region synchronises the device then the host will
  wait for the delay kernel to time out before actually launching the kernels
  to be measured. This will lead to a poor quality measurement, and an error
  message is printed. This condition can be met if one of the kernels being
  measured is lazily loaded, as lazy loading can trigger synchronisation. Best
  practice is to execute a warmup run (without timing enabled) before the timed
  execution.

The `GpuTimer::Create*` signatures that were deprecated in https://github.com/openxla/xla/pull/9841 do not benefit
from these accuracy improvements.
Copybara import of the project:

--
bcbe70801e92ba11ca65caef8bb05c847472d4ba by Olli Lupton <olupton@nvidia.com>:

GpuTimer: use delay kernel to improve accuracy

Originally imported from GitHub PR #9757.

This ensures that all the device operations to be timed are queued to
the relevant stream before any of them are executed, resulting in a more
accurate measurement. This is skipped if CUDA_LAUNCH_BLOCKING=1 or
unified addressing is not available.

Quoting my comment in the code:
// When a timer is created it launches a delay kernel into the given stream and
// queues a start event immediately afterwards. This delay kernel blocks
// execution on the stream until GetElapsedDuration() is called, at which point
// an end event is queued and the delay kernel exits. This allows the device
// execution time of the tasks queued to the stream while the timer is active
// to be measured more accurately.
this should improve the accuracy of the measurements that are used to make
auto-tuning decisions, especially for small kernels.

With the example HLO:
  parameter_0 = bf16[128,12,128]{2,1,0} parameter(0)
  parameter_1 = bf16[12,128,128]{2,1,0} parameter(1)
  ROOT dot.26 = bf16[12,128,128]{2,1,0} dot(parameter_0, parameter_1),
    lhs_batch_dims={1}, lhs_contracting_dims={0}, rhs_batch_dims={0},
    rhs_contracting_dims={2}
a cuBLAS kernel was selected with a CUPTI/NSys-measured runtime of
3.9µs and before this change, GpuTimer measured a runtime of 17.5µs.
With this change, GpuTimer measures a runtime of 8.1µs.

With the example HLO:
  p0 = bf16[128,1536]{0,1} parameter(0)
  p1 = s8[1536,12288]{0,1} parameter(1)
  c = bf16[1536,12288]{0,1} convert(p1)
  ROOT d = bf16[128,12288]{1,0} dot(p0, c), lhs_contracting_dims={1},
    rhs_contracting_dims={0}
five cuDNN plans were auto-tuned, with CUPTI/Nsys-measured runtimes of
{34.9, 18.5, 30.9, 32.4, 31.5}µs. Before this change, GpuTimer measured
runtimes of {76.6, 40.0, 52.5, 55.7, 51.8}µs. With this change, GpuTimer
measures runtimes of {39.6, 23.0, 35.4, 35.1, 35.1}µs.

In summary, with this change, GpuTimer gives results that are much
closer to the CUPTI/Nsys measurements, with a ~uniform offset of ~4µs. A
constant offset doesn't matter for auto-tuning.

There are a couple of edge cases that have special treatment:
- if `CUDA_LAUNCH_BLOCKING=1` then the delay kernel will not achieve anything,
  so we don't launch it
- if any code in the timed region synchronises the device then the host will
  wait for the delay kernel to time out before actually launching the kernels
  to be measured. This will lead to a poor quality measurement, and an error
  message is printed. This condition can be met if one of the kernels being
  measured is lazily loaded, as lazy loading can trigger synchronisation. Best
  practice is to execute a warmup run (without timing enabled) before the timed
  execution.

The `GpuTimer::Create*` signatures that were deprecated in #9841 do not benefit
from these accuracy improvements.

--
684275034a8bea55b3cbb9a1b40104feb1addad1 by Olli Lupton <olupton@nvidia.com>:

GpuTimer: use delay kernel on request only.

Only launch the delay kernel if it has been explicitly flagged that a
warm-up run, which might have triggered lazy kernel loading, has been
executed.

Merging this change closes #11172

PiperOrigin-RevId: 621460360",Olli Lupton,olupton@nvidia.com,2024-04-03 10:02:34,"third_party/xla/xla/service/gpu/autotuner_compile_util.cc, third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/kernels/topk_kernel_test.cc, third_party/xla/xla/stream_executor/blas.h, third_party/xla/xla/stream_executor/cuda/cuda_blas.cc, third_party/xla/xla/stream_executor/cuda/cuda_blas_lt.cc, third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc, third_party/xla/xla/stream_executor/dnn.h, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_timer.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer.h, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel.cu.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel.h, third_party/xla/xla/stream_executor/rocm/hip_blas_lt.cc, third_party/xla/xla/stream_executor/rocm/rocm_blas.cc, third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc, third_party/xla/xla/xla_data.proto",olupton,False
"Fixed internal issue.

This is follow up to https://github.com/openxla/xla/commit/0ab2be0b5a575da3206d2c2f92b85e6346708405,
which got reverted here https://github.com/openxla/xla/commit/b4a46471fd1b80452f913d927e7db04d4a6e260b

Reverts 5c66d026b089c47b021a65663153a268f6598e03

PiperOrigin-RevId: 621456790",Aliia Khasanova,aliia@google.com,2024-04-03 09:44:05,third_party/xla/xla/service/gpu/BUILD,,False
"Update GraphDef version to 1821.

PiperOrigin-RevId: 621448014",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 09:02:22,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-03

PiperOrigin-RevId: 621447960",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 09:02:09,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"[XLA:GPU] Forbid fusing concatenations in dots when the non-contracting dimension is split.

This is not handled correctly by codegen at this point.

PiperOrigin-RevId: 621444628",Benjamin Chetioui,bchetioui@google.com,2024-04-03 08:46:37,"third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/triton_tiling_propagation.cc",bchetioui,False
"Remove unused includes and dependencies

PiperOrigin-RevId: 621431741",Adam Banaś,adambanas@google.com,2024-04-03 07:47:40,"third_party/xla/xla/service/llvm_ir/BUILD, third_party/xla/xla/service/llvm_ir/alias_analysis_test.cc",Adam-Banas,False
"Merge pull request #62624 from Ahmad-M-Al-Khateeb:patch-1

PiperOrigin-RevId: 621410233",TensorFlower Gardener,gardener@tensorflow.org,2024-04-03 06:44:35,tensorflow/lite/g3doc/models/modify/model_maker/text_searcher.ipynb,tensorflower-gardener,False
"Create test_gather_model test.

PiperOrigin-RevId: 621403911",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 05:49:38,"tensorflow/compiler/mlir/quantization/stablehlo/python/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test_base.py",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621403466",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 05:46:26,"tensorflow/core/common_runtime/function_test.cc, tensorflow/core/common_runtime/function_testlib.cc, tensorflow/core/common_runtime/function_testlib.h, tensorflow/core/common_runtime/gradients.cc, tensorflow/core/common_runtime/gradients.h, tensorflow/core/common_runtime/graph_constructor.cc, tensorflow/core/common_runtime/graph_constructor.h, tensorflow/core/common_runtime/graph_view.h",tensorflower-gardener,False
"Make RemoveCollective virtual and return the new custom call instruction

PiperOrigin-RevId: 621400346",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 05:28:24,"third_party/xla/xla/tools/BUILD, third_party/xla/xla/tools/hlo_control_flow_flattening.cc, third_party/xla/xla/tools/hlo_control_flow_flattening.h",tensorflower-gardener,False
Merge branch 'master' into multistream-streammerge,Robin Zhang,robinz@nvidia.com,2024-04-03 05:45:46,".bazelrc, .bazelversion, .github/workflows/arm-cd.yml, .github/workflows/arm-ci-extended-cpp.yml, .github/workflows/arm-ci-extended.yml, .github/workflows/arm-ci.yml, .github/workflows/osv-scanner-scheduled.yml, .github/workflows/update-rbe.yml, .gitignore, CONTRIBUTING.md, RELEASE.md, WORKSPACE, ci/official/README.md, ci/official/any.sh, ci/official/bisect.sh, ci/official/code_check_full.sh, ci/official/containers/linux_arm64/devel.packages.txt, ci/official/containers/linux_arm64/devel.usertools/wheel_verification.bats, ci/official/containers/linux_arm64/jax.requirements.txt, ci/official/envs/ci_default, ci/official/envs/continuous_macos_x86_py310, ci/official/envs/continuous_macos_x86_py311, ci/official/envs/continuous_macos_x86_py311_cross_compile, ci/official/envs/continuous_macos_x86_py39, ci/official/envs/disk_cache, ci/official/envs/enable_pycpp_build, ci/official/envs/linux_arm64, ci/official/envs/linux_arm64_onednn, ci/official/envs/linux_x86, ci/official/envs/linux_x86_cuda, ci/official/envs/linux_x86_tpu, ci/official/envs/macos_arm64, ci/official/envs/macos_x86, ci/official/envs/macos_x86_cross_compile, ci/official/envs/multicache, ci/official/envs/nightly_linux_arm64_cpu_py310, ci/official/envs/nightly_linux_arm64_cpu_py311, ci/official/envs/nightly_linux_arm64_cpu_py312, ci/official/envs/nightly_linux_arm64_cpu_py39, ci/official/envs/nightly_macos_x86_py310, ci/official/envs/nightly_macos_x86_py311, ci/official/envs/nightly_macos_x86_py311_cross_compile, ci/official/envs/nightly_macos_x86_py312, ci/official/envs/nightly_macos_x86_py39, ci/official/envs/nightly_upload, ci/official/envs/no_upload, ci/official/envs/public_cache, ci/official/envs/public_cache_push, ci/official/envs/release_upload, ci/official/envs/versions_upload, ci/official/libtensorflow.sh, ci/official/pycpp.sh, ci/official/requirements_updater/.bazelversion, ci/official/requirements_updater/BUILD.bazel, ci/official/requirements_updater/README.md, ci/official/requirements_updater/WORKSPACE, ci/official/requirements_updater/release_updater.sh, ci/official/requirements_updater/requirements.in, ci/official/requirements_updater/updater.sh, ci/official/upload.sh, ci/official/utilities/code_check_full.bats, ci/official/utilities/rename_and_verify_wheels.sh, ci/official/utilities/setup.sh, ci/official/utilities/setup_docker.sh, ci/official/utilities/setup_macos.sh, ci/official/wheel.sh, ci/official/wheel_test/WORKSPACE, configure.py, requirements_lock_3_10.txt, requirements_lock_3_11.txt, requirements_lock_3_12.txt, requirements_lock_3_9.txt, tensorflow/BUILD, tensorflow/api_template.__init__.py, tensorflow/api_template_v1.__init__.py, tensorflow/c/BUILD, tensorflow/c/c_api_test.cc, tensorflow/c/eager/BUILD, tensorflow/c/eager/abstract_function.h, tensorflow/c/eager/abstract_tensor_handle.cc, tensorflow/c/eager/c_api.cc, tensorflow/c/eager/c_api_distributed_test.cc, tensorflow/c/eager/c_api_experimental.cc, tensorflow/c/eager/c_api_experimental.h, tensorflow/c/eager/c_api_test_util.cc, tensorflow/c/eager/c_api_unified_experimental.cc, tensorflow/c/eager/c_api_unified_experimental_graph.cc, tensorflow/c/eager/dlpack.cc, tensorflow/c/eager/gradient_checker.cc, tensorflow/c/eager/gradients.cc, tensorflow/c/eager/gradients_test.cc, tensorflow/c/eager/graph_function.cc, tensorflow/c/eager/graph_function.h, tensorflow/c/eager/immediate_execution_distributed_manager.h, tensorflow/c/eager/immediate_execution_tensor_handle.cc, tensorflow/c/eager/parallel_device/BUILD, tensorflow/c/eager/parallel_device/parallel_device_lib.cc, tensorflow/c/eager/tape.h, tensorflow/c/eager/tracing_utils.cc, tensorflow/c/eager/unified_api_test.cc, tensorflow/c/eager/unified_api_testutil.cc, tensorflow/c/eager/unified_api_testutil.h, tensorflow/c/experimental/filesystem/BUILD, tensorflow/c/experimental/filesystem/plugins/gcs/BUILD, tensorflow/c/experimental/filesystem/plugins/posix/BUILD, tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem.cc, tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem_static.cc, tensorflow/c/experimental/filesystem/plugins/windows/BUILD, tensorflow/c/experimental/gradients/BUILD, tensorflow/c/experimental/gradients/array_grad.cc, tensorflow/c/experimental/gradients/array_grad_test.cc, tensorflow/c/experimental/gradients/custom_gradient_test.cc, tensorflow/c/experimental/gradients/grad_test_helper.cc, tensorflow/c/experimental/gradients/math_grad.cc, tensorflow/c/experimental/gradients/nn_grad.cc, tensorflow/c/experimental/gradients/nn_grad_test.cc, tensorflow/c/experimental/gradients/not_differentiable.cc, tensorflow/c/experimental/gradients/tape/tape_operation.cc, tensorflow/c/experimental/grappler/BUILD, tensorflow/c/experimental/next_pluggable_device/BUILD, tensorflow/c/experimental/next_pluggable_device/tensor_pjrt_buffer_util_test.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/BUILD, tensorflow/c/experimental/ops/gen/cpp/renderers/cpp_config.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/cpp_file_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/guard_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/guard_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/include_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/include_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/namespace_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/namespace_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_comment_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_comment_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_implementation_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_implementation_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer_test.cc, tensorflow/c/experimental/pluggable_profiler/BUILD, tensorflow/c/experimental/saved_model/core/BUILD, tensorflow/c/experimental/saved_model/core/ops/BUILD, tensorflow/c/experimental/saved_model/core/saved_variable_loading_test.cc, tensorflow/c/experimental/saved_model/core/tf_saved_model_api.cc, tensorflow/c/experimental/saved_model/internal/BUILD, tensorflow/c/experimental/saved_model/internal/testdata/BUILD, tensorflow/c/experimental/stream_executor/BUILD, tensorflow/c/experimental/stream_executor/stream_executor.cc, tensorflow/c/experimental/stream_executor/stream_executor_test.cc, tensorflow/c/kernels.cc, tensorflow/c/kernels/BUILD, tensorflow/c/kernels/ops/bitcast.cc, tensorflow/c/tf_status.h, tensorflow/c/tf_status_helper.cc, tensorflow/c/tf_status_internal.h, tensorflow/c/tf_tensor.cc, tensorflow/c/tf_tensor.h, tensorflow/cc/BUILD, tensorflow/cc/client/client_session.cc, tensorflow/cc/experimental/base/tests/BUILD, tensorflow/cc/experimental/libexport/BUILD, tensorflow/cc/experimental/libexport/save.cc, tensorflow/cc/experimental/libtf/BUILD, tensorflow/cc/experimental/libtf/function.cc, tensorflow/cc/experimental/libtf/impl/BUILD, tensorflow/cc/framework/cc_op_gen_main.cc, tensorflow/cc/framework/cc_op_gen_util.cc, tensorflow/cc/framework/cc_op_gen_util.h, tensorflow/cc/framework/fuzzing/BUILD, tensorflow/cc/framework/fuzzing/cc_op_fuzz_gen.cc, tensorflow/cc/framework/fuzzing/cc_op_fuzz_gen_main.cc, tensorflow/cc/gradients/grad_testutil.cc, tensorflow/cc/ops/while_loop.cc, tensorflow/cc/saved_model/BUILD, tensorflow/cc/saved_model/fingerprinting.cc, tensorflow/cc/saved_model/fingerprinting_utils.cc, tensorflow/cc/saved_model/fingerprinting_utils.h, tensorflow/cc/saved_model/fingerprinting_utils_test.cc, tensorflow/cc/saved_model/loader.cc, tensorflow/cc/saved_model/loader_util.cc, tensorflow/cc/saved_model/metrics.cc, tensorflow/cc/saved_model/metrics.h, tensorflow/cc/saved_model/metrics_test.cc, tensorflow/cc/saved_model/reader.cc, tensorflow/cc/saved_model/reader.h, tensorflow/cc/saved_model/util.cc, tensorflow/cc/tools/BUILD, tensorflow/compat_template.__init__.py, tensorflow/compat_template_v1.__init__.py, tensorflow/compiler/aot/BUILD, tensorflow/compiler/aot/aot_only_var_handle_op.cc, tensorflow/compiler/aot/codegen.cc, tensorflow/compiler/aot/codegen_test.cc, tensorflow/compiler/aot/codegen_test_h.golden, tensorflow/compiler/aot/codegen_test_o.golden, tensorflow/compiler/aot/compile.cc, tensorflow/compiler/aot/embedded_protocol_buffers.cc, tensorflow/compiler/aot/embedded_protocol_buffers.h, tensorflow/compiler/aot/tests/BUILD, tensorflow/compiler/jit/BUILD, tensorflow/compiler/jit/build_xla_ops_pass.cc, tensorflow/compiler/jit/build_xla_ops_pass_test.cc, tensorflow/compiler/jit/clone_constants_for_better_clustering.cc, tensorflow/compiler/jit/clone_constants_for_better_clustering_test.cc, tensorflow/compiler/jit/cluster_scoping_pass.cc, tensorflow/compiler/jit/compilability_check_util.cc, tensorflow/compiler/jit/deadness_analysis.cc, tensorflow/compiler/jit/deadness_analysis.h, tensorflow/compiler/jit/deadness_analysis_test.cc, tensorflow/compiler/jit/device_compilation_cache_test.cc, tensorflow/compiler/jit/device_compilation_cluster_signature.cc, tensorflow/compiler/jit/device_compilation_cluster_signature.h, tensorflow/compiler/jit/device_compilation_profiler.cc, tensorflow/compiler/jit/device_compilation_profiler.h, tensorflow/compiler/jit/device_compiler.h, tensorflow/compiler/jit/device_compiler_client.h, tensorflow/compiler/jit/device_compiler_test.cc, tensorflow/compiler/jit/device_executable_persistor.h, tensorflow/compiler/jit/device_executable_persistor_test.cc, tensorflow/compiler/jit/device_util.cc, tensorflow/compiler/jit/device_util.h, tensorflow/compiler/jit/device_util_test.cc, tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc, tensorflow/compiler/jit/encapsulate_subgraphs_pass_test.cc, tensorflow/compiler/jit/encapsulate_util.cc, tensorflow/compiler/jit/encapsulate_util.h, tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc, tensorflow/compiler/jit/encapsulate_xla_computations_pass.h, tensorflow/compiler/jit/extract_outside_compilation_pass.cc, tensorflow/compiler/jit/flags.cc, tensorflow/compiler/jit/flags.h, tensorflow/compiler/jit/force_xla_constants_on_host_pass.cc, tensorflow/compiler/jit/force_xla_constants_on_host_pass_test.cc, tensorflow/compiler/jit/get_compiler_ir.cc, tensorflow/compiler/jit/get_compiler_ir.h, tensorflow/compiler/jit/increase_dynamism_for_auto_jit_pass.cc, tensorflow/compiler/jit/increase_dynamism_for_auto_jit_pass_test.cc, tensorflow/compiler/jit/kernels/xla_ops.cc, tensorflow/compiler/jit/mark_for_compilation_pass.cc, tensorflow/compiler/jit/mark_for_compilation_pass_test.cc, tensorflow/compiler/jit/ops/BUILD, tensorflow/compiler/jit/ops/xla_ops.cc, tensorflow/compiler/jit/partially_decluster_pass.cc, tensorflow/compiler/jit/pjrt_base_device.cc, tensorflow/compiler/jit/pjrt_base_device.h, tensorflow/compiler/jit/pjrt_device_compiler_client.cc, tensorflow/compiler/jit/pjrt_device_compiler_client.h, tensorflow/compiler/jit/pjrt_device_context.cc, tensorflow/compiler/jit/rearrange_function_argument_pass_test.cc, tensorflow/compiler/jit/resource_operation_safety_analysis.cc, tensorflow/compiler/jit/shape_inference.cc, tensorflow/compiler/jit/shape_inference.h, tensorflow/compiler/jit/shape_inference_helpers.cc, tensorflow/compiler/jit/test_util.cc, tensorflow/compiler/jit/tests/BUILD, tensorflow/compiler/jit/tests/auto_clustering_test_helper.cc, tensorflow/compiler/jit/tests/device_compiler_test_helper.cc, tensorflow/compiler/jit/tests/device_compiler_test_helper.h, tensorflow/compiler/jit/variable_info_util.cc, tensorflow/compiler/jit/xla_activity_listener.cc, tensorflow/compiler/jit/xla_activity_listener_test.cc, tensorflow/compiler/jit/xla_activity_logging_listener.cc, tensorflow/compiler/jit/xla_cluster_util.cc, tensorflow/compiler/jit/xla_cluster_util.h, tensorflow/compiler/jit/xla_cluster_util_test.cc, tensorflow/compiler/jit/xla_compile_on_demand_op.cc, tensorflow/compiler/jit/xla_compile_util.cc, tensorflow/compiler/jit/xla_compile_util.h, tensorflow/compiler/jit/xla_compiler_options_util.cc, tensorflow/compiler/jit/xla_cpu_device.cc, tensorflow/compiler/jit/xla_device.cc, tensorflow/compiler/jit/xla_device.h, tensorflow/compiler/jit/xla_device_compiler_client.cc, tensorflow/compiler/jit/xla_device_compiler_client.h, tensorflow/compiler/jit/xla_device_context.cc, tensorflow/compiler/jit/xla_device_ops.cc, tensorflow/compiler/jit/xla_gpu_device.cc, tensorflow/compiler/jit/xla_host_recv_device_context.cc, tensorflow/compiler/jit/xla_host_send_device_context.cc, tensorflow/compiler/jit/xla_host_send_recv_device_context_test.cc, tensorflow/compiler/jit/xla_launch_util.cc, tensorflow/compiler/jit/xla_launch_util.h, tensorflow/compiler/jit/xla_launch_util_test.cc, tensorflow/compiler/jit/xla_platform_info.cc, tensorflow/compiler/jit/xla_platform_info.h, tensorflow/compiler/jit/xla_tensor.cc, tensorflow/compiler/jit/xla_tpu_device.cc, tensorflow/compiler/mlir/BUILD, tensorflow/compiler/mlir/init_mlir.cc, tensorflow/compiler/mlir/init_mlir.h, tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/common/tfl_pass_config.h, tensorflow/compiler/mlir/lite/debug/debug_test.cc, tensorflow/compiler/mlir/lite/experimental/tac/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/common/utils.cc, tensorflow/compiler/mlir/lite/experimental/tac/common/utils.h, tensorflow/compiler/mlir/lite/experimental/tac/examples/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/py_wrapper/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/transforms/device_transform_patterns.cc, tensorflow/compiler/mlir/lite/flatbuffer_export.cc",buptzyb,True
"Automated Code Change

PiperOrigin-RevId: 621389364",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 04:27:56,"tensorflow/compiler/mlir/tfrt/BUILD, tensorflow/compiler/mlir/tfrt/ir/mlrt/BUILD, tensorflow/core/BUILD, tensorflow/core/framework/BUILD, tensorflow/core/nccl/BUILD, tensorflow/core/profiler/convert/BUILD, tensorflow/core/profiler/rpc/client/BUILD, tensorflow/core/tfrt/mla/BUILD, tensorflow/core/util/autotune_maps/BUILD, tensorflow/core/util/sparse/BUILD, tensorflow/python/eager/polymorphic_function/BUILD, tensorflow/python/profiler/internal/BUILD",tensorflower-gardener,False
"Preserve `stablehlo.gather` requantize pattern to meet operand and result type constraint.

github.com/openxla/stablehlo/blob/main/docs/spec.md#gatherix states `(C14) element_type(operand) = element_type(result)`.

This should be kept for `stablehlo.gather`, `stablehlo.slice`, and `stablehlo.gather_slice`.

PiperOrigin-RevId: 621388420",Jiyoun (Jen) Ha,jiyounha@google.com,2024-04-03 04:22:56,"tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.h, tensorflow/compiler/mlir/quantization/stablehlo/ops/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/ops/stablehlo_op_quant_spec.cc, tensorflow/compiler/mlir/quantization/stablehlo/ops/stablehlo_op_quant_spec.h, tensorflow/compiler/mlir/quantization/stablehlo/ops/stablehlo_op_quant_spec_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/prepare_quantize.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions.mlir",chococigar,False
"[JAX] Update JAX CI dockerfiles to use NumPy 2.0.0rc1, SciPy 1.13.0rc1, and ml_dtypes 0.4.0.

Change in preparation for releasing JAX with NumPy 2.0 support.

PiperOrigin-RevId: 621354875",Peter Hawkins,phawkins@google.com,2024-04-03 01:25:38,"tensorflow/tools/ci_build/install/install_pip_packages_by_version.sh, tensorflow/tools/toolchains/remote_config/containers.bzl, third_party/xla/third_party/tsl/tools/toolchains/remote_config/containers.bzl, third_party/xla/tools/toolchains/remote_config/containers.bzl",hawkinsp,False
"xla_compile_lib: Also support modules in binary proto format.

There's no reason not to support them, and it's a useful format.

PiperOrigin-RevId: 621354311",pizzud,pizzud@google.com,2024-04-03 01:22:41,third_party/xla/xla/tools/xla_compile_lib.cc,pizzud,False
"A couple minor bug fixes:
1. When adding unknown shardings to input parameter tuples, ignore modules with no input parameters.
2. Skip misaligned sharding checks for outfeed, send and send-done ops.

PiperOrigin-RevId: 621345164",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 00:36:58,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc,tensorflower-gardener,False
"Register fake quant gradient ops as not differentiable

PiperOrigin-RevId: 621344917",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-03 00:35:29,"tensorflow/core/ops/array_grad.cc, tensorflow/python/eager/pywrap_gradient_exclusions.cc, tensorflow/python/ops/array_grad.py",tensorflower-gardener,False
"[PJRT:CPU] Replace references to pjrt/tfrt_cpu_pjrt_client with pjrt/cpu/cpu_client.h.

The two are aliases and the former is a forwarding header pointing to the latter.

Cleanup only, no functional changes.

PiperOrigin-RevId: 621343163",Peter Hawkins,phawkins@google.com,2024-04-03 00:28:10,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/passes/bridge/convert_tf_quant_to_mhlo_int_test.cc",hawkinsp,False
"Check for empty array before access

PiperOrigin-RevId: 621336100",Thai Nguyen,thaink@google.com,2024-04-02 23:56:58,tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_driver.cc,thaink,False
"Remove stray constant folding mutex.

PiperOrigin-RevId: 621332276",Matthias Kramm,kramm@google.com,2024-04-02 23:39:30,tensorflow/compiler/mlir/tensorflow/transforms/constant_fold.cc,matthiaskramm,False
"Reverts 5bbc00214f106863808539104be9fdc6e01af02d

PiperOrigin-RevId: 621331596",Marcello Maggioni,maggioni@google.com,2024-04-02 23:37:00,"third_party/xla/xla/service/collective_opt_utils.cc, third_party/xla/xla/service/collective_opt_utils.h, third_party/xla/xla/service/reduce_scatter_decomposer.cc, third_party/xla/xla/service/reduce_scatter_decomposer.h, third_party/xla/xla/service/reduce_scatter_decomposer_test.cc",,False
"Add absl::SourceLocation to xla::Cancelled, xla::NotFound, xla::Unavailable, and xla::Unknown.

PiperOrigin-RevId: 621318215",Kyle Lucke,klucke@google.com,2024-04-02 22:43:19,third_party/xla/xla/util.h,klucke,False
"    Deserialize MLRT Bytecode path in AOT GPU

PiperOrigin-RevId: 621313822",Sania Nagpal,sanianagpal@google.com,2024-04-02 22:28:17,"tensorflow/core/tfrt/saved_model/BUILD, tensorflow/core/tfrt/saved_model/saved_model.cc, tensorflow/core/tfrt/saved_model/saved_model_util.cc, tensorflow/core/tfrt/saved_model/saved_model_util.h, tensorflow/core/tfrt/saved_model/utils/BUILD, tensorflow/core/tfrt/saved_model/utils/serialize_utils.cc, tensorflow/core/tfrt/saved_model/utils/serialize_utils.h, tensorflow/core/tfrt/saved_model/utils/serialize_utils_test.cc",sanianagpal,False
"[xla:gpu][NFC] Rename DynamicAddressComputationFusion back to AddressComputationFusion

PiperOrigin-RevId: 621309815",Eugene Zhulenev,ezhulenev@google.com,2024-04-02 22:13:59,"third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/fusions/custom.h, third_party/xla/xla/service/gpu/fusions/fusions.cc",ezhulenev,False
"Simplify LogicalBufferStruct constructor.

PiperOrigin-RevId: 621299550",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 21:37:24,tensorflow/core/profiler/convert/hlo_proto_to_memory_visualization_utils.cc,tensorflower-gardener,False
"[XLA:Runtime] Moved the nccl_api target to runtime folder.

This is part of an effort to move runtime targets to the runtime folder. #5758

PiperOrigin-RevId: 621294956",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 21:22:13,"third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/nccl_id_store.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/mock_nccl_utils.cc, third_party/xla/xla/service/gpu/mock_nccl_utils.h, third_party/xla/xla/service/gpu/mock_nccl_utils_default.cc, third_party/xla/xla/service/gpu/nccl_clique.cc, third_party/xla/xla/service/gpu/nccl_clique.h, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/nccl_all_gather_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_all_gather_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_all_reduce_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_all_reduce_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_all_to_all_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_all_to_all_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_api.cc, third_party/xla/xla/service/gpu/runtime/nccl_api.h, third_party/xla/xla/service/gpu/runtime/nccl_api_stub.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_recv_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_recv_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_send_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_send_thunk.h, third_party/xla/xla/service/gpu/runtime/thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.h",tensorflower-gardener,False
"#tf-data-service Reduce error log frequency for the auto scaler.

PiperOrigin-RevId: 621288034",Yang Chen,yangchen@google.com,2024-04-02 21:00:24,"tensorflow/core/data/service/BUILD, tensorflow/core/data/service/dispatcher_impl.cc",yangustc07,False
"[xla:gpu] NFC: Remove AddressComputationFusion emitter

After merging implementations always use DynamicAddressComputationFusion

PiperOrigin-RevId: 621282178",Eugene Zhulenev,ezhulenev@google.com,2024-04-02 20:42:15,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/fusions/custom.h, third_party/xla/xla/service/gpu/fusions/fusions.cc",ezhulenev,False
"[HloValueSemanticsAnalysis] Deduplicate some functions.

PiperOrigin-RevId: 621278403",Jinliang Wei,jlwei@google.com,2024-04-02 20:31:01,"third_party/xla/xla/service/hlo_value_semantics_analysis.cc, third_party/xla/xla/service/hlo_value_semantics_analysis.h",jinliangwei,False
"Ensure that the module's buffer donor config and the input output alias config are preserved. These seem to be getting overwritten when we move computations across modules after auto-sharding.

PiperOrigin-RevId: 621276812",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 20:26:22,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_test.cc",tensorflower-gardener,False
"PR #11122: [ROCm] Fix RCCL hang on rocm5.7

Imported from GitHub PR https://github.com/openxla/xla/pull/11122

Copybara import of the project:

--
94f7dc85f6ab07343ddb565b0aac0ed908fd66b4 by Dragan Mladjenovic <Dragan.Mladjenovic@amd.com>:

[ROCm] Allow ncclCommInitRankConfig on rocm5.7

--
2d196b645ccac046309d44f747d42777f00f1c9b by Dragan Mladjenovic <Dragan.Mladjenovic@amd.com>:

[ROCm] Fix sporadic hangs in CommInitRanks

Pointer to comm_handle must stay valid untill GroupEnd call
on pre 2.18 nccl. Only after that comm_handle contains a valid value.
Enforce this by using std::vector instead of temp local.

Merging this change closes #11122

PiperOrigin-RevId: 621262510",Dragan Mladjenovic,Dragan.Mladjenovic@amd.com,2024-04-02 19:34:57,third_party/xla/xla/service/gpu/nccl_api.cc,draganmladjenovic,False
"PR #11141: Add warmup iterations introduced in #9757

Imported from GitHub PR https://github.com/openxla/xla/pull/11141

#9757 has been rolled back and re-landed multiple times.
This commit includes just those parts that should not cause problems, shrinking the remaining diff.
Copybara import of the project:

--
6981be3191a94040c97e42a231166f7db07f8a5f by Olli Lupton <olupton@nvidia.com>:

Add warmup iterations introduced in #9757

That PR has been rolled back and relanded multiple times. This commit
includes just those parts that should not cause problems with Google
production workflows.

Merging this change closes #11141

PiperOrigin-RevId: 621259174",Olli Lupton,olupton@nvidia.com,2024-04-02 19:23:39,"third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc",olupton,False
"This CL introduces 'PluginProgram' in IFRT and exposes this in python via `xla_client.compile_ifrt_program()`.

The IFRT `PluginProgram` is simply a wrapper for arbitrary byte-strings: an IFRT backend that recognizes `PluginProgram` can interpret the byte-string in any way it sees fit.

PiperOrigin-RevId: 621258245",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 19:19:57,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/plugin_program.cc, third_party/xla/xla/python/ifrt/plugin_program.h, third_party/xla/xla/python/ifrt/plugin_program_serdes.cc, third_party/xla/xla/python/ifrt/plugin_program_serdes_test.cc, third_party/xla/xla/python/py_client.cc, third_party/xla/xla/python/py_client.h, third_party/xla/xla/python/py_program.cc, third_party/xla/xla/python/py_program.h, third_party/xla/xla/python/xla.cc, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_client.pyi, third_party/xla/xla/python/xla_client_test.py, third_party/xla/xla/python/xla_extension/__init__.pyi, third_party/xla/xla/python/xla_extension/ifrt_programs.pyi",tensorflower-gardener,False
"Roll back LiteralBase::Hash change due to performance regression.

Reverts fd5333cc3d6801cb5ce51d351ab20b0fd658f516

PiperOrigin-RevId: 621255501",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 19:09:57,"third_party/xla/xla/BUILD, third_party/xla/xla/literal.h",tensorflower-gardener,False
"Used std::move so that copy is not maintained

PiperOrigin-RevId: 621255154",Clive Verghese,cliveverghese@google.com,2024-04-02 19:08:49,"tensorflow/core/profiler/lib/profiler_factory.h, tensorflow/core/profiler/lib/traceme_encode.h",cliveverghese,False
"1. More comprehensive after-all handling. Specifically, the pass now handles after-alls with non-zero operands.
2. Add a case for merging two TupleOrToken labels. This case can arise when merging labels for multple conditional branch computations as they often return tuples.

Added tests for both these fixes.

PiperOrigin-RevId: 621254049",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 19:05:15,"third_party/xla/xla/service/hlo_value_semantics_analysis.cc, third_party/xla/xla/service/hlo_value_semantics_analysis_test.cc",tensorflower-gardener,False
"Pass the correct operands for branch computations when invoking EinsumHeightAnalysis::HandleCalledComputation.

PiperOrigin-RevId: 621245056",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 18:37:13,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_value_semantics_analysis.cc",tensorflower-gardener,False
"Small fix to avoid crashes.

PiperOrigin-RevId: 621239052",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 18:19:14,tensorflow/core/profiler/convert/hlo_proto_to_memory_visualization_utils.cc,tensorflower-gardener,False
"Update ops-related pbtxt files.

PiperOrigin-RevId: 621238660",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 18:18:06,"tensorflow/core/ops/compat/ops_history_v2/BatchFunction.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComputeDedupDataSizeV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/ComputeDedupDataTupleMaskV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/FinalizeTPUEmbeddingV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/XlaRecvTPUEmbeddingActivationsV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/XlaRecvTPUEmbeddingDeduplicationDataV2.pbtxt, tensorflow/core/ops/compat/ops_history_v2/XlaSendTPUEmbeddingGradientsV2.pbtxt, tensorflow/core/ops/ops.pbtxt",tensorflower-gardener,False
"Add an attribute for mixed priority batching policy

PiperOrigin-RevId: 621231265",Eunjae Kim,eunjaekim@google.com,2024-04-02 17:55:35,"tensorflow/compiler/mlir/quantization/tensorflow/passes/convert_tpu_model_to_cpu.td, tensorflow/compiler/mlir/tensorflow/ir/tf_generated_ops.td, tensorflow/core/kernels/BUILD, tensorflow/core/kernels/batch_kernels.cc, tensorflow/core/kernels/batch_kernels.h, tensorflow/core/kernels/batch_kernels_test.cc, tensorflow/core/kernels/batching_util/BUILD, tensorflow/core/kernels/batching_util/batch_scheduler.cc, tensorflow/core/kernels/batching_util/batch_scheduler.h, tensorflow/core/kernels/batching_util/batch_scheduler_test.cc, tensorflow/core/ops/batch_ops.cc, tensorflow/tools/api/golden/v1/tensorflow.raw_ops.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.raw_ops.pbtxt",eunjaekim-0,False
"#tf-data-service Check that tf.data snapshot path supports atomic move.

PiperOrigin-RevId: 621230652",Yang Chen,yangchen@google.com,2024-04-02 17:53:53,"tensorflow/core/kernels/data/experimental/BUILD, tensorflow/core/kernels/data/experimental/distributed_save_op.cc, tensorflow/python/data/experimental/ops/distributed_save_op.py",yangustc07,False
"[XLA] Ignore channel id for all-reduce in spmd programs

Channel IDs are not used for all-reduce in spmd mode, so we shouldn't verify their correctness when generating the module group metadata in spmd mode.

PiperOrigin-RevId: 621224865",Vlad Sytchenko,vsytch@google.com,2024-04-02 17:37:51,"third_party/xla/xla/service/hlo_module_group_metadata.cc, third_party/xla/xla/service/hlo_module_group_metadata.h",vsytch,False
"[xla:ffi] Compute correct byte size of a DeviceMemoryBase for FFI buffers

PiperOrigin-RevId: 621224859",Eugene Zhulenev,ezhulenev@google.com,2024-04-02 17:37:50,third_party/xla/xla/ffi/ffi.h,ezhulenev,False
"Migrate the SerDes logic for basic IFRT API object types from IFRT Proxy to IFRT

This CL migrates the (de)serialization logic from IFRT Proxy to IFRT for basic
IFRT object types (`DType`, `Shape`, `DeviceList`, `Sharding`). Most of them
are absorbed into IFRT types, implemting `FromProto` and `ToProto` methods. One
exception is `Sharding`, which needs further refactoring to avoid cyclic
dependency and exposing deserialization support functions to broad `Sharding`
users.

This migration defines standardized and easy-to-access (de)serialization for
IFRT API users, similar to other runtime data structures (e.g., XLA
`ShapeProto`/`OpSharding`).

PiperOrigin-RevId: 621223678",Hyeontaek Lim,hyeontaek@google.com,2024-04-02 17:34:35,"third_party/xla/xla/python/ifrt/BUILD, third_party/xla/xla/python/ifrt/device.cc, third_party/xla/xla/python/ifrt/device.h, third_party/xla/xla/python/ifrt/device.proto, third_party/xla/xla/python/ifrt/device_test.cc, third_party/xla/xla/python/ifrt/dtype.cc, third_party/xla/xla/python/ifrt/dtype.h, third_party/xla/xla/python/ifrt/dtype.proto, third_party/xla/xla/python/ifrt/dtype_test.cc, third_party/xla/xla/python/ifrt/shape.cc, third_party/xla/xla/python/ifrt/shape.h, third_party/xla/xla/python/ifrt/shape.proto, third_party/xla/xla/python/ifrt/shape_test.cc, third_party/xla/xla/python/ifrt/sharding.cc, third_party/xla/xla/python/ifrt/sharding.h, third_party/xla/xla/python/ifrt/sharding.proto, third_party/xla/xla/python/ifrt/sharding_serdes.cc, third_party/xla/xla/python/ifrt/sharding_serdes.h, third_party/xla/xla/python/ifrt/sharding_serdes.proto, third_party/xla/xla/python/ifrt/sharding_serdes_test.cc, third_party/xla/xla/python/ifrt/sharding_test.cc, third_party/xla/xla/python/ifrt_proxy/client/BUILD, third_party/xla/xla/python/ifrt_proxy/client/array.cc, third_party/xla/xla/python/ifrt_proxy/client/executable.cc, third_party/xla/xla/python/ifrt_proxy/client/executable_test.cc, third_party/xla/xla/python/ifrt_proxy/common/BUILD, third_party/xla/xla/python/ifrt_proxy/common/ifrt_service.proto, third_party/xla/xla/python/ifrt_proxy/common/types.cc, third_party/xla/xla/python/ifrt_proxy/common/types.h, third_party/xla/xla/python/ifrt_proxy/common/types.proto, third_party/xla/xla/python/ifrt_proxy/common/types_test.cc, third_party/xla/xla/python/ifrt_proxy/server/BUILD, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend_test.cc, third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/xla_sharding.proto",hyeontaek,False
"Insert QuantizationSpec to lifted functions in all functions

PiperOrigin-RevId: 621222359",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 17:30:08,"tensorflow/compiler/mlir/quantization/stablehlo/passes/lift_quantizable_spots_as_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/lift_quantizable_spots_as_functions_with_quantization_specs.mlir",tensorflower-gardener,False
"Reverts e5c11f3d1e1bef39cb1ea0937ac5addf04942f32

PiperOrigin-RevId: 621218634",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 17:18:52,"third_party/triton/cl609333259.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/cl609333259.patch, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc",tensorflower-gardener,False
"#shlo_ref Add `compare` op.

PiperOrigin-RevId: 621215145",Quentin Khan,qkhan@google.com,2024-04-02 17:08:24,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/binary_elementwise_test_util.h, tensorflow/lite/experimental/shlo/ops/compare.cc, tensorflow/lite/experimental/shlo/ops/compare.h, tensorflow/lite/experimental/shlo/ops/compare_test.cc, tensorflow/lite/experimental/shlo/ops/test_util.h",qukhan,False
"Add absl::SourceLocations to xla::ResourceExhaustedError.

PiperOrigin-RevId: 621214941",Kyle Lucke,klucke@google.com,2024-04-02 17:07:44,third_party/xla/xla/util.h,klucke,False
"#tf-data makes data_service_client.cc nonblocking when getting elements from workers

PiperOrigin-RevId: 621213580",Jim Lin,jimlintw@google.com,2024-04-02 17:03:41,"tensorflow/core/data/service/client/data_service_client.cc, tensorflow/core/data/service/client/data_service_client.h, tensorflow/core/data/service/task_runner.cc, tensorflow/core/data/service/thread_safe_buffer.h, tensorflow/core/data/service/worker.proto, tensorflow/python/data/experimental/kernel_tests/service/BUILD, tensorflow/python/data/experimental/kernel_tests/service/multi_process_cluster_test.py",jimlinntu,False
"Go: Update generated wrapper functions for TensorFlow ops.

PiperOrigin-RevId: 621208259",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 16:46:34,tensorflow/go/op/wrappers.go,tensorflower-gardener,False
"Eliminate unused Compiler::AssignBuffers method and overloads.

PiperOrigin-RevId: 621207395",Kyle Lucke,klucke@google.com,2024-04-02 16:42:57,"third_party/xla/xla/service/compiler.h, third_party/xla/xla/service/cpu/cpu_compiler.cc, third_party/xla/xla/service/cpu/cpu_compiler.h, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_compiler.h, third_party/xla/xla/service/gpu/gpu_compiler_test.cc, third_party/xla/xla/service/gpu/gpu_offloading_test.cc, third_party/xla/xla/service/gpu/nvptx_compiler_test.cc",klucke,False
"Add machine attributes to topology

(so Jax persistent cache won't reuse code from incompatible machines)

PiperOrigin-RevId: 621194963",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 15:59:21,"third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/cpu_client.cc, third_party/xla/xla/pjrt/cpu/cpu_client.h, third_party/xla/xla/pjrt/cpu/cpu_topology.cc, third_party/xla/xla/pjrt/cpu/cpu_topology.h, third_party/xla/xla/pjrt/cpu/cpu_topology.proto, third_party/xla/xla/pjrt/cpu/cpu_topology_test.cc, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/simple_orc_jit.cc, third_party/xla/xla/service/cpu/simple_orc_jit.h",tensorflower-gardener,False
"Add missing description 'END' markers to definitions of *Xla*ND ops.

In the case of AssignVariableXlaConcatND, also remove the (broken) reference to ""output"", which this op doesn't have.

PiperOrigin-RevId: 621175564",Matthias Kramm,kramm@google.com,2024-04-02 15:05:17,"tensorflow/core/api_def/base_api/api_def_AssignVariableXlaConcatND.pbtxt, tensorflow/core/api_def/base_api/api_def_ReadVariableXlaSplitND.pbtxt, tensorflow/core/api_def/base_api/api_def_XlaConcatND.pbtxt",matthiaskramm,False
"Re-enable HoistLayoutConversion pattern and mixed-precision MMA for Ampere.

PiperOrigin-RevId: 621158262",Mohammed Anany,manany@google.com,2024-04-02 13:45:17,"third_party/triton/cl609333259.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/cl609333259.patch, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc",Moerafaat,False
"Add missing parameter to xla_computation_to_mlir_module interface

Add optional 'emit_stable_hlo' parameter to xla_computation_to_mlir_module interface (already existing in implementation).
Apply correct formatting.

PiperOrigin-RevId: 621156226",Adam Banaś,adambanas@google.com,2024-04-02 13:35:15,third_party/xla/xla/python/xla_extension/mlir.pyi,Adam-Banas,False
"PR #11094: [ROCm] enable rocm for se_gpu_pjrt_compiler_aot_test

Imported from GitHub PR https://github.com/openxla/xla/pull/11094

Copybara import of the project:

--
4f002765972dd0705a3c8fb2c7b374c59e5fdb49 by Chao Chen <cchen104@amd.com>:

enable rocm for pjrt_aot

--
f0199b1fbc5929f4c2e8b48857cb975b53279bcc by Chao Chen <cchen104@amd.com>:

add requires-gpu-nvidia tag to ensure this test runs with a GPU available

--
7f5d97f0ef9d2bdfe990120e2eee629f37f106ce by Chao Chen <cchen104@amd.com>:

add if_google tag for config-cuda-only

Merging this change closes #11094

PiperOrigin-RevId: 621154868",Chao,cchen104@amd.com,2024-04-02 13:28:31,"third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler_aot_test.cc",i-chaochen,False
"#shlo_ref Print tensor types in error messages.

PiperOrigin-RevId: 621141252",Quentin Khan,qkhan@google.com,2024-04-02 12:25:09,"tensorflow/lite/experimental/shlo/data_type.h, tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/test_util.h, tensorflow/lite/experimental/shlo/ops/util.cc, tensorflow/lite/experimental/shlo/ops/util.h, tensorflow/lite/experimental/shlo/quantized_tensor_element_type.h",qukhan,False
"Automated Code Change

PiperOrigin-RevId: 621141228",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 12:25:01,"third_party/xla/xla/service/hlo_alias_analysis.cc, third_party/xla/xla/service/hlo_alias_analysis.h, third_party/xla/xla/service/hlo_computation_deduplicator.cc, third_party/xla/xla/service/hlo_computation_deduplicator.h, third_party/xla/xla/service/hlo_constant_folding.cc, third_party/xla/xla/service/hlo_constant_folding.h, third_party/xla/xla/service/hlo_cost_analysis.cc, third_party/xla/xla/service/hlo_cost_analysis.h, third_party/xla/xla/service/hlo_creation_utils.cc, third_party/xla/xla/service/hlo_creation_utils.h, third_party/xla/xla/service/hlo_cse.cc, third_party/xla/xla/service/hlo_cse.h, third_party/xla/xla/service/hlo_dataflow_analysis.cc, third_party/xla/xla/service/hlo_dataflow_analysis.h, third_party/xla/xla/service/hlo_dce.cc, third_party/xla/xla/service/hlo_dce.h, third_party/xla/xla/service/hlo_domain_isolator.cc, third_party/xla/xla/service/hlo_domain_isolator.h, third_party/xla/xla/service/hlo_domain_map.cc, third_party/xla/xla/service/hlo_domain_map.h, third_party/xla/xla/service/hlo_domain_remover.cc, third_party/xla/xla/service/hlo_domain_remover.h, third_party/xla/xla/service/hlo_domain_verifier.cc, third_party/xla/xla/service/hlo_domain_verifier.h, third_party/xla/xla/service/hlo_element_type_converter.cc, third_party/xla/xla/service/hlo_element_type_converter.h, third_party/xla/xla/service/hlo_graph_dumper.cc, third_party/xla/xla/service/hlo_graph_dumper.h, third_party/xla/xla/service/hlo_liveness_analysis.cc, third_party/xla/xla/service/hlo_liveness_analysis.h, third_party/xla/xla/service/hlo_memory_scheduler.cc, third_party/xla/xla/service/hlo_memory_scheduler.h, third_party/xla/xla/service/hlo_module_config.cc, third_party/xla/xla/service/hlo_module_config.h, third_party/xla/xla/service/hlo_module_dce.cc, third_party/xla/xla/service/hlo_module_dce.h, third_party/xla/xla/service/hlo_module_group_metadata.cc, third_party/xla/xla/service/hlo_module_group_metadata.h, third_party/xla/xla/service/hlo_module_group_util.cc, third_party/xla/xla/service/hlo_module_group_util.h, third_party/xla/xla/service/hlo_module_test.cc, third_party/xla/xla/service/hlo_module_util.cc, third_party/xla/xla/service/hlo_module_util.h, third_party/xla/xla/service/hlo_parser.cc, third_party/xla/xla/service/hlo_parser.h, third_party/xla/xla/service/hlo_parser_test.cc, third_party/xla/xla/service/hlo_pass_fix.h, third_party/xla/xla/service/hlo_pass_interface.h, third_party/xla/xla/service/hlo_pass_pipeline.cc, third_party/xla/xla/service/hlo_pass_pipeline.h",tensorflower-gardener,False
"PR #10965: [GPU] Make xla_gpu_enable_nccl_per_stream_comms false by default

Imported from GitHub PR https://github.com/openxla/xla/pull/10965

In #9845 I added a flag to toggle between per-stream communicators. The default option was true to preserve the current behavior. While per-stream comms can provide a speedup at the cost of additional memory, it doesn't seem to help for many common workloads which I have tested. I am proposing that we set the default value to false to reduce the amount of GPU memory used by XLA.

The table below shows how the total GPU memory usage changes (absolute value) and how the steps/sec changes (relative value) by changing --xla_gpu_enable_nccl_per_stream_comms **from true to false**. In all of these cases, we use less memory and the performance stays in general within 1%.

| Workload                                                                 | Mem diff (MiB) | Speedup |
| ------------------------------------------------------------------------ | ------------- | --------- |
| t5x xxl pretrain 8xh100 fp8 bs-36 insize-512 outsize-128 tp-8 te_fmha-1   | \-2596 | 1.0045 |
| t5x xxl pretrain 8xh100 fp8 bs-36 insize-512 outsize-128 tp-8 te_fmha-0   | \-2594 | 0.9963 |
| t5x xxl pretrain 8xh100 bf16 bs-36 insize-512 outsize-128 tp-8 te_fmha-1 | \-2596 | 0.9996 |
| t5x xxl pretrain 8xh100 bf16 bs-36 insize-512 outsize-128 tp-8 te_fmha-0 | \-2596 | 1.0012 |
| t5x xxl pretrain 8xh100 fp8 bs-256 insize-512 outsize-128 tp-8 te_fmha-1 | \-2596 | 1.0040 |
| t5x xxl pretrain 8xh100 fp8 bs-256 insize-512 outsize-128 tp-8 te_fmha-0 | \-2596 | 1.0000 |
| paxml llama70b evaluate 16xh100 bfloat16 bs-4 ici--1-8-1 dcn--1-2-1      | \-2644 | 1.0192 |
| paxml GPT3 train 8xh100 bfl16 bs-4 ici--4-1-2                            | \-2822 | 0.9929 |
| paxml GPT3 train 8xh100 bfl16 bs-8 ici--1-4-2                            | \-5800 |  0.9990 |
| paxml GPT3pp train 16xh100 bf16 bs-8 ici--2-2-1-2                        | \-6582 | 0.9968 |

Test settings
* T5X container: [ghcr.io/nvidia/jax:t5x-2024-03-15](http://ghcr.io/nvidia/jax:t5x-2024-03-15)
* PAX container: [ghcr.io/nvidia/jax:pax-2024-03-15](http://ghcr.io/nvidia/jax:pax-2024-03-15)
* Performed using DGXH100
* NCCL_NVLS_ENABLE=1
* XLA_PYTHON_CLIENT_MEM_FRACTION=0.8 (except paxml GPT3pp which uses 0.7 because it goes OOM otherwise when enable_nccl_per_stream_comms is true)
Copybara import of the project:

--
fed944b06a9fb830a79b874f68732bdd41a9cd75 by Trevor Morris <tmorris@nvidia.com>:

Make xla_gpu_enable_nccl_per_stream_comms false by default

Merging this change closes #10965

PiperOrigin-RevId: 621137675",Trevor Morris,tmorris@nvidia.com,2024-04-02 12:06:41,third_party/xla/xla/debug_options_flags.cc,trevor-m,False
"Automated Code Change

PiperOrigin-RevId: 621137614",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 12:06:21,tensorflow/core/lib/gtl/edit_distance_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621134180",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 11:50:00,"tensorflow/core/common_runtime/partitioning_utils_test.cc, tensorflow/core/common_runtime/placer_test.cc, tensorflow/core/common_runtime/process_function_library_runtime.cc, tensorflow/core/common_runtime/process_function_library_runtime.h, tensorflow/core/common_runtime/process_function_library_runtime_test.cc, tensorflow/core/common_runtime/rendezvous_util.cc, tensorflow/core/common_runtime/rendezvous_util.h, tensorflow/core/common_runtime/scoped_allocator.cc, tensorflow/core/common_runtime/scoped_allocator.h, tensorflow/core/common_runtime/scoped_allocator_mgr.cc, tensorflow/core/common_runtime/scoped_allocator_mgr.h",tensorflower-gardener,False
"Internal cleanup of BUILD/.bzl files

PiperOrigin-RevId: 621133166",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 11:43:35,third_party/xla/xla/stream_executor/rocm/BUILD,tensorflower-gardener,False
"Internal cleanup of BUILD/.bzl files

PiperOrigin-RevId: 621133014",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 11:42:31,third_party/xla/third_party/tsl/WORKSPACE,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621132778",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 11:41:20,tensorflow/core/kernels/batching_util/concat_split_util.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621131047",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 11:32:25,tensorflow/c/eager/tape.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621130435",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 11:29:13,"tensorflow/core/kernels/candidate_sampler_ops.cc, tensorflow/core/kernels/conv_2d.h, tensorflow/core/kernels/conv_grad_shape_utils.cc, tensorflow/core/kernels/conv_grad_shape_utils.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621130412",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 11:29:06,tensorflow/core/data/service/test_util.cc,tensorflower-gardener,False
"Switch `xla_cpu` dialect to MLIR properties.

PiperOrigin-RevId: 621128944",Christian Sigg,csigg@google.com,2024-04-02 11:21:37,third_party/xla/xla/mlir/xla_cpu/ir/xla_cpu_dialect.td,chsigg,False
"Promote TfLiteOperator functions from experimental to mostly stable.

PiperOrigin-RevId: 621128246",Fergus Henderson,fergus@google.com,2024-04-02 11:18:29,tensorflow/lite/core/c/operator.h,fergushenderson,False
"Safely cast float to int16

PiperOrigin-RevId: 621122395",Alan Kelly,alankelly@google.com,2024-04-02 10:53:14,"tensorflow/lite/kernels/cast.cc, tensorflow/lite/kernels/cast_test.cc",alankelly,False
"Automated Code Change

PiperOrigin-RevId: 621121283",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 10:47:20,tensorflow/core/kernels/barrier_ops.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621119919",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 10:40:07,"tensorflow/core/grappler/optimizers/data/auto_shard_test.cc, tensorflow/core/grappler/optimizers/data/disable_intra_op_parallelism_test.cc, tensorflow/core/grappler/optimizers/data/disable_prefetch_legacy_autotune_test.cc, tensorflow/core/grappler/optimizers/data/graph_test_utils.cc, tensorflow/core/grappler/optimizers/data/graph_utils_test.cc, tensorflow/core/grappler/optimizers/data/inject_prefetch_test.cc, tensorflow/core/grappler/optimizers/data/make_deterministic_test.cc, tensorflow/core/grappler/optimizers/data/use_private_thread_pool_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621119884",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 10:39:52,"third_party/xla/xla/tsl/util/byte_swap_array.cc, third_party/xla/xla/tsl/util/byte_swap_array.h, third_party/xla/xla/tsl/util/device_name_utils.cc, third_party/xla/xla/tsl/util/device_name_utils.h, third_party/xla/xla/tsl/util/device_name_utils_test.cc, third_party/xla/xla/tsl/util/env_var.cc, third_party/xla/xla/tsl/util/env_var.h, third_party/xla/xla/tsl/util/reporter.cc, third_party/xla/xla/tsl/util/reporter.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621119251",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 10:36:47,"third_party/xla/xla/comparison_util.cc, third_party/xla/xla/comparison_util.h",tensorflower-gardener,False
"Enable latest ops and subgraph reshaping in OS builds

PiperOrigin-RevId: 621118982",Alan Kelly,alankelly@google.com,2024-04-02 10:35:20,tensorflow/lite/CMakeLists.txt,alankelly,False
"Automated Code Change

PiperOrigin-RevId: 621114585",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 10:14:56,"third_party/xla/xla/service/stable_sort_expander.cc, third_party/xla/xla/service/stable_sort_expander.h, third_party/xla/xla/service/stochastic_convert_decomposer.cc, third_party/xla/xla/service/stochastic_convert_decomposer.h, third_party/xla/xla/service/sub_byte_normalization.cc, third_party/xla/xla/service/sub_byte_normalization.h, third_party/xla/xla/service/symbol_repository.h, third_party/xla/xla/service/topk_rewriter.cc, third_party/xla/xla/service/topk_rewriter.h, third_party/xla/xla/service/transfer_manager.cc, third_party/xla/xla/service/transfer_manager.h, third_party/xla/xla/service/transpose_folding.cc, third_party/xla/xla/service/transpose_folding.h, third_party/xla/xla/service/transpose_folding_test.cc, third_party/xla/xla/service/tree_reduction_rewriter.cc, third_party/xla/xla/service/tree_reduction_rewriter.h, third_party/xla/xla/service/triangular_solve_expander.cc, third_party/xla/xla/service/triangular_solve_expander.h, third_party/xla/xla/service/tuple_points_to_analysis.cc, third_party/xla/xla/service/tuple_points_to_analysis.h, third_party/xla/xla/service/tuple_simplifier.cc, third_party/xla/xla/service/tuple_simplifier.h, third_party/xla/xla/service/tuple_util.cc, third_party/xla/xla/service/tuple_util.h, third_party/xla/xla/service/while_loop_all_reduce_code_motion.cc, third_party/xla/xla/service/while_loop_all_reduce_code_motion.h, third_party/xla/xla/service/while_loop_analysis.cc, third_party/xla/xla/service/while_loop_analysis_test.cc, third_party/xla/xla/service/while_loop_concat_code_motion.cc, third_party/xla/xla/service/while_loop_concat_code_motion.h, third_party/xla/xla/service/while_loop_constant_sinking.cc, third_party/xla/xla/service/while_loop_constant_sinking.h, third_party/xla/xla/service/while_loop_expensive_invariant_code_motion.cc, third_party/xla/xla/service/while_loop_expensive_invariant_code_motion.h, third_party/xla/xla/service/while_loop_fusible_sinking.cc, third_party/xla/xla/service/while_loop_fusible_sinking.h, third_party/xla/xla/service/while_loop_invariant_code_motion.cc, third_party/xla/xla/service/while_loop_invariant_code_motion.h, third_party/xla/xla/service/while_loop_simplifier.cc, third_party/xla/xla/service/while_loop_simplifier.h, third_party/xla/xla/service/while_loop_trip_count_annotator.cc, third_party/xla/xla/service/while_loop_trip_count_annotator.h, third_party/xla/xla/service/while_loop_unroller.cc, third_party/xla/xla/service/while_loop_unroller.h, third_party/xla/xla/service/while_util.cc, third_party/xla/xla/service/while_util.h, third_party/xla/xla/service/while_util_test.cc, third_party/xla/xla/service/zero_sized_hlo_elimination.cc, third_party/xla/xla/service/zero_sized_hlo_elimination.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621109222",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 09:50:48,"tensorflow/core/distributed_runtime/cluster_function_library_runtime.cc, tensorflow/core/distributed_runtime/cluster_function_library_runtime.h",tensorflower-gardener,False
"Update GraphDef version to 1820.

PiperOrigin-RevId: 621098011",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 09:02:00,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-04-02

PiperOrigin-RevId: 621097961",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 09:01:48,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621094129",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 08:43:47,"tensorflow/core/kernels/data/experimental/set_stats_aggregator_dataset_op.cc, tensorflow/core/kernels/data/experimental/stats_aggregator_ops.cc",tensorflower-gardener,False
"Fix the situation where the input tensor is an empty sparse tensor with empty indices.

PiperOrigin-RevId: 621075752",Ziyin Huang,ziyinh@google.com,2024-04-02 07:17:30,tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.cc,pineapplejuice233,False
"Automated Code Change

PiperOrigin-RevId: 621074703",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 07:12:07,tensorflow/core/data/rewrite_utils_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621074007",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 07:08:04,"tensorflow/core/kernels/example_parsing_ops.cc, tensorflow/core/kernels/fake_quant_ops_test.cc, tensorflow/core/kernels/list_kernels.h, tensorflow/core/kernels/merge_v2_checkpoints_op_test.cc, tensorflow/core/kernels/padding_fifo_queue.cc, tensorflow/core/kernels/padding_fifo_queue.h, tensorflow/core/kernels/quantization_utils_test.cc, tensorflow/core/kernels/queue_base.cc, tensorflow/core/kernels/queue_base.h, tensorflow/core/kernels/ragged_tensor_to_tensor_op_test.cc, tensorflow/core/kernels/range_sampler.cc, tensorflow/core/kernels/range_sampler.h, tensorflow/core/kernels/range_sampler_test.cc, tensorflow/core/kernels/reverse_op.cc, tensorflow/core/kernels/roll_op.cc, tensorflow/core/kernels/roll_op.h, tensorflow/core/kernels/save_restore_tensor.cc, tensorflow/core/kernels/save_restore_tensor.h, tensorflow/core/kernels/save_restore_v2_ops.cc, tensorflow/core/kernels/scoped_allocator_ops_test.cc, tensorflow/core/kernels/sequence_ops_test.cc, tensorflow/core/kernels/slice_op.cc, tensorflow/core/kernels/sparse_add_op_test.cc, tensorflow/core/kernels/sparse_dense_binary_op_shared.cc, tensorflow/core/kernels/sparse_dense_binary_op_shared_test.cc, tensorflow/core/kernels/sparse_reduce_op.cc, tensorflow/core/kernels/sparse_reduce_sum_op_test.cc, tensorflow/core/kernels/sparse_reorder_op.cc, tensorflow/core/kernels/sparse_slice_op.cc, tensorflow/core/kernels/sparse_softmax_op.cc, tensorflow/core/kernels/strided_slice_op_impl.h, tensorflow/core/kernels/tensor_array_ops.cc, tensorflow/core/kernels/transpose_functor.h, tensorflow/core/kernels/transpose_functor_cpu.cc, tensorflow/core/kernels/transpose_op.cc, tensorflow/core/kernels/transpose_op.h, tensorflow/core/kernels/transpose_util_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621066820",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 06:28:24,third_party/xla/xla/python/ifrt/mock.h,tensorflower-gardener,False
"Merge pull request #63398 from tensorflow:Surya_UnicodeEncode

PiperOrigin-RevId: 621065069",TensorFlower Gardener,gardener@tensorflow.org,2024-04-02 07:32:57,tensorflow/core/kernels/unicode_ops.cc,tensorflower-gardener,False
"Merge pull request #63995 from Intel-tensorflow:mraunak/tf_configure

PiperOrigin-RevId: 621063620",TensorFlower Gardener,gardener@tensorflow.org,2024-04-02 07:12:07,configure.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 621063304",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 06:07:37,"third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/types.h",tensorflower-gardener,False
"Support RngBitGenerator HloInstruction with single output in the HLO -> MHLO conversion.

For the rng-bit-generator operator, xla HLO instruction can have two kinds of shapes, (1) tuple(output_state, output_data), and (2) output_data. On the contrary, `mhlo::RngBitGeneratorOp` has only one shape, (output_state, output_data). This cl supports RngBitGenerator HloInstruction with single output in the HLO -> MHLO conversion.

PiperOrigin-RevId: 621059534",Zixuan Jiang,zixuanjiang@google.com,2024-04-02 05:45:45,"third_party/xla/xla/translate/hlo_to_mhlo/hlo_function_importer.cc, third_party/xla/xla/translate/hlo_to_mhlo/tests/import.hlotxt",ZixuanJiang,False
"Automated Code Change

PiperOrigin-RevId: 621055899",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 05:24:17,"tensorflow/core/distributed_runtime/eager/cluster_function_library_runtime.cc, tensorflow/core/distributed_runtime/eager/cluster_function_library_runtime.h, tensorflow/core/distributed_runtime/eager/remote_mgr.cc, tensorflow/core/distributed_runtime/eager/remote_mgr.h",tensorflower-gardener,False
"Remove unnecessary GraphExportConfig flags. They are only evaluated once and are never reset.

PiperOrigin-RevId: 621049573",Arturo Schmidt,arturoschmidt@google.com,2024-04-02 04:48:59,"tensorflow/compiler/mlir/tensorflow/translate/export_graphdef.cc, tensorflow/compiler/mlir/tensorflow/translate/mlir_roundtrip_flags.h",rocketas,False
"[SavedModelBundleLite] Avoid copying the GraphDef during the load path.

Previously, we reused the ""legacy"" SavedModelBundle loading path, then discarded the unused MetaGraphDef. An old TODO called out the opportunity to avoid copying the MetaGraphDef's GraphDef, and this change does that.

PiperOrigin-RevId: 621045248",Derek Murray,mrry@google.com,2024-04-02 04:25:01,tensorflow/cc/saved_model/loader.cc,mrry,False
"Temporary fix for TensorFlow VS2019 breakage.

This is a duplicate of https://github.com/llvm/llvm-project/pull/87288.

PiperOrigin-RevId: 621034833",Chenguang Wang,chenguangwang@google.com,2024-04-02 03:28:25,"third_party/llvm/vs2019.patch, third_party/llvm/workspace.bzl",wecing,False
"#tf-data Set `warm_start` to false when global shuffling is enabled.

When `warm_start` is enabled, some ops may use the wrong IteratorContext
to prefetch elements. For example:
https://github.com/tensorflow/tensorflow/blob/29561af231863afb3b6b89e3aa8a6a550c2b7bb0/tensorflow/core/kernels/data/prefetch_dataset_op.cc#L197-L199

PiperOrigin-RevId: 621004304",Yang Chen,yangchen@google.com,2024-04-02 00:51:16,"tensorflow/python/data/experimental/ops/BUILD, tensorflow/python/data/experimental/ops/global_shuffle_op.py, tensorflow/python/data/kernel_tests/BUILD, tensorflow/python/data/kernel_tests/list_files_test.py, tensorflow/python/data/kernel_tests/map_test.py",yangustc07,False
"Speed up DetermineHloInstructionIsReplicated.

A reasonable chunk of time gets used in resizing hash sets after insertions. We can instead resize these hashsets before insertions.

PiperOrigin-RevId: 621000442",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-02 00:31:40,third_party/xla/xla/service/hlo_replication_analysis.cc,tensorflower-gardener,False
"Remove unnecessary Copybara transforms

PiperOrigin-RevId: 620991965",David Dunleavy,ddunleavy@google.com,2024-04-01 23:54:17,third_party/xla/third_party/tsl/tsl/BUILD,ddunl,False
"Fix a cornercase in lowering form saved model, for the tf.BatchFunction op.

PiperOrigin-RevId: 620985513",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-01 23:27:07,"tensorflow/compiler/mlir/tfrt/tests/hoist_invariant_ops.mlir, tensorflow/compiler/mlir/tfrt/transforms/lower_saved_model.cc",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@c09b6fac12b0

Updates LLVM usage to match
[c09b6fac12b0](https://github.com/llvm/llvm-project/commit/c09b6fac12b0)

PiperOrigin-RevId: 620985353",Jorge Gorbe Moya,jgorbe@google.com,2024-04-01 23:26:29,third_party/llvm/workspace.bzl,slackito,False
"Add replicate_on_last_tile_dims handling when validating tiled output sharding.

PiperOrigin-RevId: 620967716",Swachhand Lokhande,swachhand@google.com,2024-04-01 22:17:47,tensorflow/compiler/mlir/tensorflow/utils/xla_sharding_util.cc,swachhandl,False
"Integrate LLVM at llvm/llvm-project@0f6ed4c394fd

Updates LLVM usage to match
[0f6ed4c394fd](https://github.com/llvm/llvm-project/commit/0f6ed4c394fd)

PiperOrigin-RevId: 620947888",Alina Sbirlea,asbirlea@google.com,2024-04-01 21:06:20,third_party/llvm/workspace.bzl,alinas,False
"Hoist async copies when start_after is -1

Previously, the counter for `MemorySpaceAssignment::FixSchedule` started at `0` and would check for async copies scheduled for before the counter and after (but only the exact value). We have some async copies that set their `start_after` value to `-1` meaning we would skip inserting them at the earliest point and then catch that they weren't inserted by their `start_before` time and insert them then. This would lead to a few async copy operations where `*-start` would be scheduled immediately before their corresponding `*-done` operation, leading to none of the latency being hidden.

PiperOrigin-RevId: 620941225",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-01 20:42:17,"third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",tensorflower-gardener,False
"Add support for parameter streaming with while loop by:
- fix up shapes of root instruction of while body and parameter of while condition
- root instruction of while body should use the ""on host"" operand since it's on host
  at loop entry.

PiperOrigin-RevId: 620939395",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-01 20:35:42,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/host_offload_legalize.cc, third_party/xla/xla/service/host_offloader.cc, third_party/xla/xla/service/host_offloader.h, third_party/xla/xla/service/host_offloader_test.cc",tensorflower-gardener,False
"GPU Load tracker in TFRT.

PiperOrigin-RevId: 620936640",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-01 20:26:49,"tensorflow/compiler/jit/BUILD, tensorflow/compiler/jit/xla_launch_util.cc, tensorflow/core/common_runtime/gpu/BUILD, tensorflow/core/common_runtime/gpu/gpu_serving_device_selector.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 620932347",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-01 20:11:52,tensorflow/c/experimental/gradients/BUILD,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 620932239",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-01 20:11:31,"tensorflow/c/eager/parallel_device/BUILD, tensorflow/c/experimental/saved_model/internal/BUILD, tensorflow/core/common_runtime/next_pluggable_device/BUILD, tensorflow/core/function/polymorphism/BUILD, tensorflow/core/lib/random/BUILD, tensorflow/python/autograph/impl/BUILD, tensorflow/python/autograph/operators/BUILD, third_party/xla/xla/BUILD",tensorflower-gardener,False
"[xla:gpu][NFC] No need for custom HloModuleConfigs in address_computation_fusion_test

Since the rewriter is now in RunHloPasses, these configs do not do anything.

PiperOrigin-RevId: 620894763",Eugene Zhulenev,ezhulenev@google.com,2024-04-01 17:57:48,third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc,ezhulenev,False
"[xla:gpu] No need for dynamic/static mode in AddressComputationFusionRewriter

PiperOrigin-RevId: 620871987",Eugene Zhulenev,ezhulenev@google.com,2024-04-01 16:41:37,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc,ezhulenev,False
"[PJRT:CPU] Replace references to pjrt/tfrt_cpu_pjrt_client with pjrt/cpu/cpu_client.h.

The two are aliases and the former is a forwarding header pointing to the latter.

Cleanup only, no functional changes.

PiperOrigin-RevId: 620867527",Peter Hawkins,phawkins@google.com,2024-04-01 16:23:01,"tensorflow/c/experimental/next_pluggable_device/BUILD, tensorflow/c/experimental/next_pluggable_device/tensor_pjrt_buffer_util_test.cc, third_party/xla/xla/pjrt/cpu/BUILD",hawkinsp,False
"[PJRT:CPU] Fix thread-pool stack sizes to 2MiB.

The default thread pool size is too small on Mac OS.

An older version of this runtime based on StreamExecutor set a 2MiB stack size as well, but that change was most likely lost during the TFRT rewrite.

Fixes https://github.com/google/jax/issues/20428

PiperOrigin-RevId: 620853544",Peter Hawkins,phawkins@google.com,2024-04-01 15:19:49,third_party/xla/xla/pjrt/cpu/cpu_client.cc,hawkinsp,False
"compat: Update forward compatibility horizon to 2024-04-01

PiperOrigin-RevId: 620789797",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-01 09:02:35,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1819.

PiperOrigin-RevId: 620789686",A. Unique TensorFlower,gardener@tensorflow.org,2024-04-01 09:02:09,tensorflow/core/public/version.h,tensorflower-gardener,False
"[xla:gpu] DUS support for generic custom call emission in DynamicAddressComputationFusion emitter

PiperOrigin-RevId: 620691743",Son Tuan Vu,vuson@google.com,2024-03-31 21:34:02,"third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/fusions/custom.cc",tyb0807,False
"[xla:gpu] Generic custom call emission for DynamicAddressComputationFusion emitter

PiperOrigin-RevId: 620681261",Son Tuan Vu,vuson@google.com,2024-03-31 19:52:56,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/fusions/custom.cc",tyb0807,False
"Update GraphDef version to 1818.

PiperOrigin-RevId: 620607049",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-31 09:03:10,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-03-31

PiperOrigin-RevId: 620606935",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-31 09:02:36,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Enable SparseCore threads in TpuLayoutAssignment

PiperOrigin-RevId: 620567851",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-31 03:58:08,"third_party/xla/xla/hlo/utils/hlo_sharding_util.cc, third_party/xla/xla/hlo/utils/hlo_sharding_util.h, third_party/xla/xla/hlo/utils/hlo_sharding_util_test.cc, third_party/xla/xla/service/layout_assignment.cc, third_party/xla/xla/service/layout_assignment.h",tensorflower-gardener,False
"[xla:gpu][NFC] Use the same helpers to get slices for GEMM and generic custom call emissions

PiperOrigin-RevId: 620567579",Son Tuan Vu,vuson@google.com,2024-03-31 03:55:31,third_party/xla/xla/service/gpu/fusions/custom.cc,tyb0807,False
"[xla:gpu][NFC] Explicitly rewrite AddressComputationFusion in custom call tests

AddressComputationFusionRewriter is now part of `RunHloPasses`, we need to explicitly call it to transform the HLO in order to keep tests meaningful.

PiperOrigin-RevId: 620529073",Son Tuan Vu,vuson@google.com,2024-03-30 22:05:27,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc",tyb0807,False
"[xla:gpu][NFC] Make lambdas static functions for better reusability

PiperOrigin-RevId: 620511999",Son Tuan Vu,vuson@google.com,2024-03-30 19:09:23,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/custom.cc",tyb0807,False
"[xla:gpu] Unify static and dynamic slice cases for AddressComputationFusionRewriter

PiperOrigin-RevId: 620453556",Son Tuan Vu,vuson@google.com,2024-03-30 09:39:15,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc,tyb0807,False
"compat: Update forward compatibility horizon to 2024-03-30

PiperOrigin-RevId: 620449193",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-30 09:02:03,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1817.

PiperOrigin-RevId: 620449190",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-30 09:02:02,tensorflow/core/public/version.h,tensorflower-gardener,False
"[xla:gpu][NFC] Remove unused constexprs

PiperOrigin-RevId: 620446803",Son Tuan Vu,vuson@google.com,2024-03-30 08:42:11,third_party/xla/xla/service/gpu/fusions/custom.cc,tyb0807,False
"[xla:gpu] Unify GEMM emission for (Dynamic)AddressComputationFusion emitters

PiperOrigin-RevId: 620391616",Son Tuan Vu,vuson@google.com,2024-03-30 01:41:05,"third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/fusions/custom.cc",tyb0807,False
"[xla:gpu] AddressComputationFusionRewriter should run before other fusions

PiperOrigin-RevId: 620383409",Son Tuan Vu,vuson@google.com,2024-03-30 00:57:07,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_compiler_test.cc",tyb0807,False
"Add a contextmanager to temporarily disable XLA sharding support for ResourceVariables.

PiperOrigin-RevId: 620366887",Swachhand Lokhande,swachhand@google.com,2024-03-29 23:24:01,"tensorflow/python/compiler/xla/experimental/resource_variable_xla_sharding_test.py, tensorflow/python/eager/context.py",swachhandl,False
"In general, avoid the suffix on StatusOr.

PiperOrigin-RevId: 620366682",Gunhyun Park,gunhyun@google.com,2024-03-29 23:22:52,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"[PJRT C API] Add a PJRT extension to register custom partitioner.

- This extension has one C API which registers a custom partitioner with callbacks from the input.
- Update xla_client.register_custom_call_partitioner to take an optional PJRT_Api* input.
- Add xla_bridge.register_plugin_initialization_callbacks to register callbacks to be called with PJRT_Api* after plugins are discovered.

PiperOrigin-RevId: 620357554",Jieying Luo,jieying@google.com,2024-03-29 22:37:59,"third_party/xla/xla/pjrt/c/BUILD, third_party/xla/xla/pjrt/c/CHANGELOG.md, third_party/xla/xla/pjrt/c/pjrt_c_api.h, third_party/xla/xla/pjrt/c/pjrt_c_api_custom_partitioner_extension.h, third_party/xla/xla/pjrt/c/pjrt_c_api_gpu_internal.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/custom_call_sharding.cc, third_party/xla/xla/python/custom_partition_callback.cc, third_party/xla/xla/python/custom_partition_callback.h, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_extension/__init__.pyi",jyingl3,False
"[xla:gpu] Add a version of `HloPredicateIsOp` for `HloInstructionAdaptor`

PiperOrigin-RevId: 620335202",Son Tuan Vu,vuson@google.com,2024-03-29 21:03:53,third_party/xla/xla/service/gpu/hlo_traversal.h,tyb0807,False
"Implementation of get / retrieve buffer attributes methods in GPU async kernel.

PiperOrigin-RevId: 620328996",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 20:38:12,tensorflow/lite/delegates/gpu/delegate.cc,tensorflower-gardener,False
"Reverts 3a2cd8887ed96de6abbd26e46844b959aa42e481

PiperOrigin-RevId: 620324878",Marcello Maggioni,maggioni@google.com,2024-03-29 20:22:30,"third_party/xla/xla/service/collective_opt_utils.cc, third_party/xla/xla/service/collective_opt_utils.h, third_party/xla/xla/service/reduce_scatter_decomposer.cc, third_party/xla/xla/service/reduce_scatter_decomposer.h, third_party/xla/xla/service/reduce_scatter_decomposer_test.cc",,False
"Move `tsl/python` to `xla/tsl/python`

PiperOrigin-RevId: 620320903",David Dunleavy,ddunleavy@google.com,2024-03-29 20:05:35,"tensorflow/lite/python/interpreter_wrapper/numpy.h, tensorflow/python/BUILD, tensorflow/python/client/BUILD, tensorflow/python/client/tf_session_helper.h, tensorflow/python/client/tf_session_wrapper.cc, tensorflow/python/eager/BUILD, tensorflow/python/eager/pywrap_tensor.cc, tensorflow/python/eager/pywrap_tensor.h, tensorflow/python/framework/BUILD, tensorflow/python/lib/core/BUILD, tensorflow/python/lib/core/ndarray_tensor.cc, tensorflow/python/lib/core/ndarray_tensor_bridge.cc, tensorflow/python/lib/core/ndarray_tensor_bridge.h, tensorflow/python/lib/core/py_func.cc, tensorflow/python/lib/core/py_seq_tensor.cc, tensorflow/python/tfe_wrapper.cc, tensorflow/tools/def_file_filter/symbols_pybind.txt, tensorflow/tools/pip_package/build_pip_package.py, third_party/xla/third_party/tsl/tools/def_file_filter/symbols_pybind.txt, third_party/xla/third_party/tsl/tsl/platform/ml_dtypes.h, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/nb_numpy.cc, third_party/xla/xla/python/nb_numpy.h, third_party/xla/xla/python/pmap_lib.cc, third_party/xla/xla/python/py_compile_only_client.cc, third_party/xla/xla/python/py_values.cc, third_party/xla/xla/python/tools/BUILD, third_party/xla/xla/python/tools/_types.cc, third_party/xla/xla/python/types.cc, third_party/xla/xla/python/xla.cc, third_party/xla/xla/tsl/python/lib/core/BUILD, third_party/xla/xla/tsl/python/lib/core/ml_dtypes.cc, third_party/xla/xla/tsl/python/lib/core/ml_dtypes.h, third_party/xla/xla/tsl/python/lib/core/numpy.cc, third_party/xla/xla/tsl/python/lib/core/numpy.h",ddunl,False
"Use `bytes` proto field type for string values of `xla::PjRtValueType` to `bytes`

`xla::PjRtValueType` is defined in C++, where its `std::string` value can
contain any string (not necessarily UTF-8). Protobuf verison 3 requires a
`string` field to contain UTF-8, so it is more suitable to use `bytes` to
express this value.

(Note that the string value of `xla::PjRtValueType` would be often consumed by
Python, where nanobind would convert `std::string` into Python `str` with UTF-8
decoding. However, this is what some users of `xla::PjRtValueType` choose to
do; this is not sufficient enough to constrain the string to be UTF-8 only in
C++ APIs.)

This is a preemptive change; there is no known problem of using a `string`
field previously.

PiperOrigin-RevId: 620315110",Hyeontaek Lim,hyeontaek@google.com,2024-03-29 19:40:12,third_party/xla/xla/python/ifrt_proxy/common/types.proto,hyeontaek,False
"PR #7849: [XLA:CPU] Add support for cross-process collectives using mpi.

Imported from GitHub PR https://github.com/openxla/xla/pull/7849

Mpi collectives as proposed in https://github.com/google/jax/issues/11182?notification_referrer_id=NT_kwDOAG8zGbIzODQ5MDcxMzM0OjcyODc1Nzc#issuecomment-1851591135.

I only implemented the inter-process communication and this does not yet support more than 1 threads per process. Adding support for multiple threads/devices per process in the future seems quite a bit more involved if one wanted to do it properly.

For MPI I am building and linking against https://github.com/eschnett/MPItrampoline, which dlopens the (wrapped) mpi library at runtime. To wrap and load the desired mpi library one needs compile https://github.com/eschnett/MPIwrapper and set `MPITRAMPOLINE_LIB=/path/to/libmpiwrapper.so`.

@hawkinsp
Copybara import of the project:

--
b74bbb909d902bd30523f943a7c15f2c754cf98a by Clemens Giuliani <clemens@inailuig.it>:

add mpi collectives

--
23508eb46848464f6711dd8f3f91830ea1adb16d by Clemens Giuliani <clemens@inailuig.it>:

add explicit Init and Finalize methods and export them to python

--
bbe5840b8eb56a306a66ed03d701fd8976e01491 by Clemens Giuliani <clemens@inailuig.it>:

add comment

--
38d156282ecc89509f4b21d80db1a37cb290437a by Clemens Giuliani <clemens@inailuig.it>:

fix windows build

--
201f7238f166197ede5cf5d4d70e117a91eddcd7 by Clemens Giuliani <clemens@inailuig.it>:

fmt

--
2784869df650c1c123c346401db2f67cb153b03e by Clemens Giuliani <clemens@inailuig.it>:

bump xla_extension_version

Merging this change closes #7849

PiperOrigin-RevId: 620302264",Clemens Giuliani,clemens@inailuig.it,2024-03-29 18:49:47,"third_party/mpitrampoline/BUILD, third_party/mpitrampoline/gen.patch, third_party/mpitrampoline/mpitrampoline.BUILD, third_party/mpitrampoline/workspace.bzl, third_party/xla/third_party/mpitrampoline/BUILD, third_party/xla/third_party/mpitrampoline/gen.patch, third_party/xla/third_party/mpitrampoline/mpitrampoline.BUILD, third_party/xla/third_party/mpitrampoline/workspace.bzl, third_party/xla/workspace2.bzl, third_party/xla/xla/pjrt/cpu/BUILD, third_party/xla/xla/pjrt/cpu/mpi_collectives.cc, third_party/xla/xla/pjrt/cpu/mpi_collectives.h, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/xla.cc, third_party/xla/xla/python/xla_client.py",inailuig,False
"Add new methods in backend async kernel interface. Reflect to the design of go/async-io-coherency

New methods will set / retrieve the attributes based on the buffers.

PiperOrigin-RevId: 620300315",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 18:41:47,"tensorflow/lite/async/backend_async_kernel_interface.cc, tensorflow/lite/async/backend_async_kernel_interface.h, tensorflow/lite/async/backend_async_kernel_interface_test.cc, tensorflow/lite/async/testing/mock_async_kernel.h, tensorflow/lite/core/async/async_kernel_internal.h, tensorflow/lite/core/async/async_signature_runner.cc, tensorflow/lite/core/async/async_signature_runner.h, tensorflow/lite/core/async/async_subgraph.cc, tensorflow/lite/core/async/async_subgraph.h, tensorflow/lite/core/async/c/async_kernel.cc, tensorflow/lite/core/async/c/async_kernel.h, tensorflow/lite/delegates/gpu/delegate.cc",tensorflower-gardener,False
"Add support for LocalDeviceManager in tfrt_session.

PiperOrigin-RevId: 620292882",Chris Minge,chrisminge@google.com,2024-03-29 18:15:22,tensorflow/core/tfrt/tfrt_session/tfrt_session.cc,CMinge,False
"Integrate LLVM at llvm/llvm-project@80aa52d8c5a8

Updates LLVM usage to match
[80aa52d8c5a8](https://github.com/llvm/llvm-project/commit/80aa52d8c5a8)

PiperOrigin-RevId: 620285862",Dmitri Gribenko,dmitrig@google.com,2024-03-29 17:53:24,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",gribozavr,False
"Change include order in `ml_dtypes.cc` to prevent errors.

Trying to prevent `error: ""Using deprecated NumPy API, disable it with #define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION""`

PiperOrigin-RevId: 620284610",David Dunleavy,ddunleavy@google.com,2024-03-29 17:49:09,third_party/xla/third_party/tsl/tsl/python/lib/core/ml_dtypes.cc,ddunl,False
"[xla:gpu][NFC] Simplify `collect_slice_info`

PiperOrigin-RevId: 620281417",Son Tuan Vu,vuson@google.com,2024-03-29 17:38:02,"third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h",tyb0807,False
"Modify the matrix class to keep track of both memory and communication resharding costs for a given edge as part of one matrix object.

PiperOrigin-RevId: 620273768",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 17:12:51,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_cost_graph.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_cost_graph.h, third_party/xla/xla/hlo/experimental/auto_sharding/matrix.h",tensorflower-gardener,False
"Rollback https://github.com/openxla/xla/commit/0ab2be0b5a575da3206d2c2f92b85e6346708405.

There is an internal issue with running tests on H100s requiring the change to be rolled back.

Reverts 42883cb09d1a8155824ce4ed044794c0dffdd19f

PiperOrigin-RevId: 620273492",Reed Wanderman-Milne,reedwm@google.com,2024-03-29 17:11:59,third_party/xla/xla/service/gpu/BUILD,reedwm,False
"[tflite] Add the composite lowering logic for hardswish

This directly lowers an aten hardswish to a tflite hardswish

PiperOrigin-RevId: 620273404",Majid Dadashi,majiddadashi@google.com,2024-03-29 17:11:36,"tensorflow/compiler/mlir/lite/stablehlo/tests/composite-lowering.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_patterns.td",majiddadashi,False
"Enhanced zeta readability based on the article

Changes based on the Hurwitz Zeta algorithm from the article linked in the comments.

PiperOrigin-RevId: 620272234",Paweł Paruzel,paruzelp@google.com,2024-03-29 17:07:30,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_mhlo.mlir",pparuzel,False
"[odml] Remove MHLO from CHLO->StableHLO lowering. Migrate JAX random lowering to StableHLO

PiperOrigin-RevId: 620269527",Kevin Gleason,gleasonk@google.com,2024-03-29 17:00:03,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/tests/legalize_jax_random.mlir, tensorflow/compiler/mlir/lite/tf_tfl_passes.cc, tensorflow/compiler/mlir/lite/transforms/legalize_jax_random.cc, tensorflow/compiler/mlir/lite/transforms/passes.td, tensorflow/compiler/mlir/lite/transforms/quantize_variables.cc",GleasonK,False
"Restore GOOGLE_CUDA guard in scoped_annotation.h

PiperOrigin-RevId: 620260337",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 16:19:31,third_party/xla/third_party/tsl/tsl/profiler/lib/scoped_annotation.h,tensorflower-gardener,False
"Delete the redundant compilation_cache_test

PiperOrigin-RevId: 620259968",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 16:17:53,"third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/compilation_cache_test.cc",tensorflower-gardener,False
"Deduplicate inferred mesh shapes when try_multiple_mesh_shapes=true.

PiperOrigin-RevId: 620258542",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 16:10:25,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc,tensorflower-gardener,False
"Split hybrid quantized dot-like StableHLO ops into TFLite dequantize and float op

Hybrid quantized op has semantics for weight-only quantization within StableHLO, so it should be splitted into dequantize and float op for legalization towards TFLite.

PiperOrigin-RevId: 620197428",Doyeon Kim,doyeonkim@google.com,2024-03-29 09:52:05,"tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/uniform_quantized_stablehlo_to_tfl_pass.cc",doyeonkim0,False
"[xla:gpu][NFC] Use meaningful constexpr

PiperOrigin-RevId: 620194665",Son Tuan Vu,vuson@google.com,2024-03-29 09:31:43,third_party/xla/xla/service/gpu/fusions/custom.cc,tyb0807,False
"Update GraphDef version to 1816.

PiperOrigin-RevId: 620190062",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 09:02:26,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-03-29

PiperOrigin-RevId: 620190038",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 09:02:17,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"[xla:gpu][NFC] Add AddressComputationThunk test with GEMM operands sharing the same buffer

PiperOrigin-RevId: 620184639",Son Tuan Vu,vuson@google.com,2024-03-29 08:26:57,third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc,tyb0807,False
"Convert quantized stablehlo.constant to tfl.pseudo_qconst

PiperOrigin-RevId: 620182445",Doyeon Kim,doyeonkim@google.com,2024-03-29 08:11:55,"tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/uniform_quantized_stablehlo_to_tfl_pass.cc",doyeonkim0,False
"[xla:gpu] Create fake buffer allocations for embedded thunk

This is required in cases where embedded thunk arguments share the same buffer (i.e. they are located at different offsets of the same buffer)

PiperOrigin-RevId: 620179451",Son Tuan Vu,vuson@google.com,2024-03-29 07:54:46,"third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc",tyb0807,False
"[xla][gpu] Extracting triton codegen requirements for hlo instructions
This CL extracts current triton codegen requirements for each hlo instruction into a single function to clean the codes in the triton fusion passes.

PiperOrigin-RevId: 620157253",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 05:29:12,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/cublas_pad_for_gemms.cc, third_party/xla/xla/service/gpu/fusions/triton.cc, third_party/xla/xla/service/gpu/gemm_fusion.cc, third_party/xla/xla/service/gpu/gemm_fusion.h, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/softmax_rewriter_triton.cc, third_party/xla/xla/service/gpu/softmax_rewriter_triton_test.cc, third_party/xla/xla/service/gpu/triton_support.cc, third_party/xla/xla/service/gpu/triton_support.h, third_party/xla/xla/service/gpu/triton_support_test.cc",tensorflower-gardener,False
"[xla:gpu][NFC] Use absl::Span more consistenly

PiperOrigin-RevId: 620156928",Son Tuan Vu,vuson@google.com,2024-03-29 05:26:52,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc,tyb0807,False
"Automated Code Change

PiperOrigin-RevId: 620149815",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 04:35:01,third_party/xla/third_party/tsl/tsl/profiler/lib/connected_traceme.h,tensorflower-gardener,False
"Go: Update generated wrapper functions for TensorFlow ops.

PiperOrigin-RevId: 620131121",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 02:46:52,tensorflow/go/op/wrappers.go,tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@aa2c14de1adc

Updates LLVM usage to match
[aa2c14de1adc](https://github.com/llvm/llvm-project/commit/aa2c14de1adc)

PiperOrigin-RevId: 620124069",Dmitri Gribenko,dmitrig@google.com,2024-03-29 02:04:05,"tensorflow/compiler/mlir/lite/experimental/tac/BUILD, tensorflow/compiler/mlir/lite/quantization/ir/BUILD, tensorflow/compiler/mlir/quantization/common/ir/BUILD, tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/ir/host_runtime/BUILD, tensorflow/compiler/mlir/tfrt/ir/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/ir/BUILD, third_party/llvm/generated.patch, third_party/llvm/workspace.bzl, third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/python/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/ir/BUILD, third_party/xla/xla/service/gpu/gpu_compiler.cc",gribozavr,False
"[XLA] Respect min_rank for reduce scatter version of MatchReduceScatter.

We need to honor it.

PiperOrigin-RevId: 620121620",Marcello Maggioni,maggioni@google.com,2024-03-29 01:51:38,third_party/xla/xla/service/collective_opt_utils.cc,,False
"Enable weight-only quantization of stablehlo.convolution

PiperOrigin-RevId: 620121421",Doyeon Kim,doyeonkim@google.com,2024-03-29 01:50:52,"tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.td, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize/quantize_weight_only.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions_weight_only.mlir",doyeonkim0,False
"Add missing 'END' to definition of XlaSplitND.

PiperOrigin-RevId: 620112924",Matthias Kramm,kramm@google.com,2024-03-29 01:11:34,tensorflow/core/api_def/base_api/api_def_XlaSplitND.pbtxt,matthiaskramm,False
"Set release_base for all release platforms

PiperOrigin-RevId: 620111958",Jake Harmon,jakeharmon@google.com,2024-03-29 01:06:04,".bazelrc, third_party/xla/.bazelrc, third_party/xla/third_party/tsl/.bazelrc",jakeharmon8,False
"Remove the duplicate device assignment in ifrt_serving_executable.

PiperOrigin-RevId: 620111648",Siqiao Wu,siqiaowu@google.com,2024-03-29 01:04:29,"tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc",SiqiaoWu1993,False
"Correctly handle output streaming case where the MoveToHost annotation is the entry computation root

PiperOrigin-RevId: 620107928",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-29 00:44:19,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/host_offload_legalize.cc, third_party/xla/xla/service/host_offloader.cc, third_party/xla/xla/service/host_offloader_test.cc",tensorflower-gardener,False
"Add a Resource for KV Cache buffer storage

PiperOrigin-RevId: 620097541",T.J. Alumbaugh,talumbau@google.com,2024-03-28 23:58:40,"tensorflow/lite/experimental/resource/BUILD, tensorflow/lite/experimental/resource/cache_buffer.cc, tensorflow/lite/experimental/resource/cache_buffer.h, tensorflow/lite/experimental/resource/cache_buffer_test.cc, tensorflow/lite/experimental/resource/resource_variable.h",talumbau,False
"Delete populateRankSpecialization*Patterns functions

These were used by KernelGen but are no longer needed.

PiperOrigin-RevId: 620084345",Michael Levesque-Dion,mlevesquedion@google.com,2024-03-28 23:06:00,third_party/xla/xla/mlir_hlo/mhlo/transforms/rewriters.h,mlevesquedion,False
"Internal cleanup of BUILD/.bzl files

PiperOrigin-RevId: 620077983",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 22:41:03,"tensorflow/lite/acceleration/configuration/BUILD, tensorflow/lite/experimental/acceleration/configuration/BUILD",tensorflower-gardener,False
"Move sparsecore passes under transforms/sparsecore.

PiperOrigin-RevId: 620072718",Matthias Kramm,kramm@google.com,2024-03-28 22:22:06,"tensorflow/compiler/mlir/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/lower_cluster_to_runtime_ops.cc, tensorflow/compiler/mlir/tensorflow/transforms/passes.h, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/embedding_pipelining.cc, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/embedding_program_key.cc, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/embedding_sequencing.cc, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/sparsecore_passes.h, tensorflow/compiler/mlir/tensorflow/transforms/sparsecore/sparsecore_passes.td, tensorflow/compiler/mlir/tensorflow/transforms/tf_passes.td, tensorflow/compiler/mlir/tf2xla/internal/BUILD, tensorflow/compiler/mlir/tf2xla/internal/clustering_bridge_passes.cc, tensorflow/compiler/mlir/tf_mlir_opt_main.cc",matthiaskramm,False
"Integrate StableHLO at openxla/stablehlo@271e8634

PiperOrigin-RevId: 620069321",Gunhyun Park,gunhyun@google.com,2024-03-28 22:09:11,"third_party/stablehlo/workspace.bzl, third_party/xla/third_party/stablehlo/workspace.bzl",ghpvnist,False
"[XLA:Python] Adding `xla::PrimitiveType` <-> `numpy.dtype` conversions to the library for internal debugging tools.

PiperOrigin-RevId: 620068167",Wren Romano,wrengr@google.com,2024-03-28 22:04:52,"third_party/xla/xla/python/tools/BUILD, third_party/xla/xla/python/tools/_types.cc, third_party/xla/xla/python/tools/_types.pyi, third_party/xla/xla/python/tools/types.py, third_party/xla/xla/python/tools/types_test.py",wrengr,False
"Add quantization/legalization for `stablehlo.add` and respective pipeline changes.

* Added `enable_full_int_quantization` in `StaticRangePtqPreset` to determine full int quantization. This value will be `false` by default, meaning only compute-heavy ops will be quantized unless specified.
* Added tests for the above config change.
* Follow up tests will include e2e python tests.

PiperOrigin-RevId: 620067140",Jiyoun (Jen) Ha,jiyounha@google.com,2024-03-28 22:01:23,"tensorflow/compiler/mlir/lite/stablehlo/tests/uniform-quantized-stablehlo-to-tfl.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/uniform_quantized_stablehlo_to_tfl_pass.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/config.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/config_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/pass_pipeline.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/lift_quantizable_spots_as_functions_simple.td, tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.td, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize_composite_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/testing/passes.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/testing/passes.td, tensorflow/compiler/mlir/quantization/stablehlo/passes/testing/test_lift_quantizable_spots_as_functions_with_quantization_specs.cc, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/lift_quantizable_spots_as_functions_with_quantization_specs.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions_all_ops.mlir, tensorflow/lite/python/lite.py",chococigar,False
"Reduce memory usage of convert_control_to_data_outputs.

PiperOrigin-RevId: 620064529",Matthias Kramm,kramm@google.com,2024-03-28 21:51:37,"tensorflow/compiler/mlir/tensorflow/analysis/resource_dataflow.cc, tensorflow/compiler/mlir/tensorflow/analysis/resource_dataflow.h, tensorflow/compiler/mlir/tensorflow/transforms/convert_control_to_data_outputs.cc",matthiaskramm,False
"[XLA:Python] Add python function to convert `xla::LiteralProto` into a tuple-tree of `numpy.ndarray`.

This is intended for internal debugging use. It cannot be used on OSS because the relevant protobufs are not part of the public API. (Though it must not break the OSS build, naturally.)

PiperOrigin-RevId: 620064326",Wren Romano,wrengr@google.com,2024-03-28 21:50:54,"third_party/xla/xla/python/tools/BUILD, third_party/xla/xla/python/tools/__init__.py, third_party/xla/xla/python/tools/_types.cc, third_party/xla/xla/python/tools/_types.pyi, third_party/xla/xla/python/tools/types.py, third_party/xla/xla/python/tools/types_test.py",wrengr,False
"[MLIR Exporter] Move created `NodeDef` and `AttrValue` protocol buffers into the exported `Graph`.

PiperOrigin-RevId: 620061282",Derek Murray,mrry@google.com,2024-03-28 21:40:01,"tensorflow/compiler/mlir/tensorflow/translate/export_graphdef.cc, tensorflow/compiler/mlir/tensorflow/utils/export_utils.cc",mrry,False
"Add a field to StreamZ metric /tensorflow/core/tf_mlir_bridge_first_phase_count

Add a filed for the type of TF2XLA Phase 1 Bridge , i.e. Replicated Bridge vs. Non-replicated Bridge.

PiperOrigin-RevId: 620060074",Jian Cai,jiancai@google.com,2024-03-28 21:35:50,"tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/lower_cluster_to_runtime_ops.cc, tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/lower_cluster_to_runtime_ops_test.cc, tensorflow/compiler/mlir/tensorflow/utils/attribute_utils.h, tensorflow/compiler/mlir/tf2xla/api/v1/BUILD, tensorflow/compiler/mlir/tf2xla/api/v1/cluster_tf.cc, tensorflow/compiler/mlir/tf2xla/api/v1/cluster_tf_test.cc, tensorflow/compiler/mlir/tf2xla/api/v2/BUILD, tensorflow/compiler/mlir/tf2xla/api/v2/cluster_tf.cc, tensorflow/compiler/mlir/tf2xla/api/v2/cluster_tf_test.cc, tensorflow/compiler/tf2xla/BUILD, tensorflow/compiler/tf2xla/mlir_bridge_pass.cc, tensorflow/core/framework/metrics.cc, tensorflow/core/framework/metrics.h",jcai19,False
"Add support for tiled sharding with replicate_on_last_tile_dim in TpuRewrite pass

PiperOrigin-RevId: 620057438",Swachhand Lokhande,swachhand@google.com,2024-03-28 21:26:39,"tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/tests/tpu_rewrite.mlir, tensorflow/compiler/mlir/tensorflow/utils/xla_sharding_util.cc, tensorflow/compiler/mlir/tensorflow/utils/xla_sharding_util.h, tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_pass.cc",swachhandl,False
"[XLA:Python] Factors the "":logging"" library out from "":xla_extension"".

This is a prospective change for https://github.com/openxla/xla/pull/10966.  In particular, this will help fix an OSS build problem: ""tensorflow/xla/linux/cpu/build_cpu"" not being able to find the `InitializeAbslLogging` function.

PiperOrigin-RevId: 620055000",Wren Romano,wrengr@google.com,2024-03-28 21:18:17,third_party/xla/xla/python/BUILD,wrengr,False
"Fix a use-after-free issue, change a non-nullable pointer argument to a reference and get rid of an unused function argument.

PiperOrigin-RevId: 620047666",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 20:53:49,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.h",tensorflower-gardener,False
"Do not wrap lifted function in `TF.CustomAggregatorOp` with improper `quantization_method`.

PiperOrigin-RevId: 620045624",Jiyoun (Jen) Ha,jiyounha@google.com,2024-03-28 20:46:34,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/pre_calibration_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/testing/test_pre_calibration_component.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/pre_calibration_component.mlir, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_custom_aggregation_ops.cc",chococigar,False
"Disable Compiler ir test for h100 GPU targets

PiperOrigin-RevId: 620045586",Isha Arkatkar,ishark@google.com,2024-03-28 20:46:25,tensorflow/python/eager/polymorphic_function/BUILD,ishark,False
"Move `tsl/util` to `xla/tsl/util`

PiperOrigin-RevId: 620039887",David Dunleavy,ddunleavy@google.com,2024-03-28 20:27:01,"tensorflow/core/BUILD, tensorflow/core/common_runtime/colocate_predecessor_trees_pass.cc, tensorflow/core/common_runtime/eager/BUILD, tensorflow/core/common_runtime/eager/context.cc, tensorflow/core/common_runtime/eager/execute.cc, tensorflow/core/common_runtime/eager/execute_node.cc, tensorflow/core/common_runtime/gpu/gpu_process_state.cc, tensorflow/core/common_runtime/process_function_library_runtime.cc, tensorflow/core/data/BUILD, tensorflow/core/data/dataset_utils_test.cc, tensorflow/core/framework/BUILD, tensorflow/core/framework/tensor.cc, tensorflow/core/kernels/BUILD, tensorflow/core/kernels/image/BUILD, tensorflow/core/kernels/image/decode_image_op.cc, tensorflow/core/kernels/logging_ops_test.cc, tensorflow/core/kernels/numeric_options_utils.h, tensorflow/core/kernels/scatter_nd_util.h, tensorflow/core/profiler/convert/BUILD, tensorflow/core/profiler/convert/op_stats_to_input_pipeline_analysis.cc, tensorflow/core/profiler/utils/BUILD, tensorflow/core/profiler/utils/derived_timeline.cc, tensorflow/core/util/BUILD, tensorflow/core/util/command_line_flags.h, tensorflow/core/util/determinism.h, tensorflow/core/util/device_name_utils.h, tensorflow/core/util/env_var.h, tensorflow/core/util/mkl_util.h, tensorflow/core/util/proto/BUILD, tensorflow/core/util/proto/proto_utils.h, tensorflow/core/util/reporter.h, tensorflow/core/util/stat_summarizer_options.h, tensorflow/core/util/stats_calculator.h, tensorflow/core/util/tensor_bundle/BUILD, tensorflow/core/util/tensor_bundle/byte_swap_array.h, tensorflow/core/util/tensor_bundle/tensor_bundle.cc, tensorflow/core/util/use_cudnn.h, tensorflow/core/util/work_sharder.cc, tensorflow/dtensor/cc/BUILD, tensorflow/dtensor/cc/dtensor_device.cc, tensorflow/dtensor/cc/dtensor_utils.cc, tensorflow/dtensor/mlir/utils/BUILD, tensorflow/dtensor/mlir/utils/collective_lowering.cc, tensorflow/lite/CMakeLists.txt, tensorflow/lite/examples/label_image/CMakeLists.txt, tensorflow/lite/testing/BUILD, tensorflow/lite/testing/generated_examples_zip_test.cc, tensorflow/lite/tools/benchmark/CMakeLists.txt, tensorflow/lite/tools/benchmark/experimental/c/BUILD, tensorflow/lite/tools/benchmark/experimental/c/benchmark_c_api.cc, tensorflow/lite/tools/evaluation/stages/BUILD, tensorflow/lite/tools/evaluation/stages/image_preprocessing_stage.h, tensorflow/lite/tools/evaluation/stages/inference_profiler_stage.h, tensorflow/lite/tools/evaluation/stages/tflite_inference_stage.h, tensorflow/python/framework/BUILD, tensorflow/python/framework/offset_counter.cc, tensorflow/python/framework/python_op_gen_main.cc, tensorflow/python/util/BUILD, tensorflow/python/util/stat_summarizer_wrapper.cc, tensorflow/tools/android/inference_interface/jni/run_stats_jni.h, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/BUILD, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/third_party/tsl/tsl/distributed_runtime/rpc/BUILD, third_party/xla/third_party/tsl/tsl/distributed_runtime/rpc/grpc_channel.cc, third_party/xla/third_party/tsl/tsl/distributed_runtime/rpc/grpc_channel_test.cc, third_party/xla/third_party/tsl/tsl/distributed_runtime/rpc/grpc_state.h, third_party/xla/third_party/tsl/tsl/framework/BUILD, third_party/xla/third_party/tsl/tsl/framework/device_id_utils.h, third_party/xla/third_party/tsl/tsl/framework/device_id_utils_test.cc, third_party/xla/third_party/tsl/tsl/platform/cloud/BUILD, third_party/xla/third_party/tsl/tsl/platform/cloud/curl_http_request.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/BUILD, third_party/xla/third_party/tsl/tsl/profiler/lib/profiler_lock.cc, third_party/xla/third_party/tsl/tsl/profiler/utils/BUILD, third_party/xla/third_party/tsl/tsl/profiler/utils/xplane_utils.cc, third_party/xla/third_party/tsl/tsl/protobuf/BUILD, third_party/xla/xla/BUILD, third_party/xla/xla/backends/profiler/gpu/BUILD, third_party/xla/xla/backends/profiler/gpu/cupti_utils.cc, third_party/xla/xla/backends/profiler/gpu/device_tracer_cuda.cc, third_party/xla/xla/backends/profiler/gpu/device_tracer_rocm.cc, third_party/xla/xla/backends/profiler/gpu/rocm_collector.cc, third_party/xla/xla/debug_options_flags.cc, third_party/xla/xla/debug_options_flags.h, third_party/xla/xla/literal.cc, third_party/xla/xla/parse_flags_from_env.cc, third_party/xla/xla/parse_flags_from_env.h, third_party/xla/xla/parse_flags_from_env_test.cc, third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/gpu_helpers.cc, third_party/xla/xla/service/BUILD, third_party/xla/xla/service/cpu/BUILD, third_party/xla/xla/service/cpu/onednn_layer_norm.cc, third_party/xla/xla/service/cpu/onednn_matmul.cc, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/service/cpu/onednn_softmax.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/llvm_gpu_backend/BUILD, third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/hlo_op_profiler_run.cc, third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/service/gpu/stream_executor_util.cc, third_party/xla/xla/service/gpu/stream_executor_util_test.cc, third_party/xla/xla/service/gpu_compilation_environment.cc, third_party/xla/xla/service/xla_compile_main.cc, third_party/xla/xla/stream_executor/BUILD, third_party/xla/xla/stream_executor/cuda/BUILD, third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc, third_party/xla/xla/stream_executor/rocm/BUILD, third_party/xla/xla/stream_executor/rocm/rocm_blas.cc, third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc, third_party/xla/xla/stream_executor/stream_executor_pimpl.cc, third_party/xla/xla/tools/BUILD, third_party/xla/xla/tools/extract_collective_operations.cc, third_party/xla/xla/tools/hex_floats_to_packed_literal.cc, third_party/xla/xla/tools/hlo_bisect/BUILD, third_party/xla/xla/tools/hlo_bisect/hlo_bisect.cc, third_party/xla/xla/tools/hlo_expand.cc, third_party/xla/xla/tools/hlo_expand.h, third_party/xla/xla/tools/hlo_expand_main.cc, third_party/xla/xla/tools/hlo_opt/BUILD, third_party/xla/xla/tools/hlo_opt/opt_main.cc, third_party/xla/xla/tools/hlo_proto_to_json.cc, third_party/xla/xla/tools/interactive_graphviz.cc, third_party/xla/xla/tools/multihost_hlo_runner/BUILD, third_party/xla/xla/tools/multihost_hlo_runner/hlo_runner_main.cc, third_party/xla/xla/tools/run_hlo_module_main.cc, third_party/xla/xla/tsl/util/BUILD, third_party/xla/xla/tsl/util/byte_swap_array.cc, third_party/xla/xla/tsl/util/byte_swap_array.h, third_party/xla/xla/tsl/util/command_line_flags.cc, third_party/xla/xla/tsl/util/command_line_flags.h, third_party/xla/xla/tsl/util/determinism.cc, third_party/xla/xla/tsl/util/determinism.h, third_party/xla/xla/tsl/util/determinism_test_util.h, third_party/xla/xla/tsl/util/device_name_utils.cc, third_party/xla/xla/tsl/util/device_name_utils.h, third_party/xla/xla/tsl/util/device_name_utils_test.cc, third_party/xla/xla/tsl/util/env_var.cc, third_party/xla/xla/tsl/util/env_var.h, third_party/xla/xla/tsl/util/onednn_threadpool.h, third_party/xla/xla/tsl/util/proto/BUILD, third_party/xla/xla/tsl/util/proto/proto_utils.h, third_party/xla/xla/tsl/util/reporter.cc, third_party/xla/xla/tsl/util/reporter.h, third_party/xla/xla/tsl/util/stat_summarizer_options.h, third_party/xla/xla/tsl/util/stats_calculator.cc, third_party/xla/xla/tsl/util/stats_calculator.h, third_party/xla/xla/tsl/util/stats_calculator_test.cc, third_party/xla/xla/tsl/util/use_cudnn.cc, third_party/xla/xla/tsl/util/use_cudnn.h, third_party/xla/xla/xla.bzl",ddunl,False
"[XLA:Python] Add pytype_srcs and pytype_deps attributes to pytype_strict_library.

These attributes are ignored, because we don't use pytype in OSS builds at the moment.

While we're here, remove a copybara transformation that strips off a pytype_srcs attribute: we can just leave the attribute alone and it won't do any harm.

PiperOrigin-RevId: 620026406",Peter Hawkins,phawkins@google.com,2024-03-28 19:45:29,"third_party/xla/xla/python/BUILD, third_party/xla/xla/pytype.default.bzl",hawkinsp,False
"Add Batch Norm to the integration test. Remove all the rng_seed parameters.

PiperOrigin-RevId: 620022797",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 19:33:20,tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py,tensorflower-gardener,False
"NFC: Add `@llvm-project//mlir:TransformUtils` dependency as preparation for https://github.com/llvm/llvm-project/pull/86819.

PiperOrigin-RevId: 620006777",Christian Sigg,csigg@google.com,2024-03-28 18:39:01,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/BUILD, tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/cc/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/BUILD, tensorflow/compiler/mlir/tf2xla/transforms/BUILD, tensorflow/compiler/mlir/tfrt/BUILD, tensorflow/compiler/mlir/tfrt/ir/BUILD, tensorflow/compiler/mlir/tfrt/ir/mlrt/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/transforms/BUILD, tensorflow/compiler/mlir/tosa/BUILD, tensorflow/compiler/tf2xla/BUILD, tensorflow/core/transforms/constant_folding/BUILD, tensorflow/core/transforms/remapper/BUILD, tensorflow/dtensor/mlir/BUILD, third_party/triton/cl619443019.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/cl619443019.patch, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/xla/mlir/runtime/transforms/BUILD, third_party/xla/xla/mlir_hlo/BUILD",chsigg,False
"Change the default gpu loop value to 1

PiperOrigin-RevId: 620005388",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 18:34:59,"tensorflow/lite/delegates/gpu/api.h, tensorflow/lite/delegates/gpu/cl/api.cc, tensorflow/lite/delegates/gpu/delegate_options.cc, tensorflow/lite/delegates/gpu/delegate_options.h, tensorflow/lite/tools/benchmark/benchmark_model.cc, tensorflow/lite/tools/benchmark/benchmark_performance_options.cc, tensorflow/lite/tools/delegates/default_execution_provider.cc",tensorflower-gardener,False
"[XLA] add a setter for HloInputOutputAliasConfig and HloBufferDonorConfig

This is needed to move those configs from an old HloModule to a new one.

PiperOrigin-RevId: 620001061",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 18:23:34,third_party/xla/xla/hlo/ir/hlo_module.h,tensorflower-gardener,False
"Logs a fatal message if Auto Sharding times out (since we no longer rely on GSPMD as a backup).

PiperOrigin-RevId: 619997588",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 18:13:15,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc,tensorflower-gardener,False
"[stream_executor:host] Add missing externs to C API header

PiperOrigin-RevId: 619992965",Eugene Zhulenev,ezhulenev@google.com,2024-03-28 17:59:48,third_party/xla/xla/stream_executor/host/host_kernel_c_api.h,ezhulenev,False
"[PJRT:GPU] Fix implementation of .compute_capability on devices to remove the need for an ifdef.

PiperOrigin-RevId: 619989520",Peter Hawkins,phawkins@google.com,2024-03-28 17:49:07,third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc,hawkinsp,False
"[xla] remove BorrowingLiteral constructor for LiteralProto

PiperOrigin-RevId: 619985533",Peter Gavin,pgavin@google.com,2024-03-28 17:36:44,"third_party/xla/xla/literal.cc, third_party/xla/xla/literal.h, third_party/xla/xla/literal_test.cc",,False
"[XLA:GPU] Skip matrix-matrix multiplication in GemvRewriter

PiperOrigin-RevId: 619983009",Anlun Xu,anlunx@google.com,2024-03-28 17:29:45,"third_party/xla/xla/service/gpu/gemv_rewriter.cc, third_party/xla/xla/service/gpu/gemv_rewriter_test.cc",anlunx,False
"#shlo_ref: Fix adb typo

PiperOrigin-RevId: 619974234",RJ Ascani,rjascani@google.com,2024-03-28 17:07:47,tensorflow/lite/experimental/shlo/README.md,rascani,False
"PR #10759: [XLA:CPU][oneDNN] Enable matrix-vector and vector-vector product

Imported from GitHub PR https://github.com/openxla/xla/pull/10759

This PR relaxes conditions to rewrite dot operations of the form vector-matrix, matrix-vector, or vector-vector to oneDNN custom calls, provided the original problem meets the empirically determined multiply-accumulate threshold. In particular this PR:

1. Relaxes some constraints on Dot to oneDNN matmul custom call conversion
2. Reconfigures the dimensions of the operands and outputs of convertible dot operations.
3. Adds tests to verify rewrite and execution result
Copybara import of the project:

--
d24e5cd0b77d0734a0f33011ae03127f00d80e7d by Akhil Goel <akhil.goel@intel.com>:

Relax constraints for matmul rewrite

--
9582288fc5d06eb8f4641be32d6c41746f13dbce by Akhil Goel <akhil.goel@intel.com>:

Fix gemv test after merge

--
604d4fbd29a78a7d305092356176e31081ea4ff0 by Akhil Goel <akhil.goel@intel.com>:

Address review comments

--
4534fbd7e96a6e45ccc5a501b38b940aa8bd9d38 by Akhil Goel <akhil.goel@intel.com>:

Optional commit

Merging this change closes #10759

PiperOrigin-RevId: 619968241",akhilgoe,114951738+akhilgoe@users.noreply.github.com,2024-03-28 16:53:05,"third_party/xla/xla/service/cpu/cpu_float_support.cc, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/tests/onednn_matmul_test.cc",akhilgoe,False
"Make the computation of the memory budget lower bound more efficient. Specifically:
1. Iterate over AliasAnalysis::buffers() rather than the live ranges as the latter has too many duplicates
2. Turn a Shape object into a const reference
3. Pull out a conditional to exit early when possible.

PiperOrigin-RevId: 619967473",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 16:50:49,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc,tensorflower-gardener,False
"[stream_executor:host] Rename host_gpu_executor

PiperOrigin-RevId: 619965098",Vladyslav Tsilytskyi,tsilytskyi@google.com,2024-03-28 16:45:23,"third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_executor.cc, third_party/xla/xla/stream_executor/host/host_executor.h, third_party/xla/xla/stream_executor/host/host_platform.cc",tvladyslav,False
"[XLA] Add functionality to ReduceScatterDecomposer to be selective

PiperOrigin-RevId: 619957874",Marcello Maggioni,maggioni@google.com,2024-03-28 16:26:08,"third_party/xla/xla/service/collective_opt_utils.cc, third_party/xla/xla/service/collective_opt_utils.h, third_party/xla/xla/service/reduce_scatter_decomposer.cc, third_party/xla/xla/service/reduce_scatter_decomposer.h, third_party/xla/xla/service/reduce_scatter_decomposer_test.cc",,False
"[xla:gpu][NFC] Refactor and rename in address_computation_fusion_rewriter for clarity

PiperOrigin-RevId: 619954961",Son Tuan Vu,vuson@google.com,2024-03-28 16:16:17,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc,tyb0807,False
"PR #10344: [XLA:CPU] Enable BMM+Mul+Add fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/10344

This PR enables the BatchMatMul + Mul + Add fusion and adds a simple test
Copybara import of the project:

--
2a202c9d171064bb3005e0753af41e26f2e1baf3 by Kanvi Khanna <kanvi.khanna@intel.com>:

Enable BMM+Mul+Add fusion

--
584e59861f5f91fae8222b9281e501dbeb270b94 by Kanvi Khanna <kanvi.khanna@intel.com>:

Address review comments

Merging this change closes #10344

PiperOrigin-RevId: 619954276",Kanvi Khanna,kanvi.khanna@intel.com,2024-03-28 16:14:06,"third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/tests/onednn_matmul_test.cc",kanvi-nervana,False
"[xla:gpu] Address computation thunk should not be inside command buffer

Address computation is not compatible with command buffer since it requires a host sync.

PiperOrigin-RevId: 619951741",Son Tuan Vu,vuson@google.com,2024-03-28 16:06:31,third_party/xla/xla/service/gpu/command_buffer_scheduling.cc,tyb0807,False
"#shlo_ref Add `minimum` op.

PiperOrigin-RevId: 619948992",Quentin Khan,qkhan@google.com,2024-03-28 15:58:37,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/minimum.cc, tensorflow/lite/experimental/shlo/ops/minimum.h, tensorflow/lite/experimental/shlo/ops/minimum_test.cc",qukhan,False
"Merge pull request #64633 from rascani:move_template_specializations_to_non_namespace

PiperOrigin-RevId: 619944673",TensorFlower Gardener,gardener@tensorflow.org,2024-03-28 16:43:38,"tensorflow/lite/experimental/shlo/ops/cbrt.cc, tensorflow/lite/experimental/shlo/ops/cbrt_test.cc, tensorflow/lite/experimental/shlo/ops/ceil.cc, tensorflow/lite/experimental/shlo/ops/ceil_test.cc, tensorflow/lite/experimental/shlo/ops/cosine.cc, tensorflow/lite/experimental/shlo/ops/cosine_test.cc, tensorflow/lite/experimental/shlo/ops/exponential.cc, tensorflow/lite/experimental/shlo/ops/exponential_minus_one.cc, tensorflow/lite/experimental/shlo/ops/exponential_minus_one_test.cc, tensorflow/lite/experimental/shlo/ops/exponential_test.cc, tensorflow/lite/experimental/shlo/ops/floor.cc, tensorflow/lite/experimental/shlo/ops/floor_test.cc, tensorflow/lite/experimental/shlo/ops/log.cc, tensorflow/lite/experimental/shlo/ops/log_plus_one.cc, tensorflow/lite/experimental/shlo/ops/log_plus_one_test.cc, tensorflow/lite/experimental/shlo/ops/log_test.cc, tensorflow/lite/experimental/shlo/ops/logistic.cc, tensorflow/lite/experimental/shlo/ops/logistic_test.cc, tensorflow/lite/experimental/shlo/ops/not.cc, tensorflow/lite/experimental/shlo/ops/not_test.cc, tensorflow/lite/experimental/shlo/ops/sign.cc, tensorflow/lite/experimental/shlo/ops/sign_test.cc, tensorflow/lite/experimental/shlo/ops/sine.cc, tensorflow/lite/experimental/shlo/ops/sine_test.cc, tensorflow/lite/experimental/shlo/ops/sqrt.cc, tensorflow/lite/experimental/shlo/ops/sqrt_test.cc, tensorflow/lite/experimental/shlo/ops/tanh.cc, tensorflow/lite/experimental/shlo/ops/tanh_test.cc",tensorflower-gardener,False
"#shlo_ref Add `maximum` op.

PiperOrigin-RevId: 619940246",Quentin Khan,qkhan@google.com,2024-03-28 15:28:42,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/maximum.cc, tensorflow/lite/experimental/shlo/ops/maximum.h, tensorflow/lite/experimental/shlo/ops/maximum_test.cc",qukhan,False
"[xla:gpu] Added a test checking that Triton kernels compiled via XLA do not dedup arguments

PiperOrigin-RevId: 619940030",Sergei Lebedev,slebedev@google.com,2024-03-28 15:28:00,"third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gpu_triton_custom_call_test.cc",superbobry,False
"#tf-data-service Reduce severity of missing default transfer server log line.

PiperOrigin-RevId: 619935370",Matt Callanan,mpcallanan@google.com,2024-03-28 15:12:15,tensorflow/core/data/service/client/data_service_client.cc,mpcallanan,False
"Remove legacy post-training quantization functions

PiperOrigin-RevId: 619933983",Thai Nguyen,thaink@google.com,2024-03-28 15:07:34,"tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.h",thaink,False
"Replace usage of `PermuteShape` to `Permute<T>`.

Replaces the duplicate implementation of array permutation.

As a corollary, replaces permutation values to existing definitions in `attrs_and_constraints.h`.

PiperOrigin-RevId: 619930275",Dan Suh,dansuh@google.com,2024-03-28 14:54:27,"tensorflow/compiler/mlir/quantization/common/attrs_and_constraints.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/nchw_convolution_to_nhwc.cc",dansuh17,False
"Add Linux ppc64le support to CUDA stubs.

Update implib.so to include a commit with ppc64le support.

May fix https://github.com/google/jax/issues/19992, although I don't have such a machine so it's untested.

PiperOrigin-RevId: 619919522",Peter Hawkins,phawkins@google.com,2024-03-28 14:13:53,"third_party/implib_so/workspace.bzl, third_party/xla/third_party/implib_so/workspace.bzl, third_party/xla/third_party/tsl/third_party/implib_so/workspace.bzl, third_party/xla/xla/tsl/cuda/stub.bzl",hawkinsp,False
"Integrate LLVM at llvm/llvm-project@feebcd65fb7e

Updates LLVM usage to match
[feebcd65fb7e](https://github.com/llvm/llvm-project/commit/feebcd65fb7e)

PiperOrigin-RevId: 619913390",Dmitri Gribenko,dmitrig@google.com,2024-03-28 13:49:50,third_party/llvm/workspace.bzl,gribozavr,False
"Treat entry computation parameter that has host memory space as MoveToHost
annotation in host_offload_legalize.

PiperOrigin-RevId: 619907383",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 13:25:00,"third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/host_offload_legalize.cc, third_party/xla/xla/service/host_offload_legalize_test.cc, third_party/xla/xla/service/layout_assignment.cc",tensorflower-gardener,False
"#shlo_ref Use _Float16 for F16 with GCC

The GCC OSS build was failing to use `_Float16` for the `shlo_ref::F16` type alias despite `_Float16`'s availability with GCC. This was because the `has_keyword` macro was always returning false on GCC, as it was implemented using `__is_identifier`, which is Clang only. _Float16 should be available on both GCC & Clang, so we should just use those unless std::float16_t is available.

This also removes has_keyword.h, as it is no longer used and ensures that `BF16` and `F16` map to `std::bfloat16_t` and `std::float16_t` when those are available.

PiperOrigin-RevId: 619900330",RJ Ascani,rjascani@google.com,2024-03-28 12:57:52,"tensorflow/lite/experimental/shlo/BUILD, tensorflow/lite/experimental/shlo/bf16.h, tensorflow/lite/experimental/shlo/f16.h, tensorflow/lite/experimental/shlo/has_keyword.h, tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/is_finite_test.cc",rascani,False
"[XLA:GPU] Deprecate Triton codegen before Ampere.

Unfortunately, upstream Triton has decided to drop support for NVIDIA GPUs
below Ampere, so we bump the GPU version requirements for using Triton.

PiperOrigin-RevId: 619899728",Benjamin Chetioui,bchetioui@google.com,2024-03-28 12:55:20,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemm_fusion.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/gemm_fusion_test.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/nvptx_compiler_test.cc, third_party/xla/xla/service/gpu/softmax_rewriter_triton.cc, third_party/xla/xla/service/gpu/softmax_rewriter_triton_test.cc, third_party/xla/xla/service/gpu/tests/BUILD, third_party/xla/xla/service/gpu/tests/gpu_triton_custom_call_test.cc, third_party/xla/xla/service/gpu/triton_support.cc, third_party/xla/xla/service/gpu/triton_tiling_propagation.cc",bchetioui,False
"Add support for folding constant unary non-compute ops in RTVar optimization

So far we can only optimize away RTVars that refer to a `constant` or `iota`
HLO op. This change is extending that to unary ops without compute (given
the operand is also constant).

That includes:
- Bitcast
- Broadcast
- Reshape
- Reverse
- Slice
- Transpose

PiperOrigin-RevId: 619898399",Henning Becker,hebecker@google.com,2024-03-28 12:49:17,"third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",beckerhe,False
"[XLA:Python] Refactor jit argument parsing code.

* Put the logic to split static and dynamic arguments under ParseArguments, which returns a ArgumentSignature and a list of dynamic arguments.
* Move the other argument parsing logic for jit and pmap into a separate CallSignature type.

This simplifies the code, and prepares for adding another use case for the argument parsing code without the rest of the jit logic.

Refactoring only, no functional changes intended.

PiperOrigin-RevId: 619895559",Peter Hawkins,phawkins@google.com,2024-03-28 12:36:09,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/jax_jit.cc, third_party/xla/xla/python/jax_jit.h, third_party/xla/xla/python/pjit.cc, third_party/xla/xla/python/pmap_lib.cc",hawkinsp,False
"Use indexing map symbol rescaling in the ReduceWindow emitter

We current codegen the reduce window op as a loop nest with the inner loop
iterating over the window and accumulating input values.

If the op had a base dilation set we would still generate the same inner
loop but the loop body now woudl have an additional condition that checks
whether we are in bounds of the dilation.

This change makes use of IndexingMap's symbol rescaling which results
in the generation of an inner loop with fewer iterations. It also avoids
the in-bounds check by only iterating over the tensor elements that
actually need to be accumulated.

PiperOrigin-RevId: 619893695",Henning Becker,hebecker@google.com,2024-03-28 12:28:47,"third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc",beckerhe,False
"Avoid loading then saving reprensentative dataset again

If the representative dataset is in QuantizationOptions, currently, we first load it then save it again. This is not efficient, just use it directly.

PiperOrigin-RevId: 619879297",Thai Nguyen,thaink@google.com,2024-03-28 11:29:52,tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.py,thaink,False
"[stream_executor:host] Add LLVM kernel support in kernel_spec

Related to https://github.com/openxla/xla/issues/7234

PiperOrigin-RevId: 619878628",Vladyslav Tsilytskyi,tsilytskyi@google.com,2024-03-28 11:26:54,"third_party/xla/xla/stream_executor/kernel.h, third_party/xla/xla/stream_executor/kernel_spec.cc, third_party/xla/xla/stream_executor/kernel_spec.h",tvladyslav,False
"Run xla triton hopper tests on demand on TAP

PiperOrigin-RevId: 619877948",Aliia Khasanova,aliia@google.com,2024-03-28 11:24:07,third_party/xla/xla/service/gpu/BUILD,,False
"[xla:gpu] Sort sliced operand paths on the fly

PiperOrigin-RevId: 619867884",Son Tuan Vu,vuson@google.com,2024-03-28 10:44:05,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc",tyb0807,False
"Disable Batch Mat Mul delegate test until flaky behaviour is fixed.

PiperOrigin-RevId: 619853923",Alan Kelly,alankelly@google.com,2024-03-28 09:48:19,tensorflow/lite/delegates/xnnpack/batch_matrix_multiply_test.cc,alankelly,False
"compat: Update forward compatibility horizon to 2024-03-28

PiperOrigin-RevId: 619843215",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 09:03:41,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1815.

PiperOrigin-RevId: 619842796",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 09:02:15,tensorflow/core/public/version.h,tensorflower-gardener,False
"Merge pull request #64567 from redwrasse:redwrasse/additional-sobol-overflow-tests

PiperOrigin-RevId: 619834003",TensorFlower Gardener,gardener@tensorflow.org,2024-03-28 08:35:27,tensorflow/python/ops/sobol_ops_test.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 619820412",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 07:29:28,"tensorflow/lite/tools/BUILD, tensorflow/lite/tools/tool_params_test.cc, tensorflow/lite/tools/utils.cc",tensorflower-gardener,False
"Add basic support for folding constant RTVars

This allows turning dynamic HLO operands into a index expressions when the HLO yields some constant value.

As a first step this is adding support for the HLO ops `constant` and `iota`.

PiperOrigin-RevId: 619803271",Henning Becker,hebecker@google.com,2024-03-28 06:18:47,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/loop.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/simplify_affine.cc, third_party/xla/xla/service/gpu/fusions/scatter.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.h, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",beckerhe,False
"Automated Code Change

PiperOrigin-RevId: 619796552",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 05:51:58,"third_party/xla/xla/backends/profiler/cpu/BUILD, third_party/xla/xla/backends/profiler/cpu/host_tracer_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 619794438",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-28 05:42:07,"tensorflow/c/experimental/ops/gen/cpp/renderers/BUILD, tensorflow/c/experimental/ops/gen/cpp/renderers/cpp_config.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/cpp_file_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/guard_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/guard_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/include_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/include_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/namespace_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/namespace_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_comment_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_comment_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_implementation_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_implementation_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/op_renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/op_renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer.cc, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer.h, tensorflow/c/experimental/ops/gen/cpp/renderers/renderer_test.cc",tensorflower-gardener,False
"If two calls to ""ProductOfElementaryHouseholderReflectors"" are in the same module with the same shape of the first operand, but different shapes of tau, one will end up expanded to the wrong computation.

Append tau shape to the computation name when its there to avoid conflicts.

PiperOrigin-RevId: 619788209",Vlad Sytchenko,vsytch@google.com,2024-03-28 05:16:12,"third_party/xla/xla/client/lib/qr_test.cc, third_party/xla/xla/service/qr_expander.cc",vsytch,False
"[xla:ffi] Fix __has_builtin compilation compilation

PiperOrigin-RevId: 619745896",Eugene Zhulenev,ezhulenev@google.com,2024-03-28 02:16:10,third_party/xla/xla/ffi/api/api.h,ezhulenev,False
"[xla:gpu][NFC] Refactor address_computation_fusion_rewriter

PiperOrigin-RevId: 619738914",Son Tuan Vu,vuson@google.com,2024-03-28 01:48:15,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc,tyb0807,False
"[xla:gpu][NFC] Add test for nested tuple custom call

PiperOrigin-RevId: 619737694",Son Tuan Vu,vuson@google.com,2024-03-28 01:43:46,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc,tyb0807,False
"PR #10930: [XLA:CPU] Bug fix for enabling F16 support

Imported from GitHub PR https://github.com/openxla/xla/pull/10930

This PR fixes a bug for f16 matmul enabling.
Since dot is supported in f16, there is no need for adding an extra convert instruction after fusion similar to the bf16 case.
Also add missed changes in build file.
Copybara import of the project:

--
45f7fdbac38cf011707c704cf4e75b49261d0339 by Kanvi Khanna <kanvi.khanna@intel.com>:

Bug-Fix:Since dot has f16 support,remove extra convert after fusion; add missing build file change

--
af9d2c4f7a92e3d647f15c9d25be047461df8dea by Kanvi Khanna <kanvi.khanna@intel.com>:

fix buildifier

--
3587ef104f9b47c2fd05dda1f0008cd3b53da421 by Kanvi Khanna <kanvi.khanna@intel.com>:

address comment

Merging this change closes #10930

PiperOrigin-RevId: 619730863",Kanvi Khanna,kanvi.khanna@intel.com,2024-03-28 01:18:51,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/change_op_data_type.cc, third_party/xla/xla/service/cpu/onednn_matmul_rewriter.cc, third_party/xla/xla/tests/onednn_matmul_test.cc",kanvi-nervana,False
"Use const qualified variables where possible.

Modified files:
* third_party/tensorflow/compiler/xla/service/shape_inference_test.cc
* third_party/tensorflow/compiler/xla/client/xla_builder_test.cc

PiperOrigin-RevId: 619725388",Gunhyun Park,gunhyun@google.com,2024-03-28 00:57:46,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Remove unnecessary const qualifiers from function definitions.

`absl::Span<const T>` is already a read-only interface to the elements of its container, so the const here is redundant.

PiperOrigin-RevId: 619716367",Gunhyun Park,gunhyun@google.com,2024-03-28 00:25:23,third_party/xla/xla/client/xla_builder.cc,ghpvnist,False
"shlo_ref: Move template specializations

GCC gives compilation errors that these template specializations are in
a non-namespace scope. This PR moves the template specializations out of
the struct scope and into a namespace scope.",RJ Ascani,rjascani@google.com,2024-03-28 00:41:41,"tensorflow/lite/experimental/shlo/ops/cbrt.cc, tensorflow/lite/experimental/shlo/ops/cbrt_test.cc, tensorflow/lite/experimental/shlo/ops/ceil.cc, tensorflow/lite/experimental/shlo/ops/ceil_test.cc, tensorflow/lite/experimental/shlo/ops/cosine.cc, tensorflow/lite/experimental/shlo/ops/cosine_test.cc, tensorflow/lite/experimental/shlo/ops/exponential.cc, tensorflow/lite/experimental/shlo/ops/exponential_minus_one.cc, tensorflow/lite/experimental/shlo/ops/exponential_minus_one_test.cc, tensorflow/lite/experimental/shlo/ops/exponential_test.cc, tensorflow/lite/experimental/shlo/ops/floor.cc, tensorflow/lite/experimental/shlo/ops/floor_test.cc, tensorflow/lite/experimental/shlo/ops/log.cc, tensorflow/lite/experimental/shlo/ops/log_plus_one.cc, tensorflow/lite/experimental/shlo/ops/log_plus_one_test.cc, tensorflow/lite/experimental/shlo/ops/log_test.cc, tensorflow/lite/experimental/shlo/ops/logistic.cc, tensorflow/lite/experimental/shlo/ops/logistic_test.cc, tensorflow/lite/experimental/shlo/ops/not.cc, tensorflow/lite/experimental/shlo/ops/not_test.cc, tensorflow/lite/experimental/shlo/ops/sign.cc, tensorflow/lite/experimental/shlo/ops/sign_test.cc, tensorflow/lite/experimental/shlo/ops/sine.cc, tensorflow/lite/experimental/shlo/ops/sine_test.cc, tensorflow/lite/experimental/shlo/ops/sqrt.cc, tensorflow/lite/experimental/shlo/ops/sqrt_test.cc, tensorflow/lite/experimental/shlo/ops/tanh.cc, tensorflow/lite/experimental/shlo/ops/tanh_test.cc",rascani,True
"Remove check that the first thread pool is the default, as it is no longer needed.

PiperOrigin-RevId: 619704113",Chris Minge,chrisminge@google.com,2024-03-27 23:42:53,tensorflow/core/tfrt/tfrt_session/tfrt_session.cc,CMinge,False
"PR #10668: [XLA:GPU] Fix cuDNN FMHA rewriter sequence length checks and Bump up minimum flash attn cuDNN version to 8.9.4

Imported from GitHub PR https://github.com/openxla/xla/pull/10668

* If only seqlen_q or seqlen_kv is larger than 512, it will be lowered to fused attn instead of flash attn. This is incorrect as fused attn does not support this case. Add checks to lower to flash attn if one seqlen is larger than 512.
* While fixing the seqlen checks, also relax the seqlen/head dim constraints to support any seqlen % 2 == 0, head_dim <= 128 and head_dim % 8 = 0. (Since 8.9.4).
* Consolidate multiple get seqlen/head dim from fused attn/flash attn checks into one `getBHSD` function and rewrite both fused attn/flash attn checks to make it easier to understand.
* Bump up minimum cuDNN version require for flash attn from 8.9.3 to 8.9.4. (More seqlen/head dim support and cross attn support).
* Remove cross attn checks from rewriter and rewriter test since it is now default supported with 8.9.4.
* Add one testcase to cover the first bullet point.
Copybara import of the project:

--
bfdce45d669fe899dd845f497df783f014558384 by cjkkkk <ske@nvidia.com>:

rewrite seqlen checks

--
8a0e8b465cc1790953b1dc5f8740adfa7cf1124a by cjkkkk <ske@nvidia.com>:

return vector directly

--
72abf544d2f962c5554fe00ffea8d3167a9cde81 by cjkkkk <ske@nvidia.com>:

use struct for qkv_layout && add () for extra &&

--
0cac35422315180fcc9b04372916e061ebe17754 by cjkkkk <ske@nvidia.com>:

fix head dim check with cuDNN < 8.9.6

Merging this change closes #10668

PiperOrigin-RevId: 619703747",Shanbin Ke,shanbinke@gmail.com,2024-03-27 23:41:50,"third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter.cc, third_party/xla/xla/service/gpu/cudnn_fused_mha_rewriter_test.cc",Cjkkkk,False
"PR #9896: Opaque types for NVTX domain and string handles

Imported from GitHub PR https://github.com/openxla/xla/pull/9896

This avoids having preprocessor checks on `GOOGLE_CUDA` inside some headers, which led to ODR violations.
Copybara import of the project:

--
22e65458993aea1a9b441e6c043f7fe315ff4cc3 by Olli Lupton <olupton@nvidia.com>:

Opaque types for NVTX domain and string handles

This avoids having preprocessor checks on GOOGLE_CUDA inside some
headers, which led to ODR violations.

Merging this change closes #9896

PiperOrigin-RevId: 619675819",Olli Lupton,olupton@nvidia.com,2024-03-27 22:21:05,"third_party/xla/third_party/tsl/tsl/profiler/lib/BUILD, third_party/xla/third_party/tsl/tsl/profiler/lib/nvtx_utils.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/nvtx_utils.h, third_party/xla/third_party/tsl/tsl/profiler/lib/nvtx_utils_stub.cc, third_party/xla/third_party/tsl/tsl/profiler/lib/scoped_annotation.h, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/annotation.cc, third_party/xla/xla/service/gpu/runtime/annotation.h",olupton,False
"[tensorflow] Mark `gtl::ArraySlice` and `gtl::MutableArraySlice` with `ABSL_DEPRECATE_AND_INLINE`

PiperOrigin-RevId: 619671604",Lawrence Wolf-Sonkin,lawrencews@google.com,2024-03-27 22:08:15,"tensorflow/core/lib/gtl/BUILD, tensorflow/core/lib/gtl/array_slice.h",lwolfsonkin,False
"Integrate StableHLO at openxla/stablehlo@f4459e76

PiperOrigin-RevId: 619669095",Gunhyun Park,gunhyun@google.com,2024-03-27 22:01:41,"third_party/stablehlo/temporary.patch, third_party/stablehlo/workspace.bzl, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/workspace.bzl, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/ops.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/verifier_reduce_op.mlir",ghpvnist,False
"Do not deadlock the GPU if a pure_callback dispatches a GPU kernel

PiperOrigin-RevId: 619656442",Sergei Lebedev,slebedev@google.com,2024-03-27 21:25:19,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/py_client_gpu.cc",superbobry,False
"Change to MSA to ignore constants while calculating operand distance.

This is required for MSA to identify and optimize compiler-unrolled loops.

PiperOrigin-RevId: 619656147",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 21:24:22,third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc,tensorflower-gardener,False
"[BugFix] Fix approx_max_k first reduction smaller than the second reduction issue.

PiperOrigin-RevId: 619654498",Felix Chern,fchern@google.com,2024-03-27 21:19:38,third_party/xla/xla/client/lib/approx_topk_shape.cc,dryman,False
"[xla:gpu] Support tupled GEMM with DUS

Separate sliced operand chains from sliced user chains to support different scenarios of tupled GEMM -> DUS.
Sliced operand chains always contain the original hero ops (GEMM or custom call) as their last elements.
Sliced user chains contain dataflow sequences from different users of the original hero ops down to the DUS ops.
For hero ops returning tuples, we need to support cases where not all elements of the tuples are used, hence separating dataflow sequences for different users (i.e. get-tuple-elements) of the hero ops.

PiperOrigin-RevId: 619652937",Son Tuan Vu,vuson@google.com,2024-03-27 21:15:17,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc",tyb0807,False
"Disable the import tensorflow check for TF-TPU

For TF-TPU, import tensorflow step loads libtpu along with it, which in turn try to connect with TPU drivers. When these whls are built on a CPU only machine which doesn't have drivers, the build fails. We add an env variable to disable the import tensorflow check temporarily until we come up with a neat solution.

PiperOrigin-RevId: 619641865",Kanglan Tang,kanglan@google.com,2024-03-27 20:45:09,"ci/official/envs/ci_default, ci/official/envs/linux_x86_tpu, ci/official/utilities/rename_and_verify_wheels.sh",kanglant,False
"Merge pull request #64619 from rascani:disable_shlo_legacy_build

PiperOrigin-RevId: 619640702",TensorFlower Gardener,gardener@tensorflow.org,2024-03-27 21:09:21,"tensorflow/lite/experimental/shlo/legacy/BUILD, tensorflow/lite/experimental/shlo/legacy/bench/BUILD, tensorflow/lite/experimental/shlo/legacy/test/BUILD",tensorflower-gardener,False
"PR #10875: [XLA:CPU][oneDNN][Bugfix] Fix BF16 oneDNN Layernorm

Imported from GitHub PR https://github.com/openxla/xla/pull/10875

OneDNN expects scale and bias to be in Float32.
This PR will convert BF16/FP16 scale and weights into Float32 (similar to whats done with mkl layernorm in tensorflow [here ](https://github.com/tensorflow/tensorflow/blob/3a5a9ec33c1194f8fdec2a243714055c0118b44a/tensorflow/core/kernels/mkl/mkl_layer_norm_op.cc#L138)) , without conversion there is accuracy mismatch with oneDNN layernorm.
Copybara import of the project:

--
8563d4e9fbdc6681329960c44193ed05f8a16dfd by Sachin Muradi <sachin.muradi@intel.com>:

Fix for bf16/fp16 scale bias

--
e7328a3bbbe3e30caeebc27b7b0175eda9e8b5e9 by Sachin Muradi <sachin.muradi@intel.com>:

close review comments

Merging this change closes #10875

PiperOrigin-RevId: 619637245",sachinmuradi,sachin.muradi@intel.com,2024-03-27 20:33:33,"third_party/xla/xla/service/cpu/onednn_ops_rewriter.cc, third_party/xla/xla/tests/onednn_layer_norm_test.cc",sachinmuradi,False
"[stream_executor:host] Add initial version of a host kernel API (ABI)

XLA:CPU compiler will compile fusions into function pointers compatible with an API defined by StreamExecutor
PiperOrigin-RevId: 619622505",Eugene Zhulenev,ezhulenev@google.com,2024-03-27 19:53:53,"third_party/xla/xla/stream_executor/host/BUILD, third_party/xla/xla/stream_executor/host/host_kernel.cc, third_party/xla/xla/stream_executor/host/host_kernel.h, third_party/xla/xla/stream_executor/host/host_kernel_c_api.h, third_party/xla/xla/stream_executor/host/host_kernel_test.cc",ezhulenev,False
"Disable load reordering by buildifier in mlir BUILD

PiperOrigin-RevId: 619617017",Benjamin Kramer,kramerb@google.com,2024-03-27 19:34:46,tensorflow/compiler/mlir/tensorflow/BUILD,d0k,False
"shlo_ref: Disable legacy code build

The code under shlo/legacy is useful for reference, but cannot build
with the oss toolchains. This PR disables those targets with the no_oss
tag.",RJ Ascani,rjascani@google.com,2024-03-27 19:54:04,"tensorflow/lite/experimental/shlo/legacy/BUILD, tensorflow/lite/experimental/shlo/legacy/bench/BUILD, tensorflow/lite/experimental/shlo/legacy/test/BUILD",rascani,True
"[XLA:GPU] Add a Gemv rewriter pass to convert gemv to gemm with a trivial dimension

We need this pass since GemmFusion only accepts gemms. We should run this pass before GemmFusion. After GemmFusion, we should use AlgebraicSimplifier to remove trivial dimension from gemms that are not fused by GemmFusion.

PiperOrigin-RevId: 619615263",Anlun Xu,anlunx@google.com,2024-03-27 19:28:20,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gemv_rewriter.cc, third_party/xla/xla/service/gpu/gemv_rewriter.h, third_party/xla/xla/service/gpu/gemv_rewriter_test.cc",anlunx,False
"[xla:gpu] Do not deduplicate kernel arguments when compiling Pallas GPU kerneles

PiperOrigin-RevId: 619611227",Sergei Lebedev,slebedev@google.com,2024-03-27 19:14:15,"third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/kernel_arguments.cc, third_party/xla/xla/service/gpu/kernel_arguments.h",superbobry,False
"Supports PjRt CPU array converting py array when the CPU PjRt arrays have non-default layouts.

PiperOrigin-RevId: 619608909",Yunlong Liu,yunlongl@google.com,2024-03-27 19:05:46,third_party/xla/xla/python/py_array.cc,yliu120,False
"Remove dead values before shape refinement

Some programs have a lot of dead values, causing shape refinement to fail to
converge. Indeed, even if there is no shape refinement to do, greedy pattern
rewrites keep iterating as long as the IR changes, which includes removing dead
values.

PiperOrigin-RevId: 619606321",Michael Levesque-Dion,mlevesquedion@google.com,2024-03-27 18:58:13,"third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/python/refine_polymorphic_shapes.cc",mlevesquedion,False
"Enable test for CALIBRATION_METHOD_HISTOGRAM_PERCENTILE.

PiperOrigin-RevId: 619598572",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 18:33:34,tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py,tensorflower-gardener,False
"PR #10858: [NVIDIA GPU] Enforce first collective permute of collective matmul to always run at the top of loop.

Imported from GitHub PR https://github.com/openxla/xla/pull/10858

This is to port collective matmul related changes from this pr(https://github.com/openxla/xla/pull/10316).
We'd need the first collective permute of a collective matmul loop always run at the beginning of the loop.
We set the force_earliest_schedule flag  for that instruction to achieve so.
Force this schedule order would give about additional 3% speedup on top of existing collective matmul for GPT-3 530B model.
Copybara import of the project:

--
eb822e1493c0b0b51438f4b7153df6f9dfaa9276 by TJ Xu <tjx@nvidia.com>:

Enforce first collective permute of collective matmul to always run at
the top of loop.

Merging this change closes #10858

PiperOrigin-RevId: 619595918",TJ Xu,tjx@nvidia.com,2024-03-27 18:26:36,"third_party/xla/xla/service/gpu/gpu_windowed_einsum_handler.cc, third_party/xla/xla/service/gpu/gpu_windowed_einsum_handler_test.cc, third_party/xla/xla/service/gpu/stream_attribute_async_wrapper.cc, third_party/xla/xla/service/gpu/stream_attribute_async_wrapper_test.cc",Tixxx,False
"[xla][gpu] Make the p2p-schedule-preparation pass to not rely on certain
pattern to find the corresponding Send/Recv for SendDone/RecvDone.

Previously, we relied on certain code patterns to find the Send/Recv for
Send-done/Recv-done for a pipelined loop. Now that we realize copy-insertion
can complicate such code patterns and make such pattern matching fragile.

We modify the p2p-schedule-preparation pass to record Send/Recv in additional
to SendDone/RecvDone for each p2p communication group.

PiperOrigin-RevId: 619589458",Bixia Zheng,bixia@google.com,2024-03-27 18:07:45,"third_party/xla/xla/service/p2p_schedule_preparation.cc, third_party/xla/xla/service/p2p_schedule_preparation_test.cc",bixia1,False
"Merged commit includes the following changes:
619575611  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Run buildifier on all files where it sorts loads differently

--
619498661  by A. Unique TensorFlower<gardener@tensorflow.org>:

    [XLA:GPU][IndexAnalysis] Rename GetDefaultThreadIdToOutputIndexingMap to GetDefaultThreadIdIndexingMap.

    The ""output"" part was a bit confusing. We use this function for threadId->input
    mapping as well.

--
619490165  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Convert S8 to BF16 in one step without going though F32.

--

PiperOrigin-RevId: 619575611",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 17:27:49,"WORKSPACE, ci/official/requirements_updater/BUILD.bazel, ci/official/requirements_updater/WORKSPACE, ci/official/wheel_test/WORKSPACE, tensorflow/c/BUILD, tensorflow/c/eager/parallel_device/BUILD, tensorflow/c/experimental/filesystem/BUILD, tensorflow/c/experimental/filesystem/plugins/gcs/BUILD, tensorflow/c/experimental/filesystem/plugins/windows/BUILD, tensorflow/c/experimental/gradients/BUILD, tensorflow/c/experimental/grappler/BUILD, tensorflow/c/experimental/pluggable_profiler/BUILD, tensorflow/c/experimental/saved_model/core/BUILD, tensorflow/c/experimental/saved_model/core/ops/BUILD, tensorflow/c/experimental/saved_model/internal/BUILD, tensorflow/c/experimental/saved_model/internal/testdata/BUILD, tensorflow/c/kernels/BUILD, tensorflow/cc/BUILD, tensorflow/cc/experimental/base/tests/BUILD, tensorflow/cc/experimental/libexport/BUILD, tensorflow/cc/experimental/libtf/BUILD, tensorflow/cc/experimental/libtf/impl/BUILD, tensorflow/cc/framework/fuzzing/BUILD, tensorflow/cc/tools/BUILD, tensorflow/compiler/aot/tests/BUILD, tensorflow/compiler/jit/BUILD, tensorflow/compiler/jit/ops/BUILD, tensorflow/compiler/jit/tests/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/examples/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/py_wrapper/BUILD, tensorflow/compiler/mlir/lite/sparsity/BUILD, tensorflow/compiler/mlir/lite/stablehlo/tests/BUILD, tensorflow/compiler/mlir/lite/tests/flatbuffer2mlir/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/tests/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/stablehlo/BUILD, tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/tests/BUILD, tensorflow/compiler/mlir/tf2xla/internal/passes/BUILD, tensorflow/compiler/mlir/tf2xla/tests/BUILD, tensorflow/compiler/mlir/tf2xla/transforms/BUILD, tensorflow/compiler/mlir/tfr/BUILD, tensorflow/compiler/mlir/tfr/build_defs.bzl, tensorflow/compiler/mlir/tfrt/tests/BUILD, tensorflow/compiler/mlir/tfrt/tests/analysis/BUILD, tensorflow/compiler/mlir/tfrt/tests/ir/BUILD, tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt/BUILD, tensorflow/compiler/mlir/tfrt/tests/tf_to_corert/BUILD, tensorflow/compiler/mlir/tfrt/tests/tfrt_fallback/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/ir/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/transforms/BUILD, tensorflow/compiler/tests/BUILD, tensorflow/compiler/tf2tensorrt/BUILD, tensorflow/compiler/tf2xla/BUILD, tensorflow/compiler/tf2xla/cc/BUILD, tensorflow/compiler/tf2xla/kernels/BUILD, tensorflow/compiler/tf2xla/ops/BUILD, tensorflow/compiler/tf2xla/python/BUILD, tensorflow/core/BUILD, tensorflow/core/activity_watcher/BUILD, tensorflow/core/api_def/BUILD, tensorflow/core/common_runtime/BUILD, tensorflow/core/common_runtime/eager/BUILD, tensorflow/core/common_runtime/next_pluggable_device/c/BUILD, tensorflow/core/data/service/client/BUILD, tensorflow/core/data/service/snapshot/BUILD, tensorflow/core/debug/BUILD, tensorflow/core/distributed_runtime/BUILD, tensorflow/core/distributed_runtime/rpc/BUILD, tensorflow/core/distributed_runtime/rpc/eager/BUILD, tensorflow/core/example/BUILD, tensorflow/core/function/capture/BUILD, tensorflow/core/function/polymorphism/BUILD, tensorflow/core/function/trace_type/BUILD, tensorflow/core/graph/BUILD, tensorflow/core/graph/regularization/BUILD, tensorflow/core/grappler/BUILD, tensorflow/core/grappler/clusters/BUILD, tensorflow/core/grappler/costs/BUILD, tensorflow/core/grappler/graph_analyzer/BUILD, tensorflow/core/grappler/optimizers/BUILD, tensorflow/core/grappler/utils/BUILD, tensorflow/core/grappler/verifiers/BUILD, tensorflow/core/ir/importexport/BUILD, tensorflow/core/ir/importexport/tests/BUILD, tensorflow/core/ir/importexport/tests/graphdef_to_mlir/BUILD, tensorflow/core/ir/importexport/tests/mlir_to_graphdef/BUILD, tensorflow/core/ir/importexport/tests/roundtrip/BUILD, tensorflow/core/ir/tests/BUILD, tensorflow/core/ir/types/BUILD, tensorflow/core/kernels/BUILD, tensorflow/core/kernels/fuzzing/BUILD, tensorflow/core/kernels/image/BUILD, tensorflow/core/kernels/linalg/BUILD, tensorflow/core/kernels/mkl/BUILD, tensorflow/core/kernels/mlir_generated/build_defs.bzl, tensorflow/core/kernels/rnn/BUILD, tensorflow/core/kernels/sparse/BUILD, tensorflow/core/nccl/BUILD, tensorflow/core/ops/BUILD, tensorflow/core/ops/compat/BUILD, tensorflow/core/platform/BUILD, tensorflow/core/platform/build_config.bzl, tensorflow/core/platform/build_config.default.bzl, tensorflow/core/platform/build_config_root.bzl, tensorflow/core/platform/cloud/BUILD, tensorflow/core/platform/distribute.bzl, tensorflow/core/platform/profile_utils/BUILD, tensorflow/core/profiler/backends/gpu/BUILD, tensorflow/core/profiler/internal/BUILD, tensorflow/core/profiler/internal/advisor/BUILD, tensorflow/core/profiler/rpc/BUILD, tensorflow/core/profiler/rpc/client/BUILD, tensorflow/core/profiler/rpc/oss/BUILD, tensorflow/core/protobuf/BUILD, tensorflow/core/summary/BUILD, tensorflow/core/tfrt/common/BUILD, tensorflow/core/tfrt/fallback/BUILD, tensorflow/core/tfrt/saved_model/tests/BUILD, tensorflow/core/tpu/BUILD, tensorflow/core/tpu/graph_rewrite/BUILD, tensorflow/core/transforms/remapper/BUILD, tensorflow/core/user_ops/BUILD, tensorflow/core/util/BUILD, tensorflow/core/util/ctc/BUILD, tensorflow/core/util/proto/BUILD, tensorflow/core/util/quantization/BUILD, tensorflow/core/util/sparse/BUILD, tensorflow/distribute/experimental/rpc/kernels/BUILD, tensorflow/dtensor/cc/BUILD, tensorflow/dtensor/mlir/dtensor_dialect/BUILD, tensorflow/dtensor/mlir/tests/BUILD, tensorflow/examples/adding_an_op/BUILD, tensorflow/examples/speech_commands/BUILD, tensorflow/java/BUILD, tensorflow/java/src/main/native/BUILD, tensorflow/js/BUILD, tensorflow/lite/BUILD, tensorflow/lite/acceleration/configuration/BUILD, tensorflow/lite/acceleration/configuration/c/BUILD, tensorflow/lite/core/BUILD, tensorflow/lite/core/async/c/BUILD, tensorflow/lite/core/async/interop/c/BUILD, tensorflow/lite/core/c/BUILD, tensorflow/lite/core/experimental/acceleration/configuration/BUILD, tensorflow/lite/core/kernels/BUILD, tensorflow/lite/core/shims/BUILD, tensorflow/lite/core/shims/cc_library_with_tflite.bzl, tensorflow/lite/core/tools/BUILD, tensorflow/lite/delegates/flex/build_def.bzl, tensorflow/lite/delegates/flex/test/BUILD, tensorflow/lite/delegates/gpu/BUILD, tensorflow/lite/delegates/gpu/gl/converters/BUILD, tensorflow/lite/delegates/gpu/metal/BUILD, tensorflow/lite/delegates/gpu/metal/kernels/BUILD, tensorflow/lite/delegates/nnapi/BUILD, tensorflow/lite/experimental/acceleration/compatibility/BUILD, tensorflow/lite/experimental/acceleration/configuration/BUILD, tensorflow/lite/experimental/acceleration/mini_benchmark/BUILD, tensorflow/lite/g3doc/tools/BUILD, tensorflow/lite/ios/BUILD.apple, tensorflow/lite/ios/ios.bzl, tensorflow/lite/java/BUILD, tensorflow/lite/kernels/internal/utils/BUILD, tensorflow/lite/kernels/parse_example/BUILD, tensorflow/lite/kernels/shim/test_op/BUILD, tensorflow/lite/nnapi/BUILD, tensorflow/lite/objc/BUILD.apple, tensorflow/lite/profiling/telemetry/BUILD, tensorflow/lite/profiling/telemetry/c/BUILD, tensorflow/lite/python/BUILD, tensorflow/lite/python/metrics/BUILD, tensorflow/lite/schema/BUILD, tensorflow/lite/swift/BUILD.apple, tensorflow/lite/toco/BUILD, tensorflow/lite/toco/logging/BUILD, tensorflow/lite/tools/BUILD, tensorflow/lite/tools/benchmark/android/BUILD, tensorflow/lite/tools/benchmark/experimental/delegate_performance/android/models/BUILD, tensorflow/lite/tools/benchmark/experimental/delegate_performance/android/src/main/native/BUILD, tensorflow/lite/tools/benchmark/experimental/firebase/android/BUILD, tensorflow/lite/tools/benchmark/experimental/ios/BUILD.apple, tensorflow/lite/tools/evaluation/tasks/ios/BUILD.apple, tensorflow/lite/tools/optimize/BUILD, tensorflow/lite/tools/optimize/calibration/BUILD, tensorflow/lite/tools/signature/BUILD, tensorflow/python/BUILD, tensorflow/python/build_defs.bzl, tensorflow/python/distribute/integration_test/BUILD, tensorflow/python/eager/BUILD, tensorflow/python/eager/polymorphic_function/BUILD, tensorflow/python/kernel_tests/proto/BUILD, tensorflow/python/kernel_tests/signal/BUILD, tensorflow/python/lib/io/BUILD, tensorflow/python/ops/linalg/sparse/BUILD, tensorflow/python/ops/memory_tests/BUILD, tensorflow/python/tools/api/generator/BUILD, tensorflow/python/tools/api/generator2/BUILD, tensorflow/python/tools/api/generator2/generator/BUILD, tensorflow/python/tpu/BUILD, tensorflow/python/training/BUILD, tensorflow/tools/android/inference_interface/BUILD, tensorflow/tools/def_file_filter/def_file_filter_configure.bzl, tensorflow/tools/docs/BUILD, tensorflow/tools/lib_package/BUILD, tensorflow/tools/pip_package/BUILD, tensorflow/tools/proto_splitter/testdata/BUILD, tensorflow/tools/toolchains/cpus/aarch64/aarch64_compiler_configure.bzl, tensorflow/tools/toolchains/remote_config/rbe_config.bzl, tensorflow/tools/toolchains/win/bazel_211/BUILD, tensorflow/tools/toolchains/win/bazel_211/windows_cc_toolchain_config.bzl, tensorflow/tools/toolchains/win/tf_win_05022023/BUILD, tensorflow/tools/toolchains/win/tf_win_05022023/windows_cc_toolchain_config.bzl, tensorflow/workspace0.bzl, tensorflow/workspace1.bzl, tensorflow/workspace2.bzl, tensorflow/workspace3.bzl, third_party/flatbuffers/flatbuffers.BUILD, third_party/googleapis/build_rules.bzl, third_party/gpus/cuda_configure.bzl, third_party/gpus/rocm_configure.bzl, third_party/hwloc/hwloc.BUILD, third_party/jpeg/jpeg.BUILD, third_party/llvm_openmp/BUILD, third_party/mkl_dnn/mkldnn_acl.BUILD, third_party/mkl_dnn/mkldnn_v1.BUILD, third_party/nccl/archive.BUILD, third_party/pprof.BUILD, third_party/systemlibs/protobuf.BUILD, third_party/xla/WORKSPACE, third_party/xla/build_tools/configure/BUILD, third_party/xla/third_party/llvm_openmp/BUILD, third_party/xla/third_party/tsl/WORKSPACE, third_party/xla/third_party/tsl/third_party/gpus/cuda_configure.bzl, third_party/xla/third_party/tsl/third_party/gpus/rocm_configure.bzl, third_party/xla/third_party/tsl/third_party/hwloc/hwloc.BUILD, third_party/xla/third_party/tsl/third_party/llvm_openmp/BUILD, third_party/xla/third_party/tsl/third_party/mkl_dnn/mkldnn_acl.BUILD, third_party/xla/third_party/tsl/third_party/mkl_dnn/mkldnn_v1.BUILD, third_party/xla/third_party/tsl/third_party/nccl/archive.BUILD, third_party/xla/third_party/tsl/third_party/systemlibs/protobuf.BUILD, third_party/xla/third_party/tsl/tools/def_file_filter/def_file_filter_configure.bzl, third_party/xla/third_party/tsl/tools/toolchains/cpus/aarch64/aarch64_compiler_configure.bzl, third_party/xla/third_party/tsl/tools/toolchains/remote_config/rbe_config.bzl, third_party/xla/third_party/tsl/tools/toolchains/win/bazel_211/BUILD, third_party/xla/third_party/tsl/tools/toolchains/win/bazel_211/windows_cc_toolchain_config.bzl, third_party/xla/third_party/tsl/tools/toolchains/win/tf_win_05022023/BUILD, third_party/xla/third_party/tsl/tools/toolchains/win/tf_win_05022023/windows_cc_toolchain_config.bzl, third_party/xla/third_party/tsl/tsl/BUILD, third_party/xla/third_party/tsl/tsl/concurrency/BUILD, third_party/xla/third_party/tsl/tsl/distributed_runtime/BUILD, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/BUILD, third_party/xla/third_party/tsl/tsl/distributed_runtime/preemption/BUILD, third_party/xla/third_party/tsl/tsl/distributed_runtime/rpc/BUILD, third_party/xla/third_party/tsl/tsl/distributed_runtime/rpc/coordination/BUILD, third_party/xla/third_party/tsl/tsl/framework/BUILD, third_party/xla/third_party/tsl/tsl/framework/contraction/BUILD, third_party/xla/third_party/tsl/tsl/framework/fixedpoint/BUILD, third_party/xla/third_party/tsl/tsl/lib/core/BUILD, third_party/xla/third_party/tsl/tsl/lib/gtl/BUILD, third_party/xla/third_party/tsl/tsl/lib/hash/BUILD, third_party/xla/third_party/tsl/tsl/lib/histogram/BUILD, third_party/xla/third_party/tsl/tsl/lib/io/BUILD, third_party/xla/third_party/tsl/tsl/lib/monitoring/BUILD, third_party/xla/third_party/tsl/tsl/lib/random/BUILD, third_party/xla/third_party/tsl/tsl/lib/strings/BUILD, third_party/xla/third_party/tsl/tsl/platform/BUILD, third_party/xla/third_party/tsl/tsl/platform/cloud/BUILD, third_party/xla/third_party/tsl/tsl/platform/default/BUILD, third_party/xla/third_party/tsl/tsl/platform/default/build_config.bzl, third_party/xla/third_party/tsl/tsl/platform/profile_utils/BUILD, third_party/xla/third_party/tsl/tsl/platform/windows/BUILD, third_party/xla/third_party/tsl/tsl/profiler/backends/cpu/BUILD, third_party/xla/third_party/tsl/tsl/profiler/builds/build_config.bzl, third_party/xla/third_party/tsl/tsl/profiler/convert/BUILD, third_party/xla/third_party/tsl/tsl/profiler/lib/BUILD, third_party/xla/third_party/tsl/tsl/profiler/protobuf/BUILD, third_party/xla/third_party/tsl/tsl/profiler/rpc/BUILD, third_party/xla/third_party/tsl/tsl/profiler/rpc/client/BUILD, third_party/xla/third_party/tsl/tsl/profiler/utils/BUILD, third_party/xla/third_party/tsl/tsl/util/BUILD, third_party/xla/third_party/tsl/workspace0.bzl, third_party/xla/third_party/tsl/workspace3.bzl, third_party/xla/tools/toolchains/cpus/aarch64/aarch64_compiler_configure.bzl, third_party/xla/tools/toolchains/remote_config/rbe_config.bzl, third_party/xla/tools/toolchains/win/bazel_211/BUILD, third_party/xla/tools/toolchains/win/bazel_211/windows_cc_toolchain_config.bzl, third_party/xla/tools/toolchains/win/tf_win_05022023/BUILD, third_party/xla/tools/toolchains/win/tf_win_05022023/windows_cc_toolchain_config.bzl, third_party/xla/workspace0.bzl, third_party/xla/workspace1.bzl, third_party/xla/xla/BUILD, third_party/xla/xla/backends/profiler/cpu/BUILD, third_party/xla/xla/backends/profiler/gpu/BUILD, third_party/xla/xla/backends/profiler/plugin/BUILD, third_party/xla/xla/client/BUILD, third_party/xla/xla/client/lib/BUILD, third_party/xla/xla/ffi/BUILD",tensorflower-gardener,False
"Check that zero points of FullyConnected filter is 0 for int4 quantization

PiperOrigin-RevId: 619489290",Frederic Rechtenstein,frec@google.com,2024-03-27 11:35:23,"tensorflow/lite/kernels/BUILD, tensorflow/lite/kernels/fully_connected.cc, tensorflow/lite/kernels/fully_connected_4bit_test.cc",fredrec,False
"Automated Code Change

PiperOrigin-RevId: 619476040",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 10:30:41,tensorflow/core/runtime_fallback/BUILD,tensorflower-gardener,False
"[XLA:GPU][CoalescingAnalysis] Put the TODOs in the code.

PiperOrigin-RevId: 619470915",Alexander Belyaev,pifon@google.com,2024-03-27 10:07:56,"third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc",pifon2a,False
"Add output-to-input convolution indexing map.

Reuse the existing ReduceWindowOp code to generate the indexing map, then remap it to convolution dimensions (taken from ConvolutionDimensionNumbers).

PiperOrigin-RevId: 619469114",Sergey Kozub,sergeykozub@google.com,2024-03-27 10:00:16,"third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc",sergeykozub,False
"Add the result sharding to reshapes added in `ReshapeWithCorrectRepresentationAndSharding`.

If `ConvertMlirHloToHlo` is applied after sharding propagation, then it's important that the added reshapes will have the same sharding as that of the corresponding function outputs.

PiperOrigin-RevId: 619467471",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 09:52:13,"third_party/xla/xla/translate/mhlo_to_hlo/layout_util.cc, third_party/xla/xla/translate/mhlo_to_hlo/tests/sharding.mlir",tensorflower-gardener,False
"[XLA:GPU] Move Tiling Complexity heuristic to EmitMatMul.

Currently the heuristic lives in the wrong place. It requires to pass fusion_kind to TritonWrapper.

The heuristic is used only for GEMMs, so it should move either up (to TritonFusion::Emit), or down (to EmitMatMul). I chose EmitMatMul because it requires less changes to the current infrastructure.

PiperOrigin-RevId: 619466784",Oleg Shyshkov,shyshkov@google.com,2024-03-27 09:48:43,"third_party/xla/xla/service/gpu/fusions/triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",olegshyshkov,False
"compat: Update forward compatibility horizon to 2024-03-27

PiperOrigin-RevId: 619458776",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 09:06:11,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1814.

PiperOrigin-RevId: 619457675",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 09:02:14,tensorflow/core/public/version.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 619444679",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 07:57:47,"tensorflow/lite/kernels/perception/BUILD, tensorflow/lite/kernels/perception/dense_image_warp.cc, tensorflow/lite/kernels/perception/dense_image_warp_test.cc, tensorflow/lite/kernels/perception/max_pool_with_argmax.cc, tensorflow/lite/kernels/perception/max_pool_with_argmax_test.cc, tensorflow/lite/kernels/perception/max_unpooling_2d.cc, tensorflow/lite/kernels/perception/max_unpooling_2d_test.cc, tensorflow/lite/kernels/perception/perception_ops.cc, tensorflow/lite/kernels/perception/perception_ops.h, tensorflow/lite/kernels/perception/perception_ops_wrapper.cc",tensorflower-gardener,False
"Change default calibration options. Populate both calibration method and calibration parameters.

PiperOrigin-RevId: 619441620",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 07:38:59,"tensorflow/compiler/mlir/quantization/stablehlo/cc/config.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/config_test.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc",tensorflower-gardener,False
"Rename 'hybrid' to 'weight-only'

PiperOrigin-RevId: 619436893",Doyeon Kim,doyeonkim@google.com,2024-03-27 07:15:12,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/passes/insert_weight_param.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/passes.td, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize_composite_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/insert_weight_param.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize/quantize_weight_only.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions_weight_only.mlir",doyeonkim0,False
"Automated Code Change

PiperOrigin-RevId: 619425275",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 06:12:52,"third_party/xla/third_party/tsl/tsl/lib/io/random_inputstream.h, third_party/xla/third_party/tsl/tsl/lib/io/zlib_inputstream.h, third_party/xla/third_party/tsl/tsl/lib/io/zlib_outputbuffer.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 619422013",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 05:55:53,tensorflow/core/profiler/utils/op_metrics_db_utils.h,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 619419396",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-27 05:39:52,"tensorflow/core/distributed_runtime/coordination/BUILD, tensorflow/core/distributed_runtime/coordination/coordination_service_barrier_proxy.cc, tensorflow/core/distributed_runtime/coordination/coordination_service_barrier_proxy.h, tensorflow/core/distributed_runtime/coordination/coordination_service_barrier_proxy_test.cc",tensorflower-gardener,False
"Add a few missing enums on XLA custom call version `API_VERSION_TYPED_FFI`.

PiperOrigin-RevId: 619411280",Haoyu Zhang,haoyuzhang@google.com,2024-03-27 04:54:25,"third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/python/ops.cc, third_party/xla/xla/python/xla_extension/ops.pyi",haoyuz,False
"Allow optional `stablehlo.broadcast_in_dim` op.

When deferring `stablehlo.transpose` of the lhs of `stablehlo.add`, the rhs may have a `constant->broadcast_in_dim` pattern.
Allow the pattern `DeferActivationTransposeForAddOp` to handle such a case.

PiperOrigin-RevId: 619408551",Dan Suh,dansuh@google.com,2024-03-27 04:37:24,"tensorflow/compiler/mlir/quantization/stablehlo/passes/defer_activation_transpose.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/defer_activation_transpose.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/pipelines/process_nchw_tensor.mlir",dansuh17,False
add num_results + skip overflow check test,redwrasse,mail@redwrasse.io,2024-03-27 03:42:28,tensorflow/python/ops/sobol_ops_test.py,redwrasse,True
"Guard host transfers inside pure_callbacks from deadlocking the TPU.

Also fix python/callback.cc to not swallow errors in numpy conversions.

PiperOrigin-RevId: 619375128",Parker Schuh,parkers@google.com,2024-03-27 01:35:49,"third_party/xla/xla/pjrt/host_callback.cc, third_party/xla/xla/pjrt/host_callback.h, third_party/xla/xla/python/BUILD, third_party/xla/xla/python/callback.cc, third_party/xla/xla/python/nb_numpy.cc, third_party/xla/xla/python/nb_numpy.h",pschuh,False
"Replace `RemoteTensorHandle` with `TensorProto` for scalars in an `EnqueueRequest` except for `DT_RESOURCE`

PiperOrigin-RevId: 619364557",Anshuman Goswami,anshumang@google.com,2024-03-27 00:43:46,"tensorflow/core/common_runtime/eager/BUILD, tensorflow/core/common_runtime/eager/execute.cc",anshumang,False
"#tf-data Add type annotations for `distributed_save`.

PiperOrigin-RevId: 619353640",Yang Chen,yangchen@google.com,2024-03-26 23:57:22,"tensorflow/python/data/experimental/ops/BUILD, tensorflow/python/data/experimental/ops/distributed_save_op.py",yangustc07,False
"Reverts changelist 506335783

PiperOrigin-RevId: 619350353",Fergus Henderson,fergus@google.com,2024-03-26 23:43:03,"configure.py, tensorflow/lite/g3doc/android/lite_build.md",fergushenderson,False
"hlo_dfs_reachability_test: use batch mode in Build benchmark

- Before:
----------------------------------------------------------------------------
Benchmark                                  Time             CPU   Iterations
----------------------------------------------------------------------------
BM_HloDfsReachabilityBuild/1             143 ns          143 ns     10314343
BM_HloDfsReachabilityBuild/64           1776 ns         1776 ns       783254
BM_HloDfsReachabilityBuild/128          3565 ns         3564 ns       391936
BM_HloDfsReachabilityBuild/256          7446 ns         7445 ns       189334
BM_HloDfsReachabilityBuild/512         15044 ns        15041 ns        92625
BM_HloDfsReachabilityBuild/4096       158882 ns       158865 ns         8625
BM_HloDfsReachabilityBuild/32768     1709590 ns      1709401 ns          825
BM_HloDfsReachabilityBuild/262144   37142558 ns     37136529 ns           38

- After:
----------------------------------------------------------------------------
Benchmark                                  Time             CPU   Iterations
----------------------------------------------------------------------------
BM_HloDfsReachabilityBuild/1             135 ns          135 ns     10330052
BM_HloDfsReachabilityBuild/64           27.8 ns         27.8 ns     50131200
BM_HloDfsReachabilityBuild/128          28.7 ns         28.7 ns     47522432
BM_HloDfsReachabilityBuild/256          29.2 ns         29.2 ns     47567104
BM_HloDfsReachabilityBuild/512          29.9 ns         29.9 ns     46650880
BM_HloDfsReachabilityBuild/4096         41.1 ns         41.1 ns     36945920
BM_HloDfsReachabilityBuild/32768        59.5 ns         59.5 ns     23035904
BM_HloDfsReachabilityBuild/262144        154 ns          154 ns      8912896

PiperOrigin-RevId: 619340769",Emilio Cota,ecg@google.com,2024-03-26 23:06:21,third_party/xla/xla/service/hlo_dfs_reachability_test.cc,cota,False
"Mark alias in tensorflow::profiler to counter parts in tsl::profiler as deprecated.

PiperOrigin-RevId: 619333639",Clive Verghese,cliveverghese@google.com,2024-03-26 22:39:13,"tensorflow/core/profiler/convert/trace_viewer/trace_events_to_json.h, tensorflow/core/profiler/lib/BUILD, tensorflow/core/profiler/lib/connected_traceme.h, tensorflow/core/profiler/lib/context_types.h, tensorflow/core/profiler/lib/profiler_controller.h, tensorflow/core/profiler/lib/profiler_factory.h, tensorflow/core/profiler/lib/profiler_interface.h, tensorflow/core/profiler/lib/profiler_lock.h, tensorflow/core/profiler/lib/profiler_session.h, tensorflow/core/profiler/lib/scoped_annotation.h, tensorflow/core/profiler/lib/scoped_memory_debug_annotation.h, tensorflow/core/profiler/lib/traceme.h, tensorflow/core/profiler/lib/traceme_encode.h",cliveverghese,False
"Replace TODO bug, to track investigation and fix for histogram percentile calibration method for StableHLO Quantizer.

PiperOrigin-RevId: 619331511",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 22:31:51,"tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test_base.py",tensorflower-gardener,False
"Generate XLA's warnings.bazelrc automatically by inspecting the toolchain

PiperOrigin-RevId: 619326423",David Dunleavy,ddunleavy@google.com,2024-03-26 22:14:45,".bazelrc, third_party/xla/.bazelrc, third_party/xla/third_party/tsl/.bazelrc, third_party/xla/warnings.bazelrc",ddunl,False
"PR #10954: [ROCM] fix 'Invalid plugin kind specified: DNN' error

Imported from GitHub PR https://github.com/openxla/xla/pull/10954

This pr removes ""Invalid plugin kind specified: DNN"" error/warning often seen on ROCm platform.

@xla-rotation : would you take a look please?
Copybara import of the project:

--
b2c8d601a9aa1bcd7f6a6d9d7bb8c1b4eda93f8a by Ruturaj4 <ruturaj.vaidya@amd.com>:

fix 'Invalid plugin kind specified: DNN' error

Merging this change closes #10954

PiperOrigin-RevId: 619324921",Ruturaj Vaidya,ruturaj.vaidya@amd.com,2024-03-26 22:10:07,third_party/xla/xla/stream_executor/plugin_registry.cc,Ruturaj4,False
"PR #10376: Fix expm1 inaccuracies on complex inputs with small absolute values. Add Cosm1.

Imported from GitHub PR https://github.com/openxla/xla/pull/10376

As in the title.

Tests and improvement reports are in https://github.com/google/jax/pull/20144.

Accuracy tests are enabled in https://github.com/google/jax/pull/20436
Copybara import of the project:

--
42e222a436787c52adf453c8c0c39125b010e2b2 by Pearu Peterson <pearu.peterson@gmail.com>:

Fix expm1 inaccuracies on complex inputs with small absolute values. Add Cosm1.
Fix expm1(x+yi) when x is large and y is zero.

Merging this change closes #10376

PiperOrigin-RevId: 619324160",Pearu Peterson,pearu.peterson@gmail.com,2024-03-26 22:07:56,"third_party/xla/xla/python/xla_client.py, third_party/xla/xla/service/elemental_ir_emitter.cc, third_party/xla/xla/service/elemental_ir_emitter.h",pearu,False
"PR #10788: [ROCM] fixing build brake: disabling cudnn_fusion_compiler for ROCM

Imported from GitHub PR https://github.com/openxla/xla/pull/10788

In this PR I disable yet cudnn_fusion_compiler to fix the build brake
These feature is to be enabled later.

@xla-rotation: woud you have a look please ?

Copybara import of the project:

--
7ff1b0094f371188a8cc142eec6e6c77585ae666 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

rebased and added virtual function for cudnn compiler pass

Merging this change closes #10788

PiperOrigin-RevId: 619323685",pemeliya,141146080+pemeliya@users.noreply.github.com,2024-03-26 22:06:26,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_compiler.h, third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/service/gpu/nvptx_compiler.h",pemeliya,False
"[tflite] Add the skeleton for tflite composite lowering pass.

PiperOrigin-RevId: 619315414",Majid Dadashi,majiddadashi@google.com,2024-03-26 21:38:49,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_pass.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_pass.h, tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_patterns.td, tensorflow/compiler/mlir/lite/stablehlo/transforms/passes.h, tensorflow/compiler/mlir/lite/stablehlo/transforms/passes.td, tensorflow/compiler/mlir/lite/tf_tfl_passes.cc",majiddadashi,False
"Automated Code Change

PiperOrigin-RevId: 619311613",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 21:26:24,"tensorflow/lite/kernels/internal/BUILD, tensorflow/lite/python/testdata/BUILD",tensorflower-gardener,False
"[XLA:Runtime] Moved the thunk target to the runtime folder.

Updated the necessary directories pointing to the thunk target.

PiperOrigin-RevId: 619296551",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 20:39:17,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc, third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.h, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/copy.cc, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/fusions/fusion_emitter.h, third_party/xla/xla/service/gpu/fusions/reduction.cc, third_party/xla/xla/service/gpu/fusions/thunk_util.cc, third_party/xla/xla/service/gpu/fusions/thunk_util.h, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/gpu_executable.h, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/ir_emitter_unnested.h, third_party/xla/xla/service/gpu/mock_nccl_utils.cc, third_party/xla/xla/service/gpu/mock_nccl_utils.h, third_party/xla/xla/service/gpu/mock_nccl_utils_default.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/cholesky_thunk.h, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_emitter.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_emitter.h, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd_test.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk.h, third_party/xla/xla/service/gpu/runtime/command_buffer_thunk_test.cc, third_party/xla/xla/service/gpu/runtime/conditional_thunk.cc, third_party/xla/xla/service/gpu/runtime/conditional_thunk.h, third_party/xla/xla/service/gpu/runtime/convolution_thunk.h, third_party/xla/xla/service/gpu/runtime/copy_thunk.cc, third_party/xla/xla/service/gpu/runtime/copy_thunk.h, third_party/xla/xla/service/gpu/runtime/cub_sort_thunk.cc, third_party/xla/xla/service/gpu/runtime/cub_sort_thunk.h, third_party/xla/xla/service/gpu/runtime/cudnn_thunk.h, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.h, third_party/xla/xla/service/gpu/runtime/fft_thunk.h, third_party/xla/xla/service/gpu/runtime/fused_mha_thunk.h, third_party/xla/xla/service/gpu/runtime/gemm_thunk.cc, third_party/xla/xla/service/gpu/runtime/gemm_thunk.h, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.cc, third_party/xla/xla/service/gpu/runtime/gpublas_lt_matmul_thunk.h, third_party/xla/xla/service/gpu/runtime/infeed_thunk.h, third_party/xla/xla/service/gpu/runtime/kernel_thunk.cc, third_party/xla/xla/service/gpu/runtime/kernel_thunk.h, third_party/xla/xla/service/gpu/runtime/memset_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_all_gather_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_all_reduce_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_recv_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_send_thunk.cc, third_party/xla/xla/service/gpu/runtime/norm_thunk.h, third_party/xla/xla/service/gpu/runtime/outfeed_thunk.h, third_party/xla/xla/service/gpu/runtime/replica_id_thunk.h, third_party/xla/xla/service/gpu/runtime/send_recv_thunk.cc, third_party/xla/xla/service/gpu/runtime/send_recv_thunk.h, third_party/xla/xla/service/gpu/runtime/sequential_thunk.cc, third_party/xla/xla/service/gpu/runtime/sequential_thunk.h, third_party/xla/xla/service/gpu/runtime/thunk.cc, third_party/xla/xla/service/gpu/runtime/thunk.h, third_party/xla/xla/service/gpu/runtime/triangular_solve_thunk.h, third_party/xla/xla/service/gpu/runtime/wait_for_streams_thunk.cc, third_party/xla/xla/service/gpu/runtime/wait_for_streams_thunk.h, third_party/xla/xla/service/gpu/runtime/while_thunk.cc, third_party/xla/xla/service/gpu/runtime/while_thunk.h, third_party/xla/xla/service/gpu/stream_attribute_annotator.cc, third_party/xla/xla/service/gpu/stream_attribute_async_wrapper.cc",tensorflower-gardener,False
"Add new overload of `GraphToFunctionDef()` that can consume the graph.

Previously, we copied all of the node data from the input subgraph to the `FunctionDef`. This change reduces the memory footprint of multi-device function instantiation by (where possible) `std::move`-ing the bulk of the node data from the input graph to newly created `NodeDef` members of the resulting `FunctionDef` protocol buffer.

This change should reduce (but not completely eliminate) the need for setting `TF_PFLR_PARALLEL_INSTANTIATE_THRESHOLD` in jobs with large multi-device function graphs.

PiperOrigin-RevId: 619293682",Derek Murray,mrry@google.com,2024-03-26 20:30:19,"tensorflow/core/common_runtime/process_function_library_runtime.cc, tensorflow/core/framework/graph_to_functiondef.cc, tensorflow/core/framework/graph_to_functiondef.h",mrry,False
"Add CompositeOp to CustomOp conversion

PiperOrigin-RevId: 619291788",Kevin Gleason,gleasonk@google.com,2024-03-26 20:25:02,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/tests/legalize-stablehlo-tfl-composite.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_composite_to_tfl_custom.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/passes.td, tensorflow/compiler/mlir/lite/tf_tfl_passes.cc",GleasonK,False
"Merge pull request #64539 from rascani:add_ios_and_contributing_links

PiperOrigin-RevId: 619290596",TensorFlower Gardener,gardener@tensorflow.org,2024-03-26 20:48:50,tensorflow/lite/experimental/shlo/README.md,tensorflower-gardener,False
"Don't reset changed_ to false every time PerformSpaceToBatchOnConvolution is called.

For example after PropagateOnUsers is called, new broadcast instructions are added so changed_ should be true. This makes it possible for the hlo module to be saved after this pass has rewrote or added new hlo instructions (module pertaining to the pass is only saved if there are changes).

PiperOrigin-RevId: 619290345",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 20:20:44,third_party/xla/xla/service/space_to_batch_converter.cc,tensorflower-gardener,False
"[XLA:GPU] Fix Triton emitter for nested reducer fusions.

This should not have any reason to happen in principle, but the fusion passes
currently sometimes produce fusions inside reduction computations---causing
us to have to codegen a fusion inside our Triton fusion.

PiperOrigin-RevId: 619269385",Benjamin Chetioui,bchetioui@google.com,2024-03-26 19:07:15,"third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",bchetioui,False
"Models only a subset of memory segments that are sufficiently different from one another, skipping those that are ""similar enough.""

PiperOrigin-RevId: 619264352",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 18:51:39,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc,tensorflower-gardener,False
"shlo_ref: Add doc links for contributing & iOS

This PR adds links to the main tensorflow contributing guideline to the
SHLO doc and highlights the expectation that clang-format is to be used.
It also adds some rudimentary instructions for building targets for iOS,
but testing is still left as a todo.",RJ Ascani,rjascani@google.com,2024-03-26 18:50:16,tensorflow/lite/experimental/shlo/README.md,rascani,True
"[XLA:GPU] Revert ""Add GpuHloCostAnalysis option to estimate Triton Softmax fusions.""

PiperOrigin-RevId: 619258430",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 18:32:58,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/gpu_hlo_cost_analysis.cc, third_party/xla/xla/service/gpu/model/gpu_hlo_cost_analysis.h, third_party/xla/xla/service/gpu/model/gpu_performance_model_test.cc",tensorflower-gardener,False
"Update github xla contacts

PiperOrigin-RevId: 619239299",Elliot English,elliotenglish@google.com,2024-03-26 17:39:13,third_party/xla/README.md,,False
"[Triton] Modify disabled mixed-precision mmav2 swizzling to be enabled with different configuration.

PiperOrigin-RevId: 619236546",Mohammed Anany,manany@google.com,2024-03-26 17:31:12,"third_party/triton/cl619146327.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/cl619146327.patch, third_party/xla/third_party/triton/workspace.bzl",Moerafaat,False
"Disable Tensor Cores for 8-bit x F32 dot.

PiperOrigin-RevId: 619235998",Mohammed Anany,manany@google.com,2024-03-26 17:29:32,"third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",Moerafaat,False
"Integrate LLVM at llvm/llvm-project@3cf169ca160e

Updates LLVM usage to match
[3cf169ca160e](https://github.com/llvm/llvm-project/commit/3cf169ca160e)

PiperOrigin-RevId: 619208575",Dmitri Gribenko,dmitrig@google.com,2024-03-26 16:04:47,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",gribozavr,False
Disable grappler on TF->XLA JIT compilation.,mdfaijul,md.faijul.amin@intel.com,2024-02-28 05:03:47,"tensorflow/core/grappler/optimizers/remapper.cc, tensorflow/core/grappler/optimizers/remapper_test.cc",mdfaijul,True
"Migrate Protobuf DebugString calls

PiperOrigin-RevId: 619204340",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 15:50:08,"tensorflow/compiler/mlir/tensorflow/translate/BUILD, tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate_registration.cc, tensorflow/compiler/mlir/tensorflow/translate/translate_tf_dialect_op.cc, tensorflow/core/common_runtime/BUILD, tensorflow/core/common_runtime/direct_session_test.cc, tensorflow/core/common_runtime/process_function_library_runtime_test.cc, tensorflow/core/framework/model.cc, tensorflow/core/framework/op_kernel_test.cc, tensorflow/core/graph/optimizer_cse_test.cc, tensorflow/python/framework/BUILD, tensorflow/python/framework/python_op_gen.cc, third_party/xla/third_party/tsl/tsl/platform/protobuf.h, third_party/xla/third_party/tsl/tsl/platform/protobuf_util.cc",tensorflower-gardener,False
"[XLA:GPU] Add GpuHloCostAnalysis option to estimate Triton Softmax fusions.

PiperOrigin-RevId: 619195443",Oleg Shyshkov,shyshkov@google.com,2024-03-26 15:17:07,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/gpu_hlo_cost_analysis.cc, third_party/xla/xla/service/gpu/model/gpu_hlo_cost_analysis.h, third_party/xla/xla/service/gpu/model/gpu_performance_model_test.cc",olegshyshkov,False
"[XLA:GPU][NFC] Move tile_analysis* to symbolic_tile*.

Related code pertaining to tile propagation/analysis belongs in
symbolic_tile_analysis*.

PiperOrigin-RevId: 619171048",Benjamin Chetioui,bchetioui@google.com,2024-03-26 13:37:44,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile.cc, third_party/xla/xla/service/gpu/model/symbolic_tile.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_test.cc",bchetioui,False
"[XLA:GPU] Implement EmitDot in the new MLIR emitters

PiperOrigin-RevId: 619167898",Tamás Danyluk,tdanyluk@google.com,2024-03-26 13:23:03,"third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc",tdanyluk,False
"[XLA:GPU] Add threadId mappings to the legacy emitters and add tests to the new ones.

PiperOrigin-RevId: 619167450",Alexander Belyaev,pifon@google.com,2024-03-26 13:20:46,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/concatenate.cc, third_party/xla/xla/service/gpu/fusions/concatenate.h, third_party/xla/xla/service/gpu/fusions/concatenate_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/concatenate_test.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_test.cc, third_party/xla/xla/service/gpu/fusions/scatter.cc, third_party/xla/xla/service/gpu/fusions/scatter.h, third_party/xla/xla/service/gpu/fusions/scatter_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/scatter_test.cc",pifon2a,False
"Integrate LLVM at llvm/llvm-project@fa3d789df15b

Updates LLVM usage to match
[fa3d789df15b](https://github.com/llvm/llvm-project/commit/fa3d789df15b)

PiperOrigin-RevId: 619157908",Dmitri Gribenko,dmitrig@google.com,2024-03-26 12:41:18,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",gribozavr,False
"[XLA:GPU] Remove FusionMergerTriton pass.

This was never enabled, and is being replaced by the more principled
solution using SymbolicTileAnalysis and priority fusion.

Update an imprecise test that was supposed to test this (but apparently
wasn't).

PiperOrigin-RevId: 619151128",Benjamin Chetioui,bchetioui@google.com,2024-03-26 12:07:52,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusion_merger_triton.cc, third_party/xla/xla/service/gpu/fusion_merger_triton.h, third_party/xla/xla/service/gpu/fusion_merger_triton_test.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_parametrized_test.cc",bchetioui,False
"Do not produce negative strides when building symbolic maps

PiperOrigin-RevId: 619148171",Sergey Kozub,sergeykozub@google.com,2024-03-26 11:53:49,"third_party/xla/xla/service/gpu/model/tile_analysis.cc, third_party/xla/xla/service/gpu/model/tile_analysis.h, third_party/xla/xla/service/gpu/model/tile_analysis_test.cc",sergeykozub,False
"[XLA:GPU] Implement new Triton Softmax codegen based on symbolic tiles and indexing maps.

Symbolic tiles are still under development and can process all instructions. The new codegen is used only when all instruction in the fusion are supported, otherwise we fall back to the old codegen.

Triton Softmax codegen is behind `--xla_gpu_enable_triton_softmax_fusion` flag that is not turned on by default, so this change shouldn't affect any production workloads.

PiperOrigin-RevId: 619143278",Oleg Shyshkov,shyshkov@google.com,2024-03-26 11:27:32,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.h",olegshyshkov,False
"Automated Code Change

PiperOrigin-RevId: 619140196",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 11:12:01,"third_party/xla/xla/mlir/runtime/utils/BUILD, third_party/xla/xla/mlir/runtime/utils/async_runtime_api.cc, third_party/xla/xla/mlir/runtime/utils/async_runtime_api.h, third_party/xla/xla/mlir/runtime/utils/constraints.cc, third_party/xla/xla/mlir/runtime/utils/constraints.h, third_party/xla/xla/mlir/runtime/utils/custom_calls.cc, third_party/xla/xla/mlir/runtime/utils/custom_calls.h",tensorflower-gardener,False
"[XLA:GPU] Fix layout for kSend/kRecv on GPU to always be default

PiperOrigin-RevId: 619139935",George Karpenkov,cheshire@google.com,2024-03-26 11:10:31,"third_party/xla/xla/service/gpu/gpu_layout_assignment.cc, third_party/xla/xla/service/gpu/gpu_layout_assignment_test.cc",cheshire,False
"[XLA:GPU] Expand test coverage for SymbolicTile derivation.

Added tests to cover failure paths for mod, floordiv, and non-0 offset across
untiled dimensions.

Also contains some cosmetic/style changes.

PiperOrigin-RevId: 619128579",Benjamin Chetioui,bchetioui@google.com,2024-03-26 10:20:06,"third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc, third_party/xla/xla/service/gpu/model/tile_analysis.cc, third_party/xla/xla/service/gpu/model/tile_analysis.h, third_party/xla/xla/service/gpu/model/tile_analysis_test.cc",bchetioui,False
"Automated Code Change

PiperOrigin-RevId: 619117651",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 09:29:05,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/while_loop_fusible_sinking_test.cc, third_party/xla/xla/service/while_loop_invariant_code_motion.cc, third_party/xla/xla/service/while_loop_invariant_code_motion.h, third_party/xla/xla/service/while_loop_invariant_code_motion_test.cc, third_party/xla/xla/service/while_loop_simplifier.cc, third_party/xla/xla/service/while_loop_simplifier.h, third_party/xla/xla/service/while_loop_simplifier_test.cc, third_party/xla/xla/service/while_loop_trip_count_annotator.cc, third_party/xla/xla/service/while_loop_trip_count_annotator.h, third_party/xla/xla/service/while_loop_trip_count_annotator_test.cc, third_party/xla/xla/service/while_util.h, third_party/xla/xla/service/while_util_test.cc, third_party/xla/xla/service/xla_aot_compile_cpu_test.cc, third_party/xla/xla/service/xla_aot_compile_stablehlo_cpu_test.cc, third_party/xla/xla/service/xla_debug_info_manager.cc, third_party/xla/xla/service/xla_debug_info_manager.h, third_party/xla/xla/service/xla_debug_info_manager_test.cc, third_party/xla/xla/service/zero_sized_hlo_elimination.cc, third_party/xla/xla/service/zero_sized_hlo_elimination.h, third_party/xla/xla/service/zero_sized_hlo_elimination_test.cc",tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-03-26

PiperOrigin-RevId: 619111587",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 09:03:22,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1813.

PiperOrigin-RevId: 619111353",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 09:02:34,tensorflow/core/public/version.h,tensorflower-gardener,False
"[XLA:GPU] Add option to return FDO profile as textproto.

PiperOrigin-RevId: 619105468",George Karpenkov,cheshire@google.com,2024-03-26 08:34:47,"third_party/xla/xla/python/BUILD, third_party/xla/xla/python/profiler.cc, third_party/xla/xla/python/xla_extension/profiler.pyi",cheshire,False
"No public description

PiperOrigin-RevId: 619089713",Dan Suh,dansuh@google.com,2024-03-26 07:19:11,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/config.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/config_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/ops/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/ops/stablehlo_op_quant_spec.cc, tensorflow/compiler/mlir/quantization/stablehlo/ops/stablehlo_op_quant_spec_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/quantization_config.proto, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/prepare_quantize/prepare_quantize_per_channel.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions.mlir, tensorflow/compiler/mlir/quantization/tensorflow/python/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc",dansuh17,False
"Add deferring transposes of the input of `stablehlo.maximum` to output.

PiperOrigin-RevId: 619052298",Dan Suh,dansuh@google.com,2024-03-26 04:04:08,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/passes/defer_activation_transpose.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/defer_activation_transpose.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/pipelines/process_nchw_tensor.mlir",dansuh17,False
"PR #10892: Fix some clang-tidy reported issues in xla/service

Imported from GitHub PR https://github.com/openxla/xla/pull/10892

Fixes:
1. `~BufferAllocation() {}` - There is no needed to define empty dtor explicitly. Also, if dtor is explicitly defined we also need to define copy ctor and copy operator=. The right solution here is to not define dtor explicitly.
2. `std::move(target_config)` - `target_config` is const ref - it is not possible to move/modify const refs. std::move can be removed since it is not doing anything here.
3. `mutable_dot_config()->insert(MapPair)` - better to use `try_emplace(K&&, V&&)` directly because it accepts K&& and V&& params, where `insert` requires to create temp `MapPair` object. Internally `insert` uses `try_emplace`.
4. `const std::vector<bool> require_broadcast` - remove const from this param because `require_broadcast` will be moved in this function
5. add `std::move` to `set_auto_spmd_partitioning_mesh_shape` and `set_auto_spmd_partitioning_mesh_ids` to make them similar and consistent with other setter(std::vector) functions in `HloModuleConfig` class.
6. update callers of HloModuleConfig setter(std::vector) functions to use std::move or rvalue to avoid vector copy.
7. `chunk_(std::move(chunk))` - remove move because struct Chunk is trivially-copyable type. So, move have the same price as copy for such types.
8. `additional_sort_data_.insert(pair)` - replaced with `try_emplace(K&&, V&&)` to remove `std::make_pair`. Remove move from `std::move(sort_data)` -  sort_data type AdditionalSortData is trivially-copyable type.
9. `std::move(*buffer_assignment_proto_after_opt)` - remove move because `buffer_assignment_proto_after_opt` is `const BufferAssignmentProto*` - it can not be moved/modified. move does nothing here.
10. return std::move(executable)` - move is not needed in return. It breaks RVO/NRVO compiler optimization.
11. `run_options_(std::move(run_options))` - `std::move` is removed because run_options type ExecutableRunOptions is trivially-copyable type. move has no effect here.
Copybara import of the project:

--
0ad7bde68fea25b626ef1e2ac99ca007151f8b0b by Alexander Pivovarov <pivovaa@amazon.com>:

Fix some clang-tidy reported issues in xla/service

Merging this change closes #10892

PiperOrigin-RevId: 619029010",Alexander Pivovarov,pivovaa@amazon.com,2024-03-26 01:58:57,"third_party/xla/xla/client/executable_build_options.cc, third_party/xla/xla/hlo/ir/hlo_module.cc, third_party/xla/xla/service/buffer_assignment.h, third_party/xla/xla/service/compiler.h, third_party/xla/xla/service/hlo_module_config.cc, third_party/xla/xla/service/hlo_module_config.h, third_party/xla/xla/service/hlo_module_util.cc, third_party/xla/xla/service/memory_space_assignment/allocation.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc, third_party/xla/xla/service/service.cc, third_party/xla/xla/service/service_executable_run_options.h, third_party/xla/xla/stream_executor/tpu/c_api_conversions.cc",apivovarov,False
"Remove CHECKs from op_profile_builder.cc

PiperOrigin-RevId: 619015115",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 00:54:53,"tensorflow/core/profiler/convert/BUILD, tensorflow/core/profiler/convert/op_profile_builder.cc",tensorflower-gardener,False
"Add two arguments in OpExpanderPass: `preserve_sharding` and `relay_control_dependency`.

PiperOrigin-RevId: 619014199",Zixuan Jiang,zixuanjiang@google.com,2024-03-26 00:50:14,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/op_expander_pass.cc, third_party/xla/xla/service/op_expander_pass.h",ZixuanJiang,False
"Use the information in allow_spmd_sharding_propagation_to_output and allow_spmd_sharding_propagation_to_parameters to determine what input and output tuple elements we are allowed to modfy the shardings of.

PiperOrigin-RevId: 619013275",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 00:45:59,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.h",tensorflower-gardener,False
"Change tf.IfrtLoadVariableOp to receive tensor future from
IfrtRestoreTensorRegistry instead of from resource manager.
Correspondingly, IfrtLoadVariableRegistry is changed to
store a future of array.
This enables tfrt+ifrt to restore tensor asynchronously

PiperOrigin-RevId: 619011241",Deqiang Chen,deqiangc@google.com,2024-03-26 00:37:02,"tensorflow/compiler/mlir/tfrt/transforms/ifrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_types.h, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf2hlo.h, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf_ifrt_passes.cc, tensorflow/core/tfrt/ifrt/BUILD, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.cc, tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.h, tensorflow/core/tfrt/ifrt/ifrt_model_context.h, tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc, tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test.cc, tensorflow/core/tfrt/mlrt/kernel/BUILD, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc, tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc, tensorflow/core/tfrt/saved_model/tests/saved_model_ifrt_test.cc",deqiangc,False
"Create a util function `BuildGetTupleElementsForTupleResults` with proper processing on the shardings.

**Issue 1.**
The following code snippet is widely used in `mlir_hlo_to_hlo.cc` when exporting to a XlaOp if the op has multiple results, such as RngBitGeneratorOp and OptimizationBarrierOp. We create a util function to replace the repeating code snippets.
```
for (auto [index, result] : llvm::enumerate(op.getResults())) {
    value_map[result] = xla::GetTupleElement(tuple, index);
}
```

**Issue 2.**
When we build `xla::GetTupleElement` in the code snippet, we inherit the tuple sharding (if any) and assign the tuple sharding to the `xla::GetTupleElement`. This triggers a mismatching error on shape and sharding in XlaBuilder. This cl uses `XlaScopedShardingAssignment` to process it appropriately.

Enhance the test cases accordingly.

PiperOrigin-RevId: 619009107",Zixuan Jiang,zixuanjiang@google.com,2024-03-26 00:28:50,"third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc, third_party/xla/xla/translate/mhlo_to_hlo/tests/export.mlir, third_party/xla/xla/translate/mhlo_to_hlo/tests/sharding.mlir",ZixuanJiang,False
"PR #10835: [GPU] Add support of select operation in cuDNN fusions.

Imported from GitHub PR https://github.com/openxla/xla/pull/10835

Copybara import of the project:

--
90c7996c704aeb1edde40243c2770654e9aca446 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Add support of select operation in cuDNN fusions.

Merging this change closes #10835

PiperOrigin-RevId: 619006475",Ilia Sergachev,isergachev@nvidia.com,2024-03-26 00:17:31,"third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/fusions/cudnn_test.cc",sergachev,False
"Ensure that the module we consume has no unused computations. This can causes issues as we clone modules to support try_multiple_mesh_shapes, and cloning an HLO module removes dead computations leading to mismatches.

PiperOrigin-RevId: 619002992",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-26 00:03:23,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_test.cc",tensorflower-gardener,False
"PR #10925: Include FP8 GEMMs in IsCublasGemm

Imported from GitHub PR https://github.com/openxla/xla/pull/10925

Adds FP8 GEMM Custom Calls to the set of ops considered in function IsCublasGemm.
Copybara import of the project:

--
8449c5ec4a1349fe54f211a2dbe4a0deb78a240b by Philipp Hack <phack@nvidia.com>:

Include FP8 GEMMs in function IsCublasGemm.

--
f09bcb8b208c6a74567093af505b26436bd3df9c by Philipp Hack <phack@nvidia.com>:

Include FP8 GEMMs in function IsCublasGemm.

Merging this change closes #10925

PiperOrigin-RevId: 619002481",Philipp Hack,phack@nvidia.com,2024-03-26 00:01:43,"third_party/xla/xla/service/gpu/cublas_cudnn.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc",philipphack,False
"[xla][gpu] Change related to the handling of pipelined Send/Recv.

Previously, we relied on certain code patterns to find the Send/Recv for
Send-done/Recv-done for a pipelined loop. Now that we realize copy-insertion
can complicate such code patterns and make such pattern matching fragile.

We modify the collective-permute-decomposer to annotate the pipeline decision
on Send-done/Recv-done, in additional to Send/Recv. We also change the HLO
scheduler and verifier to use such annotation instead of relying on code
pattern matching.

PiperOrigin-RevId: 619001952",Bixia Zheng,bixia@google.com,2024-03-26 00:00:07,"third_party/xla/xla/service/collective_permute_decomposer.cc, third_party/xla/xla/service/collective_permute_decomposer_test.cc, third_party/xla/xla/service/collective_pipeliner_test.cc, third_party/xla/xla/service/gpu/gpu_hlo_schedule.cc, third_party/xla/xla/service/gpu/gpu_hlo_schedule_test.cc, third_party/xla/xla/service/gpu/gpu_p2p_pipeliner_test.cc, third_party/xla/xla/service/hlo_parser_test.cc, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/hlo_verifier_test.cc, third_party/xla/xla/service/layout_assignment_test.cc",bixia1,False
"Log checkpoint hashing error.

PiperOrigin-RevId: 619000563",Adam Cogdell,adamcogdell@google.com,2024-03-25 23:55:12,"tensorflow/cc/saved_model/BUILD, tensorflow/cc/saved_model/fingerprinting.cc",BlaziusMaximus,False
"PR #10878: Disable Fusion of FP8 Matrix Bias

Imported from GitHub PR https://github.com/openxla/xla/pull/10878

Disables the fusion of a matrix bias into a GEMM Custom Call when the bias has an FP8 data type.
Copybara import of the project:

--
83d29227b698059b56bed4d84ef44c0967a003fe by Philipp Hack <phack@nvidia.com>:

Disable FP8 matrix bias fusion.

Merging this change closes #10878

PiperOrigin-RevId: 618999250",Philipp Hack,phack@nvidia.com,2024-03-25 23:49:51,"third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc",philipphack,False
"#tf-data Add a test for global shuffling `list_files` dataset.

PiperOrigin-RevId: 618989811",Yang Chen,yangchen@google.com,2024-03-25 23:13:25,"tensorflow/python/data/kernel_tests/BUILD, tensorflow/python/data/kernel_tests/list_files_test.py",yangustc07,False
"Use the sharding of the appropriate tuple element rather than that of the entire tuple when computing input_shardings for get-tuple-element HLO ops with user sharding annotations.

PiperOrigin-RevId: 618989496",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 23:12:12,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_test.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc",tensorflower-gardener,False
"[XLA:GPU] Enable GemmFusion to fuse dot with trivial non-contracting dimension

PiperOrigin-RevId: 618981039",Anlun Xu,anlunx@google.com,2024-03-25 22:39:45,"third_party/xla/xla/service/gpu/gemm_fusion.cc, third_party/xla/xla/service/gpu/gemm_fusion_test.cc",anlunx,False
"[xla:gpu] Handle OOB start indices in AddressComputationThunk

PiperOrigin-RevId: 618975990",Son Tuan Vu,vuson@google.com,2024-03-25 22:21:42,"third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc",tyb0807,False
"Integrate StableHLO at openxla/stablehlo@b27ef13c

PiperOrigin-RevId: 618971032",Sandeep Dasgupta,sdasgup@google.com,2024-03-25 22:04:06,"tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/nchw_convolution_to_nhwc.mlir, third_party/stablehlo/temporary.patch, third_party/stablehlo/workspace.bzl, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/workspace.bzl",sdasgup3,False
"Add `tsl::testing::AppendDotExeIfWindows` and use it inside `filecheck.cc` to fix Windows build errors

PiperOrigin-RevId: 618962127",David Dunleavy,ddunleavy@google.com,2024-03-25 21:33:59,"third_party/xla/third_party/tsl/tsl/platform/path.cc, third_party/xla/third_party/tsl/tsl/platform/path.h, third_party/xla/third_party/tsl/tsl/platform/subprocess_test.cc, third_party/xla/xla/stream_executor/gpu/asm_compiler.cc, third_party/xla/xla/tests/filecheck.cc",ddunl,False
"[xla:gpu][NFC] Add `update` accessor to HloDynamicUpdateSliceInstruction API

PiperOrigin-RevId: 618959577",Son Tuan Vu,vuson@google.com,2024-03-25 21:25:45,"third_party/xla/xla/hlo/ir/hlo_instructions.h, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/ir_emission_utils.cc, third_party/xla/xla/service/gpu/kernels/cutlass_gemm_fusion.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.cc",tyb0807,False
"Add a pass to remove unused restore op

PiperOrigin-RevId: 618946899",Deqiang Chen,deqiangc@google.com,2024-03-25 20:45:19,"tensorflow/compiler/mlir/tfrt/tests/ifrt/tf_restore_pruning.mlir, tensorflow/compiler/mlir/tfrt/transforms/ifrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/ifrt/passes.td, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf_ifrt_passes.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf_ifrt_passes.h, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf_restore_pruning.cc",deqiangc,False
"[xla:gpu] Support DUS for AddressComputationFusionRewriter

PiperOrigin-RevId: 618942742",Son Tuan Vu,vuson@google.com,2024-03-25 20:31:33,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc",tyb0807,False
"[xla:ffi] Pass device allocator and device ordinal to FFI execution context

PiperOrigin-RevId: 618936780",Eugene Zhulenev,ezhulenev@google.com,2024-03-25 20:11:48,"third_party/xla/xla/service/gpu/custom_call_test.cc, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc",ezhulenev,False
"Ensure that the module we consume has no unused computations. This can causes issues as we clone modules to support try_multiple_mesh_shapes, and cloning an HLO module removes dead computations leading to mismatches.

PiperOrigin-RevId: 618932647",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 19:58:35,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_test.cc",tensorflower-gardener,False
"Remove unused ConvertFunctionToBef.

PiperOrigin-RevId: 618931239",Arturo Schmidt,arturoschmidt@google.com,2024-03-25 19:53:32,"tensorflow/compiler/mlir/tfrt/translate/import_model.cc, tensorflow/compiler/mlir/tfrt/translate/import_model.h",rocketas,False
Update configure.py,mraunak,83710963+mraunak@users.noreply.github.com,2024-03-25 20:45:31,configure.py,mraunak,True
"[xla:ffi] Add support for array attributes to custom call thunk

PiperOrigin-RevId: 618927279",Eugene Zhulenev,ezhulenev@google.com,2024-03-25 19:39:40,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/ffi_test.cc, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/custom_call_test.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/custom_call_thunk.cc",ezhulenev,False
Update configure.py,mraunak,83710963+mraunak@users.noreply.github.com,2024-03-25 20:33:24,configure.py,mraunak,True
"[xla:gpu] Support dynamic offset size in AddressComputationThunk

Contrary to the documentation, dynamic-slice and DUS ops may have start indices of type different than S64[]. We need to be more precise when loading the offset from device to host at runtime.

PiperOrigin-RevId: 618927023",Son Tuan Vu,vuson@google.com,2024-03-25 19:38:42,"third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/fusions/custom.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc, third_party/xla/xla/service/gpu/runtime/address_computation_thunk.h, third_party/xla/xla/service/gpu/runtime/address_computation_thunk_test.cc",tyb0807,False
"Avoid out-of-range crashes in hlo_proto_to_memory_visualization_utils.cc

PiperOrigin-RevId: 618926813",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 19:37:54,"tensorflow/core/profiler/convert/BUILD, tensorflow/core/profiler/convert/hlo_proto_to_memory_visualization_utils.cc",tensorflower-gardener,False
Update configure.py,mraunak,83710963+mraunak@users.noreply.github.com,2024-03-25 20:08:24,configure.py,mraunak,True
"#tf-data Fix autograppler pattern mismatch for `framework_type` metric.

PiperOrigin-RevId: 618921260",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 19:16:57,tensorflow/core/framework/metrics.cc,tensorflower-gardener,False
"Fix memory budget lower bound computation for the case of solve_nd_sharding_iteratively=true

** Description of the issue
When solve_nd_sharding_iteratively is turned on, say for a 2D mesh [N,M] where N >= M, we would first shard the module across the partial mesh [N,1], and then use these results to prune the search space for sharding the module across the full mesh [N,M]. An artifact of the way we have implemented this is that after sharding the module with the partial mesh, we annotate the module with the computed partial shardings (in the SetHloSharding() function).

Given that we are sharding the devices across a different number of devices each time (N vs N*M), we re-compute the memory budget lower bound (in MemoryBudgetLowerBound()). This function uses pre-existing sharding annotations, if any, on instructions for computing a lower bound on the memory consumed per device. When computing the lower bound for the case of the full mesh, we therefore end up using the partial sharding annotations on the instructions to compute the lower bound, leading to a memory budget that is ~M times larger than it should be.

** Fix
This CL fixes this issue by enforcing that preexisting shardings annotations be used only if they correspond to the same number of devices as the current device mesh.

In some cases, user annotations may not be adjusted for partial meshes. Therefore we skip the above check for instructions with user annotations. If this is found to not affect results, it can be simplified.

PiperOrigin-RevId: 618916013",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 18:58:53,"third_party/xla/xla/hlo/experimental/auto_sharding/BUILD, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.h, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_test.cc",tensorflower-gardener,False
"Add a parameter to BuildHloFromGraph to enable the choice to force the use of `_output_shapes` attribute.

PiperOrigin-RevId: 618913733",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 18:51:25,"tensorflow/compiler/mlir/tf2xla/api/v1/BUILD, tensorflow/compiler/mlir/tf2xla/api/v1/compile_mlir_util.cc, tensorflow/compiler/mlir/tf2xla/api/v1/compile_mlir_util.h, tensorflow/compiler/mlir/tf2xla/api/v1/compile_mlir_util_test.cc, tensorflow/compiler/tf2xla/mlir_xla_op_kernel.cc",tensorflower-gardener,False
"Remove stale todo.

PiperOrigin-RevId: 618912481",Arturo Schmidt,arturoschmidt@google.com,2024-03-25 18:47:38,tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate_registration.cc,rocketas,False
"Add temporary backwards compatibility aliases that forward the old
names (TfLiteRegistrationExternal etc.) to the new names (TfLiteOperator etc.).
These backwards compatibility aliases are needed even though these
names are experimental, because the old names are currently referenced
in MediaPipe, which is in a separate repository, and thus can't be
updated atomically.

PiperOrigin-RevId: 618911115",Fergus Henderson,fergus@google.com,2024-03-25 18:43:34,tensorflow/lite/c/c_api.h,fergushenderson,False
"[xla:gpu][NFC] Rename for consistency

PiperOrigin-RevId: 618904228",Son Tuan Vu,vuson@google.com,2024-03-25 18:23:32,third_party/xla/xla/service/gpu/runtime/address_computation_thunk.cc,tyb0807,False
"[xla:ffi] Add support for passing array attributes

PiperOrigin-RevId: 618896639",Eugene Zhulenev,ezhulenev@google.com,2024-03-25 18:01:09,"third_party/xla/xla/ffi/BUILD, third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/api/ffi_test.cc, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/call_frame.h, third_party/xla/xla/ffi/ffi.h, third_party/xla/xla/ffi/ffi_test.cc",ezhulenev,False
"[XLA:GPU][IndexAnalysis] Implement fusion of indexing maps with RTVars.

PiperOrigin-RevId: 618891650",Alexander Belyaev,pifon@google.com,2024-03-25 17:46:09,"third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc, third_party/xla/xla/service/gpu/model/indexing_map.cc",pifon2a,False
"Delete obsolete block

PiperOrigin-RevId: 618884984",Jake Harmon,jakeharmon@google.com,2024-03-25 17:26:15,third_party/xla/third_party/tsl/README.md,jakeharmon8,False
"[XLA:GPU] Run canonicalizer and CSE after creating Triton module.

PiperOrigin-RevId: 618881884",Oleg Shyshkov,shyshkov@google.com,2024-03-25 17:17:13,"third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton_test.cc",olegshyshkov,False
Update configure.py,mraunak,83710963+mraunak@users.noreply.github.com,2024-03-25 17:42:12,configure.py,mraunak,True
"Remove angerson from workflow reviewers

PiperOrigin-RevId: 618879841",Michael Hudgins,michaelhudgins@google.com,2024-03-25 17:10:46,.github/workflows/update-rbe.yml,MichaelHudgins,False
"[Take 2] Expose .layout on jax.Array. Also add checks in the AOT path to make sure that the input Array's layout matches the layout given to jax.jit.

PiperOrigin-RevId: 618878870",Yash Katariya,yashkatariya@google.com,2024-03-25 17:07:55,"third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_client.pyi",yashk2810,False
"Fix build errors and warnings when building TF with oneDNN v2.x.
- Add missing ENABLE_ONEDNN_V3 guards for oneDNN sparse matmul op since the CSR primitive is only available in oneDNN v3+.
- Add missing header includes and remove unused ones.
- Add missing build dependencies.
- Also fix the years in the copyright header. They were changed in PR #63030. The years shouldn't be changed when the files are updated.

Example error message:
```
In file included from tensorflow/core/kernels/mkl/mkl_batch_matmul_helper.h:25:
tensorflow/core/kernels/mkl/mkl_matmul_ops_common.h:927:38: error: no member named 'csr' in 'dnnl::memory::desc'
  927 |       const auto tmp = memory::desc::csr(
      |                        ~~~~~~~~~~~~~~^
1 error generated.
```

PiperOrigin-RevId: 618874937",Penporn Koanantakool,penporn@google.com,2024-03-25 16:57:33,"tensorflow/core/common_runtime/eager/mkl_eager_op_rewrite.cc, tensorflow/core/common_runtime/mkl_layout_pass.cc, tensorflow/core/graph/mkl_graph_util.h, tensorflow/core/graph/mkl_testlib.cc, tensorflow/core/graph/mkl_testlib.h, tensorflow/core/kernels/mkl/mkl_matmul_ops_common.h, tensorflow/core/kernels/mkl/mkl_sparse_matrix_matmul_op_benchmark.cc, tensorflow/core/ops/BUILD, tensorflow/core/ops/sparse_csr_matrix_ops.cc, tensorflow/core/util/onednn_env_vars.cc, tensorflow/core/util/onednn_env_vars.h",penpornk,False
"Print out a warning if an instruction with misaligned sharding annotations.

PiperOrigin-RevId: 618874284",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 16:55:17,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.h",tensorflower-gardener,False
"[xla:gpu] Use fusion shape instead of hero shape when emit AddressComputationThunk

Supporting DUS in AddressComputationFusion means the fusion shape might be different from the hero custom call shape. Sometimes not the whole tuple returned by the hero custom call op is used, but only the output (e.g. the workspace is ignored for GEMM custom call). As a result, we should emit AddressComputationThunk based on the shape of the fusion instruction and not the one from hero custom call op

PiperOrigin-RevId: 618872694",Son Tuan Vu,vuson@google.com,2024-03-25 16:49:47,"third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/fusions/custom.cc",tyb0807,False
"#shlo_ref Add `xor` op.

PiperOrigin-RevId: 618866356",Quentin Khan,qkhan@google.com,2024-03-25 16:27:47,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/xor.cc, tensorflow/lite/experimental/shlo/ops/xor.h, tensorflow/lite/experimental/shlo/ops/xor_test.cc",qukhan,False
"[xla:ffi] Change scalar attributes ABI and annotate error handling branches with XLA_FFI_PREDICT_FALSE

In preparation for adding dense array attributes change scalar attributes ABI for consistency

Small regression in decoding attributes because of one extra branch.

name                old cpu/op   new cpu/op   delta
BM_BufferBaseArgX1  9.51ns ± 5%  9.10ns ± 5%  -4.29%  (p=0.000 n=20+18)
BM_BufferBaseArgX4  17.4ns ± 7%  16.3ns ± 7%  -6.15%  (p=0.000 n=19+20)
BM_BufferArgX1      10.8ns ±11%  11.4ns ±15%  +5.86%  (p=0.010 n=20+20)
BM_BufferArgX4      19.3ns ± 8%  18.5ns ± 4%  -3.99%  (p=0.000 n=20+20)
BM_TupleOfI32Attrs  56.5ns ± 3%  60.9ns ± 3%  +7.90%  (p=0.000 n=20+20)

BM_BufferArgX1 regression looks like noise

PiperOrigin-RevId: 618857817",Eugene Zhulenev,ezhulenev@google.com,2024-03-25 15:58:45,"third_party/xla/xla/ffi/api/api.h, third_party/xla/xla/ffi/api/c_api.h, third_party/xla/xla/ffi/api/ffi.h, third_party/xla/xla/ffi/call_frame.cc, third_party/xla/xla/ffi/call_frame.h, third_party/xla/xla/ffi/ffi.h",ezhulenev,False
"#shlo_ref Add `or` op.

PiperOrigin-RevId: 618837226",Quentin Khan,qkhan@google.com,2024-03-25 14:39:47,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/or.cc, tensorflow/lite/experimental/shlo/ops/or.h, tensorflow/lite/experimental/shlo/ops/or_test.cc",qukhan,False
"#shlo_ref Add `and` op.

PiperOrigin-RevId: 618834802",Quentin Khan,qkhan@google.com,2024-03-25 14:29:30,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/and.cc, tensorflow/lite/experimental/shlo/ops/and.h, tensorflow/lite/experimental/shlo/ops/and_test.cc",qukhan,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/968eb3e5b0aa2e20301a41af9bb14a48dd1aee40.

PiperOrigin-RevId: 618832399",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 14:19:37,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"#shlo_ref Add `subtract` op.

PiperOrigin-RevId: 618832074",Quentin Khan,qkhan@google.com,2024-03-25 14:18:13,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/subtract.cc, tensorflow/lite/experimental/shlo/ops/subtract.h, tensorflow/lite/experimental/shlo/ops/subtract_test.cc",qukhan,False
"#shlo_ref Add `divide` op.

PiperOrigin-RevId: 618830161",Quentin Khan,qkhan@google.com,2024-03-25 14:09:39,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/divide.cc, tensorflow/lite/experimental/shlo/ops/divide.h, tensorflow/lite/experimental/shlo/ops/divide_test.cc",qukhan,False
"#shlo_ref Small fixes to `test_util.h`

- Add comments describing the test helpers.
- Rename Distribution to UniformDistribution.
- Make RandomBuffer's distribution configurable.
- Improve IotaBuffer's usability.
- Fix IotaBuffer's behaviour.

PiperOrigin-RevId: 618827551",Quentin Khan,qkhan@google.com,2024-03-25 13:58:22,tensorflow/lite/experimental/shlo/ops/test_util.h,qukhan,False
"Integrate LLVM at llvm/llvm-project@7ac7d418ac2b

Updates LLVM usage to match
[7ac7d418ac2b](https://github.com/llvm/llvm-project/commit/7ac7d418ac2b)

PiperOrigin-RevId: 618825418",Dmitri Gribenko,dmitrig@google.com,2024-03-25 13:47:34,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",gribozavr,False
"Automated Code Change

PiperOrigin-RevId: 618801338",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 11:39:58,"tensorflow/core/grappler/inputs/BUILD, tensorflow/core/grappler/inputs/file_input_yielder.cc, tensorflow/core/grappler/inputs/trivial_test_graph_input_yielder.cc, tensorflow/core/grappler/inputs/utils.cc, tensorflow/core/grappler/inputs/utils.h, tensorflow/core/grappler/inputs/utils_test.cc",tensorflower-gardener,False
"[XLA:GPU] Remove unused RTVars when calling RemoveUnusedSymbols.

PiperOrigin-RevId: 618799014",Alexander Belyaev,pifon@google.com,2024-03-25 11:27:00,"third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",pifon2a,False
"Add version checks to FindCudaExecutable

Currently we look for ptxas and nvlink in a few different places on the host machine, then we choose the first found binary without taking its version into account. If the chosen binary doesn't fulfill our version requirements we will later fail even if there was a suitable ptxas or nvlink in the search path in the first place.

This change makes it take the version of each binary into account when going through the search path. Unsuitable binaries will be discarded right away and the search continues until we are out of locations to check.

This should help with host environments that have multiple CUDA toolkits installed and should make ptxas and nvlink selection more robust.

The concreate changes:

1. `FindCudaExecutable` now also takes a minimum version and a list of forbidden (think buggy) versions that are supposed to be skipped.
2. `WarnIfBadPtxAsVersion` has been removed. It was checking for ptxas < 11.1 which is way older than our minimum supported version of 11.8 and was not doing anything given the check described in #3.
3. There was another version check for `ptxas` in `NVPTXCompiler::ChooseLinkingMethod` which was checking for `version(ptxas)` < 11.8. This has also been removed/replace by the version check described in #4.
4. Version checking for `ptxas` and `nvlink` has been consolidated into 2 methods `FindPtxAsExectuable` and `FindNvLinkExecutable`. These methods hard code the current minimum version (and the list of excluded versions) of each tool in one place. It's still not great but at least less spaghetti-like.

PiperOrigin-RevId: 618797392",Henning Becker,hebecker@google.com,2024-03-25 11:18:18,"third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/stream_executor/cuda/BUILD, third_party/xla/xla/stream_executor/cuda/cuda_asm_compiler.cc, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/asm_compiler.cc, third_party/xla/xla/stream_executor/gpu/asm_compiler.h",beckerhe,False
"Consistently handle algorithm selection in GemmAlgorithmPicker

PiperOrigin-RevId: 618789520",Henning Becker,hebecker@google.com,2024-03-25 10:39:02,third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc,beckerhe,False
"[XLA:GPU] Implement TiledHloInstruction graph in SymbolicTileAnalysis.

SymbolicTileAnalysis create a new tiled HLO node for each unique (HLO instruction, indexing map) pair. Tiled instructions are stored in def-before-use order for easier access.

This representation makes it easier to write codegen, because each instruction knows about it's operands and we can efficiently cache emitter values. Those also allows to do some degree of CSE, but it can be CSEd more for concrete tile sizes.

PiperOrigin-RevId: 618788735",Oleg Shyshkov,shyshkov@google.com,2024-03-25 10:36:21,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc",olegshyshkov,False
"Implement deferring `stablehlo.transpose` ops for the input of `stablehlo.reduce_window` op with `maximum` reduce function.

Implements a pattern `RewriteMaxPoolReduceWindowOpWithActivationTranspose`. This pattern defers `stablehlo.transpose` op from the input to the result of `stablehlo.reduce_window` op. The `reduce_window`'s reduction function should be semantically equivalent to a `stablehlo.maximum`, which represents a max pool operation.

PiperOrigin-RevId: 618788424",Dan Suh,dansuh@google.com,2024-03-25 10:34:56,"tensorflow/compiler/mlir/quantization/common/attrs_and_constraints.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/defer_activation_transpose.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/defer_activation_transpose.mlir, tensorflow/compiler/mlir/quantization/stablehlo/tests/pipelines/process_nchw_tensor.mlir",dansuh17,False
"Add support for symbol rescaling to the indexing map

Rescaling allows symbols that are constrained by a modulus expression:

```
s_k mod C = [N, N]
```

to be replaced by:

```
s_k -> C * s_k + N
```

PiperOrigin-RevId: 618786490",Henning Becker,hebecker@google.com,2024-03-25 10:26:41,"third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",beckerhe,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/b182e75065369d1eea499fe1d08b6c57d03da2ab.

PiperOrigin-RevId: 618784568",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 10:15:57,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Expand StableHLO Quantizer presets for the ODML entrypoint.

The expanded StableHLO Quantizer currently does not have any visible change of behavior as the current expansion is not used downstream, but it will be used by features to be introduced.

PiperOrigin-RevId: 618781102",Dan Suh,dansuh@google.com,2024-03-25 10:00:42,"tensorflow/compiler/mlir/lite/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/lite/quantization/stablehlo/quantization.cc",dansuh17,False
"[xla:gpu] multi_output_fusion_test: drop dependency on gunit

PiperOrigin-RevId: 618774780",Emilio Cota,ecg@google.com,2024-03-25 09:28:23,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/multi_output_fusion_test.cc",cota,False
"compat: Update forward compatibility horizon to 2024-03-25

PiperOrigin-RevId: 618769534",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 09:03:46,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Update GraphDef version to 1812.

PiperOrigin-RevId: 618769038",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 09:02:05,tensorflow/core/public/version.h,tensorflower-gardener,False
"Refactor patterns in `quantize_patterns.cc` depending on compute-heaviness.

* Implemented and added tests for `GetElementType`, and had minor cleanups.
* Refactor singular op patterns into `QuantizeSingularOpPattern`, excluding unnecessary requantize for singular ops with qi8 output.

PiperOrigin-RevId: 618738661",Jiyoun (Jen) Ha,jiyounha@google.com,2024-03-25 06:21:22,"tensorflow/compiler/mlir/quantization/common/attrs_and_constraints_test.cc, tensorflow/compiler/mlir/quantization/common/uniform_quantized_types.h, tensorflow/compiler/mlir/quantization/common/uniform_quantized_types_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantization_patterns.h, tensorflow/compiler/mlir/quantization/stablehlo/passes/quantize.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/quantize_composite_functions.mlir",chococigar,False
"Implement `GetQuantizationMethodOrDefault`.

This is similar to `GetQuantizationMethod`, but returns a default instance of `Method` when there is no quantization method attribute instead of returning a non-ok `Status`.
This allows to avoid one extra level of indirection from checking the `Status`.

PiperOrigin-RevId: 618735895",Dan Suh,dansuh@google.com,2024-03-25 06:03:49,"tensorflow/compiler/mlir/quantization/common/BUILD, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.cc, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.h, tensorflow/compiler/mlir/quantization/common/lift_as_function_call_test.cc, tensorflow/compiler/mlir/quantization/common/test_base.h",dansuh17,False
"Set `SetSingleLineMode` to `true` to embed `Method` textprotos in a single line.

Previous implementation manually removed `\n` symbols, which resulted in some verbosity where extra whitespaces are included.
Use `SetSingleLineMode` API to achieve the same, but resulting in a more compact string representation.

PiperOrigin-RevId: 618719668",Dan Suh,dansuh@google.com,2024-03-25 04:24:54,"tensorflow/compiler/mlir/quantization/stablehlo/passes/lift_quantizable_spots_as_functions.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/passes/lift_quantizable_spots_as_functions_with_quantization_specs.mlir",dansuh17,False
"Automated Code Change

PiperOrigin-RevId: 618696528",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-25 01:42:02,"tensorflow/compiler/mlir/lite/metrics/BUILD, tensorflow/compiler/mlir/lite/metrics/error_collector_inst.cc, tensorflow/compiler/mlir/lite/metrics/error_collector_inst.h, tensorflow/compiler/mlir/lite/metrics/error_collector_inst_test.cc, tensorflow/compiler/mlir/lite/metrics/types_util.cc",tensorflower-gardener,False
"Add a function to determine whether an op is inside a StableHLO op with `Region`.

This will be used for filtering target lift patterns in `TableGen` file.

Additionally, this CL does the following:
* Use the `Operation*` than reference-by-value for consistency with MLIR norm.
* Adds additional tests for `IsStablehlOp`.

PiperOrigin-RevId: 618686954",Jiyoun (Jen) Ha,jiyounha@google.com,2024-03-25 00:24:25,"tensorflow/compiler/mlir/quantization/common/BUILD, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.cc, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.h, tensorflow/compiler/mlir/quantization/common/lift_as_function_call.td, tensorflow/compiler/mlir/quantization/common/lift_as_function_call_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/utils/stablehlo_type_utils_test.cc",chococigar,False
"[xla:tpu] Allow host offloading ops to pass hlo verification when changing layout.

Host offloading ops (dynamic slice, copy, and dynamic update slice) move tensors between device memory and host memory space. This can cause the hlo verifier to fail as it interprets this layout to be unequal. This change allows for memory space to be ignored when comparing layouts for these ops.

PiperOrigin-RevId: 618677446",Jackson Stokes,jacksonstokes@google.com,2024-03-24 23:04:13,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/service/hlo_verifier_test.cc",jvstokes,False
"Automated Code Change

PiperOrigin-RevId: 618671497",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-24 22:14:43,tensorflow/python/client/BUILD,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618656675",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-24 20:00:44,"tensorflow/c/experimental/filesystem/plugins/posix/BUILD, tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem.cc, tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem_static.cc",tensorflower-gardener,False
"Update GraphDef version to 1811.

PiperOrigin-RevId: 618579478",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-24 09:02:13,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-03-24

PiperOrigin-RevId: 618579417",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-24 09:01:55,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618568619",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-24 07:37:45,"tensorflow/compiler/mlir/quantization/tensorflow/ops/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/ops/tf_op_quant_spec.cc, tensorflow/compiler/mlir/quantization/tensorflow/ops/tf_quantize_op.h, tensorflow/compiler/mlir/quantization/tensorflow/ops/uniform_op_quant_spec.cc",tensorflower-gardener,False
"Open source IdentityPropogation pass

PiperOrigin-RevId: 618508615",Deqiang Chen,deqiangc@google.com,2024-03-23 23:27:00,"tensorflow/compiler/mlir/tfrt/tests/ifrt/tf_identity_propagation.mlir, tensorflow/compiler/mlir/tfrt/transforms/ifrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/ifrt/passes.td, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf_identity_propagation.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf_ifrt_passes.cc, tensorflow/compiler/mlir/tfrt/transforms/ifrt/tf_ifrt_passes.h",deqiangc,False
"Convert absl::string_view to std::string before calling ParseFromString()

The OSS version of ParseFromString() does not accept absl::string_view yet.

PiperOrigin-RevId: 618501554",Kuangyuan Chen,chky@google.com,2024-03-23 22:23:54,tensorflow/core/tfrt/mlrt/kernel/kernel.cc,cky9301,False
"[XLA:Runtime] Moved the nccl_collective_broadcast thunk to new folder and removed unused dependencies.Updated the necessary directories pointing to this thunk and removed it from the nccl_collectives_thunks build and removed the nccl_collectives_thunk target as all the remaining thunks have been moved out. #5758

PiperOrigin-RevId: 618491660",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 20:50:42,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/ir_emitter_context.h, third_party/xla/xla/service/gpu/ir_emitter_unnested.cc, third_party/xla/xla/service/gpu/mock_nccl_utils.cc, third_party/xla/xla/service/gpu/mock_nccl_utils.h, third_party/xla/xla/service/gpu/mock_nccl_utils_default.cc, third_party/xla/xla/service/gpu/runtime/BUILD, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.cc, third_party/xla/xla/service/gpu/runtime/command_buffer_cmd.h, third_party/xla/xla/service/gpu/runtime/nccl_all_gather_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_all_gather_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_all_reduce_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_all_reduce_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_all_to_all_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_all_to_all_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_broadcast_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_permute_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_collective_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_p2p_thunk_common.h, third_party/xla/xla/service/gpu/runtime/nccl_recv_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_recv_thunk.h, third_party/xla/xla/service/gpu/runtime/nccl_send_thunk.cc, third_party/xla/xla/service/gpu/runtime/nccl_send_thunk.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618447348",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 14:30:02,"third_party/xla/xla/client/local_client.cc, third_party/xla/xla/client/local_client.h, third_party/xla/xla/client/value_inference.cc, third_party/xla/xla/client/value_inference.h, third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder.h, third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/client/xla_computation.cc, third_party/xla/xla/client/xla_computation.h",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618445781",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 14:14:11,"third_party/xla/xla/service/memory_space_assignment/best_fit_repacker.cc, third_party/xla/xla/service/memory_space_assignment/best_fit_repacker.h, third_party/xla/xla/service/memory_space_assignment/cost_analysis.cc, third_party/xla/xla/service/memory_space_assignment/cost_analysis.h, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.h, third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc, third_party/xla/xla/service/memory_space_assignment/repacking.h, third_party/xla/xla/service/memory_space_assignment/slice.h, third_party/xla/xla/service/memory_space_assignment/testing_utils.h",tensorflower-gardener,False
"[XLA:GPU] Remove special pretty printing for symbolic tiles.

Now that the parameters represent only sizes, there is no ambiguity as to
what they represent. Furthermore, this pretty printing is not applied
automatically everywhere, making error messages sometimes inconsistent.

PiperOrigin-RevId: 618432739",Benjamin Chetioui,bchetioui@google.com,2024-03-23 12:19:33,"third_party/xla/xla/service/gpu/model/tile_analysis.cc, third_party/xla/xla/service/gpu/model/tile_analysis.h, third_party/xla/xla/service/gpu/model/tile_analysis_test.cc",bchetioui,False
"Optimize XLA Compiler.

This results in 2% improvement on some representative large model compilation benchmarks.

1. `MayUseOperandValue(position.index, user)`, `(user->IsRoot() && root_positions.contains(user)` is computed once per <position, user> instead of once per <position, user, operand>. We don't need to pass `i` to `MayUseOperandValue`. We can instead bring the `CHECK` out at the call site.
2. Use `emplace_back` instead of `push_back` and `std::move`. Why: https://godbolt.org/z/sT54Ef88h

PiperOrigin-RevId: 618429256",Shahriar Rouf,nafi@google.com,2024-03-23 11:52:36,"third_party/xla/xla/service/hlo_value.cc, third_party/xla/xla/service/hlo_value.h",nafi3000,False
"Automated Code Change

PiperOrigin-RevId: 618418197",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 10:27:45,"third_party/xla/xla/translate/mhlo_to_hlo/attribute_exporter.cc, third_party/xla/xla/translate/mhlo_to_hlo/attribute_exporter.h, third_party/xla/xla/translate/mhlo_to_hlo/layout_util.cc, third_party/xla/xla/translate/mhlo_to_hlo/layout_util.h, third_party/xla/xla/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc, third_party/xla/xla/translate/mhlo_to_hlo/translate.cc, third_party/xla/xla/translate/mhlo_to_hlo/type_to_shape_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618412188",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 09:46:05,"third_party/xla/xla/shape_util.cc, third_party/xla/xla/shape_util.h, third_party/xla/xla/shape_util_test.cc, third_party/xla/xla/status_macros_test.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618411919",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 09:44:19,third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc,tensorflower-gardener,False
"Update GraphDef version to 1810.

PiperOrigin-RevId: 618405120",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 09:02:10,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-03-23

PiperOrigin-RevId: 618405038",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 09:01:50,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618403903",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 08:54:20,"tensorflow/core/common_runtime/node_file_writer.cc, tensorflow/core/common_runtime/node_file_writer.h, tensorflow/core/common_runtime/optimize_cross_host_control_deps.cc, tensorflow/core/common_runtime/optimize_function_graph_utils.cc, tensorflow/core/common_runtime/optimize_function_graph_utils.h, tensorflow/core/common_runtime/optimize_function_graph_utils_test.cc, tensorflow/core/common_runtime/optimized_function_graph_info.cc, tensorflow/core/common_runtime/optimized_function_graph_info.h, tensorflow/core/common_runtime/optimized_function_graph_info_test.cc, tensorflow/core/common_runtime/partitioning_utils.cc, tensorflow/core/common_runtime/partitioning_utils.h, tensorflow/core/common_runtime/process_function_library_runtime.cc, tensorflow/core/common_runtime/type_inference.cc",tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618378402",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 06:08:21,tensorflow/core/profiler/convert/op_stats_to_tf_stats_test.cc,tensorflower-gardener,False
"Automated Code Change

PiperOrigin-RevId: 618378151",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 06:06:34,"tensorflow/core/profiler/convert/op_stats_to_overview_page.cc, tensorflow/core/profiler/convert/op_stats_to_tf_stats.cc",tensorflower-gardener,False
"[xla:gpu] dot_merger: reorder merge checks to call IsReachableNonConst last

Only perform the reachability check if necessary, since it can be expensive.

This brings a 1.5x compilation time speedup for a large, dense model.

PiperOrigin-RevId: 618355183",Emilio Cota,ecg@google.com,2024-03-23 03:13:24,third_party/xla/xla/service/dot_merger.cc,cota,False
"graphcycles: extract NodeIO out of Node

To improve cache locality when doing DFS.

name                          old time/op  new time/op  delta
BM_StressTest/2048             492ns ± 2%   470ns ± 1%   -4.38%  (p=0.008 n=5+5)
BM_StressTest/4096             499ns ± 2%   478ns ± 1%   -4.07%  (p=0.008 n=5+5)
BM_StressTest/32768            512ns ± 2%   494ns ± 1%   -3.52%  (p=0.016 n=5+4)
BM_StressTest/262144           558ns ± 2%   537ns ± 1%   -3.77%  (p=0.016 n=5+4)
BM_StressTest/1048576          621ns ± 2%   692ns ±23%     ~     (p=0.690 n=5+5)
BM_ContractEdge/1000           104ns ± 2%   106ns ± 5%     ~     (p=0.286 n=5+4)
BM_ContractEdge/10000          119ns ± 2%   119ns ± 1%     ~     (p=0.651 n=5+5)
BM_IsReachableNonConst/10     9.76ns ±10%  9.17ns ±12%     ~     (p=0.095 n=5+5)
BM_IsReachableNonConst/50     15.4ns ±11%  13.6ns ± 5%  -11.41%  (p=0.032 n=5+5)
BM_IsReachableNonConst/100    17.5ns ±13%  15.3ns ± 7%  -12.66%  (p=0.032 n=5+5)
BM_IsReachableNonConst/200    20.1ns ± 7%  18.1ns ± 9%   -9.71%  (p=0.016 n=5+5)
BM_IsReachableNonConst/1000   25.5ns ± 5%  22.7ns ± 3%  -10.98%  (p=0.008 n=5+5)
BM_IsReachableNonConst/30000  45.0ns ± 3%  39.2ns ± 3%  -12.95%  (p=0.008 n=5+5)

PiperOrigin-RevId: 618348701",Emilio Cota,ecg@google.com,2024-03-23 02:34:23,third_party/xla/xla/service/graphcycles/graphcycles.cc,cota,False
"#tf-data Re-use `GlobalShuffleIterator` for the Bag dataset.

Added an `AnyContext` class for use cases that need to pass
in either an `OpKernelContext` or `IteratorContext`.

For the `BagDataset::Get`, it needs to access `ctx.allocator`
from either `OpKernelContext` or `IteratorContext`.

PiperOrigin-RevId: 618331917",Yang Chen,yangchen@google.com,2024-03-23 00:47:58,"tensorflow/core/data/dataset_utils.cc, tensorflow/core/data/dataset_utils.h, tensorflow/core/data/global_shuffle_utils.cc, tensorflow/core/framework/dataset.cc, tensorflow/core/framework/dataset.h, tensorflow/core/kernels/data/batch_dataset_op.cc, tensorflow/core/kernels/data/experimental/list_dataset_op.cc, tensorflow/core/kernels/data/parallel_batch_dataset_op.cc, tensorflow/core/kernels/data/range_dataset_op.cc, tensorflow/core/kernels/data/tensor_dataset_op.cc, tensorflow/core/kernels/data/tensor_slice_dataset_op.cc",yangustc07,False
"Fix a bug in the pattern to fuse reshape around batch matmul.

FuseReshapesAroundBatchMatMulLHS1 pattern to apply only when higher shaped LHS is being reshaped. Added a missing check to make sure the LHS shape. is greated than 3.

PiperOrigin-RevId: 618323430",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-23 00:02:06,"tensorflow/compiler/mlir/lite/tests/optimize.mlir, tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td",tensorflower-gardener,False
"#tf-data Do not skip in the global shuffling mode.

PiperOrigin-RevId: 618322598",Yang Chen,yangchen@google.com,2024-03-22 23:58:11,tensorflow/core/kernels/data/skip_dataset_op.cc,yangustc07,False
"#tf-data Support global shuffle for the from_list dataset.

PiperOrigin-RevId: 618310825",Yang Chen,yangchen@google.com,2024-03-22 23:00:25,"tensorflow/core/kernels/data/experimental/BUILD, tensorflow/core/kernels/data/experimental/list_dataset_op.cc, tensorflow/python/data/experimental/kernel_tests/BUILD, tensorflow/python/data/experimental/kernel_tests/from_list_test.py",yangustc07,False
"[XLA:GPU][TileAnalysis] Re-think symbolic tiles and their parameter extraction.

Previously, symbolic tiles could take offsets and strides as input parameters.
While there is a use for it at codegen time (e.g. to use the symbolic tile to
directly produce the overall offset for loading a parameter, and similarly for
the strides), the benefit is marginal. However, it turns out to be highly
problematic for more important use cases, such as concrete size propagation;
indeed, a combination of a non-trivial reshape with an unknown stride gives
rise to stride-dependent sizes---thus completely preventing concrete size
propagation until a constant stride is chosen.

If we need to choose a constant stride anyway, then there is no use in carrying
around this parameter. There is likely no such problem with offsets, but we
likewise elide them from the list of input parameters in order to simplify
things.

We take this opportunity to simplify our extraction logic as well, and
implement logic able to handle merge reshapes correctly. Thanks to
the simplification of the structure of symbolic tiles, we can now make stronger
assumptions about our intermediate expressions (e.g. where constants appear),
and as a result the logic is much easier to follow.

PiperOrigin-RevId: 618308540",Benjamin Chetioui,bchetioui@google.com,2024-03-22 22:49:55,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc, third_party/xla/xla/service/gpu/model/tile_analysis.cc, third_party/xla/xla/service/gpu/model/tile_analysis.h, third_party/xla/xla/service/gpu/model/tile_analysis_test.cc",bchetioui,False
"Pass ModuleOp directly from pre-calibration to post-calibration

This will avoid saving calibrated model as well as loading it.

PiperOrigin-RevId: 618298618",Thai Nguyen,thaink@google.com,2024-03-22 22:08:39,"tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/component.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/statistics.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/calibration/statistics.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/debugger.cc, tensorflow/compiler/mlir/quantization/stablehlo/cc/debugger.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/pass_pipeline.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/add_dump_tensor_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_quantize_model.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.cc, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.h, tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.py, tensorflow/compiler/mlir/quantization/tensorflow/python/representative_dataset.py, tensorflow/compiler/mlir/quantization/tensorflow/tests/add_dump_tensor_op.mlir, tensorflow/compiler/mlir/quantization/tensorflow/tests/add_dump_tensor_op_stablehlo.mlir, tensorflow/tools/api/golden/v1/tensorflow.quantization.experimental.-tf-record-representative-dataset-saver.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.quantization.experimental.-tf-record-representative-dataset-saver.pbtxt, tensorflow/tools/def_file_filter/symbols_pybind.txt, third_party/xla/third_party/tsl/tools/def_file_filter/symbols_pybind.txt",thaink,False
"Fix the comment for an Env. It is currently full of lies.

PiperOrigin-RevId: 618291265",Martin Wicke,wicke@google.com,2024-03-22 21:40:31,third_party/xla/third_party/tsl/tsl/platform/env.h,martinwicke,False
"Add unbounded dynamism test for OrOp.

PiperOrigin-RevId: 618287342",Gunhyun Park,gunhyun@google.com,2024-03-22 21:25:29,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"[xla:gpu] Support dynamic slices for AddressComputationFusionRewriter

PiperOrigin-RevId: 618279032",Son Tuan Vu,vuson@google.com,2024-03-22 20:55:52,"third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc, third_party/xla/xla/service/gpu/address_computation_fusion_rewriter_test.cc",tyb0807,False
"[XLA:GPU] Remove IndexingContext.

PiperOrigin-RevId: 618278599",Alexander Belyaev,pifon@google.com,2024-03-22 20:54:02,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/concatenate.cc, third_party/xla/xla/service/gpu/fusions/concatenate.h, third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/concatenate_mlir.h, third_party/xla/xla/service/gpu/fusions/fusion_emitter.cc, third_party/xla/xla/service/gpu/fusions/fusion_emitter.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/input_slices.cc, third_party/xla/xla/service/gpu/fusions/input_slices.h, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.cc, third_party/xla/xla/service/gpu/fusions/input_slices_mlir.h, third_party/xla/xla/service/gpu/fusions/input_slices_test.cc, third_party/xla/xla/service/gpu/fusions/loop.cc, third_party/xla/xla/service/gpu/fusions/loop.h, third_party/xla/xla/service/gpu/fusions/loop_mlir.cc, third_party/xla/xla/service/gpu/fusions/loop_mlir.h, third_party/xla/xla/service/gpu/fusions/loop_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/loop_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter.h, third_party/xla/xla/service/gpu/fusions/mlir/mlir_fusion_emitter_test.cc, third_party/xla/xla/service/gpu/fusions/mlir/simplify_affine.cc, third_party/xla/xla/service/gpu/fusions/mlir_emitter_test_base.cc, third_party/xla/xla/service/gpu/fusions/mlir_emitter_test_base.h, third_party/xla/xla/service/gpu/fusions/reduction_base.cc, third_party/xla/xla/service/gpu/fusions/reduction_base.h, third_party/xla/xla/service/gpu/fusions/reduction_base_test.cc, third_party/xla/xla/service/gpu/fusions/reduction_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter.h, third_party/xla/xla/service/gpu/fusions/scatter_mlir.cc, third_party/xla/xla/service/gpu/fusions/scatter_mlir.h, third_party/xla/xla/service/gpu/fusions/scatter_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/transpose.cc, third_party/xla/xla/service/gpu/fusions/transpose.h, third_party/xla/xla/service/gpu/fusions/transpose_mlir.cc, third_party/xla/xla/service/gpu/fusions/transpose_mlir.h, third_party/xla/xla/service/gpu/fusions/transpose_mlir_test.cc, third_party/xla/xla/service/gpu/fusions/transpose_test.cc, third_party/xla/xla/service/gpu/ir_emitter_context.h, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/coalescing_analysis.cc, third_party/xla/xla/service/gpu/model/coalescing_analysis.h, third_party/xla/xla/service/gpu/model/coalescing_analysis_test.cc, third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.cc, third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.h, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.h, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc, third_party/xla/xla/service/gpu/model/indexing_test_utils.cc, third_party/xla/xla/service/gpu/model/indexing_test_utils.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc, third_party/xla/xla/service/gpu/model/tile_analysis.cc",pifon2a,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/5c38721c44d1366b675e38651c4c1cc885054f7b.

PiperOrigin-RevId: 618277026",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 20:47:51,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Use the appropriate operand sharding when computing resharding costs for HLO ops when a new ShardingStrategy is generated for n op based on a user annotation.

PiperOrigin-RevId: 618269975",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 20:20:56,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_test.cc",tensorflower-gardener,False
"[XLA:GPU] Fix possible bug in libdevice path logic.

* When copying a C string, we need to include the null terminator byte. It seems likely this code reads off the end of the array since it only copies non-null bytes. But if we use a std::string it will handle this for us.
* dirname() may not be thread-safe. On Linux it likely is, but better to avoid it and just use the TSL utility for this.

This may be the cause of a flaky test failure in JAX CI.

PiperOrigin-RevId: 618267961",Peter Hawkins,phawkins@google.com,2024-03-22 20:12:57,third_party/xla/third_party/tsl/tsl/platform/default/cuda_libdevice_path.cc,hawkinsp,False
"[xla:gpu] Factor out AddressComputationFusionRewriter::Run to handle dynamic slices

PiperOrigin-RevId: 618267336",Son Tuan Vu,vuson@google.com,2024-03-22 20:10:53,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc,tyb0807,False
"Enable more warnings for XLA

PiperOrigin-RevId: 618259828",David Dunleavy,ddunleavy@google.com,2024-03-22 19:40:59,".bazelrc, third_party/xla/.bazelrc, third_party/xla/.kokoro/linux/build.sh, third_party/xla/third_party/tsl/.bazelrc, third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/sharding_propagation_test.cc, third_party/xla/xla/service/spmd/spmd_partitioner_util.h",ddunl,False
"Migrate direct callers of options().packed() to is_packed() helper.

PiperOrigin-RevId: 618254593",Mike Kruskal,mkruskal@google.com,2024-03-22 19:21:04,tensorflow/core/kernels/encode_proto_op.cc,mkruskal-google,False
"Add public visibility for tensorflow protobuf BUILD targets ""for_core_protos"".

PiperOrigin-RevId: 618251933",Eric Yang,yijieyang@google.com,2024-03-22 19:10:41,tensorflow/core/protobuf/BUILD,yijie-yang,False
"Implement pass to convert custom calls to composites

PiperOrigin-RevId: 618249745",Michael Levesque-Dion,mlevesquedion@google.com,2024-03-22 19:03:15,"tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/tests/stablehlo-custom-call-legalize-composite.mlir, tensorflow/compiler/mlir/lite/stablehlo/transforms/legalize_stablehlo_custom_call_to_composite.cc, tensorflow/compiler/mlir/lite/stablehlo/transforms/passes.h, tensorflow/compiler/mlir/lite/stablehlo/transforms/passes.td, tensorflow/compiler/mlir/lite/tf_tfl_passes.cc",mlevesquedion,False
"[XLA:GPU] [NFC] Switch DynCast to Cast

The pointer is dereferenced later anyway, DynCast is just hiding bugs.

PiperOrigin-RevId: 618244837",George Karpenkov,cheshire@google.com,2024-03-22 18:46:31,third_party/xla/xla/service/gpu/gpu_hlo_schedule.cc,cheshire,False
"[XLA:GPU][NFC] Remove unused variable

PiperOrigin-RevId: 618243919",Son Tuan Vu,vuson@google.com,2024-03-22 18:43:30,third_party/xla/xla/service/gpu/hlo_traversal_test.cc,tyb0807,False
"Temporarily comment @fused_batchnorm_no_training() as it breaks the msan check.

PiperOrigin-RevId: 618241782",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 18:36:38,"tensorflow/compiler/mlir/lite/stablehlo/transforms/fold_broadcast_pass.cc, tensorflow/compiler/mlir/quantization/stablehlo/tests/components/tf_to_stablehlo.mlir",tensorflower-gardener,False
"Merge pull request #62817 from Intel-tensorflow:gaurides/amp_fp16

PiperOrigin-RevId: 618237841",TensorFlower Gardener,gardener@tensorflow.org,2024-03-22 18:57:18,"tensorflow/core/grappler/optimizers/auto_mixed_precision.cc, tensorflow/core/grappler/optimizers/auto_mixed_precision.h, tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h, tensorflow/core/grappler/optimizers/auto_mixed_precision_test.cc, tensorflow/core/grappler/optimizers/meta_optimizer.cc, tensorflow/core/protobuf/rewriter_config.proto, tensorflow/python/framework/config.py",tensorflower-gardener,False
"Removes the deprecated build_pip_package.sh script.

PiperOrigin-RevId: 618222286",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 17:35:59,"tensorflow/opensource_only.files, tensorflow/tools/pip_package/build_pip_package.sh",tensorflower-gardener,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/29bfd29cf353020006fa20ec0a41062ff699678d.

PiperOrigin-RevId: 618222196",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 17:35:44,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"[XLA:GPU][NFC] Cosmetic and safety fixes to symbolic tile analysis code.

PiperOrigin-RevId: 618219557",Benjamin Chetioui,bchetioui@google.com,2024-03-22 17:27:43,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc",bchetioui,False
"#shlo_ref Add `multiply` op and binary element-wise test utils.

PiperOrigin-RevId: 618215004",Quentin Khan,qkhan@google.com,2024-03-22 17:12:49,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/binary_elementwise_test_util.h, tensorflow/lite/experimental/shlo/ops/multiply.cc, tensorflow/lite/experimental/shlo/ops/multiply.h, tensorflow/lite/experimental/shlo/ops/multiply_test.cc, tensorflow/lite/experimental/shlo/ops/test_util.h, tensorflow/lite/experimental/shlo/ops/util.cc, tensorflow/lite/experimental/shlo/ops/util.h",qukhan,False
"Relocate the graph executor mode metric.

PiperOrigin-RevId: 618210183",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 16:58:47,"tensorflow/core/tfrt/graph_executor/graph_executor.cc, tensorflow/core/tfrt/saved_model/BUILD, tensorflow/core/tfrt/saved_model/saved_model.cc",tensorflower-gardener,False
"Integrate LLVM at llvm/llvm-project@6f44bb771789

Updates LLVM usage to match
[6f44bb771789](https://github.com/llvm/llvm-project/commit/6f44bb771789)

PiperOrigin-RevId: 618207998",Augie Fackler,augie@google.com,2024-03-22 16:51:14,third_party/llvm/workspace.bzl,durin42,False
"#shlo_ref Move helpers that are shared between unary and binary element-wise tests to test_util.

PiperOrigin-RevId: 618206610",Quentin Khan,qkhan@google.com,2024-03-22 16:45:58,"tensorflow/lite/experimental/shlo/ops/test_util.h, tensorflow/lite/experimental/shlo/ops/unary_elementwise_test_util.h",qukhan,False
"#shlo_ref Add a helper for binary elementwise ops.

PiperOrigin-RevId: 618203876",Quentin Khan,qkhan@google.com,2024-03-22 16:35:02,"tensorflow/lite/experimental/shlo/ops/BUILD, tensorflow/lite/experimental/shlo/ops/binary_elementwise.h, tensorflow/lite/experimental/shlo/ops/binary_elementwise_test.cc",qukhan,False
"[XLA:GPU][NFC] Fix style in in_place_dynamic_update_slice_mlir.cc for consistency

PiperOrigin-RevId: 618199494",Son Tuan Vu,vuson@google.com,2024-03-22 16:19:42,third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc,tyb0807,False
"#tf-data To help debugging, output the autotuned `max_outstanding_requests` in xprof.

PiperOrigin-RevId: 618198886",Wilsin Gosti,wilsin@google.com,2024-03-22 16:17:23,tensorflow/core/data/service/client/data_service_client.cc,wilsingosti,False
"graphcycles: keep nodes in a vector + move user_data out of it

This improves cache locality.

Note that user_data currently has no callers, so accessing it
quickly is not something we want to optimize for.

name                          old time/op  new time/op  delta
BM_StressTest/2048             474ns ± 1%   492ns ± 1%   +3.63%  (p=0.008 n=5+5)
BM_StressTest/4096             490ns ± 1%   497ns ± 1%   +1.52%  (p=0.008 n=5+5)
BM_StressTest/32768            504ns ± 1%   508ns ± 1%   +0.86%  (p=0.032 n=5+5)
BM_StressTest/262144           553ns ± 1%   557ns ± 3%     ~     (p=0.548 n=5+5)
BM_StressTest/1048576          617ns ± 2%   616ns ± 2%     ~     (p=0.690 n=5+5)
BM_ContractEdge/1000           121ns ± 2%   104ns ± 6%  -13.56%  (p=0.008 n=5+5)
BM_ContractEdge/10000          147ns ± 1%   119ns ± 1%  -18.86%  (p=0.008 n=5+5)
BM_IsReachableNonConst/10     10.4ns ±35%   9.3ns ± 6%     ~     (p=0.310 n=5+5)
BM_IsReachableNonConst/50     15.8ns ±12%  15.4ns ±10%     ~     (p=0.841 n=5+5)
BM_IsReachableNonConst/100    17.4ns ± 6%  17.5ns ±13%     ~     (p=0.841 n=5+5)
BM_IsReachableNonConst/200    19.7ns ± 6%  19.5ns ± 6%     ~     (p=0.690 n=5+5)
BM_IsReachableNonConst/1000   25.2ns ± 4%  24.9ns ± 6%     ~     (p=0.690 n=5+5)
BM_IsReachableNonConst/30000  49.8ns ± 4%  44.3ns ± 5%  -10.98%  (p=0.008 n=5+5)

PiperOrigin-RevId: 618196781",Emilio Cota,ecg@google.com,2024-03-22 16:09:26,third_party/xla/xla/service/graphcycles/graphcycles.cc,cota,False
"Replace hard-failing CHECKs in triton emitter with TF_RET_CHECK, TF_RETURN_IF_ERROR, and the like.

PiperOrigin-RevId: 618195809",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 16:05:54,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/triton.cc, third_party/xla/xla/service/gpu/gemm_fusion.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.h, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.cc, third_party/xla/xla/service/gpu/ir_emitter_triton.h, third_party/xla/xla/service/gpu/matmul_utils.cc, third_party/xla/xla/service/gpu/matmul_utils.h, third_party/xla/xla/service/gpu/split_k_gemm_rewriter.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis.cc, third_party/xla/xla/service/gpu/triton_fusion_analysis.h",tensorflower-gardener,False
"[XLA] Add missing HTML stage from flag description.

PiperOrigin-RevId: 618194178",Greg Olechwierowicz,olechwierowicz@google.com,2024-03-22 16:00:23,third_party/xla/xla/tools/hlo_opt/opt_main.cc,golechwierowicz,False
"[xla:gpu][NFC] Documenting address_computation_fusion_rewriter

PiperOrigin-RevId: 618188208",Son Tuan Vu,vuson@google.com,2024-03-22 15:37:10,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc,tyb0807,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/7b008a767fce1d12c85f25772323ae0ee0bdc31c.

PiperOrigin-RevId: 618187987",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 15:36:18,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"`DCHECK_EQ(layout, layout_i)` will compare addresses of two pointers, we should compare values.

Also fixed some headers.

PiperOrigin-RevId: 618184954",Yue Sheng,yueshengys@google.com,2024-03-22 15:24:09,"third_party/xla/xla/python/pjrt_ifrt/BUILD, third_party/xla/xla/python/pjrt_ifrt/pjrt_array.cc",yueshengys,False
"[XLA:Python] Include missing nanobind std::set header.

Fixes a failure reported after the nanobind switch.

PiperOrigin-RevId: 618183044",Peter Hawkins,phawkins@google.com,2024-03-22 15:16:33,third_party/xla/xla/python/xla.cc,hawkinsp,False
"#shlo_ref Improve the `RandomBuffer` test helper.

PiperOrigin-RevId: 618179438",Quentin Khan,qkhan@google.com,2024-03-22 15:03:33,tensorflow/lite/experimental/shlo/ops/test_util.h,qukhan,False
"graphcycles: drop Vec<>; use std::vector instead

name                          old time/op  new time/op  delta
BM_StressTest/2048             487ns ± 1%   482ns ± 3%     ~     (p=0.310 n=5+5)
BM_StressTest/4096             498ns ± 2%   491ns ± 0%     ~     (p=0.111 n=5+4)
BM_StressTest/32768            523ns ± 1%   512ns ± 2%     ~     (p=0.056 n=5+5)
BM_StressTest/262144           613ns ± 5%   588ns ±11%     ~     (p=0.548 n=5+5)
BM_StressTest/1048576          758ns ± 3%   775ns ±26%     ~     (p=1.000 n=5+5)
BM_ContractEdge/1000           127ns ± 3%   121ns ± 5%     ~     (p=0.056 n=5+5)
BM_ContractEdge/10000          149ns ± 2%   146ns ± 1%   -1.47%  (p=0.032 n=5+5)
BM_IsReachableNonConst/10     12.1ns ± 9%  10.1ns ±11%  -16.69%  (p=0.016 n=5+5)
BM_IsReachableNonConst/50     20.6ns ±17%  14.7ns ±13%  -29.00%  (p=0.008 n=5+5)
BM_IsReachableNonConst/100    25.4ns ±20%  18.3ns ±13%  -27.98%  (p=0.008 n=5+5)
BM_IsReachableNonConst/200    30.6ns ±27%  20.1ns ± 6%  -34.35%  (p=0.008 n=5+5)
BM_IsReachableNonConst/1000   40.1ns ±27%  25.8ns ± 5%  -35.71%  (p=0.008 n=5+5)
BM_IsReachableNonConst/30000  67.1ns ± 2%  49.2ns ± 4%  -26.77%  (p=0.016 n=4+5)

PiperOrigin-RevId: 618179344",Emilio Cota,ecg@google.com,2024-03-22 15:03:18,third_party/xla/xla/service/graphcycles/graphcycles.cc,cota,False
"Integrate LLVM at llvm/llvm-project@de7a50fb88fa

Updates LLVM usage to match
[de7a50fb88fa](https://github.com/llvm/llvm-project/commit/de7a50fb88fa)

PiperOrigin-RevId: 618179147",Benjamin Kramer,kramerb@google.com,2024-03-22 15:02:38,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/experimental/tac/BUILD, tensorflow/compiler/mlir/quantization/common/ir/BUILD, tensorflow/compiler/mlir/tensorflow/transforms/BUILD, tensorflow/compiler/mlir/tfrt/BUILD, tensorflow/compiler/mlir/tfrt/ir/BUILD, tensorflow/compiler/mlir/tfrt/ir/mlrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/mlrt/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/BUILD, tensorflow/compiler/mlir/tools/kernel_gen/transforms/BUILD, tensorflow/dtensor/mlir/BUILD, third_party/llvm/workspace.bzl, third_party/triton/cl617812302.patch, third_party/triton/workspace.bzl, third_party/xla/third_party/triton/cl617812302.patch, third_party/xla/third_party/triton/workspace.bzl, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/BUILD, third_party/xla/xla/service/gpu/fusions/mlir/ir/BUILD",d0k,False
"Implement EmitReduceWindow in the new MLIR emitters

PiperOrigin-RevId: 618172208",Henning Becker,hebecker@google.com,2024-03-22 14:33:14,"third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir_test.cc, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc",beckerhe,False
"[XLA:Python] Fix build failures on Windows.

PiperOrigin-RevId: 618168554",Peter Hawkins,phawkins@google.com,2024-03-22 14:18:55,"third_party/xla/xla/python/ifrt_proxy/client/device.h, third_party/xla/xla/python/ifrt_proxy/client/memory.h, third_party/xla/xla/python/ifrt_proxy/server/host_callback.cc, third_party/xla/xla/python/py_client.cc",hawkinsp,False
"[XLA:GPU] Add MLIR-based DUS emitter.

PiperOrigin-RevId: 618166719",Son Tuan Vu,vuson@google.com,2024-03-22 14:09:01,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/fusions.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.cc, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir.h, third_party/xla/xla/service/gpu/fusions/in_place_dynamic_update_slice_mlir_test.cc",tyb0807,False
"PR #10519: [GPU] Upgrade cuDNN frontend to v1.2.0.

Imported from GitHub PR https://github.com/openxla/xla/pull/10519

This will for instance allow fusion of scalar constants.
Copybara import of the project:

--
4695023e035516db05b707d79409a60eba9f47f7 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Upgrade cuDNN frontend to v1.2.0.

Merging this change closes #10519

PiperOrigin-RevId: 618165755",Ilia Sergachev,isergachev@nvidia.com,2024-03-22 14:03:48,"tensorflow/workspace2.bzl, third_party/xla/workspace2.bzl",sergachev,False
"[XLA] Tiny fixes for indexing.md

PiperOrigin-RevId: 618162572",Tamás Danyluk,tdanyluk@google.com,2024-03-22 13:46:49,third_party/xla/docs/indexing.md,tdanyluk,False
"[xla:gpu][NFC] Simplify AddressComputationFusionRewriter::Run

PiperOrigin-RevId: 618160571",Son Tuan Vu,vuson@google.com,2024-03-22 13:36:10,third_party/xla/xla/service/gpu/address_computation_fusion_rewriter.cc,tyb0807,False
"[XLA:GPU][NFC] Remove unnecessary check in  MlirConcatenateFusion emitter

This is already checked at creation of the emitter.

PiperOrigin-RevId: 618153022",Son Tuan Vu,vuson@google.com,2024-03-22 13:00:01,"third_party/xla/xla/service/gpu/fusions/concatenate_mlir.cc, third_party/xla/xla/service/gpu/fusions/concatenate_mlir.h, third_party/xla/xla/service/gpu/fusions/fusions.cc",tyb0807,False
"Automated Code Change

PiperOrigin-RevId: 618144863",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 12:16:05,tensorflow/compiler/tf2xla/kernels/xla_call_module_loader.cc,tensorflower-gardener,False
"[XLA] [NFC] Don't use deprecated tsl Status helpers

PiperOrigin-RevId: 618138716",George Karpenkov,cheshire@google.com,2024-03-22 11:43:13,"third_party/xla/xla/BUILD, third_party/xla/xla/test_helpers.h",cheshire,False
"PR #10316: [NVIDIA GPU] Add a mechanism in GpuAsyncTracker to force delaying scheduling of an instruction.

Imported from GitHub PR https://github.com/openxla/xla/pull/10316

latency hiding scheduler has a property for each HloScheduleNode called SetForceDelay, setting this to true for a node will result in forcing LHS to ignore all cost info and schedule the instruction to the very beginning of the instruction sequence.
This is useful in manually enforcing an instruction to run before anything else in the scheduled graph.
Passes can set `should_force_delay` attribute in the GpuBackendConfig to instruct how this instruction will be scheduled. It's set to false by default.
An example usage:
```
original sequence:

allreduce-start
allreduce-done
add0, backend_config={should_force_delay=true}
add1

schedule after LHS:
add0, backend_config={should_force_delay=true}
allreduce-start
add1
allreduce-done
```
Copybara import of the project:

--
74267e60142c5161310580db5b760a3fe6d4f625 by TJ <tjx@nvidia.com>:

Add a mechanism in GpuAsyncTracker to force delaying scheduling
of an instruction.

--
0aac4cf8c42f2ca210450581f05239378d8a33c2 by TJ <tjx@nvidia.com>:

Fix failing backend config test

--
4deab8393ecb01ca010e0cf4ea30930ac448b815 by TJ <tjx@nvidia.com>:

Use force delay for windowed einsum loops

--
a1321e88fd336f83a4fcfcc89037b8d4a3d1903f by TJ <tjx@nvidia.com>:

Revert changes in gpu_windowed_einsum_handler, moving them to a separate
pr

--
86ffb97db8ce167438562f997316033b61316003 by TJ Xu <tjx@nvidia.com>:

Fix internal linter error

Merging this change closes #10316

PiperOrigin-RevId: 618138328",TJ Xu,tjx@nvidia.com,2024-03-22 11:40:45,"third_party/xla/xla/service/gpu/backend_configs.proto, third_party/xla/xla/service/gpu/backend_configs_test.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner_test.cc, third_party/xla/xla/service/gpu/gpu_hlo_schedule.cc, third_party/xla/xla/service/gpu/gpu_hlo_schedule_test.cc, third_party/xla/xla/service/xla_aot_compile_test_autotune_results.prototxt",Tixxx,False
"Automated Code Change

PiperOrigin-RevId: 618136248",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 11:30:26,"third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/coordination_service.cc, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/coordination_service.h, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/coordination_service_agent.cc, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/coordination_service_agent.h, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/coordination_service_agent_test.cc, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/coordination_service_rpc_handler.cc, third_party/xla/third_party/tsl/tsl/distributed_runtime/coordination/coordination_service_test.cc",tensorflower-gardener,False
"Do not fuse gelu into FP8 cublasLT matmul on CUDA versions less than 12.4.

This causes cublas LT to give an error in certain cases. Specially, it always causes an error on Ada and causes an error when fast accumulation is disabled on Hopper, at least in the cases I've tried. I am just disabling it in general for older CUDA versions in case there are other scenarios where it fails.

The issue actually only occurs on CUDA versions less than 12.3.2, but there is no good way of checking the patch version of CUDA, so I'm disabling it on CUDA versions less than 12.4. There is a CUBLAS_VER_PATCH with the patch version of cublas but this is undocumented so I'd rather not use it.

Thank you @philipphack and @artem-b for helping me debug this.

PiperOrigin-RevId: 618135629",Reed Wanderman-Milne,reedwm@google.com,2024-03-22 11:27:17,"third_party/xla/xla/service/gpu/gemm_rewriter.cc, third_party/xla/xla/service/gpu/tests/gemm_rewrite_test.cc",reedwm,False
"Automated Code Change

PiperOrigin-RevId: 618132891",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 11:12:21,"third_party/xla/xla/tsl/c/tsl_status.cc, third_party/xla/xla/tsl/c/tsl_status_internal.h",tensorflower-gardener,False
"PR #10724: [NVIDIA GPU] Fix crash in thunk lowering

Imported from GitHub PR https://github.com/openxla/xla/pull/10724

send and recv will have tuple as output shape, the tuple contains a token field, we only want to use the memory space of the first element in the tuple which is the actual data, not the token element.
Copybara import of the project:

--
89981b6576a22134831ddfc528fad900129d5058 by TJ <tjx@nvidia.com>:

fix crash in thunk lowering

Merging this change closes #10724

PiperOrigin-RevId: 618128910",TJ Xu,tjx@nvidia.com,2024-03-22 10:53:35,third_party/xla/xla/service/gpu/ir_emitter_unnested.cc,Tixxx,False
"Expose `.layout` on jax.Array. Also add checks in the AOT path to make sure that the input `Array`'s layout matches the layout given to `jax.jit`.

PiperOrigin-RevId: 618127324",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 10:45:15,"third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_client.pyi",tensorflower-gardener,False
"Experimental: Allow users to enable all features of default delegates in python

XNNPack is the only default delegate and this will allow users to benefit from all flag protected features. Other delegates can use this in the future.

PiperOrigin-RevId: 618111218",Alan Kelly,alankelly@google.com,2024-03-22 09:30:51,"RELEASE.md, tensorflow/lite/python/interpreter.py, tensorflow/lite/python/interpreter_wrapper/BUILD, tensorflow/lite/python/interpreter_wrapper/interpreter_wrapper.cc, tensorflow/lite/python/interpreter_wrapper/interpreter_wrapper.h, tensorflow/lite/python/interpreter_wrapper/interpreter_wrapper_pybind11.cc, tensorflow/tools/api/golden/v1/tensorflow.lite.-interpreter.pbtxt, tensorflow/tools/api/golden/v2/tensorflow.lite.-interpreter.pbtxt",alankelly,False
"[xla:gpu] Simplify the search for operand slices in DynamicAddressComputationFusion

PiperOrigin-RevId: 618110053",Son Tuan Vu,vuson@google.com,2024-03-22 09:24:59,"third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/custom.cc",tyb0807,False
"Update GraphDef version to 1809.

PiperOrigin-RevId: 618105375",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 09:02:20,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-03-22

PiperOrigin-RevId: 618105316",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 09:02:07,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"[xla:ffi] Refactor custom call tests to reduce code duplication

Move builder and module setup to test fixture constructor.
Extract 'module build & execute' code shared by most tests as fixture function.

PiperOrigin-RevId: 618101366",Adam Banaś,adambanas@google.com,2024-03-22 08:42:15,"third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/custom_call_test.cc",Adam-Banas,False
"Rollback of GpuTimer change

PiperOrigin-RevId: 618095643",Henning Becker,hebecker@google.com,2024-03-22 08:13:39,"third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_timer.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer.h, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel.cu.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel.h",beckerhe,False
"[xla:gpu] Support DUS in DynamicAddressComputationFusion

PiperOrigin-RevId: 618092070",Son Tuan Vu,vuson@google.com,2024-03-22 07:58:23,"third_party/xla/xla/service/gpu/fusions/address_computation_fusion_test.cc, third_party/xla/xla/service/gpu/fusions/custom.cc",tyb0807,False
"Merge pull request #63114 from tensorflow:SuryanarayanaY-patch-22

PiperOrigin-RevId: 618072710",TensorFlower Gardener,gardener@tensorflow.org,2024-03-22 06:35:34,"tensorflow/core/kernels/bincount_op.cc, tensorflow/core/ops/math_ops.cc",tensorflower-gardener,False
"Merge pull request #63950 from tensorflow:Update_BoundingBox_coordinates

PiperOrigin-RevId: 618072337",TensorFlower Gardener,gardener@tensorflow.org,2024-03-22 06:15:49,tensorflow/lite/kernels/detection_postprocess.cc,tensorflower-gardener,False
"Remove the `OpSet` alias in `mlir::quant` namespace.

It is defined in the `tensorflow::quantization::` namespace (as part of `QuantizationOptions` proto), but has been unexpectedly exposed under `mlir::quant` due to a `using` directive in `attrs_and_constraints.h`. Remove this exposure and use the one in the `tensorflow::quantization::`.

This change also fixes some include warnings along the way.

PiperOrigin-RevId: 618067952",Dan Suh,dansuh@google.com,2024-03-22 05:45:28,"tensorflow/compiler/mlir/quantization/common/attrs_and_constraints.h, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/passes/duplicate_shape_determining_constants.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_quantized_functions.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/insert_save_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/lift_quantizable_spots_as_functions.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/lift_quantizable_spots_as_functions_drq.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/merge_save_function_ops_to_main.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/optimize.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/passes.h, tensorflow/compiler/mlir/quantization/tensorflow/passes/prepare_lifting.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/prepare_quantize_drq.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/preprocess_op.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/quantize.cc, tensorflow/compiler/mlir/quantization/tensorflow/passes/quantize_composite_functions.cc",dansuh17,False
"PR #10811: Restore ReshapeDecomposer And LayoutNormalization Passes in GPU Compiler

Imported from GitHub PR https://github.com/openxla/xla/pull/10811

Restores individual ReshapeDecomposer and LayoutNormalization passes in the GPU compiler previously removed in #9852 and fixes failures in cudnn_norm_rewriter_test.cc.
Copybara import of the project:

--
52065712a6bd4f6bb874575d82b4d99b8f2d16dd by Philipp Hack <phack@nvidia.com>:

Restore ReshapeDecomposer and LayoutNormalization passes.

Merging this change closes #10811

PiperOrigin-RevId: 618059598",Philipp Hack,phack@nvidia.com,2024-03-22 04:55:33,third_party/xla/xla/service/gpu/gpu_compiler.cc,philipphack,False
"Merge pull request #64155 from Aloqeely:update-contributing-image

PiperOrigin-RevId: 618051554",TensorFlower Gardener,gardener@tensorflow.org,2024-03-22 04:28:55,CONTRIBUTING.md,tensorflower-gardener,False
"Expose `.layout` on jax.Array. Also add checks in the AOT path to make sure that the input `Array`'s layout matches the layout given to `jax.jit`.

PiperOrigin-RevId: 618050680",Yash Katariya,yashkatariya@google.com,2024-03-22 04:01:50,"third_party/xla/xla/python/py_array.cc, third_party/xla/xla/python/py_array.h, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_client.pyi",yashk2810,False
"Use a compact format for const ops in MLRT

PiperOrigin-RevId: 618012307",Kuangyuan Chen,chky@google.com,2024-03-22 00:36:26,"tensorflow/compiler/mlir/tfrt/ir/mlrt/tf_mlrt_ops.td, tensorflow/compiler/mlir/tfrt/tests/mlrt/inline.mlir, tensorflow/compiler/mlir/tfrt/tests/mlrt/tf_to_mlrt.mlir, tensorflow/compiler/mlir/tfrt/transforms/mlrt/BUILD, tensorflow/compiler/mlir/tfrt/transforms/mlrt/tf_to_mlrt.cc, tensorflow/core/tfrt/mlrt/kernel/BUILD, tensorflow/core/tfrt/mlrt/kernel/kernel.cc",cky9301,False
"Changes visibility for metrics_proto to public.

PiperOrigin-RevId: 618009221",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-22 00:21:28,third_party/xla/xla/service/BUILD,tensorflower-gardener,False
"Add missing includes and fix typo.

PiperOrigin-RevId: 618003369",Gunhyun Park,gunhyun@google.com,2024-03-21 23:56:10,"third_party/xla/xla/client/BUILD, third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder_test.cc",ghpvnist,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/71863e46b69913a87dc676428355d00fa717de8e.

PiperOrigin-RevId: 618003172",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 23:55:22,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"Implement `Permute`.

This change is turning the function originally defined in `fold_constant_transpose.cc` into a library API for more general usages.

PiperOrigin-RevId: 618000924",Dan Suh,dansuh@google.com,2024-03-21 23:44:47,"tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/cc/permutation.h, tensorflow/compiler/mlir/quantization/stablehlo/cc/permutation_test.cc, tensorflow/compiler/mlir/quantization/stablehlo/passes/fold_constant_transpose.cc",dansuh17,False
"Do not pack int4 values on the interpreter in PJRT.

The interpreter does not expect int4 values to be packed, so this fixes incorrect results when the interpreter is used and PJRT transfers int4 values to the device.

PiperOrigin-RevId: 618000661",Reed Wanderman-Milne,reedwm@google.com,2024-03-21 23:43:32,"third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/service/generic_transfer_manager.h, third_party/xla/xla/service/transfer_manager.h, third_party/xla/xla/stream_executor/tpu/tpu_transfer_manager_interface.h",reedwm,False
"Allow scheduling from the low priority tasks only which is padded to the allowed batch sizes in the low priority batch params

PiperOrigin-RevId: 618000151",Eunjae Kim,eunjaekim@google.com,2024-03-21 23:41:43,"tensorflow/core/kernels/batch_kernels_test.cc, tensorflow/core/kernels/batching_util/batch_resource_base.cc, tensorflow/core/kernels/batching_util/batch_resource_base.h, tensorflow/core/kernels/batching_util/shared_batch_scheduler.h, tensorflow/core/kernels/batching_util/shared_batch_scheduler_test.cc",eunjaekim-0,False
"Integrate LLVM at llvm/llvm-project@9fb85b099461

Updates LLVM usage to match
[9fb85b099461](https://github.com/llvm/llvm-project/commit/9fb85b099461)

PiperOrigin-RevId: 617993699",Augie Fackler,augie@google.com,2024-03-21 23:15:55,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl, third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/mlir_hlo/transforms/test_hlo_transform_dialect_interpreter.cc",durin42,False
"[XLA:Python] Add a C++ implementation of flatten_one_level.

Also add a copy of the default registry that doesn't have None registered as a leaf, which is slightly faster than using an is_leaf function.

This is mostly just doing an old TODO.

PiperOrigin-RevId: 617988496",Peter Hawkins,phawkins@google.com,2024-03-21 22:56:42,"third_party/xla/xla/python/pytree.cc, third_party/xla/xla/python/pytree.h, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_extension/pytree.pyi",hawkinsp,False
"Fix typo in compile_mlir_util deprecation description.

PiperOrigin-RevId: 617986722",Arturo Schmidt,arturoschmidt@google.com,2024-03-21 22:49:55,tensorflow/compiler/mlir/tf2xla/api/v1/compile_mlir_util.h,rocketas,False
"Adjust singleCompileOp to compile with old bridge.

PiperOrigin-RevId: 617975218",Arturo Schmidt,arturoschmidt@google.com,2024-03-21 22:06:40,tensorflow/compiler/tf2xla/xla_compiler.cc,rocketas,False
"Call unbounded broadcast only when necessary.

The scale of improvement is more apparent with shapes that have multiple unbounded sizes. Here's a before & after HLO for `add(f32[1,?,2,?,<=2,?,?], f32[?,1,?,2,?,<=2,?])` where implicit broadcasting is not necessary:

Before:
```
HloModule UnboundedBinaryOpTest_0.35, entry_computation_layout={(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0}, f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0})->f32[?,?,2,2,<=2,<=2,?]{6,5,4,3,2,1,0}}

ENTRY %UnboundedBinaryOpTest_0.35 (lhs.1: f32[1,?,2,?,<=2,?,?], rhs.2: f32[?,1,?,2,?,<=2,?]) -> f32[?,?,2,2,<=2,<=2,?] {
  %constant.3 = s32[1]{0} constant({1})
  %constant.16 = s32[1]{0} constant({1})
  %lhs.1 = f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} parameter(0)
  %constant.4 = s32[1]{0} constant({1})
  %get-dimension-size.5 = s32[] get-dimension-size(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} %lhs.1), dimensions={1}
  %reshape.6 = s32[1]{0} reshape(s32[] %get-dimension-size.5)
  %constant.7 = s32[1]{0} constant({2})
  %get-dimension-size.8 = s32[] get-dimension-size(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} %lhs.1), dimensions={3}
  %reshape.9 = s32[1]{0} reshape(s32[] %get-dimension-size.8)
  %get-dimension-size.10 = s32[] get-dimension-size(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} %lhs.1), dimensions={4}
  %reshape.11 = s32[1]{0} reshape(s32[] %get-dimension-size.10)
  %get-dimension-size.12 = s32[] get-dimension-size(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} %lhs.1), dimensions={5}
  %reshape.13 = s32[1]{0} reshape(s32[] %get-dimension-size.12)
  %get-dimension-size.14 = s32[] get-dimension-size(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} %lhs.1), dimensions={6}
  %reshape.15 = s32[1]{0} reshape(s32[] %get-dimension-size.14)
  %concatenate.29 = s32[7]{0} concatenate(s32[1]{0} %constant.4, s32[1]{0} %reshape.6, s32[1]{0} %constant.7, s32[1]{0} %reshape.9, s32[1]{0} %reshape.11, /*index=5*/s32[1]{0} %reshape.13, s32[1]{0} %reshape.15), dimensions={0}
  %rhs.2 = f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} parameter(1)
  %get-dimension-size.17 = s32[] get-dimension-size(f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} %rhs.2), dimensions={0}
  %reshape.18 = s32[1]{0} reshape(s32[] %get-dimension-size.17)
  %constant.19 = s32[1]{0} constant({1})
  %get-dimension-size.20 = s32[] get-dimension-size(f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} %rhs.2), dimensions={2}
  %reshape.21 = s32[1]{0} reshape(s32[] %get-dimension-size.20)
  %constant.22 = s32[1]{0} constant({2})
  %get-dimension-size.23 = s32[] get-dimension-size(f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} %rhs.2), dimensions={4}
  %reshape.24 = s32[1]{0} reshape(s32[] %get-dimension-size.23)
  %get-dimension-size.25 = s32[] get-dimension-size(f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} %rhs.2), dimensions={5}
  %reshape.26 = s32[1]{0} reshape(s32[] %get-dimension-size.25)
  %get-dimension-size.27 = s32[] get-dimension-size(f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} %rhs.2), dimensions={6}
  %reshape.28 = s32[1]{0} reshape(s32[] %get-dimension-size.27)
  %concatenate.30 = s32[7]{0} concatenate(s32[1]{0} %reshape.18, s32[1]{0} %constant.19, s32[1]{0} %reshape.21, s32[1]{0} %constant.22, s32[1]{0} %reshape.24, /*index=5*/s32[1]{0} %reshape.26, s32[1]{0} %reshape.28), dimensions={0}
  %maximum.31 = s32[7]{0} maximum(s32[7]{0} %concatenate.29, s32[7]{0} %concatenate.30)
  %custom-call.32 = f32[?,?,2,2,<=2,<=2,?]{6,5,4,3,2,1,0} custom-call(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} %lhs.1, s32[7]{0} %maximum.31), custom_call_target=""mhlo.dynamic_broadcast_in_dim"", backend_config={broadcast_dimensions=[0,1,2,3,4,5,6]}
  %custom-call.33 = f32[?,?,2,2,<=2,<=2,?]{6,5,4,3,2,1,0} custom-call(f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} %rhs.2, s32[7]{0} %maximum.31), custom_call_target=""mhlo.dynamic_broadcast_in_dim"", backend_config={broadcast_dimensions=[0,1,2,3,4,5,6]}
  ROOT %add.34 = f32[?,?,2,2,<=2,<=2,?]{6,5,4,3,2,1,0} add(f32[?,?,2,2,<=2,<=2,?]{6,5,4,3,2,1,0} %custom-call.32, f32[?,?,2,2,<=2,<=2,?]{6,5,4,3,2,1,0} %custom-call.33)
}
```

After:
```
HloModule UnboundedBinaryOpTest_0.4, entry_computation_layout={(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0}, f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0})->f32[?,?,2,2,<=2,<=2,?]{6,5,4,3,2,1,0}}

ENTRY %UnboundedBinaryOpTest_0.4 (lhs.1: f32[1,?,2,?,<=2,?,?], rhs.2: f32[?,1,?,2,?,<=2,?]) -> f32[?,?,2,2,<=2,<=2,?] {
  %lhs.1 = f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} parameter(0)
  %rhs.2 = f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} parameter(1)
  ROOT %add.3 = f32[?,?,2,2,<=2,<=2,?]{6,5,4,3,2,1,0} add(f32[1,?,2,?,<=2,?,?]{6,5,4,3,2,1,0} %lhs.1, f32[?,1,?,2,?,<=2,?]{6,5,4,3,2,1,0} %rhs.2)
}
```

PiperOrigin-RevId: 617973981",Gunhyun Park,gunhyun@google.com,2024-03-21 22:02:18,third_party/xla/xla/client/xla_builder.cc,ghpvnist,False
"Change pybind11_abseil `type_caster` `const_name` `Span` to `Sequence`.

PiperOrigin-RevId: 617961866",Ralf W. Grosse-Kunstleve,rwgk@google.com,2024-03-21 21:19:18,tensorflow/python/_pywrap_dtensor_device.pyi,rwgk,False
"Add a capacity check when scheduling a low priority task

PiperOrigin-RevId: 617961589",Eunjae Kim,eunjaekim@google.com,2024-03-21 21:18:22,"tensorflow/core/kernels/batch_kernels_test.cc, tensorflow/core/kernels/batching_util/BUILD, tensorflow/core/kernels/batching_util/batch_resource_base.cc, tensorflow/core/kernels/batching_util/shared_batch_scheduler.h, tensorflow/core/kernels/batching_util/shared_batch_scheduler_test.cc",eunjaekim-0,False
"Add unbounded dynamism test for for Atan2Op.

PiperOrigin-RevId: 617957700",Gunhyun Park,gunhyun@google.com,2024-03-21 21:05:12,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"[NFC] Spelling fix.

PiperOrigin-RevId: 617938324",Rahul Joshi,jurahul@google.com,2024-03-21 20:05:01,third_party/xla/xla/service/scatter_expander.cc,jurahul,False
"Add unbounded dynamism test for BitcastConvertOp.

PiperOrigin-RevId: 617934413",Gunhyun Park,gunhyun@google.com,2024-03-21 19:52:23,"third_party/xla/xla/client/xla_builder_test.cc, third_party/xla/xla/service/shape_inference_test.cc",ghpvnist,False
"Fix a bug in which an absl hashtable is used with inconsistent hash/eq functors.

`eq(k1, k2) -> hash(k1) == hash(k2)` must be true for hashtable usage to be valid.

PiperOrigin-RevId: 617929842",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 19:36:01,"third_party/xla/xla/BUILD, third_party/xla/xla/literal.h",tensorflower-gardener,False
"Update implicit broadcast output shape element type to match operand.

Some binary ops return types whose element type differs from the operand element types (e.g. Ne). While broadcasting, it should use the element type of the operand instead of the inferred type.

Before:
```
HloModule UnboundedBinaryOpTest_8.15, entry_computation_layout={(f32[?,10]{1,0}, f32[1]{0})->pred[?,10]{1,0}}

ENTRY %UnboundedBinaryOpTest_8.15 (lhs.1: f32[?,10], rhs.2: f32[1]) -> pred[?,10] {
  %constant.3 = s32[1]{0} constant({1})
  %lhs.1 = f32[?,10]{1,0} parameter(0)
  %get-dimension-size.4 = s32[] get-dimension-size(f32[?,10]{1,0} %lhs.1), dimensions={0}
  %reshape.5 = s32[1]{0} reshape(s32[] %get-dimension-size.4)
  %constant.6 = s32[1]{0} constant({10})
  %concatenate.9 = s32[2]{0} concatenate(s32[1]{0} %reshape.5, s32[1]{0} %constant.6), dimensions={0}
  %constant.7 = s32[1]{0} constant({1})
  %constant.8 = s32[1]{0} constant({1})
  %concatenate.10 = s32[2]{0} concatenate(s32[1]{0} %constant.7, s32[1]{0} %constant.8), dimensions={0}
  %maximum.11 = s32[2]{0} maximum(s32[2]{0} %concatenate.9, s32[2]{0} %concatenate.10)
  %custom-call.12 = pred[?,10]{1,0} custom-call(f32[?,10]{1,0} %lhs.1, s32[2]{0} %maximum.11), custom_call_target=""mhlo.dynamic_broadcast_in_dim"", backend_config={broadcast_dimensions=[0,1]}
  %rhs.2 = f32[1]{0} parameter(1)
  %custom-call.13 = pred[?,10]{1,0} custom-call(f32[1]{0} %rhs.2, s32[2]{0} %maximum.11), custom_call_target=""mhlo.dynamic_broadcast_in_dim"", backend_config={broadcast_dimensions=[1]}
  ROOT %compare.14 = pred[?,10]{1,0} compare(pred[?,10]{1,0} %custom-call.12, pred[?,10]{1,0} %custom-call.13), direction=NE
}
```

After:
```
HloModule UnboundedBinaryOpTest_8.15, entry_computation_layout={(f32[?,10]{1,0}, f32[1]{0})->pred[?,10]{1,0}}

ENTRY %UnboundedBinaryOpTest_8.15 (lhs.1: f32[?,10], rhs.2: f32[1]) -> pred[?,10] {
  %constant.3 = s32[1]{0} constant({1})
  %lhs.1 = f32[?,10]{1,0} parameter(0)
  %get-dimension-size.4 = s32[] get-dimension-size(f32[?,10]{1,0} %lhs.1), dimensions={0}
  %reshape.5 = s32[1]{0} reshape(s32[] %get-dimension-size.4)
  %constant.6 = s32[1]{0} constant({10})
  %concatenate.9 = s32[2]{0} concatenate(s32[1]{0} %reshape.5, s32[1]{0} %constant.6), dimensions={0}
  %constant.7 = s32[1]{0} constant({1})
  %constant.8 = s32[1]{0} constant({1})
  %concatenate.10 = s32[2]{0} concatenate(s32[1]{0} %constant.7, s32[1]{0} %constant.8), dimensions={0}
  %maximum.11 = s32[2]{0} maximum(s32[2]{0} %concatenate.9, s32[2]{0} %concatenate.10)
  %custom-call.12 = f32[?,10]{1,0} custom-call(f32[?,10]{1,0} %lhs.1, s32[2]{0} %maximum.11), custom_call_target=""mhlo.dynamic_broadcast_in_dim"", backend_config={broadcast_dimensions=[0,1]}
  %rhs.2 = f32[1]{0} parameter(1)
  %custom-call.13 = f32[?,10]{1,0} custom-call(f32[1]{0} %rhs.2, s32[2]{0} %maximum.11), custom_call_target=""mhlo.dynamic_broadcast_in_dim"", backend_config={broadcast_dimensions=[1]}
  ROOT %compare.14 = pred[?,10]{1,0} compare(f32[?,10]{1,0} %custom-call.12, f32[?,10]{1,0} %custom-call.13), direction=NE
}
```

Notice the difference in `mhlo.dynamic_broadcast_in_dim` custom call return type `pred[?,10]` vs `f32[?,10]`. The HLO after the change correctly returns unchanged element type from the operand.

PiperOrigin-RevId: 617921912",Gunhyun Park,gunhyun@google.com,2024-03-21 19:07:51,"third_party/xla/xla/client/xla_builder.cc, third_party/xla/xla/client/xla_builder_test.cc",ghpvnist,False
"No public change.

PiperOrigin-RevId: 617921687",Anurag Arnab,aarnab@google.com,2024-03-21 19:07:01,tensorflow/python/ops/BUILD,anuragarnab,False
"Update `Shape::Equals()` to have proper default comparison for unbounded shapes.

Previously, the default `Shape::Equals()` used `ShapeUtil::SameDimensions(lhs, rhs)` to check whether the two shapes are equal. However, the implementation of `ShapeUtil::SameDimensions()` was updated such that when one the dimension of one shape is unbounded, it compares equal for each dimension.

The default behavior should be that unbounded size compared to any size other than unbounded size should compare not equal.

PiperOrigin-RevId: 617921492",Gunhyun Park,gunhyun@google.com,2024-03-21 19:06:24,"third_party/xla/xla/shape.cc, third_party/xla/xla/shape_util_test.cc",ghpvnist,False
"Rename `TfLiteRegistrationExternal` as `TfLiteOperator`.
Likewise rename corresponding API functions (all experimental).
Rename (experimental) `TfLiteInterpreterOptionsAddRegistrationExternal` as `TfLiteInterpreterOptionsAddOperator`.
Rename (private) header registration_external.h as operator.h and
rename registration_external.cc as operator.cc.

Also add temporary backwards compatibility aliases that forward the old
names to the new names. These backwards compatibility aliases are needed
even though these names are experimental, because the old names are currently
referenced in MediaPipe, which is in a separate repository, and thus can't be
updated atomically.

PiperOrigin-RevId: 617909917",Fergus Henderson,fergus@google.com,2024-03-21 18:29:13,"RELEASE.md, tensorflow/lite/c/BUILD, tensorflow/lite/c/CMakeLists.txt, tensorflow/lite/c/c_api_internal.h, tensorflow/lite/c/c_api_opaque_internal.cc, tensorflow/lite/c/c_api_opaque_internal.h, tensorflow/lite/c/c_api_opaque_internal_test.cc, tensorflow/lite/c/common_internal.h, tensorflow/lite/core/api/op_resolver.h, tensorflow/lite/core/api/op_resolver_internal.h, tensorflow/lite/core/c/BUILD, tensorflow/lite/core/c/c_api.cc, tensorflow/lite/core/c/c_api.h, tensorflow/lite/core/c/c_api_experimental.cc, tensorflow/lite/core/c/c_api_experimental.h, tensorflow/lite/core/c/c_api_experimental_test.cc, tensorflow/lite/core/c/c_api_opaque.cc, tensorflow/lite/core/c/c_api_opaque.h, tensorflow/lite/core/c/c_api_opaque_test.cc, tensorflow/lite/core/c/c_api_test.cc, tensorflow/lite/core/c/common.h, tensorflow/lite/core/c/operator.cc, tensorflow/lite/core/c/operator.h, tensorflow/lite/core/c/registration_external.cc, tensorflow/lite/core/subgraph.cc, tensorflow/lite/core/subgraph.h, tensorflow/lite/delegates/delegate_test.cc, tensorflow/lite/delegates/opaque_delegate_test.cc, tensorflow/lite/delegates/utils/experimental/sample_stable_delegate/sample_stable_delegate.cc, tensorflow/lite/delegates/utils/experimental/sample_stable_delegate/sample_stable_delegate.h, tensorflow/lite/delegates/utils/experimental/sample_stable_delegate/sample_stable_delegate_with_control_flow.cc, tensorflow/lite/delegates/utils/experimental/sample_stable_delegate/sample_stable_delegate_with_control_flow.h, tensorflow/lite/delegates/utils/simple_opaque_delegate.cc, tensorflow/lite/delegates/utils/simple_opaque_delegate.h, tensorflow/lite/delegates/utils/simple_opaque_delegate_test.cc, tensorflow/lite/ios/BUILD.apple, tensorflow/lite/ios/TensorFlowLiteC.h, tensorflow/lite/mutable_op_resolver_utils.cc, tensorflow/lite/mutable_op_resolver_utils.h, tensorflow/lite/mutable_op_resolver_utils_test.cc, tensorflow/lite/objc/TensorFlowLiteObjC.podspec",fergushenderson,False
"Fix a bug where `PjRtStreamExecutorBuffer::CopyRawToHostFuture` causes a crash in GPUs

The current implementation of `PjRtStreamExecutorBuffer::CopyRawToHostFuture` calls `CopyRawToHost()` inside the `dst` future's OnReady callback. Since `PjRtFuture` invokes the callbacks inline in the context where the corresponding promise is set, this becomes a problem when the `dst` is fulfilled in the context of device buffer ready events, e.g., `stream_executor::gpu::GpuExecutor::InternalHostCallback()`.

This CL fixes the aforementioned issue by adding a trampoline thread before calling `CopyRawToHost()`, thus ensuring that `CopyRawToHost()` is called outside any callback context. The added test in `se_gpu_pjrt_client_test.cc` fails without this trampoline.

PiperOrigin-RevId: 617907276",Junwhan Ahn,junwhan@google.com,2024-03-21 18:21:07,"third_party/xla/xla/pjrt/gpu/BUILD, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc, third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",junwhanahn,False
"[xla:ffi] Improved fail messages for custom call tests

In case a custom call is not found, the tests now fail gracefully instead of crashing.

PiperOrigin-RevId: 617898636",Adam Banaś,adambanas@google.com,2024-03-21 17:55:23,"third_party/xla/xla/tests/BUILD, third_party/xla/xla/tests/custom_call_test.cc",Adam-Banas,False
"[PJRT][IFRT] Update PJRT, IFRT, and Py executable getters to return PjRtLayouts

PiperOrigin-RevId: 617889924",Yue Sheng,yueshengys@google.com,2024-03-21 17:30:09,"third_party/xla/xla/pjrt/BUILD, third_party/xla/xla/pjrt/pjrt_executable.cc, third_party/xla/xla/pjrt/pjrt_executable.h, third_party/xla/xla/python/ifrt/array.h, third_party/xla/xla/python/ifrt/executable.h, third_party/xla/xla/python/ifrt/mock.h, third_party/xla/xla/python/ifrt_proxy/client/BUILD, third_party/xla/xla/python/ifrt_proxy/client/executable.cc, third_party/xla/xla/python/ifrt_proxy/client/executable.h, third_party/xla/xla/python/ifrt_proxy/client/executable_test.cc, third_party/xla/xla/python/ifrt_proxy/server/BUILD, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc, third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend_test.cc, third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.h, third_party/xla/xla/python/py_executable.cc, third_party/xla/xla/python/py_executable.h, third_party/xla/xla/python/xla.cc, third_party/xla/xla/python/xla_client.py, third_party/xla/xla/python/xla_client_test.py",yueshengys,False
"Integrate CHLO->StableHLO lowerings in XLA

PiperOrigin-RevId: 617886759",Kevin Gleason,gleasonk@google.com,2024-03-21 17:21:18,"tensorflow/compiler/mlir/lite/stablehlo/BUILD, tensorflow/compiler/mlir/lite/stablehlo/transforms/tf_stablehlo_pass.cc, tensorflow/compiler/mlir/lite/tf_tfl_passes.cc, tensorflow/compiler/mlir/quantization/stablehlo/BUILD, tensorflow/compiler/mlir/quantization/stablehlo/passes/bridge/passes.cc, tensorflow/compiler/mlir/tf2xla/transforms/BUILD, tensorflow/compiler/mlir/tf2xla/transforms/xla_legalize_targets.cc, tensorflow/compiler/mlir/tf2xla/transforms/xla_legalize_tf.cc, tensorflow/compiler/mlir/tf2xla/transforms/xla_legalize_tf_passes.td, tensorflow/compiler/tf2xla/kernels/xla_call_module_loader.cc, third_party/stablehlo/temporary.patch, third_party/xla/third_party/stablehlo/temporary.patch, third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/mlir_hlo/mhlo/transforms/CMakeLists.txt, third_party/xla/xla/mlir_hlo/mhlo/transforms/chlo_legalize_to_hlo/chlo_legalize_to_hlo.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/chlo_legalize_to_hlo/chlo_legalize_to_hlo_pass.cc, third_party/xla/xla/mlir_hlo/mhlo/transforms/chlo_legalize_to_hlo/chlo_legalize_to_hlo_patterns.td, third_party/xla/xla/mlir_hlo/mhlo/transforms/mhlo_passes.td, third_party/xla/xla/mlir_hlo/mhlo/transforms/passes.h, third_party/xla/xla/mlir_hlo/mhlo/transforms/rewriters.h, third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_hlo_broadcasts.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_hlo_no_broadcasts.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_mhlo.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_mhlo_basis_ops.mlir, third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/lower-complex.mlir, third_party/xla/xla/pjrt/mlir_to_hlo.cc",GleasonK,False
"graphcycles_test: add BM_IsReachableNonConst

name                          time/op
BM_StressTest/2048             489ns ± 5%
BM_StressTest/4096             501ns ± 6%
BM_StressTest/32768            521ns ± 4%
BM_StressTest/262144           575ns ±11%
BM_StressTest/1048576          614ns ± 2%
BM_ContractEdge/1000           129ns ± 2%
BM_ContractEdge/10000          148ns ± 1%
BM_IsReachableNonConst/10     12.2ns ± 7%
BM_IsReachableNonConst/50     19.9ns ±14%
BM_IsReachableNonConst/100    24.7ns ± 7%
BM_IsReachableNonConst/200    26.3ns ± 3%
BM_IsReachableNonConst/1000   37.3ns ± 5%
BM_IsReachableNonConst/30000  66.4ns ± 3%

PiperOrigin-RevId: 617886294",Emilio Cota,ecg@google.com,2024-03-21 17:19:55,"third_party/xla/xla/service/graphcycles/BUILD, third_party/xla/xla/service/graphcycles/graphcycles_test.cc",cota,False
"Rename `DequantizeOpQuantizePerChannel` to `DequantizeOpQuantizePerAxis`.

PiperOrigin-RevId: 617878310",Quentin Khan,qkhan@google.com,2024-03-21 16:59:36,tensorflow/lite/experimental/shlo/ops/unary_elementwise.h,qukhan,False
"Ignore nested tuples, if present, during post processing.

This is a hack for some cases (specifically observed for the llama and gemma models) where nested tuples as used as inputs/outputs of the kOptimizationBarrier instruction.

PiperOrigin-RevId: 617866604",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 16:23:28,third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc,tensorflower-gardener,False
"Merge pull request #64021 from RoboSchmied:patch-1

PiperOrigin-RevId: 617859532",TensorFlower Gardener,gardener@tensorflow.org,2024-03-21 16:25:27,tensorflow/core/lib/png/png_io.h,tensorflower-gardener,False
"graphcycles_test: use batch mode in benchmarks

So that results are easier to interpret and compare.

Before:
----------------------------------------------------------------
Benchmark                      Time             CPU   Iterations
----------------------------------------------------------------
BM_StressTest/2048        989074 ns       988955 ns          707
BM_StressTest/4096       2043829 ns      2043653 ns          346
BM_StressTest/32768     17073324 ns     17071023 ns           40
BM_StressTest/262144   152278792 ns    152251000 ns            4
BM_StressTest/1048576 1403662723 ns   1397561773 ns            1
BM_ContractEdge/1000      122874 ns       122842 ns         5702
BM_ContractEdge/10000    1471461 ns      1471153 ns          477

After:
----------------------------------------------------------------
Benchmark                      Time             CPU   Iterations
----------------------------------------------------------------
BM_StressTest/2048           482 ns          482 ns      1394688
BM_StressTest/4096           494 ns          494 ns      1409024
BM_StressTest/32768          546 ns          546 ns      1409024
BM_StressTest/262144         568 ns          568 ns      1310720
BM_StressTest/1048576       1176 ns         1176 ns      1048576
BM_ContractEdge/1000         130 ns          130 ns      5271000
BM_ContractEdge/10000        150 ns          150 ns      4680000
PiperOrigin-RevId: 617853860",Emilio Cota,ecg@google.com,2024-03-21 15:38:28,third_party/xla/xla/service/graphcycles/graphcycles_test.cc,cota,False
"Simplify indexing maps with mod constraints for symbols/dims

PiperOrigin-RevId: 617853049",Sergey Kozub,sergeykozub@google.com,2024-03-21 15:35:28,"third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",sergeykozub,False
"Bugfix, nit: do not use designated initializers for aggregate initialization.

PiperOrigin-RevId: 617848873",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 15:19:19,third_party/xla/xla/python/ifrt_proxy/client/compiler.cc,tensorflower-gardener,False
"[xla][gpu] Preserve a frontend attribute for runtime optimization when
decomposing a CollectivePermute with a cycle.

The frontend attribute annotates a range of runtime execution instances where
each source-target pair is communicating data that affects the outcome of the
application. As such, when we split the source-target pairs for the decomposed
CollectivePermute, we also need to split the corresponding bounds represented
by the frontend attribute.

Modify two existing tests.

PiperOrigin-RevId: 617846437",Bixia Zheng,bixia@google.com,2024-03-21 15:09:53,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/collective_permute_cycle_decomposer.cc, third_party/xla/xla/service/gpu/collective_permute_cycle_decomposer_test.cc",bixia1,False
"Fix for tuples inside loops in LayoutAssignment

PiperOrigin-RevId: 617838261",George Karpenkov,cheshire@google.com,2024-03-21 14:36:55,"third_party/xla/xla/service/layout_assignment.cc, third_party/xla/xla/service/layout_assignment_test.cc",cheshire,False
"Address some ClangTidy warnings.

PiperOrigin-RevId: 617832727",Fergus Henderson,fergus@google.com,2024-03-21 14:13:32,"tensorflow/lite/c/c_api_opaque_internal.cc, tensorflow/lite/core/c/BUILD, tensorflow/lite/core/c/c_api_test.cc, tensorflow/lite/core/c/registration_external.cc, tensorflow/lite/delegates/BUILD, tensorflow/lite/delegates/opaque_delegate_test.cc",fergushenderson,False
"Make EmitReduce use indexing maps

All index calculation are now performed by the new indexing maps
which makes the implementation of `EmitReduce` quite a bit simpler.

PiperOrigin-RevId: 617828935",Henning Becker,hebecker@google.com,2024-03-21 13:56:18,"third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.cc, third_party/xla/xla/service/gpu/fusions/mlir/elemental_hlo_to_mlir.h",beckerhe,False
"The value of 'num_results_' in XlaCompiledCpuFunction::StaticData was previously unset, so XlaCompiledCpuFunction::num_results() would always return 0.
This is an issue with code that relies on the XlaCompiledCpuFunction interface rather than the ProgramShape proto.

PiperOrigin-RevId: 617827439",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 13:49:26,"tensorflow/compiler/tf2xla/BUILD, tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.cc, tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function_test.cc",tensorflower-gardener,False
"[xla:gpu][NFC] Simplify HloPredicateIsOp

PiperOrigin-RevId: 617817125",Son Tuan Vu,vuson@google.com,2024-03-21 13:00:01,third_party/xla/xla/hlo/ir/hlo_instruction.h,tyb0807,False
"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/3192a484ad8453b5f6f1227b35b91235045569c4.

PiperOrigin-RevId: 617815258",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 12:49:51,"third_party/tf_runtime/workspace.bzl, third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",tensorflower-gardener,False
"[IndexAnalysis] Use mlir::AffineMap instead of IndexingMap for RTVars.

If we want to compose the indexing map within RTVar with the indexing map of `hlo` that it is associated with, we can just construct an indexing map using the domain of the IndexingMap to which the RTVar belongs to.

PiperOrigin-RevId: 617809869",Alexander Belyaev,pifon@google.com,2024-03-21 12:22:29,"third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc, third_party/xla/xla/service/gpu/model/indexing_context.cc, third_party/xla/xla/service/gpu/model/indexing_context.h, third_party/xla/xla/service/gpu/model/indexing_map.cc, third_party/xla/xla/service/gpu/model/indexing_map.h, third_party/xla/xla/service/gpu/model/indexing_map_test.cc",pifon2a,False
"Integrate LLVM at llvm/llvm-project@407937036fa7

Updates LLVM usage to match
[407937036fa7](https://github.com/llvm/llvm-project/commit/407937036fa7)

PiperOrigin-RevId: 617807327",Benjamin Kramer,kramerb@google.com,2024-03-21 12:08:30,"third_party/llvm/generated.patch, third_party/llvm/workspace.bzl",d0k,False
"Migrate `UniformSupport*` and `FakeQuantSupport*` components from `lite` directory.

* Uses namespaces rather than `using-directives`.
* Cleans up header imports.

PiperOrigin-RevId: 617798874",Jiyoun (Jen) Ha,jiyounha@google.com,2024-03-21 11:23:58,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/lite/quantization/ir/BUILD, tensorflow/compiler/mlir/lite/quantization/ir/ConvertConst.cc, tensorflow/compiler/mlir/lite/quantization/ir/ConvertSimQuant.cc, tensorflow/compiler/mlir/lite/quantization/ir/QuantizeUtils.cc, tensorflow/compiler/mlir/lite/quantization/lite/BUILD, tensorflow/compiler/mlir/lite/transforms/default_quant_params.cc, tensorflow/compiler/mlir/lite/transforms/legalize_tf.cc, tensorflow/compiler/mlir/lite/transforms/prepare_quantize.cc, tensorflow/compiler/mlir/lite/transforms/prepare_quantize_helper.h, tensorflow/compiler/mlir/lite/transforms/prepare_tf.cc, tensorflow/compiler/mlir/quantization/common/ir/BUILD, tensorflow/compiler/mlir/quantization/common/ir/FakeQuantSupport.cc, tensorflow/compiler/mlir/quantization/common/ir/FakeQuantSupport.h, tensorflow/compiler/mlir/quantization/common/ir/UniformSupport.cc, tensorflow/compiler/mlir/quantization/common/ir/UniformSupport.h, tensorflow/compiler/mlir/quantization/common/quantization_lib/BUILD, tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.cc, tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.h, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/passes/prepare_quantize.cc",chococigar,False
Update lifetime of a PR diagram image,Abdulaziz Aloqeely,52792999+Aloqeely@users.noreply.github.com,2024-03-21 11:45:51,CONTRIBUTING.md,Aloqeely,True
"[XLA:GPU] Move helper to set target tile sizes with default offsets and strides.

PiperOrigin-RevId: 617796445",Oleg Shyshkov,shyshkov@google.com,2024-03-21 11:10:47,"third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h, third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc",olegshyshkov,False
"Update documentation for using custom ops to recommend using the
stable custom ops API.

PiperOrigin-RevId: 617793327",Fergus Henderson,fergus@google.com,2024-03-21 10:58:24,tensorflow/lite/g3doc/guide/ops_custom.md,fergushenderson,False
"Allow Shardonnay to use XLA targets.

PiperOrigin-RevId: 617790756",Bart Chrzaszcz,bartchr@google.com,2024-03-21 10:47:38,third_party/xla/xla/BUILD,bartchr808,False
"Add tflite_disable_mobile_test tag to mutable_op_resolver_utils_test.

PiperOrigin-RevId: 617788624",Fergus Henderson,fergus@google.com,2024-03-21 10:38:23,tensorflow/lite/BUILD,fergushenderson,False
"PR #10685: [ROCM] GPU profiling code refactor - seperarted rocm event tracer and…

Imported from GitHub PR https://github.com/openxla/xla/pull/10685

rocm profiler code refactored, Separated tracing and event collecting into rocm tracer (rocm_tracer.cc/h) and event collector (rocm_collector.cc/h).
Copybara import of the project:

--
9ada3c5629c208de530cf88beb934f401c8d99be by zahiqbal <zahid.iqbal@amd.com>:

[ROCM] GPU profiling code refactor - seperarted rocm event tracer and event collector.

Merging this change closes #10685

PiperOrigin-RevId: 617785573",zahiqbal,zahid.iqbal@amd.com,2024-03-21 10:26:59,"third_party/xla/xla/backends/profiler/gpu/BUILD, third_party/xla/xla/backends/profiler/gpu/device_tracer_rocm.cc, third_party/xla/xla/backends/profiler/gpu/rocm_collector.cc, third_party/xla/xla/backends/profiler/gpu/rocm_collector.h, third_party/xla/xla/backends/profiler/gpu/rocm_tracer.cc, third_party/xla/xla/backends/profiler/gpu/rocm_tracer.h",zahiqbal,False
"Also verify whether instructions are allowed to change layouts.

If a test provides a instruction_can_change_layout_func, we should also use it
for the HloVerifier created inside the VerifiedHloModule.
Doing this exposed a bug in algebraic_simplifier where a simplification didn't
check whether it is running in layout sensitive mode (since it doesn't handle
layouts in any way, it should not be used in layout sensitive mode).
Also adjust HloVerifier to be not as strict regarding tiling and memory space
to make a test pass.

PiperOrigin-RevId: 617784203",Adrian Kuegel,akuegel@google.com,2024-03-21 10:20:39,"third_party/xla/xla/service/algebraic_simplifier.cc, third_party/xla/xla/service/algebraic_simplifier_test.cc, third_party/xla/xla/service/hlo_verifier.cc, third_party/xla/xla/tests/hlo_test_base.cc, third_party/xla/xla/tests/hlo_test_base.h, third_party/xla/xla/tests/verified_hlo_module.h",akuegel,False
"Explicitly depend on MLIR interface targets.

Preparation for https://github.com/llvm/llvm-project/pull/85867.

PiperOrigin-RevId: 617781882",Christian Sigg,csigg@google.com,2024-03-21 10:10:36,"tensorflow/compiler/mlir/lite/BUILD, tensorflow/compiler/mlir/quantization/common/ir/BUILD, tensorflow/compiler/mlir/quantization/tensorflow/BUILD, tensorflow/compiler/mlir/tensorflow/BUILD, tensorflow/compiler/mlir/tfrt/ir/BUILD, tensorflow/core/ir/BUILD, third_party/xla/xla/mlir/runtime/ir/BUILD, third_party/xla/xla/mlir_hlo/BUILD, third_party/xla/xla/python/ifrt/ir/BUILD, third_party/xla/xla/translate/hlo_to_mhlo/BUILD",chsigg,False
"Update GraphDef version to 1808.

PiperOrigin-RevId: 617768132",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 09:03:04,tensorflow/core/public/version.h,tensorflower-gardener,False
"compat: Update forward compatibility horizon to 2024-03-21

PiperOrigin-RevId: 617768081",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 09:02:54,tensorflow/python/compat/compat.py,tensorflower-gardener,False
"[XLA:GPU][IndexAnalysis] Add indexing map for gather.

PiperOrigin-RevId: 617767558",Alexander Belyaev,pifon@google.com,2024-03-21 09:00:27,"third_party/xla/xla/service/gather_simplifier.cc, third_party/xla/xla/service/gather_simplifier.h, third_party/xla/xla/service/gpu/model/BUILD, third_party/xla/xla/service/gpu/model/indexing_analysis.cc, third_party/xla/xla/service/gpu/model/indexing_analysis_test.cc",pifon2a,False
"Reland of GpuTimer: improve kernel execution time measurement accuracy

Some production workloads show drastically increased latency. The log shows many instance of this message:

```
Delay kernel timed out: measured time has sub-optimal accuracy.
There may be a missing warmup execution, please investigate in Nsight Systems.
```

PiperOrigin-RevId: 617765839",Henning Becker,hebecker@google.com,2024-03-21 08:50:54,"third_party/xla/xla/service/gpu/conv_algorithm_picker.cc, third_party/xla/xla/service/gpu/gemm_algorithm_picker.cc, third_party/xla/xla/stream_executor/gpu/BUILD, third_party/xla/xla/stream_executor/gpu/gpu_timer.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer.h, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel.cu.cc, third_party/xla/xla/stream_executor/gpu/gpu_timer_kernel.h",beckerhe,False
"Add checks for output file size ratio in the integration tests

PiperOrigin-RevId: 617764047",Doyeon Kim,doyeonkim@google.com,2024-03-21 08:41:28,"tensorflow/compiler/mlir/quantization/common/python/testing.py, tensorflow/compiler/mlir/quantization/common/python/testing_test.py, tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test.py, tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test_base.py",doyeonkim0,False
"Integrate Triton up to [92ac0aad](https://github.com/openai/triton/commits/92ac0aade352d7be626e8c608331ddebfe5f6fb2)

PiperOrigin-RevId: 617761210",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 08:28:15,"third_party/triton/workspace.bzl, third_party/xla/third_party/triton/workspace.bzl",tensorflower-gardener,False
"Fix JAX PjRT Clients using XLA pins from 12/2023.

PiperOrigin-RevId: 617727497",Kevin Gleason,gleasonk@google.com,2024-03-21 05:19:43,"third_party/xla/xla/pjrt/mlir_to_hlo.cc, third_party/xla/xla/pjrt/mlir_to_hlo.h, third_party/xla/xla/pjrt/pjrt_c_api_client.cc",GleasonK,False
"Add `gpu_h100` backend to the `tf_xla_py_test` build macro.

PiperOrigin-RevId: 617727265",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 05:18:22,"tensorflow/compiler/tests/BUILD, tensorflow/compiler/tests/build_defs.bzl",tensorflower-gardener,False
"Change flat_hash_map to vector to have deterministic order while unrolling.

PiperOrigin-RevId: 617714545",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 04:02:44,"third_party/xla/xla/service/BUILD, third_party/xla/xla/service/while_loop_unroller.cc, third_party/xla/xla/service/while_loop_unroller.h, third_party/xla/xla/service/while_loop_unroller_test.cc",tensorflower-gardener,False
"PR #10730: [GPU] Reorganize compilation of cuDNN fusions.

Imported from GitHub PR https://github.com/openxla/xla/pull/10730

As discussed recently this moves compiled cuDNN graphs from HLO attributes to a separate structure passed to GPU executable.

cuDNN backend is now explicitly disabled in deviceless compilation mode - in the GEMM fusion autotuner pass and in the GPU compiler.
Copybara import of the project:

--
e25ae7343bf08a88b0e917a10267d644dabde2d3 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Reorganize compilation of cuDNN fusions.

Merging this change closes #10730

PiperOrigin-RevId: 617692885",Ilia Sergachev,isergachev@nvidia.com,2024-03-21 02:16:34,"third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/backend_configs.proto, third_party/xla/xla/service/gpu/cudnn_fusion_compiler.cc, third_party/xla/xla/service/gpu/cudnn_fusion_compiler.h, third_party/xla/xla/service/gpu/executable.proto, third_party/xla/xla/service/gpu/fusions/BUILD, third_party/xla/xla/service/gpu/fusions/cudnn.cc, third_party/xla/xla/service/gpu/gemm_fusion_autotuner.cc, third_party/xla/xla/service/gpu/gpu_compiler.cc, third_party/xla/xla/service/gpu/gpu_compiler.h, third_party/xla/xla/service/gpu/gpu_executable.cc, third_party/xla/xla/service/gpu/gpu_executable.h, third_party/xla/xla/service/gpu/nvptx_compiler.cc, third_party/xla/xla/service/gpu/runtime/cudnn_thunk.cc, third_party/xla/xla/service/gpu/runtime/cudnn_thunk.h, third_party/xla/xla/service/gpu/thunk.h",sergachev,False
"Create new PjRt GPU client with remote devices after coordination service agent is available

This does not modify the previous PjRt GPU client. The test environment case where multiple threads are used to simulate multiple workers is supported.

For the PjRt GPU MultiWorkerMirroredStrategy (MWMS) case where there are multiple workers each with a GPU or GPUs, the symptom of a client without this fix is a error message like the following where the number at the end is the ID of the first remote device, e.g. 8 when there are eight local GPUs with IDs 0..7. (Another example is 1 when there is one local GPU with ID 0.)
`INVALID_ARGUMENT: No matching device found for device_id 8`

Note that while the primary purpose of `BaseGPUDeviceFactory::CreateDevices` is to do one-time initialization, it is often called multiple times. In the typical production MWMS case, it is called both when creating a TF Context and when creating GRPC servers when enabling collectives. In the unit test added by this CL (which uses two GPUs), it is first called when a TF Context is created when starting up the test environment (with both GPUS) and then two worker TF processes are created which both call it twice during MWMS startup (each with the one GPU assigned to the process). Other test cases have different patterns.

PiperOrigin-RevId: 617685758",Edward Schwartz,schwartzedward@google.com,2024-03-21 01:42:18,"tensorflow/core/common_runtime/eager/BUILD, tensorflow/core/common_runtime/eager/context_distributed_manager.cc, tensorflow/core/common_runtime/gpu/gpu_device.cc, tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc, tensorflow/core/tfrt/common/BUILD, tensorflow/core/tfrt/common/pjrt_state.cc, tensorflow/core/tfrt/common/pjrt_state.h, tensorflow/core/tfrt/common/pjrt_util.cc, tensorflow/core/tfrt/common/pjrt_util.h, tensorflow/python/distribute/BUILD, tensorflow/python/distribute/mwms_pjrt_gpu_test.py, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc, third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h",SeeForTwo,False
"Minor changes that help debugability:
1. Cast the printed memory budget into double to make it easy to compare it with the estimated minumum memory required, and thereby easy to compare.
2. Guard some checks when computing the memory lower bound within vlogs as the checks are often slow.
3. Increase the VLOG level for printing the memory usage of the solution as computing this also often takes a while.

PiperOrigin-RevId: 617677396",A. Unique TensorFlower,gardener@tensorflow.org,2024-03-21 01:01:43,"third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc, third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_solver.cc",tensorflower-gardener,False
"[xla:gpu] Enable command buffers for FFI handlers registered as compatible

PiperOrigin-RevId: 617673413",Eugene Zhulenev,ezhulenev@google.com,2024-03-21 00:40:50,"third_party/xla/xla/ffi/ffi_api.cc, third_party/xla/xla/ffi/ffi_api.h, third_party/xla/xla/service/gpu/BUILD, third_party/xla/xla/service/gpu/command_buffer_scheduling.cc",ezhulenev,False
"#tf-data Fix global shuffling for shard dataset.

The issue is similar to batching without dropping remainders:
The input dataset may return `end_of_sequence` in the middle
of its output since the index is shuffled.

For example, without fix, when shuffling
```
range(10).shard(3, 0)
```
The range dataset could return `end_of_sequence` after producing
9.

This CL fixes the index mapper for `shard` so no skipping is
needed for global shuffling.

PiperOrigin-RevId: 617670463",Yang Chen,yangchen@google.com,2024-03-21 00:27:36,"tensorflow/core/kernels/data/BUILD, tensorflow/core/kernels/data/shard_dataset_op.cc, tensorflow/python/data/experimental/kernel_tests/BUILD, tensorflow/python/data/experimental/kernel_tests/auto_shard_dataset_test.py, tensorflow/python/data/kernel_tests/shard_test.py",yangustc07,False
